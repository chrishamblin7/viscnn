{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate mds projections of nodes layerwise, as determined by their per category rank scores\n",
    "#os.chdir('/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prep_model_scripts/')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./'))\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "sys.path.insert(0, os.path.abspath('../visualizer_scripts/'))\n",
    "\n",
    "\n",
    "os.chdir('../')\n",
    "from prep_model_parameters import output_folder\n",
    "from visualizer_helper_functions import rank_file_2_df\n",
    "os.chdir('./prep_model_scripts')\n",
    "\n",
    "print('generating mds projection of nodes')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "\n",
    "categories_nodes_df = pd.read_csv('../prepped_models/%s/ranks/categories_nodes_ranks.csv'%output_folder)\n",
    "overall_edge_df = rank_file_2_df('../prepped_models/%s/ranks/categories_edges/overall_edges_rank.pt'%output_folder)\n",
    "\n",
    "misc_data = pickle.load(open('../prepped_models/%s/misc_graph_data.pkl'%output_folder,'rb'))\n",
    "layer_nodes = misc_data['layer_nodes']\n",
    "num_layers = misc_data['num_layers']\n",
    "num_nodes = misc_data['num_nodes']\n",
    "categories = misc_data['categories']\n",
    "num_img_chan = misc_data['num_img_chan']\n",
    "imgnode_positions = misc_data['imgnode_positions']\n",
    "imgnode_colors = misc_data['imgnode_colors']\n",
    "imgnode_names = misc_data['imgnode_names']\n",
    "\n",
    "\n",
    "#make wide version of nodes_df\n",
    "def get_col(node_num, df = categories_nodes_df, idx = 'node_num', col = 'layer'):\n",
    "    return df.loc[(df[idx] == node_num) & (df['category'] == df['category'].unique()[0]), col].item()\n",
    "\n",
    "def add_norm_col(df,categories=categories[1:]):\n",
    "    norms = []\n",
    "    for index, row in df.iterrows():\n",
    "        norm = 0\n",
    "        for category in categories:\n",
    "            norm += row[category]**2\n",
    "        norm = np.sqrt(norm)\n",
    "        norms.append(norm)\n",
    "    norms = np.array(norms)\n",
    "    df['category_norm'] = norms\n",
    "    return df\n",
    "\n",
    "def gen_wide_df(rank_type,df=categories_nodes_df):\n",
    "    print('making wide version of df')\n",
    "    nodes_wide_df = df.pivot(index = 'node_num',columns='category', values=rank_type)\n",
    "    nodes_wide_df.reset_index(inplace=True)\n",
    "    #nodes_wide_df = nodes_wide_df.drop(['overall'], axis=1)\n",
    "    nodes_wide_df['layer'] = nodes_wide_df['node_num'].apply(get_col)  #SLOOOOOOWWWWWWW\n",
    "    nodes_wide_df = nodes_wide_df.rename(columns = {'category':'index'})\n",
    "    nodes_wide_df = add_norm_col(nodes_wide_df) \n",
    "    return nodes_wide_df\n",
    "\n",
    "#rotation for mds plots\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "\n",
    "def rotate_cartesian(vec2d,r):    #rotates 2d cartesian coordinates by some radians \n",
    "    x,y = vec2d[0], vec2d[1]\n",
    "    x_out = np.sqrt(x**2+y**2)*np.cos(np.arctan2(y,x)+r)\n",
    "    y_out = np.sqrt(x**2+y**2)*np.sin(np.arctan2(y,x)+r)\n",
    "    return np.array([x_out,y_out])\n",
    "\n",
    "def rotate_mds(layer_mds,rank_type,imgnode_positions=imgnode_positions,max_edges = 40,angles_tested=64):\n",
    "    print('rotating layers to minimize edge lengths')\n",
    "    for layer in range(len(layer_mds)):\n",
    "        all_layer_positions = layer_mds[layer]\n",
    "        layer_df = overall_edge_df.loc[(overall_edge_df['layer']==layer)].sort_values(rank_type+'_rank',ascending=False).head(max_edges)\n",
    "        if layer == 0:\n",
    "            all_prev_layer_positions = np.swapaxes(np.array([imgnode_positions['Y'],imgnode_positions['Z']]),0,1)\n",
    "        else:\n",
    "            all_prev_layer_positions = layer_mds[layer-1]\n",
    "        #gen positions matrix for important edges\n",
    "        select_layer_positions = []\n",
    "        select_prev_layer_positions = []\n",
    "        for row in layer_df.itertuples():\n",
    "            select_layer_positions.append(all_layer_positions[row.out_channel])\n",
    "            select_prev_layer_positions.append(all_prev_layer_positions[row.in_channel])\n",
    "        #go through discrete rotations and find min distance\n",
    "        min_dist = 10000000\n",
    "        min_discrete_angle = 0\n",
    "        for p in range(0,angles_tested):\n",
    "            test_layer_positions=np.apply_along_axis(rotate_cartesian, 1, select_layer_positions,r=p*2*np.pi/angles_tested)\n",
    "            dist = sum(np.diagonal(cdist(test_layer_positions,select_prev_layer_positions)))\n",
    "            if dist < min_dist:\n",
    "                min_discrete_angle = p\n",
    "                min_dist = dist\n",
    "        #update layer mds at layer by rotating by optimal angle\n",
    "        print('rotating layer %s by %s rads'%(str(layer),str(min_discrete_angle*2*np.pi/angles_tested)))\n",
    "        layer_mds[layer] = np.apply_along_axis(rotate_cartesian, 1, layer_mds[layer],r=min_discrete_angle*2*np.pi/angles_tested)\n",
    "    return layer_mds \n",
    "\n",
    "\n",
    "def gen_layer_projections(nodes_df=categories_nodes_df,projections=['mds','pca']):\n",
    "    mds_projections ={}\n",
    "    for rank_type in ['actxgrad','act','grad']:\n",
    "        nodes_wide_df = gen_wide_df(rank_type+'_rank',df=nodes_df)\n",
    "        layer_similarities = {}\n",
    "        for layer in range(len(layer_nodes)):\n",
    "            layer_df = nodes_wide_df[nodes_wide_df['layer'] == layer]\n",
    "            for category in categories:\n",
    "                layer_df[category] = layer_df.apply(lambda row : row[category]/row['category_norm'], axis = 1)   \n",
    "            layer_similarities[layer] = euclidean_distances(layer_df.iloc[:,1:-2])\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        layer_mds = {}\n",
    "        for layer in layer_similarities:\n",
    "            print('layer: %s'%str(layer))\n",
    "            mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, \n",
    "              random_state=2, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "            pos = mds.fit(layer_similarities[layer]).embedding_\n",
    "            layer_mds[layer] = pos\n",
    "        layer_mds = rotate_mds(layer_mds,rank_type)\n",
    "        mds_projections[rank_type] = layer_mds\n",
    "    return mds_projections\n",
    "\n",
    "\n",
    "#grid layer projection\n",
    "\n",
    "def gen_grid_positions():\n",
    "    grid_projections = {}\n",
    "    for layer in range(len(layer_nodes)):\n",
    "        grid_projections[layer] = []\n",
    "        num_nodes = len(layer_nodes[layer][1])\n",
    "        if num_nodes == 1:\n",
    "            grid_projections[layer] = np.array([[0,0]])\n",
    "            continue\n",
    "        elif num_nodes == 2:\n",
    "            grid_projections[layer] = np.array([[.1,0],\n",
    "                                                [-.1,0]])\n",
    "            continue\n",
    "        elif num_nodes == 3:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [0,0],\n",
    "                                                [-.1,-.1]])\n",
    "            continue\n",
    "        elif num_nodes == 4:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [-.1,.1],\n",
    "                                                [.1,-.1],\n",
    "                                                [-.1,-.1]])\n",
    "            continue\n",
    "        elif num_nodes == 5:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [-.1,.1],\n",
    "                                                [0,0],\n",
    "                                                [.1,-.1],\n",
    "                                                [-.1,-.1]])\n",
    "            continue\n",
    "        elif num_nodes == 6:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [0,.1],\n",
    "                                                [-.1,.1],\n",
    "                                                [.1,-.1],\n",
    "                                                [0,-.1],\n",
    "                                                [-.1,-.1]])\n",
    "            continue\n",
    "        elif num_nodes == 7:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [0,.1],\n",
    "                                                [-.1,.1],\n",
    "                                                [0,0],\n",
    "                                                [.1,-.1],\n",
    "                                                [0,-.1],\n",
    "                                                [-.1,-.1]])\n",
    "            continue\n",
    "        elif num_nodes == 8:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [0,.1],\n",
    "                                                [-.1,.1],\n",
    "                                                [-.1,0],\n",
    "                                                [.1,0],\n",
    "                                                [.1,-.1],\n",
    "                                                [0,-.1],\n",
    "                                                [-.1,-.1]])  \n",
    "            continue\n",
    "        elif num_nodes == 9:\n",
    "            grid_projections[layer] = np.array([[.1,.1],\n",
    "                                                [0,.1],\n",
    "                                                [-.1,.1],\n",
    "                                                [-.1,0],\n",
    "                                                [0,0],\n",
    "                                                [.1,0],\n",
    "                                                [.1,-.1],\n",
    "                                                [0,-.1],\n",
    "                                                [-.1,-.1]]) \n",
    "            continue\n",
    "            \n",
    "        elif num_nodes < 20:\n",
    "            max_dis = .2\n",
    "        elif num_nodes < 40:\n",
    "            max_dis = .3\n",
    "        elif num_nodes < 60:\n",
    "            max_dis = .4\n",
    "        elif num_nodes < 80:\n",
    "            max_dis = .5\n",
    "        elif num_nodes < 100:\n",
    "            max_dis = .6\n",
    "        elif num_nodes < 120:\n",
    "            max_dis = .7\n",
    "        elif num_nodes < 140:\n",
    "            max_dis = .8\n",
    "        else:\n",
    "            max_dis = 1\n",
    "        if np.floor(np.sqrt(num_nodes))*np.ceil(np.sqrt(num_nodes)) < num_nodes:\n",
    "            x_spaces, y_spaces = np.ceil(np.sqrt(num_nodes)),np.ceil(np.sqrt(num_nodes))\n",
    "        else:\n",
    "            x_spaces, y_spaces = np.floor(np.sqrt(num_nodes)),np.ceil(np.sqrt(num_nodes))\n",
    "        x = np.linspace(max_dis,-1*max_dis,int(x_spaces))\n",
    "        y = np.linspace(max_dis,-1*max_dis,int(y_spaces))\n",
    "        X,Y = np.meshgrid(x,y)\n",
    "        X_flat = [item for sublist in X for item in sublist]\n",
    "        Y_flat = [item for sublist in Y for item in sublist]\n",
    "        for i in range(num_nodes):\n",
    "            grid_projections[layer].append([X_flat[i],Y_flat[i]])    \n",
    "        grid_projections[layer] = np.array(grid_projections[layer])\n",
    "    return grid_projections\n",
    "\n",
    "\n",
    "def format_node_positions(projection='MDS',rank_type = 'actxgrad'):\n",
    "    layer_distance = 1   # distance in X direction each layer is separated by\n",
    "    node_positions = []\n",
    "    layer_offset = 0\n",
    "    if projection == 'MDS':\n",
    "        unformatted = all_node_positions_unformatted['MDS'][rank_type]\n",
    "    else:\n",
    "        unformatted = all_node_positions_unformatted['Grid']\n",
    "    for layer in unformatted:\n",
    "        node_positions.append({})\n",
    "        node_positions[-1]['X'] = [] \n",
    "        node_positions[-1]['Y'] = [] \n",
    "        node_positions[-1]['Z'] = []  \n",
    "        for i in range(len(unformatted[layer])): \n",
    "            node_positions[-1]['Y'].append(unformatted[layer][i][0])\n",
    "            node_positions[-1]['Z'].append(unformatted[layer][i][1])\n",
    "            node_positions[-1]['X'].append(layer_offset)\n",
    "        layer_offset+=1*layer_distance\n",
    "    return node_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=categories_nodes_df\n",
    "rank_type = 'act_rank'\n",
    "nodes_wide_df = df.pivot(index = 'node_num',columns='category', values=rank_type)\n",
    "nodes_wide_df = nodes_wide_df.drop(['overall'], axis=1)\n",
    "nodes_wide_df.reset_index(inplace=True)\n",
    "nodes_wide_df['layer'] = nodes_wide_df['node_num'].apply(get_col)\n",
    "nodes_wide_df = nodes_wide_df.rename(columns = {'category':'index'})\n",
    "nodes_wide_df = add_norm_col(nodes_wide_df) \n",
    "\n",
    "nodes_wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_norms = np.array(nodes_wide_df['category_norm'])\n",
    "np.array(nodes_wide_df['category_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_wide_df['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "layer_df = nodes_wide_df[nodes_wide_df['layer'] == layer]\n",
    "\n",
    "layer_similarities = {}\n",
    "\n",
    "#categories_no_overall = deepcopy(categories)\n",
    "#categories_no_overall.remove('overall')\n",
    "\n",
    "for category in categories[1:]:\n",
    "        layer_df[category] = layer_df.apply(lambda row : row[category]/row['category_norm'], axis = 1) \n",
    "layer_similarities[layer] = euclidean_distances(layer_df.iloc[:,1:-2])       \n",
    " \n",
    "    \n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, \n",
    "               random_state=2, dissimilarity=\"precomputed\", n_jobs=1)    \n",
    "pos = mds.fit(layer_similarities[layer]).embedding_\n",
    "\n",
    "# def gen_layer_projections(nodes_df=categories_nodes_df,projections=['mds','pca']):\n",
    "#     mds_projections ={}\n",
    "#     for rank_type in ['actxgrad','act','grad']:\n",
    "#         nodes_wide_df = gen_wide_df(rank_type+'_rank',df=nodes_df)\n",
    "#         layer_similarities = {}\n",
    "#         for layer in range(len(layer_nodes)):\n",
    "#             layer_df = nodes_wide_df[nodes_wide_df['layer'] == layer]\n",
    "#             for category in categories:\n",
    "#                 layer_df[category] = layer_df.apply(lambda row : row[category]/row['category_norm'], axis = 1)   \n",
    "#             layer_similarities[layer] = euclidean_distances(layer_df.iloc[:,1:-2])\n",
    "#             import pdb; pdb.set_trace()\n",
    "\n",
    "#         layer_mds = {}\n",
    "#         for layer in layer_similarities:\n",
    "#             print('layer: %s'%str(layer))\n",
    "#             mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, \n",
    "#               random_state=2, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "#             pos = mds.fit(layer_similarities[layer]).embedding_\n",
    "#             layer_mds[layer] = pos\n",
    "#         layer_mds = rotate_mds(layer_mds,rank_type)\n",
    "#         mds_projections[rank_type] = layer_mds\n",
    "#     return mds_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "smooth_positions = pickle.load(open('/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prepped_models/alexnet/node_positions.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_pos = smooth_positions['MDS']['actxgrad'][3]\n",
    "smooth_pos = np.column_stack((smooth_pos['Y'],smooth_pos['Z'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth_pos.shape\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissim_list(matrix):\n",
    "    dis_matrix = euclidean_distances(matrix)\n",
    "    length = dis_matrix.shape[0]\n",
    "    return list(dis_matrix[np.triu_indices(length, k = 1)])\n",
    "    \n",
    "\n",
    "#smooth_pos_dis = dissim_list(smooth_pos)\n",
    "#pos_dis = dissim_list(pos)\n",
    "#print(euclidean_distances(smooth_pos))\n",
    "#smooth_pos_dis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=smooth_pos_dis, xbins=dict(start=np.min(smooth_pos_dis), size=0.01, end=np.max(smooth_pos_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smooth histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=smooth_pos_dis, xbins=dict(start=np.min(smooth_pos_dis), size=0.01, end=np.max(smooth_pos_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smooth histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=smooth_pos_dis, xbins=dict(start=np.min(smooth_pos_dis), size=0.01, end=np.max(smooth_pos_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smooth histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=pos_dis, xbins=dict(start=np.min(pos_dis), size=0.01, end=np.max(pos_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"unsmooth histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=pos_dis, xbins=dict(start=np.min(pos_dis), size=0.01, end=np.max(pos_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"unsmooth histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_function(dis_list, a = .6):\n",
    "    return [x**a for x in dis_list]\n",
    "\n",
    "pos_dis_smoothed = smoothing_function(pos_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objs as go\n",
    "#generate a perfectly smooth circular distribution\n",
    "\n",
    "x = [.05*i for i in range(20)]\n",
    "y = [-i for i in x]\n",
    "x = x+y\n",
    "\n",
    "l = []\n",
    "\n",
    "#make square\n",
    "for i in x:\n",
    "    for j in x:\n",
    "        l.append([i,j])  \n",
    "        \n",
    "print(len(l))\n",
    "#print(l)\n",
    "#make circle\n",
    "for _ in range(10):\n",
    "    for p in l:\n",
    "        if np.sqrt(p[0]**2+p[1]**2) > 1:\n",
    "            l.remove(p)\n",
    "\n",
    "\n",
    "print(len(l))\n",
    "#print(l)\n",
    "perf_smooth = np.array(l)\n",
    "\n",
    "#print(perf_smooth)\n",
    "perf_smooth_dis = dissim_list(perf_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_smooth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(data=go.Scatter(x=perf_smooth[:,0], y=perf_smooth[:,1], mode='markers'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=perf_smooth_dis, xbins=dict(start=np.min(perf_smooth_dis), size=0.05, end=np.max(perf_smooth_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smoothed histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=perf_smooth_dis, xbins=dict(start=np.min(perf_smooth_dis), size=0.05, end=np.max(perf_smooth_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smoothed histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=perf_smooth_dis, xbins=dict(start=np.min(perf_smooth_dis), size=0.01, end=np.max(perf_smooth_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smoothed histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=perf_smooth_dis, xbins=dict(start=np.min(perf_smooth_dis), size=0.01, end=np.max(perf_smooth_dis)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smoothed histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Histogram(x=pos_dis_smoothed, xbins=dict(start=np.min(pos_dis_smoothed), size=0.01, end=np.max(pos_dis_smoothed)),\n",
    "                   marker=dict(color='rgb(0, 0, 100)'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"smoothed histogram\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=go.Data([trace]), layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2 = np.swapaxes(pos2,0,1)\n",
    "\n",
    "pos2 = pos2+.4\n",
    "pos3 = np.concatenate((pos,pos2),axis=1)\n",
    "pos3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "\n",
    "n_neighbors = 10\n",
    "n_components = 2\n",
    "\n",
    "LLE = partial(manifold.LocallyLinearEmbedding,\n",
    "              n_neighbors, n_components, eigen_solver='auto')\n",
    "\n",
    "methods = OrderedDict()\n",
    "methods['LLE'] = LLE(method='standard')\n",
    "#methods['LTSA'] = LLE(method='ltsa')\n",
    "#methods['Hessian LLE'] = LLE(method='hessian')\n",
    "methods['Modified LLE'] = LLE(method='modified')\n",
    "methods['Isomap'] = manifold.Isomap(n_neighbors, n_components)\n",
    "methods['MDS'] = manifold.MDS(n_components, max_iter=1000, n_init=1)\n",
    "methods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n",
    "                                           n_neighbors=n_neighbors)\n",
    "methods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n",
    "                                 random_state=0)\n",
    "methods['fa'] = FactorAnalysis(n_components = n_components)\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "fig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n",
    "             % (1000, n_neighbors), fontsize=14)\n",
    "\n",
    "# Add 3d scatter plot\n",
    "#ax = fig.add_subplot(251, projection='3d')\n",
    "#ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "#ax.view_init(4, -72)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(layer_df.iloc[:,1:-2])\n",
    "\n",
    "# Plot results\n",
    "for i, (label, method) in enumerate(methods.items()):\n",
    "\n",
    "    t0 = time()\n",
    "    Y = method.fit_transform(X)\n",
    "    t1 = time()\n",
    "    print(\"%s: %.2g sec\" % (label, t1 - t0))\n",
    "    ax = fig.add_subplot(2, 6, 2 + i + (i > 3))\n",
    "    ax.scatter(Y[:, 0], Y[:, 1],c=color[:384], cmap=plt.cm.Spectral)\n",
    "    ax.set_title(\"%s (%.2g sec)\" % (label, t1 - t0))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')\n",
    "    \n",
    "\n",
    "Y = pos\n",
    "ax = fig.add_subplot(2, 6, 2 + 9 + (9 > 3))\n",
    "ax.scatter(Y[:, 0], Y[:, 1],c=color[:384], cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"euclidean MDS\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#l1_data_transformed = fa.fit_transform(l1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "\n",
    "n_neighbors = 10\n",
    "n_components = 2\n",
    "\n",
    "LLE = partial(manifold.LocallyLinearEmbedding,\n",
    "              n_neighbors, n_components, eigen_solver='auto')\n",
    "\n",
    "methods = OrderedDict()\n",
    "methods['LLE'] = LLE(method='standard')\n",
    "#methods['LTSA'] = LLE(method='ltsa')\n",
    "methods['Hessian LLE'] = LLE(method='hessian')\n",
    "methods['Modified LLE'] = LLE(method='modified')\n",
    "methods['Isomap'] = manifold.Isomap(n_neighbors, n_components)\n",
    "methods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
    "methods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n",
    "                                           n_neighbors=n_neighbors)\n",
    "methods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n",
    "                                 random_state=0)\n",
    "methods['fa'] = FactorAnalysis(n_components = n_components)\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "fig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n",
    "             % (1000, n_neighbors), fontsize=14)\n",
    "\n",
    "# Add 3d scatter plot\n",
    "#ax = fig.add_subplot(251, projection='3d')\n",
    "#ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "#ax.view_init(4, -72)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(layer_df.iloc[:,1:-2])\n",
    "\n",
    "# Plot results\n",
    "for i, (label, method) in enumerate(methods.items()):\n",
    "    t0 = time()\n",
    "    Y = method.fit_transform(X)\n",
    "    t1 = time()\n",
    "    print(\"%s: %.2g sec\" % (label, t1 - t0))\n",
    "    ax = fig.add_subplot(2, 6, 2 + i + (i > 3))\n",
    "    ax.scatter(Y[:, 0], Y[:, 1],c=color[:384], cmap=plt.cm.Spectral)\n",
    "    ax.set_title(\"%s (%.2g sec)\" % (label, t1 - t0))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')\n",
    "\n",
    "\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#l1_data_transformed = fa.fit_transform(l1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jake Vanderplas -- <vanderplas@astro.washington.edu>\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "# Next line to silence pyflakes. This import is needed.\n",
    "Axes3D\n",
    "\n",
    "n_points = 1000\n",
    "X, color = datasets.make_s_curve(n_points, random_state=0)\n",
    "n_neighbors = 10\n",
    "n_components = 2\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "fig.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n",
    "             % (1000, n_neighbors), fontsize=14)\n",
    "\n",
    "# Add 3d scatter plot\n",
    "ax = fig.add_subplot(251, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "ax.view_init(4, -72)\n",
    "\n",
    "# Set-up manifold methods\n",
    "LLE = partial(manifold.LocallyLinearEmbedding,\n",
    "              n_neighbors, n_components, eigen_solver='auto')\n",
    "\n",
    "methods = OrderedDict()\n",
    "methods['LLE'] = LLE(method='standard')\n",
    "methods['LTSA'] = LLE(method='ltsa')\n",
    "methods['Hessian LLE'] = LLE(method='hessian')\n",
    "methods['Modified LLE'] = LLE(method='modified')\n",
    "methods['Isomap'] = manifold.Isomap(n_neighbors, n_components)\n",
    "methods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
    "methods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n",
    "                                           n_neighbors=n_neighbors)\n",
    "methods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n",
    "                                 random_state=0)\n",
    "\n",
    "# Plot results\n",
    "for i, (label, method) in enumerate(methods.items()):\n",
    "    t0 = time()\n",
    "    Y = method.fit_transform(X)\n",
    "    t1 = time()\n",
    "    print(\"%s: %.2g sec\" % (label, t1 - t0))\n",
    "    ax = fig.add_subplot(2, 5, 2 + i + (i > 3))\n",
    "    ax.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "    ax.set_title(\"%s (%.2g sec)\" % (label, t1 - t0))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(x=l1_data_transformed[:,0],y=l1_data_transformed[:,1],\n",
    "                 color_discrete_sequence= px.colors.sequential.Plasma_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=l1_data_transformed[:,0],y=l1_data_transformed[:,1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=l1_data_transformed[:,0],y=l1_data_transformed[:,1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(x=l1_data_transformed[:,0],y=l1_data_transformed[:,1])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "print(X.shape)\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "pca.fit(X)\n",
    "\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n",
    "\n",
    "#pca = PCA(n_components=1, svd_solver='arpack')\n",
    "#pca.fit(X)\n",
    "#PCA(n_components=1, svd_solver='arpack')\n",
    "\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#print(pca.singular_values_)\n",
    "\n",
    "\n",
    "Y=pca.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(x=X[:,0],y=X[:,1])\n",
    "fig.show()\n",
    "\n",
    "fig2= px.scatter(x=Y[:,0],y=Y[:,1])\n",
    "fig2.show()\n",
    "#print(X)\n",
    "#X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes_wide_df = add_norm_col(nodes_wide_df)\n",
    "list(nodes_wide_df[nodes_wide_df['layer'] == 0]['category_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_projections = gen_grid_positions()       \n",
    "mds_projections = gen_layer_projections()\n",
    "all_node_positions_unformatted = {'MDS':mds_projections,'Grid':grid_projections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_node_positions_formatted = {'MDS':{}}\n",
    "for rank_type in ['actxgrad','act','grad']:\n",
    "    all_node_positions_formatted['MDS'][rank_type] =  format_node_positions(projection = 'MDS',rank_type = rank_type) \n",
    "all_node_positions_formatted['Grid'] = format_node_positions(projection = 'Grid') \n",
    "\n",
    "\n",
    "pickle.dump(all_node_positions_formatted, open('../prepped_models/%s/node_positions_2.pkl'%output_folder,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import FFTKDE\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Generate a distribution and draw 2**6 data points\n",
    "dist = norm(loc=0, scale=1)\n",
    "data = dist.rvs(2**6)\n",
    "\n",
    "# Compute kernel density estimate on a grid using Silverman's rule for bw\n",
    "x, y1 = FFTKDE(bw=\"silverman\").fit(data).evaluate(2**10)\n",
    "\n",
    "# Compute a weighted estimate on the same grid, using verbose API\n",
    "weights = np.arange(len(data)) + 1\n",
    "estimator = FFTKDE(kernel='biweight', bw='silverman')\n",
    "y2 = estimator.fit(data, weights=weights).evaluate(x)\n",
    "\n",
    "plt.plot(x, y1, label='KDE estimate with defaults')\n",
    "plt.plot(x, y2, label='KDE estimate with verbose API')\n",
    "plt.plot(x, dist.pdf(x), label='True distribution')\n",
    "plt.grid(True, ls='--', zorder=-15); plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import FFTKDE\n",
    "\n",
    "# Create 2D data of shape (obs, dims)\n",
    "data = np.random.randn(2**4, 2)\n",
    "\n",
    "grid_points = 2**7  # Grid points in each dimension\n",
    "N = 16  # Number of contours\n",
    "\n",
    "for plt_num, norm in enumerate([1, 2, np.inf], 1):\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, plt_num)\n",
    "    ax.set_title(f'Norm $p={norm}$')\n",
    "\n",
    "    # Compute the kernel density estimate\n",
    "    kde = FFTKDE(kernel='box', norm=norm)\n",
    "    grid, points = kde.fit(data).evaluate(grid_points)\n",
    "\n",
    "    # The grid is of shape (obs, dims), points are of shape (obs, 1)\n",
    "    x, y = np.unique(grid[:, 0]), np.unique(grid[:, 1])\n",
    "    z = points.reshape(grid_points, grid_points).T\n",
    "\n",
    "    # Plot the kernel density estimate\n",
    "    ax.contour(x, y, z, N, linewidths=0.8, colors='k')\n",
    "    ax.contourf(x, y, z, N, cmap=\"RdBu_r\")\n",
    "    ax.plot(data[:, 0], data[:, 1], 'ok', ms=3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import FFTKDE\n",
    "data = np.random.randn(2**6)\n",
    "\n",
    "# Notice how bw (standard deviation), kernel, weights and grid points are set\n",
    "x, y = FFTKDE(bw=1, kernel='gaussian').fit(data, weights=None).evaluate(2**8)\n",
    "\n",
    "plt.plot(x, y); plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import FFTKDE\n",
    "data = np.exp(np.random.randn(2**6))  # Lognormal data\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for plt_num, kernel in enumerate(['box', 'biweight', 'gaussian'], 1):\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, plt_num)\n",
    "    ax.set_title(f'Kernel: \"{kernel}\"')\n",
    "    x, y = FFTKDE(kernel=kernel, bw='silverman').fit(data).evaluate()\n",
    "    ax.plot(x, y)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "from KDEpy import FFTKDE\n",
    "\n",
    "# Create 2D data of shape (obs, dims)\n",
    "data = np.random.randn(2**4, 2)\n",
    "#data = pos\n",
    "\n",
    "grid_points = 2**7  # Grid points in each dimension\n",
    "N = 16  # Number of contours\n",
    "\n",
    "for plt_num, norm in enumerate([1, 2, np.inf], 1):\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, plt_num)\n",
    "    ax.set_title(f'Norm $p={norm}$')\n",
    "\n",
    "    # Compute the kernel density estimate\n",
    "    kde = FFTKDE(kernel='box', norm=norm)\n",
    "    grid, points = kde.fit(data).evaluate(grid_points)\n",
    "\n",
    "    # The grid is of shape (obs, dims), points are of shape (obs, 1)\n",
    "    x, y = np.unique(grid[:, 0]), np.unique(grid[:, 1])\n",
    "    z = points.reshape(grid_points, grid_points).T\n",
    "\n",
    "    # Plot the kernel density estimate\n",
    "    ax.contour(x, y, z, N, linewidths=0.8, colors='k')\n",
    "    ax.contourf(x, y, z, N, cmap=\"RdBu_r\")\n",
    "    ax.plot(data[:, 0], data[:, 1], 'ok', ms=3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import NaiveKDE\n",
    "\n",
    "x, y = NaiveKDE(bw=np.mean(layer_similarities[layer])).fit(pos).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_similarities[layer].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(layer_similarities[layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "# Create 2D data of shape (obs, dims)\n",
    "data_samp = np.random.randn(2**4, 2)\n",
    "# data = pos\n",
    "\n",
    "# grid_points = 2**7  # Grid points in each dimension\n",
    "# N = 16  # Number of contours\n",
    "\n",
    "\n",
    "\n",
    "#     # Compute the kernel density estimate\n",
    "#     kde = FFTKDE(kernel='box', norm=norm)\n",
    "#     grid, points = kde.fit(data).evaluate(grid_points)\n",
    "\n",
    "#     # The grid is of shape (obs, dims), points are of shape (obs, 1)\n",
    "#     x, y = np.unique(grid[:, 0]), np.unique(grid[:, 1])\n",
    "#     z = points.reshape(grid_points, grid_points).T\n",
    "\n",
    "#     # Plot the kernel density estimate\n",
    "#     ax.contour(x, y, z, N, linewidths=0.8, colors='k')\n",
    "#     ax.contourf(x, y, z, N, cmap=\"RdBu_r\")\n",
    "#     ax.plot(data[:, 0], data[:, 1], 'ok', ms=3)\n",
    "\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp = np.random.randn(2**4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def measure(n):\n",
    "    \"Measurement model, return two coupled measurements.\"\n",
    "    m1 = np.random.normal(size=n)\n",
    "    m2 = np.random.normal(scale=0.5, size=n)\n",
    "    return m1+m2, m1-m2\n",
    "\n",
    "m1, m2 = measure(2000)\n",
    "xmin = m1.min()\n",
    "xmax = m1.max()\n",
    "ymin = m2.min()\n",
    "ymax = m2.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "values = np.vstack([m1, m2])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel(positions).T, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "          extent=[xmin, xmax, ymin, ymax])\n",
    "ax.plot(m1, m2, 'k.', markersize=2)\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.shape\n",
    "pos = np.swapaxes(pos,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos.shape\n",
    "from scipy import stats\n",
    "xmin = pos[0,:].min()\n",
    "xmax = pos[0,:].max()\n",
    "ymin = pos[1,:].min()\n",
    "ymax = pos[1,:].max()\n",
    "\n",
    "\n",
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "kernel = stats.gaussian_kde(pos, bw_method=.2)\n",
    "Z = np.reshape(kernel(positions).T, X.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "          extent=[xmin, xmax, ymin, ymax])\n",
    "ax.plot(pos[0,:], pos[1,:], 'k.', markersize=2)\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.shape\n",
    "\n",
    "def gussian_gradient_field(points,sigma = .3, ):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = np.arange(-10, 10, 1)\n",
    "Y = np.arange(-10, 10, 1)\n",
    "U, V = np.meshgrid(X, Y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V)\n",
    "ax.quiverkey(q, X=0.3, Y=1.1, U=10,\n",
    "             label='Quiver key, length = 10', labelpos='E')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "#Gaussian force field\n",
    "\n",
    "variance = .2\n",
    "sigma = math.sqrt(variance)\n",
    "mu = 0\n",
    "\n",
    "X = np.arange(-2, 2, .1)\n",
    "Y = np.arange(-2, 2, .1)\n",
    "listU = []\n",
    "listV = []\n",
    "for x in X:\n",
    "    listU.append([])\n",
    "    listV.append([])\n",
    "    for y in Y:\n",
    "        listV[-1].append(x/sigma*np.e**(-(x**2+y**2))/sigma+(x-1.6)/sigma*np.e**(-((x-1.6)**2+(y-1.6)**2)/sigma))\n",
    "        listU[-1].append(y/sigma*np.e**(-(x**2+y**2))/sigma+(y-1.6)/sigma*np.e**(-((x-1.6)**2+(y-1.6)**2)/sigma))\n",
    "\n",
    "U = np.array(listU)\n",
    "V = np.array(listV)\n",
    "        \n",
    "#U, V = np.meshgrid(-X/sigma*np.e**((X**2+Y**2)/sigma), -Y/sigma*np.e**((X**2+Y**2)/sigma))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "q = ax.quiver(X, Y, U, V)\n",
    "ax.quiverkey(q, X=0.3, Y=1.1, U=10,\n",
    "             label='Quiver key, length = 10', labelpos='E')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pos[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pos\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "distances = euclidean_distances(points)\n",
    "print(time.time()-start)\n",
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear force field\n",
    "import time\n",
    "\n",
    "#center of mass\n",
    "def points_2_com(points):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs center of mass as np.array([dim1,dim2, . . . ])\n",
    "    outlist = []\n",
    "    for dim in range(points.shape[1]):\n",
    "        outlist.append(np.mean(points[:,dim]))\n",
    "    return np.array(outlist)\n",
    "\n",
    "def distance_and_direction(p1,p2):\n",
    "    #returns a scalar magnitude and direction vector [x,y] from p1 [x,y] to p2[x,y]\n",
    "    distance = np.sqrt((p1[0]-p2[0])**2+(p1[1]-p2[1])**2)\n",
    "    direction = [p1[0]-p2[0],p1[1]-p2[1]]\n",
    "    return distance, direction\n",
    "\n",
    "def magnitude(point):\n",
    "    return np.sqrt(np.sum(point**2))\n",
    "\n",
    "def euc_2_polar(points):\n",
    "    x,y = points[:,0], points[:,1]\n",
    "    r = np.sqrt(x**2+y**2)\n",
    "    t = np.arctan2(y,x)\n",
    "    return r,t\n",
    "\n",
    "def polar_2_euc(r,t):\n",
    "    x = r*np.cos(t)\n",
    "    y = r*np.sin(t)\n",
    "    points = np.array([x,y]).transpose()\n",
    "    return points\n",
    "\n",
    "def scaling_forces(points):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs scalar forcing scaling factor\n",
    "    distances = euclidean_distances(points)\n",
    "    m = np.min(distances[np.triu_indices(points.shape[0], k = 1)])\n",
    "    return m/2\n",
    "    \n",
    "\n",
    "def points_2_lin_repel(points, scaling):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "    distances = euclidean_distances(points)\n",
    "    mean_dis = np.mean(distances)\n",
    "    #max_dis = np.max(distances)\n",
    "    def force_on_point(point, points = points,scale = 1/mean_dis):\n",
    "        dif = points - point\n",
    "        dif_r, dif_t = euc_2_polar(dif)\n",
    "        same_point_indices = np.where(dif_r == 0)[0]\n",
    "        #magnitude = np.apply_along_axis(magnitude, 1, dif) \n",
    "        force_mag = scaling*(1-scale*dif_r)\n",
    "        force_vecs = polar_2_euc(force_mag,dif_t)\n",
    "        force_vecs = -1*np.delete(force_vecs, same_point_indices, axis=0)\n",
    "        return np.sum(force_vecs,axis=0) \n",
    "    return np.apply_along_axis(force_on_point, 1, points)\n",
    "    \n",
    "    \n",
    "def points_2_com_lin_attract(points,scaling):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "    com = points_2_com(points)\n",
    "    num_points = points.shape[0]\n",
    "    def com_force_on_point(point, com = com, num_points = num_points,scaling=scaling):\n",
    "        return [(com[0]-point[0])*scaling,(com[1]-point[1])*scaling]\n",
    "    return np.apply_along_axis(com_force_on_point, 1, points)\n",
    "    \n",
    "    \n",
    "\n",
    "def points_2_lin_force_field(points, scaling=1):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "    scaling = scaling*scaling_forces(points)\n",
    "    return points_2_lin_repel(points,scaling)+points_2_com_lin_attract(points,scaling)\n",
    "\n",
    "def push_points(points,rate=.1):\n",
    "    forces = points_2_lin_force_field(points)\n",
    "    return points + rate*forces\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# X = np.arange(-2, 2, .1)\n",
    "# Y = np.arange(-2, 2, .1)\n",
    "# listU = []\n",
    "# listV = []\n",
    "# for x in X:\n",
    "#     listU.append([])\n",
    "#     listV.append([])\n",
    "#     for y in Y:\n",
    "#         listV[-1].append(x/sigma*np.e**(-(x**2+y**2))/sigma+(x-1.6)/sigma*np.e**(-((x-1.6)**2+(y-1.6)**2)/sigma))\n",
    "#         listU[-1].append(y/sigma*np.e**(-(x**2+y**2))/sigma+(y-1.6)/sigma*np.e**(-((x-1.6)**2+(y-1.6)**2)/sigma))\n",
    "\n",
    "# U = np.array(listU)\n",
    "# V = np.array(listV)\n",
    "        \n",
    "# #U, V = np.meshgrid(-X/sigma*np.e**((X**2+Y**2)/sigma), -Y/sigma*np.e**((X**2+Y**2)/sigma))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# q = ax.quiver(X, Y, U, V)\n",
    "# ax.quiverkey(q, X=0.3, Y=1.1, U=10,\n",
    "#              label='Quiver key, length = 10', labelpos='E')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array([1,2,3,4,5])\n",
    "same_point_indices = np.where(r == 4)[0]\n",
    "r = np.delete(r, same_point_indices, axis=0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonlinear force field\n",
    "import time\n",
    "\n",
    "#center of mass\n",
    "def points_2_com(points):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs center of mass as np.array([dim1,dim2, . . . ])\n",
    "    outlist = []\n",
    "    for dim in range(points.shape[1]):\n",
    "        outlist.append(np.mean(points[:,dim]))\n",
    "    return np.array(outlist)\n",
    "\n",
    "def distance_and_direction(p1,p2):\n",
    "    #returns a scalar magnitude and direction vector [x,y] from p1 [x,y] to p2[x,y]\n",
    "    distance = np.sqrt((p1[0]-p2[0])**2+(p1[1]-p2[1])**2)\n",
    "    direction = [p1[0]-p2[0],p1[1]-p2[1]]\n",
    "    return distance, direction\n",
    "\n",
    "def magnitude(point):\n",
    "    return np.sqrt(np.sum(point**2))\n",
    "\n",
    "def euc_2_polar(points):\n",
    "    x,y = points[:,0], points[:,1]\n",
    "    r = np.sqrt(x**2+y**2)\n",
    "    t = np.arctan2(y,x)\n",
    "    return r,t\n",
    "\n",
    "def polar_2_euc(r,t):\n",
    "    x = r*np.cos(t)\n",
    "    y = r*np.sin(t)\n",
    "    points = np.array([x,y]).transpose()\n",
    "    return points\n",
    "\n",
    "def scaling_forces(points):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs scalar forcing scaling factor\n",
    "    distances = euclidean_distances(points)\n",
    "    m = np.min(distances[np.triu_indices(points.shape[0], k = 1)])\n",
    "    return m/2\n",
    "    \n",
    "\n",
    "def points_2_nonlin_repel(points, scaling):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "    distances = euclidean_distances(points)\n",
    "    mean_dis = np.mean(distances)\n",
    "    #max_dis = np.max(distances)\n",
    "    def force_on_point(point, points = points,scale = 1/mean_dis):\n",
    "        dif = points - point\n",
    "        dif_r, dif_t = euc_2_polar(dif)\n",
    "        same_point_indices = np.where(dif_r == 0)[0]\n",
    "        dif_r = np.delete(dif_r, same_point_indices, axis=0)\n",
    "        dif_t = np.delete(dif_t, same_point_indices, axis=0)\n",
    "        #magnitude = np.apply_along_axis(magnitude, 1, dif) \n",
    "        #force_mag = scaling*(1-scale*dif_r)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        force_mag = 1/(dif_r)*mean_dis\n",
    "        force_vecs = -1*polar_2_euc(force_mag,dif_t)\n",
    "        #force_vecs = -1*np.delete(force_vecs, same_point_indices, axis=0)\n",
    "        return np.sum(force_vecs,axis=0) \n",
    "    return np.apply_along_axis(force_on_point, 1, points)\n",
    "    \n",
    "    \n",
    "def points_2_com_nonlin_attract(points,scaling):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "    com = points_2_com(points)\n",
    "    num_points = points.shape[0]\n",
    "    def com_force_on_point(point, com = com, num_points = num_points,scaling=scaling):\n",
    "        return [(com[0]-point[0])*scaling*num_points,(com[1]-point[1])*scaling*num_points]\n",
    "    return np.apply_along_axis(com_force_on_point, 1, points)\n",
    "    \n",
    "    \n",
    "\n",
    "def points_2_nonlin_force_field(points, scaling=1):\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "    scaling = scaling*scaling_forces(points)\n",
    "    #return points_2_nonlin_repel(points,scaling)\n",
    "    return points_2_nonlin_repel(points,scaling)+points_2_com_nonlin_attract(points,scaling)\n",
    "\n",
    "def nonlinear_push_points(points,rate=.1):\n",
    "    forces = points_2_nonlin_force_field(points)\n",
    "    return points + rate*forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eccen_and_angle_colorscale(points):\n",
    "    r,t = euc_2_polar(points)\n",
    "    t = np.where(t < 0, 2*np.pi+t, t)\n",
    "    eccen_colors = (r - np.min(r))/(np.max(r)-np.min(r))\n",
    "    angle_colors = (t - np.min(t))/(np.max(t)-np.min(t))\n",
    "    return eccen_colors,angle_colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,t = euc_2_polar(pos)\n",
    "print(t)\n",
    "print(np.where(t < 0, 2*np.pi+t, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(x=pos[:,0], y=pos[:,1],color = eccen_and_angle_colorscale(pos)[0], color_continuous_scale='viridis')\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccen_colors, angle_colors = eccen_and_angle_colorscale(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=10, cols=2)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=pos[:,0], y=pos[:,1],mode='markers',marker=dict(color = eccen_colors, coloraxis='coloraxis')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=pos[:,0], y=pos[:,1],mode='markers',marker=dict(color = angle_colors, coloraxis='coloraxis2')),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400,width=700,coloraxis_showscale=False,\n",
    "                  coloraxis=dict(colorscale='viridis',showscale=False),\n",
    "                  coloraxis2 = dict(showscale=False, colorscale='mrybm')\n",
    "                 )\n",
    "#fig.update_coloraxes(colorscale='viridis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "x,y = np.meshgrid(np.arange(-2, 2, .2),\n",
    "                  np.arange(-2, 2, .25))\n",
    "z = x*np.exp(-x**2 - y**2)\n",
    "v, u = np.gradient(z, .2, .2)\n",
    "\n",
    "# Create quiver figure\n",
    "fig = ff.create_quiver(x, y, u, v,\n",
    "                       scale=.25,\n",
    "                       arrow_scale=.4,\n",
    "                       name='quiver',\n",
    "                       line_width=1)\n",
    "\n",
    "# Add points to figure\n",
    "fig.add_trace(go.Scatter(x=[-.7, .75], y=[0,0],\n",
    "                    mode='markers',\n",
    "                    marker_size=12,\n",
    "                    name='points'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# data\n",
    "x,y = np.meshgrid(np.arange(0, 2, .2), np.arange(0, 2, .2))\n",
    "u = np.cos(x)*y\n",
    "v = np.sin(x)*y\n",
    "\n",
    "# quiver plots\n",
    "fig1 = ff.create_quiver(x, y, u, v)\n",
    "fig2 = ff.create_quiver(x, y, u*0.9, v*1.1)\n",
    "    \n",
    "# subplot setup\n",
    "subplots = make_subplots(rows=1, cols=2)\n",
    "\n",
    "# add all fig1.data as individual traces in fig at row=1, col=1\n",
    "for d in fig1.data:\n",
    "    subplots.add_trace(go.Scatter(x=d['x'], y=d['y']),\n",
    "                  row=1, col=1)\n",
    "\n",
    "# add all fig2.data as individual traces in fig at row=1, col=2\n",
    "for d in fig1.data:\n",
    "    subplots.add_trace(go.Scatter(x=d['x'], y=d['y']),\n",
    "                  row=1, col=2)\n",
    "subplots.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def force_points_fig(points,iterations=100):\n",
    "    eccen_colors, angle_colors = eccen_and_angle_colorscale(points)\n",
    "    j = list(range(len(points)))\n",
    "    fig = make_subplots(rows=iterations, cols=2)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=points[:,0], y=points[:,1],\n",
    "               mode='markers',text = j,hoverinfo='text',\n",
    "               marker=dict(color = eccen_colors, coloraxis='coloraxis')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=points[:,0], y=points[:,1],\n",
    "               mode='markers',text = j,hoverinfo='text',\n",
    "               marker=dict(color = angle_colors, coloraxis='coloraxis2')),\n",
    "    row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=350*iterations,width=700,coloraxis_showscale=False, showlegend=False,\n",
    "                  coloraxis=dict(colorscale='rainbow',showscale=False),\n",
    "                  coloraxis2 = dict(showscale=False, colorscale='hsv')\n",
    "                 )\n",
    "    init_rate = .0001\n",
    "    for i in range(1,iterations):\n",
    "        #move_points \n",
    "        prev_points = deepcopy(points)\n",
    "        points = nonlinear_push_points(points,rate=np.min([init_rate+i*init_rate/10,init_rate*10]))\n",
    "        #quiver plot points\n",
    "        ##qx = prev_points[:,0]\n",
    "        #qy = prev_points[:,1]\n",
    "        #qv = points[:,0]-prev_points[:,0]\n",
    "        #qu = points[:,1]-prev_points[:,1]\n",
    "        #qfig = ff.create_quiver(qx, qy, qu, qv,\n",
    "                                #line_width=1,scale=1,\n",
    "                                #text = j,hoverinfo='text')\n",
    "        #plot all traces\n",
    "        #eccen\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=points[:,0], y=points[:,1],\n",
    "                       mode='markers',text = j,hoverinfo='text',\n",
    "                       marker=dict(color = 'blue')\n",
    "                       #marker=dict(color = eccen_colors, coloraxis='coloraxis')\n",
    "                      ),\n",
    "            row=1+i, col=1\n",
    "            )\n",
    "        #polar angle\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=points[:,0], y=points[:,1],\n",
    "                       mode='markers',text = j,hoverinfo='text',\n",
    "                       #marker=dict(color = angle_colors, coloraxis='coloraxis2')\n",
    "                       marker=dict(color = 'blue')\n",
    "                      ),\n",
    "            row=1+i, col=2\n",
    "            )\n",
    "        #quiver\n",
    "        #for d in qfig.data:\n",
    "        #    fig.add_trace(\n",
    "        #        go.Scatter(x=d['x'], y=d['y']),\n",
    "        #        row=1+i, col=3)\n",
    "#         fig.add_trace(\n",
    "#                     ff.create_quiver(qx, qy, qu, qv,\n",
    "#                                      scale=.1,\n",
    "#                                      arrow_scale=.2,\n",
    "#                                      name='quiver',\n",
    "#                                      line_width=.5),\n",
    "#             row=1+i, col=3\n",
    "#             )\n",
    "        \n",
    "    return fig\n",
    "\n",
    "fig = force_points_fig(pos)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "import os\n",
    "\n",
    "if not os.path.exists('force_field_vids'):\n",
    "    os.mkdir('force_field_vids')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def force_points_video(points,name,iterations=100):\n",
    "    eccen_colors, angle_colors = eccen_and_angle_colorscale(points)\n",
    "    j = list(range(len(points)))\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=points[:,0], y=points[:,1],\n",
    "               mode='markers',text = j,hoverinfo='text',\n",
    "               marker=dict(color = eccen_colors, coloraxis='coloraxis')),\n",
    "      row=1, col=1  \n",
    "    )\n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=points[:,0], y=points[:,1],\n",
    "               mode='markers',text = j,hoverinfo='text',\n",
    "               marker=dict(color = angle_colors, coloraxis='coloraxis2')),\n",
    "    row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=350,width=700,coloraxis_showscale=False, showlegend=False,\n",
    "                  coloraxis=dict(colorscale='rainbow',showscale=False),\n",
    "                  coloraxis2 = dict(showscale=False, colorscale='hsv')\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    init_rate = .0001\n",
    "    for i in range(1,iterations):\n",
    "        #move_points \n",
    "        prev_points = deepcopy(points)\n",
    "        points = nonlinear_push_points(points,rate=np.min([init_rate+i*init_rate/10,init_rate*10]))\n",
    "        #quiver plot points\n",
    "        ##qx = prev_points[:,0]\n",
    "        #qy = prev_points[:,1]\n",
    "        #qv = points[:,0]-prev_points[:,0]\n",
    "        #qu = points[:,1]-prev_points[:,1]\n",
    "        #qfig = ff.create_quiver(qx, qy, qu, qv,\n",
    "                                #line_width=1,scale=1,\n",
    "                                #text = j,hoverinfo='text')\n",
    "        #plot all traces\n",
    "        #eccen\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=points[:,0], y=points[:,1],\n",
    "                       mode='markers',text = j,hoverinfo='text',\n",
    "                       marker=dict(color = 'blue')\n",
    "                       #marker=dict(color = eccen_colors, coloraxis='coloraxis')\n",
    "                      ),\n",
    "            row=1+i, col=1\n",
    "            )\n",
    "        #polar angle\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=points[:,0], y=points[:,1],\n",
    "                       mode='markers',text = j,hoverinfo='text',\n",
    "                       #marker=dict(color = angle_colors, coloraxis='coloraxis2')\n",
    "                       marker=dict(color = 'blue')\n",
    "                      ),\n",
    "            row=1+i, col=2\n",
    "            )\n",
    "        #quiver\n",
    "        #for d in qfig.data:\n",
    "        #    fig.add_trace(\n",
    "        #        go.Scatter(x=d['x'], y=d['y']),\n",
    "        #        row=1+i, col=3)\n",
    "#         fig.add_trace(\n",
    "#                     ff.create_quiver(qx, qy, qu, qv,\n",
    "#                                      scale=.1,\n",
    "#                                      arrow_scale=.2,\n",
    "#                                      name='quiver',\n",
    "#                                      line_width=.5),\n",
    "#             row=1+i, col=3\n",
    "#             )\n",
    "        \n",
    "    return fig\n",
    "\n",
    "fig = force_points_fig(pos)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "def force_points_fig(points,iterations=100):\n",
    "    eccen_colors, angle_colors = eccen_and_angle_colorscale(points)\n",
    "    j = list(range(len(points)))\n",
    "    fig = make_subplots(rows=iterations, cols=2)\n",
    "    \n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=points[:,0], y=points[:,1],\n",
    "               mode='markers',text = j,hoverinfo='text',\n",
    "               marker=dict(color = eccen_colors, coloraxis='coloraxis')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=points[:,0], y=points[:,1],\n",
    "               mode='markers',text = j,hoverinfo='text',\n",
    "               marker=dict(color = angle_colors, coloraxis='coloraxis2')),\n",
    "    row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=350*iterations,width=700,coloraxis_showscale=False, showlegend=False,\n",
    "                  coloraxis=dict(colorscale='rainbow',showscale=False),\n",
    "                  coloraxis2 = dict(showscale=False, colorscale='hsv')\n",
    "                 )\n",
    "    init_rate = .0001\n",
    "    for i in range(1,iterations):\n",
    "        #move_points \n",
    "        prev_points = deepcopy(points)\n",
    "        points = nonlinear_push_points(points,rate=np.min([init_rate+i*init_rate/10,init_rate*10]))\n",
    "        #quiver plot points\n",
    "        ##qx = prev_points[:,0]\n",
    "        #qy = prev_points[:,1]\n",
    "        #qv = points[:,0]-prev_points[:,0]\n",
    "        #qu = points[:,1]-prev_points[:,1]\n",
    "        #qfig = ff.create_quiver(qx, qy, qu, qv,\n",
    "                                #line_width=1,scale=1,\n",
    "                                #text = j,hoverinfo='text')\n",
    "        #plot all traces\n",
    "        #eccen\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=points[:,0], y=points[:,1],\n",
    "                       mode='markers',text = j,hoverinfo='text',\n",
    "                       marker=dict(color = 'blue')\n",
    "                       #marker=dict(color = eccen_colors, coloraxis='coloraxis')\n",
    "                      ),\n",
    "            row=1+i, col=1\n",
    "            )\n",
    "        #polar angle\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=points[:,0], y=points[:,1],\n",
    "                       mode='markers',text = j,hoverinfo='text',\n",
    "                       #marker=dict(color = angle_colors, coloraxis='coloraxis2')\n",
    "                       marker=dict(color = 'blue')\n",
    "                      ),\n",
    "            row=1+i, col=2\n",
    "            )\n",
    "        #quiver\n",
    "        #for d in qfig.data:\n",
    "        #    fig.add_trace(\n",
    "        #        go.Scatter(x=d['x'], y=d['y']),\n",
    "        #        row=1+i, col=3)\n",
    "#         fig.add_trace(\n",
    "#                     ff.create_quiver(qx, qy, qu, qv,\n",
    "#                                      scale=.1,\n",
    "#                                      arrow_scale=.2,\n",
    "#                                      name='quiver',\n",
    "#                                      line_width=.5),\n",
    "#             row=1+i, col=3\n",
    "#             )\n",
    "        \n",
    "    return fig\n",
    "\n",
    "fig = force_points_fig(pos)\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('test_plot.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repel = points_2_lin_repel(points, scaling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = np.array([2,2,2])\n",
    "np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([[-1,1],[1,1],[1,-1],[-1,-1]])\n",
    "scaling= 1\n",
    "    #in_arr.shape = (num_points,dimensionality of points)\n",
    "    #outputs array of same shape with (num_points, dimensions of force vectors on those point)\n",
    "distances = euclidean_distances(points)\n",
    "mean_dis = np.mean(distances[np.triu_indices(points.shape[0], k = 1)])\n",
    "print(mean_dis)\n",
    "point = points[0,:]\n",
    "print(point)\n",
    "dif = points - point\n",
    "print(dif)\n",
    "dif_r, dif_t = euc_2_polar(dif)\n",
    "same_point_indices = np.where(dif_r == 0)[0]\n",
    "print(dif_r)\n",
    "print(dif_t)\n",
    "force_mag = scaling*(1-1/mean_dis*dif_r)\n",
    "force_mag[force_mag<0] = 0\n",
    "print(force_mag)\n",
    "force_vecs = polar_2_euc(force_mag,dif_t)\n",
    "print(force_vecs)\n",
    "force_vecs=-1*np.delete(force_vecs, same_point_indices, axis=0)\n",
    "print(force_vecs)\n",
    "print(np.sum(force_vecs,axis=0))\n",
    "\n",
    "#     def force_on_point(point, points = points,scale = 1/mean_dis):\n",
    "#         dif = points - point\n",
    "#         dif_r, dif_t = euc_2_polar(dif)\n",
    "#         #magnitude = np.apply_along_axis(magnitude, 1, dif) \n",
    "#         force_mag = scaling*(1-scale*dif_r)\n",
    "#         force_vecs = polar_2_euc(force_mag,dif_t)\n",
    "#         return np.sum(force_vecs,axis=0)-scaling # subtract scaling so point doesnt exert force on itself   \n",
    "#     return np.apply_along_axis(force_on_point, 1, points)\n",
    "\n",
    "# repel = points_2_lin_repel(points, scaling=1)\n",
    "# repel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(force_vecs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([[-1,1],[1,1],[1,-1],[-1,-1]])\n",
    "scaling= 1\n",
    "\n",
    "repel = points_2_lin_repel(points, scaling=1)\n",
    "repel\n",
    "\n",
    "attract = points_2_com_lin_attract(points,scaling=1)\n",
    "attract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dif,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "s1 = points_2_com_lin_attract(points,1)\n",
    "print(time.time() -start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = points_2_com(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.07833023*np.sqrt(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-(-10-mu)/sigma*stats.norm.pdf(-10, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pos = np.swapaxes(pos,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.dataset[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "points = pos3\n",
    "\n",
    "diff = kernel.dataset - points[:, i]\n",
    "tdiff = dot(kernel.inv_cov, diff)\n",
    "energy = sum(diff * tdiff, axis=0) / 2.0\n",
    "result[i] = sum(exp(-energy), axis=0)\n",
    "\n",
    "result = zeros((kernel.d,m), dtype=float)    \n",
    "\n",
    "diff = kernel.dataset - points[:, i]\n",
    "tdiff = dot(kernel.inv_cov, diff)\n",
    "energy = sum(diff * tdiff, axis=0) / 2.0\n",
    "grad = dot(kernel.inv_cov, diff)\n",
    "result[:,i] = sum(grad * exp(-energy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.pdf(np.array([.2,.2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "mu = 0\n",
    "mu2 = 1\n",
    "variance = .1\n",
    "sigma = math.sqrt(variance)\n",
    "x = np.linspace(mu - 10*sigma, mu + 10*sigma, 300)\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "axs[0].plot(x, stats.norm.pdf(x, mu, sigma)+stats.norm.pdf(x, mu2, sigma))\n",
    "axs[1].plot(x, -(x-mu)/sigma*stats.norm.pdf(x, mu, sigma)-(x-mu2)/sigma*stats.norm.pdf(x, mu2, sigma))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(x,-(x-mu)/sigma*stats.norm.pdf(x, mu, sigma)-(x-mu2)/sigma*stats.norm.pdf(x, mu2, sigma))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2 * np.pi, 400)\n",
    "y = np.sin(x ** 2)\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "axs[0].plot(x, y)\n",
    "axs[1].plot(x, -y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_viz_test",
   "language": "python",
   "name": "prune_viz_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
