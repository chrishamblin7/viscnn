{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible models to visualizer are:\n",
      "['mnist_resize', 'alexnet_old.tar.gz', 'mnist_old', '.keep', 'mnist', 'old', 'alexnet10', 'letter_mixed_not_trained', 'imagenet10_sparse', 'alexnet_sparse_test', '.DS_Store', 'alexnet_sparse_full_model_10classes', 'imagenet10', 'alexnet_sparse', 'alexnet_lucent', 'mnist.tgz', 'alexnet', 'letter_mixed', 'googlenet10_test', '._.DS_Store', 'alexnet_corrupted', 'alexnet.tar.gz']\n",
      "\n",
      "You've chosen to visualize alexnet_sparse\n"
     ]
    }
   ],
   "source": [
    "#fetch command line argument (prepped model)\n",
    "#%reset\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import torch\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('./prep_model_scripts/'))\n",
    "sys.path.insert(0, os.path.abspath('./visualizer_scripts/'))\n",
    "from visualizer_helper_functions import *\n",
    "from contrast_helper_functions import *\n",
    "from featureviz_helper_functions import *\n",
    "from subgraph_helper_functions import *\n",
    "from ablation_functions import *\n",
    "from receptive_field import *\n",
    "from dissected_Conv2d import *\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "py.init_notebook_mode(connected=True)   #jupyter notebook only\n",
    "\n",
    "prepped_model_folder = 'alexnet_sparse'    #set this to a subfolder of prunned_models\n",
    "\n",
    "full_prepped_model_folder = os.path.abspath('prepped_models/%s'%prepped_model_folder)\n",
    "\n",
    "possible_models = os.listdir('prepped_models')\n",
    "print('possible models to visualizer are:')\n",
    "print(possible_models)\n",
    "\n",
    "print('\\nYou\\'ve chosen to visualize %s'%prepped_model_folder)\n",
    "\n",
    "\n",
    "sys.path.insert(0,'prepped_models/%s'%prepped_model_folder)\n",
    "\n",
    "import prep_model_params_used as prep_model_params\n",
    "\n",
    "params = {}\n",
    "params['prepped_model'] = prepped_model_folder\n",
    "params['prepped_model_path'] = full_prepped_model_folder\n",
    "params['device'] = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "\n",
    "#Non-GUI parameters\n",
    "\n",
    "#deepviz\n",
    "params['deepviz_param'] = None\n",
    "params['deepviz_optim'] = None\n",
    "params['deepviz_transforms'] = None\n",
    "params['deepviz_image_size'] = prep_model_params.deepviz_image_size\n",
    "\n",
    "#backend\n",
    "params['cuda'] = prep_model_params.cuda    #use gpu acceleration when running model forward\n",
    "params['input_image_directory'] = prep_model_params.input_img_path+'/'   #path to directory of imput images you want fed through the network\n",
    "params['preprocess'] = prep_model_params.preprocess     #torchvision transfrom to pass input images through\n",
    "params['label_file_path'] = prep_model_params.label_file_path\n",
    "params['criterion'] = prep_model_params.criterion\n",
    "params['rank_img_path'] = prep_model_params.rank_img_path\n",
    "params['num_workers'] = prep_model_params.num_workers\n",
    "params['seed'] = prep_model_params.seed\n",
    "params['batch_size'] = prep_model_params.batch_size\n",
    "#params['dynamic_act_cache_num'] = 4  #max number of input image activations 'dynamic_activations' will have simultaneously\n",
    "\n",
    " \n",
    "#aesthetic \n",
    "\n",
    "params['node_size'] = 12\n",
    "params['edge_size'] = 1\n",
    "params['max_node_inputs'] = 10    #there is a dropdown showing the top weighted edge inputs to nodes, how many maps in dropdown?\n",
    "params['layer_colors'] = ['rgba(31,119,180,', \n",
    "                          'rgba(255,127,14,',\n",
    "                          'rgba(44,160,44,', \n",
    "                          'rgba(214,39,40,',\n",
    "                          'rgba(39, 208, 214,', \n",
    "                          'rgba(242, 250, 17,',\n",
    "                          'rgba(196, 94, 255,',\n",
    "                          'rgba(193, 245, 5,',\n",
    "                          'rgba(245, 85, 5,',\n",
    "                          'rgba(5, 165, 245,',\n",
    "                          'rgba(245, 5, 105,',\n",
    "                          'rgba(218, 232, 23,',\n",
    "                          'rgba(148, 23, 232,',\n",
    "                          'rgba(23, 232, 166,',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#GUI parameters initialization (these parameters can be set in the GUI, but what values should they be initialized to?)\n",
    "target_category = 'overall'     #category of images edges and nodes are weighted based on (which subgraph) \n",
    "rank_type = 'actxgrad'       #weighting criterion (actxgrad, act, grad, or weight)\n",
    "projection = 'MDS smooth'           #how nodes within a layer are projected into the 2d plane (MDS or Grid)\n",
    "edge_threshold = [.7,1]     #what range do edge ranks need to be in to be visualized\n",
    "node_threshold = [.4,1]     #only relevant for hierarchical subgraph \n",
    "\n",
    "#### DONT EDIT BELOW initializations\n",
    "\n",
    "figure_init = go.Figure()\n",
    "figure_init.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[]))\n",
    "figure_init.update_layout(xaxis=dict(visible=False),\n",
    "                  yaxis=dict(visible=False),\n",
    "                  annotations = [dict(text=\"No Inputs\",\n",
    "                                      xref=\"paper\",\n",
    "                                      yref=\"paper\",\n",
    "                                      showarrow=False,\n",
    "                                      font=dict(size=28))]\n",
    "                 )\n",
    "\n",
    "params['max_edge_weight'] = 1  #for the edge threshold slider, this dynamically adjusted its max value to max edge rank\n",
    "                     #before there were multiple rank criterions, which made things confusing\n",
    "                     #so well just fix it to 1 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model:\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Model\n",
    "\n",
    "model_dis = dissect_model(deepcopy(prep_model_params.model),store_ranks=True,clear_ranks=True,cuda=params['cuda'],device=params['device']) #version of model with accessible preadd activations in Conv2d modules \n",
    "if params['cuda']:\n",
    "    model_dis.cuda()\n",
    "model_dis = model_dis.eval()    \n",
    "model_dis.to(params['device'])\n",
    "\n",
    "print('loaded model:')\n",
    "print(prep_model_params.model)\n",
    "        \n",
    "#del prep_model_params.model\n",
    "model = prep_model_params.model\n",
    "if params['cuda']:\n",
    "    model.cuda()\n",
    "model = model.eval()\n",
    "model.to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading misc graph data\n",
      "model has categories:\n",
      "['overall', 'Afghan_hound', 'African_chameleon', 'African_crocodile', 'African_elephant', 'African_grey', 'African_hunting_dog', 'Airedale', 'American_Staffordshire_terrier', 'American_alligator', 'American_black_bear', 'American_chameleon', 'American_coot', 'American_egret', 'American_lobster', 'Angora', 'Appenzeller', 'Arabian_camel', 'Arctic_fox', 'Australian_terrier', 'Band_Aid', 'Bedlington_terrier', 'Bernese_mountain_dog', 'Blenheim_spaniel', 'Border_collie', 'Border_terrier', 'Boston_bull', 'Bouvier_des_Flandres', 'Brabancon_griffon', 'Brittany_spaniel', 'CD_player', 'Cardigan_corgi', 'Chesapeake_Bay_retriever', 'Chihuahua', 'Christmas_stocking', 'Crock_Pot', 'Dandie_Dinmont', 'Doberman', 'Dungeness_crab', 'Dutch_oven', 'Egyptian_cat', 'English_foxhound', 'English_setter', 'English_springer', 'EntleBucher', 'Eskimo_dog', 'European_fire_salamander', 'European_gallinule', 'French_bulldog', 'French_horn', 'French_loaf', 'German_shepherd', 'German_short_haired_pointer', 'Gila_monster', 'Gordon_setter', 'Granny_Smith', 'Great_Dane', 'Great_Pyrenees', 'Greater_Swiss_Mountain_dog', 'Ibizan_hound', 'Indian_cobra', 'Indian_elephant', 'Irish_setter', 'Irish_terrier', 'Irish_water_spaniel', 'Irish_wolfhound', 'Italian_greyhound', 'Japanese_spaniel', 'Kerry_blue_terrier', 'Komodo_dragon', 'Labrador_retriever', 'Lakeland_terrier', 'Leonberg', 'Lhasa', 'Loafer', 'Madagascar_cat', 'Maltese_dog', 'Mexican_hairless', 'Model_T', 'Newfoundland', 'Norfolk_terrier', 'Norwegian_elkhound', 'Norwich_terrier', 'Old_English_sheepdog', 'Pekinese', 'Pembroke', 'Persian_cat', 'Petri_dish', 'Polaroid_camera', 'Pomeranian', 'Rhodesian_ridgeback', 'Rottweiler', 'Saint_Bernard', 'Saluki', 'Samoyed', 'Scotch_terrier', 'Scottish_deerhound', 'Sealyham_terrier', 'Shetland_sheepdog', 'Shih_Tzu', 'Siamese_cat', 'Siberian_husky', 'Staffordshire_bullterrier', 'Sussex_spaniel', 'Tibetan_mastiff', 'Tibetan_terrier', 'Walker_hound', 'Weimaraner', 'Welsh_springer_spaniel', 'West_Highland_white_terrier', 'Windsor_tie', 'Yorkshire_terrier', 'abacus', 'abaya', 'academic_gown', 'accordion', 'acorn', 'acorn_squash', 'acoustic_guitar', 'admiral', 'affenpinscher', 'agama', 'agaric', 'aircraft_carrier', 'airliner', 'airship', 'albatross', 'alligator_lizard', 'alp', 'altar', 'ambulance', 'amphibian', 'analog_clock', 'anemone_fish', 'ant', 'apiary', 'apron', 'armadillo', 'artichoke', 'ashcan', 'assault_rifle', 'axolotl', 'baboon', 'backpack', 'badger', 'bagel', 'bakery', 'balance_beam', 'bald_eagle', 'balloon', 'ballplayer', 'ballpoint', 'banana', 'banded_gecko', 'banjo', 'bannister', 'barbell', 'barber_chair', 'barbershop', 'barn', 'barn_spider', 'barometer', 'barracouta', 'barrel', 'barrow', 'baseball', 'basenji', 'basketball', 'basset', 'bassinet', 'bassoon', 'bath_towel', 'bathing_cap', 'bathtub', 'beach_wagon', 'beacon', 'beagle', 'beaker', 'bearskin', 'beaver', 'bee', 'bee_eater', 'beer_bottle', 'beer_glass', 'bell_cote', 'bell_pepper', 'bib', 'bicycle_built_for_two', 'bighorn', 'bikini', 'binder', 'binoculars', 'birdhouse', 'bison', 'bittern', 'black_and_gold_garden_spider', 'black_and_tan_coonhound', 'black_footed_ferret', 'black_grouse', 'black_stork', 'black_swan', 'black_widow', 'bloodhound', 'bluetick', 'boa_constrictor', 'boathouse', 'bobsled', 'bolete', 'bolo_tie', 'bonnet', 'book_jacket', 'bookcase', 'bookshop', 'borzoi', 'bottlecap', 'bow', 'bow_tie', 'box_turtle', 'boxer', 'brain_coral', 'brambling', 'brass', 'brassiere', 'breakwater', 'breastplate', 'briard', 'broccoli', 'broom', 'brown_bear', 'bubble', 'bucket', 'buckeye', 'buckle', 'bulbul', 'bull_mastiff', 'bullet_train', 'bulletproof_vest', 'bullfrog', 'burrito', 'bustard', 'butcher_shop', 'butternut_squash', 'cab', 'cabbage_butterfly', 'cairn', 'caldron', 'can_opener', 'candle', 'cannon', 'canoe', 'capuchin', 'car_mirror', 'car_wheel', 'carbonara', 'cardigan_sweater', 'cardoon', 'carousel', 'carpenters_kit', 'carton', 'cash_machine', 'cassette', 'cassette_player', 'castle', 'catamaran', 'cauliflower', 'cello', 'cellular_telephone', 'centipede', 'chain', 'chain_mail', 'chain_saw', 'chainlink_fence', 'chambered_nautilus', 'cheeseburger', 'cheetah', 'chest', 'chickadee', 'chiffonier', 'chime', 'chimpanzee', 'china_cabinet', 'chiton', 'chocolate_sauce', 'chow', 'church', 'cicada', 'cinema', 'cleaver', 'cliff', 'cliff_dwelling', 'cloak', 'clog', 'clumber', 'cocker_spaniel', 'cockroach', 'cocktail_shaker', 'coffee_mug', 'coffeepot', 'coho', 'coil', 'collie', 'colobus', 'combination_lock', 'comic_book', 'common_iguana', 'common_newt', 'computer_keyboard', 'conch', 'confectionery', 'consomme', 'container_ship', 'convertible', 'coral_fungus', 'coral_reef', 'corkscrew', 'corn', 'cornet', 'coucal', 'cougar', 'cowboy_boot', 'cowboy_hat', 'coyote', 'cradle', 'crane_bird', 'crane_equipment', 'crash_helmet', 'crate', 'crayfish', 'crib', 'cricket', 'croquet_ball', 'crossword_puzzle', 'crutch', 'cucumber', 'cuirass', 'cup', 'curly_coated_retriever', 'custard_apple', 'daisy', 'dalmatian', 'dam', 'damselfly', 'desk', 'desktop_computer', 'dhole', 'dial_telephone', 'diamondback', 'diaper', 'digital_clock', 'digital_watch', 'dingo', 'dining_table', 'dishrag', 'dishwasher', 'disk_brake', 'dock', 'dogsled', 'dome', 'doormat', 'dough', 'dowitcher', 'dragonfly', 'drake', 'drilling_platform', 'drum', 'drumstick', 'dugong', 'dumbbell', 'dung_beetle', 'ear', 'earthstar', 'echidna', 'eel', 'eft', 'eggnog', 'electric_fan', 'electric_guitar', 'electric_locomotive', 'electric_ray', 'entertainment_center', 'envelope', 'espresso', 'espresso_maker', 'face_powder', 'feather_boa', 'fiddler_crab', 'fig', 'file', 'fire_engine', 'fire_screen', 'fireboat', 'flagpole', 'flamingo', 'flat_coated_retriever', 'flatworm', 'flute', 'fly', 'folding_chair', 'football_helmet', 'forklift', 'fountain', 'fountain_pen', 'four_poster', 'fox_squirrel', 'freight_car', 'frilled_lizard', 'frying_pan', 'fur_coat', 'gar', 'garbage_truck', 'garden_spider', 'garter_snake', 'gas_pump', 'gasmask', 'gazelle', 'geyser', 'giant_panda', 'giant_schnauzer', 'gibbon', 'go_kart', 'goblet', 'golden_retriever', 'goldfinch', 'goldfish', 'golf_ball', 'golfcart', 'gondola', 'gong', 'goose', 'gorilla', 'gown', 'grand_piano', 'grasshopper', 'great_grey_owl', 'great_white_shark', 'green_lizard', 'green_mamba', 'green_snake', 'greenhouse', 'grey_fox', 'grey_whale', 'grille', 'grocery_store', 'groenendael', 'groom', 'ground_beetle', 'guacamole', 'guenon', 'guillotine', 'guinea_pig', 'gyromitra', 'hair_slide', 'hair_spray', 'half_track', 'hammer', 'hammerhead', 'hamper', 'hamster', 'hand_blower', 'hand_held_computer', 'handkerchief', 'hard_disc', 'hare', 'harmonica', 'harp', 'hartebeest', 'harvester', 'harvestman', 'hatchet', 'hay', 'head_cabbage', 'hen', 'hen_of_the_woods', 'hermit_crab', 'hip', 'hippopotamus', 'hog', 'hognose_snake', 'holster', 'home_theater', 'honeycomb', 'hook', 'hoopskirt', 'horizontal_bar', 'hornbill', 'horned_viper', 'horse_cart', 'hot_pot', 'hotdog', 'hourglass', 'house_finch', 'howler_monkey', 'hummingbird', 'hyena', 'iPod', 'ibex', 'ice_bear', 'ice_cream', 'ice_lolly', 'impala', 'indigo_bunting', 'indri', 'iron', 'isopod', 'jacamar', 'jack_o_lantern', 'jackfruit', 'jaguar', 'jay', 'jean', 'jeep', 'jellyfish', 'jersey', 'jigsaw_puzzle', 'jinrikisha', 'joystick', 'junco', 'keeshond', 'kelpie', 'killer_whale', 'kimono', 'king_crab', 'king_penguin', 'king_snake', 'kit_fox', 'kite', 'knee_pad', 'knot', 'koala', 'komondor', 'kuvasz', 'lab_coat', 'lacewing', 'ladle', 'ladybug', 'lakeside', 'lampshade', 'langur', 'laptop', 'lawn_mower', 'leaf_beetle', 'leafhopper', 'leatherback_turtle', 'lemon', 'lens_cap', 'leopard', 'lesser_panda', 'letter_opener', 'library', 'lifeboat', 'lighter', 'limousine', 'limpkin', 'liner', 'lion', 'lionfish', 'lipstick', 'little_blue_heron', 'llama', 'loggerhead', 'long_horned_beetle', 'lorikeet', 'lotion', 'loudspeaker', 'loupe', 'lumbermill', 'lycaenid', 'lynx', 'macaque', 'macaw', 'magnetic_compass', 'magpie', 'mailbag', 'mailbox', 'maillot_1', 'maillot_2', 'malamute', 'malinois', 'manhole_cover', 'mantis', 'maraca', 'marimba', 'marmoset', 'marmot', 'mashed_potato', 'mask', 'matchstick', 'maypole', 'maze', 'measuring_cup', 'meat_loaf', 'medicine_chest', 'meerkat', 'megalith', 'menu', 'microphone', 'microwave', 'military_uniform', 'milk_can', 'miniature_pinscher', 'miniature_poodle', 'miniature_schnauzer', 'minibus', 'miniskirt', 'minivan', 'mink', 'missile', 'mitten', 'mixing_bowl', 'mobile_home', 'modem', 'monarch', 'monastery', 'mongoose', 'monitor', 'moped', 'mortar', 'mortarboard', 'mosque', 'mosquito_net', 'motor_scooter', 'mountain_bike', 'mountain_tent', 'mouse', 'mousetrap', 'moving_van', 'mud_turtle', 'mushroom', 'muzzle', 'nail', 'neck_brace', 'necklace', 'nematode', 'night_snake', 'nipple', 'notebook', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil_filter', 'orange', 'orangutan', 'organ', 'oscilloscope', 'ostrich', 'otter', 'otterhound', 'overskirt', 'ox', 'oxcart', 'oxygen_mask', 'oystercatcher', 'packet', 'paddle', 'paddlewheel', 'padlock', 'paintbrush', 'pajama', 'palace', 'panpipe', 'paper_towel', 'papillon', 'parachute', 'parallel_bars', 'park_bench', 'parking_meter', 'partridge', 'passenger_car', 'patas', 'patio', 'pay_phone', 'peacock', 'pedestal', 'pelican', 'pencil_box', 'pencil_sharpener', 'perfume', 'photocopier', 'pick', 'pickelhaube', 'picket_fence', 'pickup', 'pier', 'piggy_bank', 'pill_bottle', 'pillow', 'pineapple', 'ping_pong_ball', 'pinwheel', 'pirate', 'pitcher', 'pizza', 'plane', 'planetarium', 'plastic_bag', 'plate', 'plate_rack', 'platypus', 'plow', 'plunger', 'pole', 'polecat', 'police_van', 'pomegranate', 'poncho', 'pool_table', 'pop_bottle', 'porcupine', 'pot', 'potpie', 'potters_wheel', 'power_drill', 'prairie_chicken', 'prayer_rug', 'pretzel', 'printer', 'prison', 'proboscis_monkey', 'projectile', 'projector', 'promontory', 'ptarmigan', 'puck', 'puffer', 'pug', 'punching_bag', 'purse', 'quail', 'quill', 'quilt', 'racer', 'racket', 'radiator', 'radio', 'radio_telescope', 'rain_barrel', 'ram', 'rapeseed', 'recreational_vehicle', 'red_backed_sandpiper', 'red_breasted_merganser', 'red_fox', 'red_wine', 'red_wolf', 'redbone', 'redshank', 'reel', 'reflex_camera', 'refrigerator', 'remote_control', 'restaurant', 'revolver', 'rhinoceros_beetle', 'rifle', 'ringlet', 'ringneck_snake', 'robin', 'rock_beauty', 'rock_crab', 'rock_python', 'rocking_chair', 'rooster', 'rotisserie', 'rubber_eraser', 'ruddy_turnstone', 'ruffed_grouse', 'rugby_ball', 'rule', 'running_shoe', 'safe', 'safety_pin', 'saltshaker', 'sandal', 'sandbar', 'sarong', 'sax', 'scabbard', 'scale', 'schipperke', 'school_bus', 'schooner', 'scoreboard', 'scorpion', 'screen', 'screw', 'screwdriver', 'scuba_diver', 'sea_anemone', 'sea_cucumber', 'sea_lion', 'sea_slug', 'sea_snake', 'sea_urchin', 'seashore', 'seat_belt', 'sewing_machine', 'shield', 'shoe_shop', 'shoji', 'shopping_basket', 'shopping_cart', 'shovel', 'shower_cap', 'shower_curtain', 'siamang', 'sidewinder', 'silky_terrier', 'ski', 'ski_mask', 'skunk', 'sleeping_bag', 'slide_rule', 'sliding_door', 'slot', 'sloth_bear', 'slug', 'small_SPAN', 'snail', 'snorkel', 'snow_leopard', 'snowmobile', 'snowplow', 'soap_dispenser', 'soccer_ball', 'sock', 'soft_coated_wheaten_terrier', 'solar_dish', 'sombrero', 'sorrel', 'soup_bowl', 'space_bar', 'space_heater', 'space_shuttle', 'spaghetti_squash', 'spatula', 'speedboat', 'spider_monkey', 'spider_web', 'spindle', 'spiny_lobster', 'spoonbill', 'sports_car', 'spotlight', 'spotted_salamander', 'squirrel_monkey', 'stage', 'standard_poodle', 'standard_schnauzer', 'starfish', 'steam_locomotive', 'steel_arch_bridge', 'steel_drum', 'stethoscope', 'stingray', 'stinkhorn', 'stole', 'stone_wall', 'stopwatch', 'stove', 'strainer', 'strawberry', 'street_sign', 'streetcar', 'stretcher', 'studio_couch', 'stupa', 'sturgeon', 'submarine', 'suit', 'sulphur_butterfly', 'sulphur_crested_cockatoo', 'sundial', 'sunglass', 'sunglasses', 'sunscreen', 'suspension_bridge', 'swab', 'sweatshirt', 'swimming_trunks', 'swing', 'switch', 'syringe', 'tabby', 'table_lamp', 'tailed_frog', 'tank', 'tape_player', 'tarantula', 'teapot', 'teddy', 'television', 'tench', 'tennis_ball', 'terrapin', 'thatch', 'theater_curtain', 'thimble', 'three_toed_sloth', 'thresher', 'throne', 'thunder_snake', 'tick', 'tiger', 'tiger_beetle', 'tiger_cat', 'tiger_shark', 'tile_roof', 'timber_wolf', 'titi', 'toaster', 'tobacco_shop', 'toilet_seat', 'toilet_tissue', 'torch', 'totem_pole', 'toucan', 'tow_truck', 'toy_poodle', 'toy_terrier', 'toyshop', 'tractor', 'traffic_light', 'trailer_truck', 'tray', 'tree_frog', 'trench_coat', 'triceratops', 'tricycle', 'trifle', 'trilobite', 'trimaran', 'tripod', 'triumphal_arch', 'trolleybus', 'trombone', 'tub', 'turnstile', 'tusker', 'typewriter_keyboard', 'umbrella', 'unicycle', 'upright', 'vacuum', 'valley', 'vase', 'vault', 'velvet', 'vending_machine', 'vestment', 'viaduct', 'vine_snake', 'violin', 'vizsla', 'volcano', 'volleyball', 'vulture', 'waffle_iron', 'walking_stick', 'wall_clock', 'wallaby', 'wallet', 'wardrobe', 'warplane', 'warthog', 'washbasin', 'washer', 'water_bottle', 'water_buffalo', 'water_jug', 'water_ouzel', 'water_snake', 'water_tower', 'weasel', 'web_site', 'weevil', 'whippet', 'whiptail', 'whiskey_jug', 'whistle', 'white_stork', 'white_wolf', 'wig', 'wild_boar', 'window_screen', 'window_shade', 'wine_bottle', 'wing', 'wire_haired_fox_terrier', 'wok', 'wolf_spider', 'wombat', 'wood_rabbit', 'wooden_spoon', 'wool', 'worm_fence', 'wreck', 'yawl', 'yellow_ladys_slipper', 'yurt', 'zebra', 'zucchini']\n"
     ]
    }
   ],
   "source": [
    "#load misc graph data\n",
    "print('loading misc graph data')\n",
    "misc_data = pickle.load(open('./prepped_models/%s/misc_graph_data.pkl'%prepped_model_folder,'rb'))\n",
    "params['layer_nodes'] = misc_data['layer_nodes']\n",
    "params['num_layers'] = misc_data['num_layers']\n",
    "params['num_nodes'] = misc_data['num_nodes']\n",
    "params['categories'] = misc_data['categories']\n",
    "params['num_img_chan'] = misc_data['num_img_chan']\n",
    "params['imgnode_positions'] = misc_data['imgnode_positions']\n",
    "params['imgnode_colors'] = misc_data['imgnode_colors']\n",
    "params['imgnode_names'] = misc_data['imgnode_names']\n",
    "params['prepped_model_path'] = full_prepped_model_folder\n",
    "params['ranks_data_path'] = full_prepped_model_folder+'/ranks/'\n",
    "\n",
    "\n",
    "print('model has categories:')\n",
    "print(params['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading nodes rank data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py:146: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading node position data\n"
     ]
    }
   ],
   "source": [
    "#load nodes df\n",
    "print('loading nodes rank data')\n",
    "target_node = 'loss'\n",
    "\n",
    "categories_nodes_df = pd.read_csv('prepped_models/%s/ranks/categories_nodes_ranks.csv'%prepped_model_folder)\n",
    "target_nodes_df = categories_nodes_df.loc[categories_nodes_df['category']==target_category]\n",
    "\n",
    "target_nodes_df = minmax_normalize_ranks_df(target_nodes_df,params,weight=False)\n",
    "\n",
    "weight_nodes_df = pd.read_csv('prepped_models/%s/ranks/weight_nodes_ranks.csv'%prepped_model_folder)\n",
    "\n",
    "weight_nodes_df = minmax_normalize_ranks_df(weight_nodes_df,params,weight=True)\n",
    "\n",
    "node_colors,node_weights = gen_node_colors(target_nodes_df,rank_type,params) \n",
    "\n",
    "#load node positions\n",
    "print('loading node position data')\n",
    "all_node_positions = pickle.load(open('./prepped_models/%s/node_positions.pkl'%prepped_model_folder,'rb'))\n",
    "\n",
    "if projection == 'Grid':\n",
    "    node_positions = all_node_positions[projection]\n",
    "else:\n",
    "    node_positions = all_node_positions[projection][rank_type]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading edge data\n"
     ]
    }
   ],
   "source": [
    "#load edges\n",
    "print('loading edge data')\n",
    "\n",
    "categories_edges_df = None\n",
    "if os.path.exists('prepped_models/%s/edge_ranks.csv'%prepped_model_folder):\n",
    "    categories_edges_df = pd.read_csv('prepped_models/%s/ranks/categories_edges_ranks.csv'%prepped_model_folder)   #load edges\n",
    "\n",
    "if categories_edges_df is not None:\n",
    "    #overall_edges_df = categories_edges_df.loc[categories_edges_df['category']=='overall']\n",
    "    target_edges_df = categories_edges_df.loc[categories_edges_df['category']==target_category]\n",
    "else:\n",
    "    #overall_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','overall_edges_rank.pt'))\n",
    "    target_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','%s_edges_rank.pt'%target_category))\n",
    "\n",
    "target_edges_df = minmax_normalize_ranks_df(target_edges_df,params,weight=False)\n",
    "\n",
    "weight_edges_df = pd.read_csv('prepped_models/%s/ranks/weight_edges_ranks.csv'%prepped_model_folder)\n",
    "  \n",
    "weight_edges_df = minmax_normalize_ranks_df(weight_edges_df,params,weight=True)    \n",
    "    \n",
    "edges_thresholded_df = get_thresholded_ranksdf(edge_threshold,rank_type,target_edges_df)\n",
    " \n",
    "    \n",
    "num_edges = len(target_edges_df)\n",
    "edges_df_columns = list(target_edges_df.columns)\n",
    "\n",
    "edge_positions, edge_colors, edge_widths, edge_weights, edge_names, max_edge_width_indices = gen_edge_graphdata(edges_thresholded_df, node_positions, rank_type, target_category,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading convolutional kernels\n"
     ]
    }
   ],
   "source": [
    "#Load Edge Kernels\n",
    "print('loading convolutional kernels')\n",
    "kernels = torch.load('prepped_models/%s/kernels.pt'%prepped_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Image names\n",
    "params['input_image_directory'] = prep_model_params.input_img_path+'/'\n",
    "params['input_image_list'] = os.listdir(params['input_image_directory'])\n",
    "params['input_image_list'].sort()\n",
    "input_image_name = params['input_image_list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features_-1',\n",
       "              OrderedDict([('j', 1.0),\n",
       "                           ('r', 1.0),\n",
       "                           ('start', 0.5),\n",
       "                           ('conv_stage', True),\n",
       "                           ('output_shape', [-1, 3, 224, 224])])),\n",
       "             ('features_0',\n",
       "              OrderedDict([('j', 4.0),\n",
       "                           ('r', 11.0),\n",
       "                           ('start', 3.5),\n",
       "                           ('input_shape', [-1, 3, 224, 224]),\n",
       "                           ('output_shape', [-1, 64, 55, 55])])),\n",
       "             ('features_1',\n",
       "              OrderedDict([('j', 4.0),\n",
       "                           ('r', 11.0),\n",
       "                           ('start', 3.5),\n",
       "                           ('input_shape', [-1, 64, 55, 55]),\n",
       "                           ('output_shape', [-1, 64, 55, 55])])),\n",
       "             ('features_2',\n",
       "              OrderedDict([('j', 8.0),\n",
       "                           ('r', 19.0),\n",
       "                           ('start', 7.5),\n",
       "                           ('input_shape', [-1, 64, 55, 55]),\n",
       "                           ('output_shape', [-1, 64, 27, 27])])),\n",
       "             ('features_3',\n",
       "              OrderedDict([('j', 8.0),\n",
       "                           ('r', 51.0),\n",
       "                           ('start', 7.5),\n",
       "                           ('input_shape', [-1, 64, 27, 27]),\n",
       "                           ('output_shape', [-1, 192, 27, 27])])),\n",
       "             ('features_4',\n",
       "              OrderedDict([('j', 8.0),\n",
       "                           ('r', 51.0),\n",
       "                           ('start', 7.5),\n",
       "                           ('input_shape', [-1, 192, 27, 27]),\n",
       "                           ('output_shape', [-1, 192, 27, 27])])),\n",
       "             ('features_5',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 67.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 192, 27, 27]),\n",
       "                           ('output_shape', [-1, 192, 13, 13])])),\n",
       "             ('features_6',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 99.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 192, 13, 13]),\n",
       "                           ('output_shape', [-1, 384, 13, 13])])),\n",
       "             ('features_7',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 99.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 384, 13, 13]),\n",
       "                           ('output_shape', [-1, 384, 13, 13])])),\n",
       "             ('features_8',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 131.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 384, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_9',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 131.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_10',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 163.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_11',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 163.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_12',\n",
       "              OrderedDict([('j', 32.0),\n",
       "                           ('r', 195.0),\n",
       "                           ('start', 31.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 6, 6])])),\n",
       "             ('input_size', (3, 224, 224))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields = None\n",
    "if os.path.exists('prepped_models/%s/receptive_fields.pkl'%prepped_model_folder):\n",
    "    receptive_fields = pickle.load(open('prepped_models/%s/receptive_fields.pkl'%prepped_model_folder,'rb'))\n",
    "    \n",
    "input_image_size = 224   #got to figure out a way not to hard-code this\n",
    "receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading activation maps\n"
     ]
    }
   ],
   "source": [
    "#Format Node Feature Maps\n",
    "print('loading activation maps')\n",
    "\n",
    "all_activations = {'nodes':{},'edges_in':{},'edges_out':{}}\n",
    "if os.path.exists('prepped_models/%s/input_img_activations.pt'%prepped_model_folder):\n",
    "    all_activations = torch.load('prepped_models/%s/input_img_activations.pt'%prepped_model_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden state, stores python values within the html itself\n",
    "state = {'projection':projection,'rank_type':rank_type,'edge_positions':edge_positions,'edge_colors': edge_colors, 'edge_widths':edge_widths,'edge_names':edge_names,\n",
    "         'edge_threshold':edge_threshold,'edge_weights':edge_weights,'max_edge_width_indices':max_edge_width_indices,\n",
    "         'node_positions':node_positions,'node_colors':node_colors,'node_weights':node_weights,'node_threshold':node_threshold,'target_category':target_category,'target_node':'loss',\n",
    "         'node_select_history':['0'],'edge_select_history':[edge_names[0][0]],'last_trigger':None,'input_image_name':input_image_name,\n",
    "         'imgnode_positions':params['imgnode_positions'],'imgnode_colors':params['imgnode_colors'],'imgnode_names':params['imgnode_names']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#App Component Layouts\n",
    "axis=dict(showbackground=False,\n",
    "          showspikes=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          #range=[0,0],\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=-1.00, y=-1.25, z=1.25)\n",
    ")\n",
    "\n",
    "\n",
    "network_graph_layout = go.Layout(\n",
    "         #title=\"%s through Prunned Cifar10 CNN\"%target_category,\n",
    "         #title = target_category,\n",
    "         #width=1000,\n",
    "         clickmode = 'event+select',\n",
    "         transition = {'duration': 20},\n",
    "         height=500,\n",
    "         #showlegend=False,\n",
    "         margin = dict(l=20, r=20, t=20, b=20),\n",
    "         scene=dict(\n",
    "             xaxis=dict(axis),\n",
    "             yaxis=dict(axis),\n",
    "             zaxis=dict(axis),\n",
    "             aspectmode =\"manual\", \n",
    "             aspectratio = dict(x=1, y=0.5, z=0.5) #adjusting this stretches the network layer-to-layer\n",
    "         ),\n",
    "         scene_camera = camera,\n",
    "         uirevision =  True   \n",
    "         #hovermode='closest',\n",
    "   )\n",
    "\n",
    "\n",
    "input_image_layout = go.Layout(#width=200, \n",
    "                      #height=200,\n",
    "                      uirevision = True,\n",
    "                      margin=dict(\n",
    "                        l=12,\n",
    "                        r=1,\n",
    "                        b=12,\n",
    "                        t=1,\n",
    "                        pad=10\n",
    "                        ),\n",
    "                        paper_bgcolor='rgba(0,0,0,0)',\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',\n",
    "                        xaxis=dict(range=(0,10),showline=False,showgrid=False,showticklabels=False),\n",
    "                        yaxis=dict(range=(0,10),showline=False,showgrid=False,showticklabels=False))\n",
    "\n",
    "\n",
    "node_actmap_layout = go.Layout(\n",
    "    #autosize=False,\n",
    "    #width=270,\n",
    "    #height=200,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=1,\n",
    "        pad=1\n",
    "    ))\n",
    "\n",
    "\n",
    "edge_inmap_layout = go.Layout(\n",
    "    #title = 'edge input map',\n",
    "    #autosize=False,\n",
    "    #width=270,\n",
    "    #height=200,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=10,\n",
    "        pad=1\n",
    "    ))\n",
    "\n",
    "\n",
    "edge_outmap_layout = go.Layout(\n",
    "    #title = 'edge output map',\n",
    "    #autosize=False,\n",
    "    #width=270,\n",
    "    #height=200,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=10,\n",
    "        pad=1\n",
    "    ))\n",
    "\n",
    "\n",
    "kernel_layout = go.Layout(\n",
    "    #title='kernel'\n",
    "    #autosize=False,\n",
    "    #width=180,\n",
    "    #height=120,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=1,\n",
    "        pad=1\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building graph from browser \"state\"\n"
     ]
    }
   ],
   "source": [
    "#Generate Network Graph\n",
    "combined_traces = gen_networkgraph_traces(state,params)\n",
    "network_graph_fig=go.Figure(data=combined_traces, layout=network_graph_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up dash app\n"
     ]
    }
   ],
   "source": [
    "#Dash App Setup\n",
    "print('setting up dash app')\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_daq as daq\n",
    "from dash.exceptions import PreventUpdate\n",
    "#import utils.dash_reusable_components as drc\n",
    "import flask\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from flask_caching import Cache\n",
    "\n",
    "#external_stylesheets = ['https://codepen.io/amyoshino/pen/jzXypZ.css']\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(external_stylesheets = external_stylesheets)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(full_prepped_model_folder+'/cache/'):\n",
    "    os.mkdir(full_prepped_model_folder+'/cache/')\n",
    "CACHE_CONFIG = {\n",
    "    # try 'filesystem' if you don't want to setup redis\n",
    "    'CACHE_TYPE': 'filesystem',\n",
    "    'CACHE_DIR': full_prepped_model_folder+'/cache/'}\n",
    "cache = Cache()\n",
    "cache.init_app(app.server, config=CACHE_CONFIG)\n",
    "    \n",
    "\n",
    "\n",
    "styles = {\n",
    "    'pre': {\n",
    "        'border': 'thin lightgrey solid',\n",
    "        'overflowX': 'scroll'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "theme =  {\n",
    "    'dark': True,\n",
    "    'detail': '#007439',\n",
    "    'primary': '#00EA64',\n",
    "    'secondary': '#6E6E6E',\n",
    "}\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "        html.Div(\n",
    "            children = [\n",
    "                \n",
    "            html.Div(\n",
    "                #Left side control panel\n",
    "                children = [\n",
    "                 html.Label('Subgraph Controls', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "                 html.Br(),\n",
    "                 html.Label('Input'),\n",
    "                 #dcc.Dropdown(\n",
    "                 #  id='weight-category',\n",
    "                 #  options=[{'label': i, 'value': i} for i in params['categories']],\n",
    "                 #   value=target_category\n",
    "                 #   ),\n",
    "                dcc.Input(id='input-category',value=state['target_category']),\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.Label('Output'),\n",
    "                 #dcc.Dropdown(\n",
    "                 #  id='weight-category',\n",
    "                 #  options=[{'label': i, 'value': i} for i in params['categories']],\n",
    "                 #   value=target_category\n",
    "                 #   ),\n",
    "                dcc.Dropdown(\n",
    "                    id='target-node',\n",
    "                    options=[\n",
    "                    {'label': i, 'value': i} for i in ['loss']+[str(node) for node in list(range(params['num_nodes']))]\n",
    "                    ],\n",
    "                    value=state['target_node']),\n",
    "                 html.Br(),\n",
    "                 html.Label('Subgraph Criterion'),\n",
    "                 dcc.Dropdown(\n",
    "                    id='subgraph-criterion',\n",
    "                    options=[\n",
    "                        {'label': 'Activations*Grads', 'value': 'actxgrad'},\n",
    "                        {'label': 'Activations', 'value': 'act'},\n",
    "                        {'label': 'Gradients', 'value': 'grad'},\n",
    "                        {'label': 'Weights', 'value': 'weight'},\n",
    "                        {'label': 'Hierarchical', 'value': 'hierarchical'}\n",
    "                        \n",
    "                    ],\n",
    "                    value='actxgrad'\n",
    "                    ),\n",
    "                 html.Br(),   \n",
    "                 html.Label('Layer Projection'),\n",
    "                 dcc.Dropdown(\n",
    "                    id = 'layer-projection',\n",
    "                    options=[\n",
    "                        {'label': 'MDS', 'value': 'MDS'},\n",
    "                        {'label': 'MDS smooth', 'value': 'MDS smooth'},\n",
    "                        {'label': 'Grid', 'value': 'Grid'},\n",
    "                        #{'label': 'SOM', 'value': 'SOM'}\n",
    "                    ],\n",
    "                    value='MDS smooth'\n",
    "                    ),\n",
    "\n",
    "                html.Br(),\n",
    "                html.Label('Edge Thresholds'),\n",
    "                    dcc.RangeSlider(\n",
    "                        id='edge-thresh-slider',\n",
    "                        min=0,\n",
    "                        max=np.ceil(params['max_edge_weight']*10)/10,\n",
    "                        step=0.001,\n",
    "                        marks={i/10: str(i/10) for i in range(0,int(np.ceil(params['max_edge_weight']*10))+1,int(round(np.ceil(params['max_edge_weight']*10)/5)))},\n",
    "                        value=edge_threshold,\n",
    "                    ),\n",
    "                html.Label('Node Thresholds'),\n",
    "                    dcc.RangeSlider(\n",
    "                        id='node-thresh-slider',\n",
    "                        min=0,\n",
    "                        max=1,\n",
    "                        step=0.001,\n",
    "                        marks={i/10: str(i/10.0) for i in range(0,11)},\n",
    "                        value=node_threshold,\n",
    "                    ),\n",
    "\n",
    "                ], className=\"two columns\",\n",
    "                ),\n",
    "                \n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='network-graph',\n",
    "                    figure=network_graph_fig\n",
    "                )\n",
    "                ], className= 'ten columns'\n",
    "                ),\n",
    "            ], className=\"row\"\n",
    "        ),\n",
    "\n",
    "\n",
    "                \n",
    "        html.Div([\n",
    "            html.Div([\n",
    "            html.Label('Input Image', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            dcc.Dropdown(id=\"dynamic-input-image-dropdown\",value=params['input_image_list'][0]),\n",
    "            #dcc.Dropdown(\n",
    "            #    id='input-image-dropdown',\n",
    "            #    options=[{'label': i, 'value': i} for i in params['input_image_list']+os.listdir(params['prepped_model_path']+'/visualizations/images/')],\n",
    "            #    value=input_image_name\n",
    "            #),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='img-actmap-graph',\n",
    "                style={\n",
    "               'width': '14vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=image2heatmap(params['input_image_directory']+input_image_name,input_image_layout),\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            )\n",
    "            ], className = \"two columns\"),\n",
    "\n",
    "            html.Div([\n",
    "            html.Label('Node', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            dcc.Dropdown(\n",
    "                id='node-actmap-dropdown',\n",
    "                options=[{'label': str(j), 'value': str(j)} for j in params['imgnode_names']]+[{'label': str(i), 'value': str(i)} for i in range(params['num_nodes'])],\n",
    "                value='0'\n",
    "            ),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='node-actmap-graph',\n",
    "                style={\n",
    "               'width': '18vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            dcc.Checklist(\n",
    "                id = 'relu-checkbox',\n",
    "                options = [{'label':'relu','value':'relu'}],\n",
    "                value = []\n",
    "                \n",
    "            ),\n",
    "            html.Div(id='node-sum', style={'whiteSpace': 'pre-line'}),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='node-deepviz-image',\n",
    "                style={\n",
    "               'width': '14vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            )\n",
    "            ], className = \"three columns\"),\n",
    "            \n",
    "            html.Div([\n",
    "            html.Label('Node Inputs', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            html.Br(),\n",
    "            html.Div(dcc.Graph(\n",
    "                id='node-inputs-graph',\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),style={'overflowY': 'scroll', 'height': 500})\n",
    "            ], className = \"three columns\"),\n",
    "\n",
    "            html.Div([\n",
    "            html.Label('Edge', style={'fontSize': 18,'font-weight':'bold'}),    \n",
    "            dcc.Input(\n",
    "                id='edge-actmaps-input',value=state['edge_names'][0][0], type='text'),\n",
    "            #html.Button(id='edge-kernel-button',n_clicks=0, children='Submit'),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Label('Kernel'),\n",
    "            dcc.Graph(\n",
    "                id='edge-kernel-graph',\n",
    "                style={\n",
    "               'width': '14vw',\n",
    "               'height':'10vw'\n",
    "                },\n",
    "                figure=go.Figure(data=go.Heatmap(\n",
    "                                    z = edgename_2_edge_figures(state['edge_names'][0][0], input_image_name, kernels, None,params)[0]),\n",
    "                                 layout=kernel_layout\n",
    "                                ),\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "               id='edge-deepviz-image',\n",
    "               style={\n",
    "              'width': '14vw',\n",
    "              'height':'14vw'\n",
    "               },\n",
    "               figure=figure_init,\n",
    "               config={\n",
    "                       'displayModeBar': False\n",
    "                       }\n",
    "            )\n",
    "            ], className = \"two columns\"),\n",
    "\n",
    "\n",
    "            html.Div([\n",
    "            html.Label('Edge Input'),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='edge-inmap-graph',\n",
    "                style={\n",
    "               'width': '18vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            html.Div(id='edgein-sum', style={'whiteSpace': 'pre-line'}),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Label('Edge Output'),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='edge-outmap-graph',\n",
    "                style={\n",
    "               'width': '18vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            html.Div(id='edgeout-sum', style={'whiteSpace': 'pre-line'}),\n",
    "\n",
    "            ], className = \"two columns\")\n",
    "\n",
    "\n",
    "         ], className= 'row'\n",
    "         ),\n",
    "    \n",
    "    \n",
    "    html.Div([\n",
    "            html.Div([\n",
    "            html.Label('Image Manipulations', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            html.Br(),\n",
    "            html.Label('rotation'),\n",
    "            dcc.Slider(\n",
    "                id='image-rotation-slider',\n",
    "                min=0,\n",
    "                max=350,\n",
    "                step=10,\n",
    "                marks={\n",
    "                        0:   '0°',\n",
    "                        20:  '20°',\n",
    "                        40:  '40°',\n",
    "                        60:  '60°',\n",
    "                        80:  '80°',\n",
    "                        100: '100°',\n",
    "                        120: '120°',\n",
    "                        140: '140°',\n",
    "                        160: '160°',\n",
    "                        180: '180°',\n",
    "                        200: '200°',\n",
    "                        220: '220°',\n",
    "                        240: '240°',\n",
    "                        260: '260°',\n",
    "                        280: '280°',\n",
    "                        300: '300°',\n",
    "                        320: '320°',\n",
    "                        340: '240°',\n",
    "                        },\n",
    "                included=False,\n",
    "                value=0,\n",
    "            ),\n",
    "            html.Br(),\n",
    "            html.Label('scaling'),\n",
    "            dcc.Slider(\n",
    "                id='image-scaling-slider',\n",
    "                min=-10,\n",
    "                max=10,\n",
    "                step=1,\n",
    "                marks={\n",
    "                        -8:  '.33',\n",
    "                        -6:  '.4',\n",
    "                        -4: '.5',\n",
    "                        -2: '.67',\n",
    "                         0: '1',\n",
    "                         2: '1.5',\n",
    "                         4: '2',\n",
    "                         6: '2.5',\n",
    "                         8: '3',\n",
    "                        },\n",
    "                included=False,\n",
    "                value=0,\n",
    "            ),            \n",
    "            html.Br(),\n",
    "            html.Label('colors'),\n",
    "\n",
    "                    html.Label('R',style={'fontSize': 10,'font-weight':'italic'}),\n",
    "                    dcc.Slider(\n",
    "                        id='image-r-slider',\n",
    "                        min=-1,\n",
    "                        max=1,\n",
    "                        step=.05,\n",
    "                        marks={\n",
    "                                -1:'-1',\n",
    "                                -.8:'-.8',\n",
    "                                -.6:'-.6',\n",
    "                                -.4:'-.4',\n",
    "                                 -.2:'-.2',\n",
    "                                 0:'0',\n",
    "                                 .2:'.2',\n",
    "                                 .4:'.4',\n",
    "                                 .6:'.6',\n",
    "                                 .8:'.8',\n",
    "                                  1:'1',\n",
    "                                },\n",
    "                        included=False,\n",
    "                        value=0,\n",
    "                    ),\n",
    " \n",
    "\n",
    "                    html.Label('G',style={'fontSize': 10,'font-weight':'italic'}),\n",
    "                    dcc.Slider(\n",
    "                        id='image-g-slider',\n",
    "                        min=-1,\n",
    "                        max=1,\n",
    "                        step=.05,\n",
    "                        marks={\n",
    "                                -1:'-1',\n",
    "                                -.8:'-.8',\n",
    "                                -.6:'-.6',\n",
    "                                -.4:'-.4',\n",
    "                                 -.2:'-.2',\n",
    "                                 0:'0',\n",
    "                                 .2:'.2',\n",
    "                                 .4:'.4',\n",
    "                                 .6:'.6',\n",
    "                                 .8:'.8',\n",
    "                                  1:'1',\n",
    "                                },\n",
    "                        included=False,\n",
    "                        value=0,\n",
    "                    ),\n",
    "    \n",
    "\n",
    "                    html.Label('B',style={'fontSize': 10,'font-weight':'italic'}),\n",
    "                    dcc.Slider(\n",
    "                        id='image-b-slider',\n",
    "                        min=-1,\n",
    "                        max=1,\n",
    "                        step=.05,\n",
    "                        marks={\n",
    "                                -1:'-1',\n",
    "                                -.8:'-.8',\n",
    "                                -.6:'-.6',\n",
    "                                -.4:'-.4',\n",
    "                                 -.2:'-.2',\n",
    "                                 0:'0',\n",
    "                                 .2:'.2',\n",
    "                                 .4:'.4',\n",
    "                                 .6:'.6',\n",
    "                                 .8:'.8',\n",
    "                                  1:'1',\n",
    "                                },\n",
    "                        included=False,\n",
    "                        value=0,\n",
    "                    )\n",
    "           \n",
    "            ], className = \"three columns\"),\n",
    "                \n",
    "                \n",
    "            html.Div([\n",
    "            html.Label('Feature Visualizations', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            html.Br(),\n",
    "            html.Div( style=dict(display='flex'),\n",
    "                children = [     \n",
    "                    daq.ToggleSwitch(\n",
    "                        id='featviz-nodeedge-toggle',\n",
    "                        label=['node','edge    '],\n",
    "                        style={'float': 'right','margin': 'auto'}\n",
    "                        #labelPosition='bottom'\n",
    "                    ), \n",
    "                    html.Label(''),\n",
    "                    daq.ToggleSwitch(\n",
    "                        id='featviz-channelneuron-toggle',\n",
    "                        label=['channel','neuron    '],\n",
    "                        style={'float': 'right','margin': 'auto'}\n",
    "                        #labelPosition='bottom'\n",
    "                    ),\n",
    "                    html.Label(''),\n",
    "                    daq.ToggleSwitch(\n",
    "                        id='featviz-positivenegative-toggle',\n",
    "                        label=['positive','negative    '],\n",
    "                        style={'float': 'right','margin': 'auto'}\n",
    "                        #labelPosition='bottom'\n",
    "                    )\n",
    "                ]),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "               id='featviz-image',\n",
    "               style={\n",
    "              'width': '14vw',\n",
    "              'height':'14vw'\n",
    "               },\n",
    "               figure=figure_init,\n",
    "               config={\n",
    "                       'displayModeBar': False\n",
    "                       }\n",
    "            ),\n",
    "            html.Button('Generate', id='featviz-button')\n",
    "            #html.Button('Generate', id='gen-featviz-button')\n",
    "            ], className= \"five columns\"),\n",
    "        \n",
    "        \n",
    "        \n",
    "            html.Div([\n",
    "            html.Label('Model Ablations', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            dcc.Textarea(\n",
    "                id='ablations-textarea',\n",
    "                value='',\n",
    "                style={'width': '70%', 'height': 300}),\n",
    "            html.Button('Ablate', id='ablate-model-button')\n",
    "            ], className= \"four columns\"),\n",
    "        \n",
    "        ], className=\"row\"\n",
    "        ),\n",
    "                \n",
    "#         html.Div([\n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Hover Data**\n",
    "\n",
    "#                     Mouse over values in the graph.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='hover-data', style=styles['pre'])\n",
    "#             ], className='two columns'),\n",
    "\n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Click Data**\n",
    "\n",
    "#                     Click on points in the graph.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='click-data', style=styles['pre']),\n",
    "#             ], className='two columns'),\n",
    "\n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Selection Data**\n",
    "\n",
    "#                     Choose the lasso or rectangle tool in the graph's menu\n",
    "#                     bar and then select points in the graph.\n",
    "\n",
    "#                     Note that if `layout.clickmode = 'event+select'`, selection data also \n",
    "#                     accumulates (or un-accumulates) selected data if you hold down the shift\n",
    "#                     button while clicking.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='selected-data', style=styles['pre']),\n",
    "#             ], className='two columns'),\n",
    "\n",
    "# #                 html.Div([\n",
    "# #                     dcc.Markdown(\"\"\"\n",
    "# #                         **Zoom and Relayout Data**\n",
    "\n",
    "# #                         Click and drag on the graph to zoom or click on the zoom\n",
    "# #                         buttons in the graph's menu bar.\n",
    "# #                         Clicking on legend items will also fire\n",
    "# #                         this event.\n",
    "# #                     \"\"\"),\n",
    "# #                     html.Pre(id='relayout-data', style=styles['pre']),\n",
    "# #                 ], className='two columns')\n",
    "                \n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Figure Data**\n",
    "\n",
    "#                     Figure json info.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='figure-data', style=styles['pre']),\n",
    "#             ], className='four columns')\n",
    "\n",
    "#         ], className= 'row'\n",
    "#         ),\n",
    "\n",
    "    #hidden divs for storing intermediate values     \n",
    "    # The memory store reverts to the default on every page refresh\n",
    "    dcc.Store(id='memory',data=state),\n",
    "    # The local store will take the initial data\n",
    "    # only the first time the page is loaded\n",
    "    # and keep it until it is cleared.\n",
    "    #dcc.Store(id='local', storage_type='local'),\n",
    "    # Same as the local store but will lose the data\n",
    "    # when the browser/tab closes.\n",
    "    #dcc.Store(id='session', storage_type='session',data=state),\n",
    "    \n",
    "\n",
    "    # hidden signal value\n",
    "    html.Div(id='input-image-signal',  style={'display': 'none'}),\n",
    "    html.Div(id='target-signal', style={'display': 'none'},children = [state['target_category'],state['target_node']]),\n",
    "    html.Div(id='ablations-signal',  style={'display': 'none'}, children = [])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# perform expensive computations in this \"global store\"\n",
    "# these computations are cached in a globally available\n",
    "# 'cached' folder in the prepped_models/[model] folder\n",
    "@cache.memoize()\n",
    "def activations_store(image_name,ablation_list):\n",
    "\n",
    "    print('Updating cached activations with {}'.format(image_name))\n",
    "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
    "    \n",
    "    return activations\n",
    "\n",
    "@app.callback(Output('input-image-signal', 'children'), \n",
    "              [Input('dynamic-input-image-dropdown', 'value'),\n",
    "               Input('ablations-signal', 'children')])\n",
    "def update_activations_store(image_name,ablation_list):\n",
    "    # compute value and send a signal when done\n",
    "    activations_store(image_name,ablation_list)\n",
    "    return image_name\n",
    "\n",
    "\n",
    "@cache.memoize()\n",
    "def ranksdf_store(target_category, target_node,ablation_list,model_dis=model_dis):\n",
    "    print('Updating cached rank dfs with {}'.format(target_category))\n",
    "    model_dis = clear_ranks_across_model(model_dis)\n",
    "    target_type = image_category_or_contrast(target_category,params)\n",
    "    target_category_nodes_df = None\n",
    "    target_category_edges_df = None\n",
    "    if target_type == 'category' and target_node == 'loss' and ablation_list == []:\n",
    "        #edges\n",
    "        if categories_edges_df is not None:\n",
    "            if len(categories_edges_df.loc[categories_edges_df['category']==target_category]) > 0:\n",
    "                target_category_edges_df = categories_edges_df.loc[categories_edges_df['category']==target_category]\n",
    "        if target_category_edges_df is None:\n",
    "            target_category_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','%s_edges_rank.pt'%target_category))   \n",
    "        #node\n",
    "        if categories_nodes_df is not None:\n",
    "            if len(categories_nodes_df.loc[categories_nodes_df['category']==target_category]) > 0:\n",
    "                target_category_nodes_df = categories_nodes_df.loc[categories_nodes_df['category']==target_category]\n",
    "        if target_category_nodes_df is None:\n",
    "            target_category_nodes_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_nodes','%s_nodes_rank.pt'%target_category))\n",
    "    elif target_type == 'category':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
    "    elif target_type == 'input_image':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_from_image(get_image_path(target_category,params)[1],target_node, model_dis, params))\n",
    "\n",
    "    else:  #contrast\n",
    "        target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
    "    #print('FROM RANKS DF STORE')\n",
    "    print(target_category_edges_df)\n",
    "    return target_category_nodes_df,target_category_edges_df\n",
    "\n",
    "@app.callback(Output('target-signal', 'children'), \n",
    "              [Input('input-category', 'value'),\n",
    "               Input('target-node','value'),\n",
    "               Input('ablations-signal', 'children')])\n",
    "def update_ranksdf_store(target_category,target_node,ablation_list):\n",
    "    # compute value and send a signal when done\n",
    "    print('update ranksdf_store triggered')\n",
    "    ranksdf_store(target_category,target_node,ablation_list)\n",
    "    return [target_category,target_node]\n",
    "\n",
    "\n",
    "\n",
    "####Call Back Functions\n",
    "\n",
    "#Ablations\n",
    "@app.callback(Output('ablations-signal', 'children'), \n",
    "              [Input('ablate-model-button', 'n_clicks')],\n",
    "              [State('ablations-textarea','value')])\n",
    "def update_ablations(n_clicks,text,model_dis=model_dis):\n",
    "    # compute value and send a signal when done\n",
    "    ablation_list = ablation_text_2_list(text, params)\n",
    "    ablate_model_with_list(ablation_list,model_dis,params)\n",
    "    return ablation_list\n",
    "\n",
    "\n",
    "#Hidden State\n",
    "@app.callback(\n",
    "    Output('memory', 'data'),\n",
    "    [Input('target-signal', 'children'),\n",
    "     Input('node-actmap-dropdown', 'value'),\n",
    "     Input('edge-actmaps-input', 'value'),\n",
    "     Input('edge-thresh-slider','value'),\n",
    "     Input('node-thresh-slider','value'),\n",
    "     Input('layer-projection','value'),\n",
    "     Input('subgraph-criterion','value')],\n",
    "    [State('memory', 'data'),\n",
    "     State('ablations-signal', 'children')])\n",
    "def update_store(target,node_value,edge_value,edge_threshold,node_threshold,projection,rank_type,state,ablation_list):\n",
    "    print('CALLED: update_store\\n')\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        raise Exception('no figure updates yet')\n",
    "    else:\n",
    "        trigger = ctx.triggered[0]['prop_id']\n",
    "    state['last_trigger'] = trigger  #store the last trigger of state change in state\n",
    "    print('TRIGGER %s'%trigger)\n",
    "    \n",
    "    hierarchical = False\n",
    "    if rank_type == 'hierarchical':\n",
    "        hierarchical = True\n",
    "        rank_type = 'actxgrad'\n",
    "        \n",
    "    target_category,target_node = target[0],target[1]\n",
    "    #fetch select edges DF\n",
    "    if trigger in ['target-signal.children','edge-thresh-slider.value','node-thresh-slider.value','layer-projection.value','subgraph-criterion.value']:\n",
    "        if rank_type == 'weight':\n",
    "            target_edges_df = weight_edges_df\n",
    "            target_nodes_df = weight_nodes_df\n",
    "            weight=True\n",
    "        else:   \n",
    "            target_nodes_df,target_edges_df = ranksdf_store(target_category,target_node,ablation_list)\n",
    "            weight=False   \n",
    "        target_edges_df = minmax_normalize_ranks_df(target_edges_df,params,weight=weight)\n",
    "        target_nodes_df = minmax_normalize_ranks_df(target_nodes_df,params,weight=weight)\n",
    "\n",
    "        if hierarchical:\n",
    "            #nodes_thresholded_df = get_thresholded_ranksdf(node_threshold,rank_type, target_nodes_df)\n",
    "            #filter_edges_df = filter_edges_by_nodes(target_edges_df,nodes_thresholded_df)\n",
    "            #edges_thresholded_df = get_thresholded_ranksdf(edge_threshold,rank_type,filter_edges_df)\n",
    "            #edges_thresholded_df = hierarchically_threshold_edges(edge_threshold,rank_type,target_edges_df,nodes_thresholded_df)\n",
    "            print('finding hierarchical subgraph')\n",
    "            start = time.time()\n",
    "            nodes_thresholded_df,edges_thresholded_df = hierarchical_accum_threshold(node_threshold[0],edge_threshold[0],rank_type,target_edges_df,target_nodes_df,ascending=False)\n",
    "            print('time: %s'%str(time.time() - start))\n",
    "            print('found %s nodes and %s edges'%(str(len(nodes_thresholded_df)),str(len(edges_thresholded_df))))\n",
    "            #node_minmax = node_threshold\n",
    "            node_min = {}\n",
    "            for layer in target_nodes_df['layer'].unique():\n",
    "                if len(nodes_thresholded_df.loc[nodes_thresholded_df['layer']==layer]) > 1:\n",
    "                    node_min[layer] = nodes_thresholded_df.loc[nodes_thresholded_df['layer']==layer][rank_type+'_rank'].min()\n",
    "                else:\n",
    "                    node_min[layer] = None\n",
    "\n",
    "        else: \n",
    "            nodes_thresholded_df = None\n",
    "            edges_thresholded_df = get_thresholded_ranksdf(edge_threshold,rank_type,target_edges_df)\n",
    "            node_min = None\n",
    "\n",
    "    if trigger == 'target-signal.children':\n",
    "        print('changing target category to %s'%target_category)\n",
    "        #print(target_nodes_df)\n",
    "        state['node_colors'], state['node_weights'] = gen_node_colors(target_nodes_df,rank_type,params,node_min=node_min)\n",
    "        #state['max_edge_weight'] = get_max_edge_weight(target_category)\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'],state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "\n",
    "    elif trigger == 'node-actmap-dropdown.value' or trigger == 'edge-actmaps-input.value':\n",
    "        state['last_trigger'] = 'selection_change'\n",
    "        print(edge_value)\n",
    "        #update node if button value different than store value\n",
    "        if state['node_select_history'][-1] != node_value:\n",
    "            print('changing selected node to %s'%node_value)\n",
    "            state['node_select_history'].append(node_value)\n",
    "            if len(state['node_select_history']) > 10:\n",
    "                del state['node_select_history'][0] \n",
    "        #update edge if button value different than store value\n",
    "        if state['edge_select_history'][-1] != edge_value and check_edge_validity(edge_value.strip(),params)[0]:\n",
    "            print('changing selected edge to %s'%edge_value)\n",
    "            state['edge_select_history'].append(edge_value)\n",
    "            print(state['edge_select_history'])\n",
    "            if len(state['edge_select_history']) > 10:\n",
    "                del state['edge_select_history'][0]              \n",
    "\n",
    "    elif trigger == 'edge-thresh-slider.value':\n",
    "        print('changing edge thresholds to %s - %s'%(edge_threshold[0],edge_threshold[1]))\n",
    "        state['edge_threshold'] == edge_threshold\n",
    "        print('found %s edges'%len(edges_thresholded_df))\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'], state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "    \n",
    "    elif trigger == 'node-thresh-slider.value':\n",
    "        print('changing node thresholds to %s - %s'%(node_threshold[0],node_threshold[1]))\n",
    "        state['node_threshold'] == node_threshold\n",
    "        print('found %s nodes'%len(nodes_thresholded_df))\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'], state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "        state['node_colors'], state['node_weights'] = gen_node_colors(target_nodes_df,rank_type,params,node_min=node_min)\n",
    "        \n",
    "        \n",
    "    elif trigger == 'layer-projection.value':\n",
    "        print('changing layer projection to %s\\n'%projection)\n",
    "        state['projection']=projection\n",
    "        if projection == 'Grid':\n",
    "            node_positions = all_node_positions[projection]\n",
    "        else:\n",
    "            node_positions = all_node_positions[projection][rank_type]\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'],state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "\n",
    "    elif trigger == 'subgraph-criterion.value':\n",
    "        print('changing weighting criterion to %s\\n'%rank_type)\n",
    "        state['rank_type']=rank_type\n",
    "        state['node_colors'], state['node_weights'] = gen_node_colors(target_nodes_df,rank_type,params,node_min=node_min)\n",
    "        #state['node_positions']=format_node_positions(projection=projection,rank_type=rank_type)\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'],state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "\n",
    "    else:\n",
    "        raise Exception('unknown trigger: %s'%trigger)    \n",
    "    return state\n",
    "\n",
    "\n",
    "#Network Graph Figure\n",
    "@app.callback(\n",
    "    Output('network-graph', 'figure'),\n",
    "    [Input('memory', 'data')],\n",
    "    [State('network-graph','figure')])\n",
    "def update_figure(state, fig):\n",
    "    #network_graph_layout['uirevision'] = True\n",
    "    print('CALLED: update_figure\\n')\n",
    "    print(state['edge_threshold'])\n",
    "    print(state['edge_select_history'])\n",
    "    print(state['node_select_history'])\n",
    "    if state['last_trigger'] == 'selection_change':   #minimal updates\n",
    "        #hightlight edge\n",
    "        print('updating edge highlight to %s'%state['edge_select_history'][-1])\n",
    "        #if len(state['edge_select_history']) >1:\n",
    "        #if state['edge_select_history'][-1] != state['edge_select_history'][-2]:  #didnt click same point\n",
    "        flat_edge_names = [item for sublist in state['edge_names'] for item in sublist]\n",
    "        flat_edge_colors = [item for sublist in state['edge_colors'] for item in sublist]\n",
    "        try:  #update current edge if it exists to black\n",
    "            #print(flat_edge_names)\n",
    "            fig['data'][flat_edge_names.index(state['edge_select_history'][-1])+params['num_layers']+1]['line']['color'] = 'rgba(0,0,0,1)'\n",
    "        except:\n",
    "            print('select edge, %s,  not recolored as no longer shown'%state['edge_select_history'][-1])\n",
    "        if len(state['edge_select_history']) > 1: #there is a previous edge to unselect\n",
    "            try: #recolor previous edge if it exists from black\n",
    "                fig['data'][flat_edge_names.index(state['edge_select_history'][-2])+params['num_layers']+1]['line']['color'] = flat_edge_colors[flat_edge_names.index(state['edge_select_history'][-2])]\n",
    "            except:\n",
    "                print('previous edge, %s,  not recolored as no longer shown'%state['edge_select_history'][-2])\n",
    "        #highlight node\n",
    "        print('updating node highlight to %s'%state['node_select_history'][-1])\n",
    "        #if len(state['node_select_history']) >1:\n",
    "        #    if state['node_select_history'][-1] != state['node_select_history'][-2]: \n",
    "                #update current node color to black\n",
    "        if str(state['node_select_history'][-1]).isnumeric():  #if normal node\n",
    "            select_layer,select_position,select_layer_name = nodeid_2_perlayerid(state['node_select_history'][-1],params)\n",
    "            fig['data'][select_layer+1]['marker']['color'][select_position] = 'rgba(0,0,0,1)'\n",
    "        else:   #imgnode\n",
    "            fig['data'][0]['marker']['color'][fig['data'][0]['text'].index(state['node_select_history'][-1])] = 'rgba(0,0,0,1)'\n",
    "        #update previous node color to its usual color\n",
    "        if len(state['node_select_history']) > 1: #there is a previous node to unselect\n",
    "            if str(state['node_select_history'][-2]).isnumeric():  #if normal node\n",
    "                prev_select_layer,prev_select_position,prev_select_layer_name = nodeid_2_perlayerid(state['node_select_history'][-2],params)\n",
    "                print(prev_select_layer,prev_select_position,prev_select_layer_name)\n",
    "                fig['data'][prev_select_layer+1]['marker']['color'][prev_select_position] = state['node_colors'][prev_select_layer][prev_select_position]\n",
    "            else:   #imgnode\n",
    "                fig['data'][0]['marker']['color'][fig['data'][0]['text'].index(state['node_select_history'][-2])] = state['imgnode_colors'][fig['data'][0]['text'].index(state['node_select_history'][-2])]\n",
    "        #fig['layout']['uirevision']=True   \n",
    "        return fig    \n",
    "    else:   #regenerate full traces\n",
    "        combined_traces = gen_networkgraph_traces(state,params)\n",
    "        fig['data'] = combined_traces\n",
    "        #layout = network_graph_layout\n",
    "        #layout['uirevision'] = True\n",
    "        return fig\n",
    "\n",
    "#Node Actmap Dropdown\n",
    "@app.callback(\n",
    "    Output('node-actmap-dropdown', 'value'),\n",
    "    [Input('network-graph', 'clickData')],\n",
    "    [State('node-actmap-dropdown', 'value')])\n",
    "def switch_node_actmap_click(clickData,current_value):\n",
    "    print('CALLED: switch_node_actmap_click')\n",
    "    if clickData is None:\n",
    "        return current_value \n",
    "        #raise Exception('no click data')\n",
    "    if int(clickData['points'][0]['curveNumber']) > params['num_layers']:\n",
    "        return current_value\n",
    "        #raise Exception('edge was clicked')\n",
    "    return clickData['points'][0]['text']\n",
    "\n",
    "#Edge Actmaps Input\n",
    "@app.callback(\n",
    "    Output('edge-actmaps-input', 'value'),\n",
    "    [Input('network-graph', 'clickData')],\n",
    "    [State('edge-actmaps-input', 'value'),\n",
    "     State('memory', 'data')])\n",
    "def switch_edge_actmaps_click(clickData,current_value,state):\n",
    "    print('CALLED: switch_edge_actmaps_click')\n",
    "    if clickData is None:\n",
    "        return current_value\n",
    "        #raise Exception('no click data')\n",
    "    if int(clickData['points'][0]['curveNumber']) <= params['num_layers']:\n",
    "        return current_value\n",
    "        #raise Exception('node was clicked')\n",
    "    return get_nth_element_from_nested_list(state['edge_names'],int(clickData['points'][0]['curveNumber'])-(params['num_layers']+1))\n",
    "\n",
    "\n",
    "#Node actmap graph\n",
    "@app.callback(\n",
    "    Output('node-actmap-graph', 'figure'),\n",
    "    [Input('node-actmap-dropdown', 'value'),\n",
    "     Input('relu-checkbox','value'),\n",
    "     Input('input-image-signal', 'children')],\n",
    "    [State('ablations-signal', 'children')])\n",
    "def update_node_actmap(nodeid,relu_checked,image_name,ablation_list):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_node_actmap')\n",
    "    layer, within_id,layer_name = nodeid_2_perlayerid(nodeid,params)\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations  = activations_store(image_name,ablation_list)\n",
    "        \n",
    "    if layer == 'img': #code for returning color channel as activation map\n",
    "        #np_chan_im = get_channelwise_image(image_name,state['imgnode_names'].index(nodeid),params['input_image_directory']=params['input_image_directory'])\n",
    "        np_chan_im = activations['edges_in'][image_name][0][within_id]\n",
    "        return go.Figure(data=go.Heatmap( z = np.flip(np_chan_im,0), name = nodeid),\n",
    "                        layout=node_actmap_layout) \n",
    "    act_map = activations['nodes'][image_name][layer][within_id]\n",
    "    if relu_checked != []:\n",
    "        act_map = relu(act_map)\n",
    "    return go.Figure(data=go.Heatmap( z = np.flip(act_map,0),\n",
    "                                      #zmin=-11,\n",
    "                                      #zmax=14,\n",
    "                                      colorbar = dict(thicknessmode = \"fraction\",thickness=.1)\n",
    "                                    ),\n",
    "                     layout=node_actmap_layout) \n",
    "\n",
    "@app.callback(\n",
    "    Output('node-sum', 'children'),\n",
    "    [Input('node-actmap-graph', 'figure')])\n",
    "def update_node_sum(fig):\n",
    "    mean = np.mean(fig['data'][0]['z'])\n",
    "    return 'mean: %s'%str(mean)\n",
    "\n",
    "\n",
    "#Node deepviz graph\n",
    "@app.callback(\n",
    "    Output('node-deepviz-image', 'figure'),\n",
    "    [Input('node-actmap-dropdown', 'value')])\n",
    "def update_node_deepviz(nodeid):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_node_deepviz')\n",
    "    layer,within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)    \n",
    "    if layer == 'img': \n",
    "        return figure_init\n",
    "    image_name = fetch_deepviz_img(model,str(nodeid),params)\n",
    "    image_path = params['prepped_model_path']+'/visualizations/images/'+image_name\n",
    "    return image2plot(image_path,input_image_layout)\n",
    "    \n",
    "\n",
    "#Edge deepviz graph\n",
    "@app.callback(\n",
    "    Output('edge-deepviz-image', 'figure'),\n",
    "    [Input('edge-actmaps-input', 'value')])\n",
    "def update_edge_deepviz(edgename):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_edge_deepviz')\n",
    "    #layer,within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)    \n",
    "    #if layer == 'img': \n",
    "    #    return figure_init\n",
    "    image_name = fetch_deepviz_img(model_dis,edgename,params)\n",
    "    image_path = params['prepped_model_path']+'/visualizations/images/'+image_name\n",
    "    return image2plot(image_path,input_image_layout)\n",
    "     \n",
    "\n",
    "#Node inputs actmap graph\n",
    "@app.callback(\n",
    "    Output('node-inputs-graph', 'figure'),\n",
    "    [Input('node-actmap-dropdown', 'value'),\n",
    "     Input('input-image-signal', 'children'),\n",
    "     Input('target-signal', 'children'),\n",
    "     Input('subgraph-criterion','value')],\n",
    "     [State('ablations-signal', 'children')])\n",
    "def update_node_inputs(nodeid,image_name,target,rank_type,ablation_list,model=model_dis,max_num = params['max_node_inputs']):       \n",
    "    print('CALLED: update_node_inputs')\n",
    "    \n",
    "    hierarchical = False\n",
    "    if rank_type == 'hierarchical':\n",
    "        hierarchical = True\n",
    "        rank_type = 'actxgrad'\n",
    "    \n",
    "    \n",
    "    target_category,target_node = target[0],target[1]\n",
    "    node_layer,node_within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations = activations_store(image_name,ablation_list)\n",
    "    #fetch edges df\n",
    "    if rank_type == 'weight':\n",
    "        target_edges_df = weight_edges_df\n",
    "    else:\n",
    "        target_edges_df = ranksdf_store(target_category,target_node,ablation_list)[1]\n",
    "    #return no input if on input image node \n",
    "    if node_layer == 'img':\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[]))\n",
    "        fig.update_layout(xaxis=dict(visible=False),\n",
    "                          yaxis=dict(visible=False),\n",
    "                          annotations = [dict(text=\"No Inputs\",\n",
    "                                              xref=\"paper\",\n",
    "                                              yref=\"paper\",\n",
    "                                              showarrow=False,\n",
    "                                              font=dict(size=28))]\n",
    "                         )\n",
    "        return fig\n",
    "\n",
    "    all_node_edges_df = target_edges_df.loc[(target_edges_df['layer']==node_layer) & (target_edges_df['out_channel'] == node_within_layer_id)]\n",
    "    #if sort_images:                      \n",
    "    all_node_edges_df = all_node_edges_df.sort_values(by=[rank_type+'_rank'],ascending=False)\n",
    "    top_node_edges_df = all_node_edges_df.head(max_num)\n",
    "    fig = make_subplots(rows=len(top_node_edges_df)+1, cols=3)\n",
    "    #print(top_node_edges_df)\n",
    "    i=1\n",
    "    for row in top_node_edges_df.itertuples():\n",
    "        if node_layer == 0:\n",
    "            edge_name = str(params['imgnode_names'][row.in_channel])+'-'+str(nodeid)\n",
    "        else:\n",
    "            edge_name = str(params['layer_nodes'][node_layer-1][1][row.in_channel])+'-'+str(nodeid)\n",
    "        #add activation map\n",
    "        fig.add_trace(\n",
    "               go.Heatmap(z = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)[2],\n",
    "                          #zmin = -1,\n",
    "                          #zmax = 1,\n",
    "                          name = edge_name,\n",
    "                          coloraxis=\"coloraxis\"\n",
    "                          #showscale = False,\n",
    "                          #colorbar = dict(lenmode='fraction',len=1/len(top_node_edges_df), \n",
    "                          #                y=(i)/len(top_node_edges_df)-.01,\n",
    "                          #                thicknessmode = \"fraction\",thickness=.1,\n",
    "                          #                ypad=1\n",
    "                          #               )\n",
    "                          ),\n",
    "               row=i, col=2),\n",
    "        #add kernel\n",
    "        fig.add_trace(\n",
    "               go.Heatmap(z = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)[0],\n",
    "                          #zmin = -1,\n",
    "                          #zmax = 1,\n",
    "                          name = edge_name+'_kernel',\n",
    "                          coloraxis=\"coloraxis2\"\n",
    "                          #showscale = False,\n",
    "                          #colorbar = dict(lenmode='fraction',len=1/len(top_node_edges_df), \n",
    "                          #                y=(i)/len(top_node_edges_df)-.01,\n",
    "                          #                thicknessmode = \"fraction\",thickness=.1,\n",
    "                          #                ypad=1\n",
    "                          #               )\n",
    "                          ),\n",
    "               row=i, col=3),\n",
    "\n",
    "        #add visualization\n",
    "        viz_img_name = fetch_deepviz_img_for_node_inputs(model,edge_name,params)\n",
    "        viz_img_path = params['prepped_model_path']+'/visualizations/images/'+viz_img_name\n",
    "        viz_img = Image.open(viz_img_path)\n",
    "        #fig.add_trace(go.Image(z=viz_img,name=viz_img_name), row=i, col=1)\n",
    "        fig.add_trace(go.Scatter(x=[],y=[]),row=i,col=1)\n",
    "        fig.add_layout_image(\n",
    "                            source=viz_img,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"y\",\n",
    "                            x=0,\n",
    "                            y=10,\n",
    "                            sizex=10,\n",
    "                            sizey=10,\n",
    "                            sizing=\"stretch\",\n",
    "                            opacity=1,\n",
    "                            layer=\"below\",\n",
    "                            row=i, col=1\n",
    "                            )\n",
    "        fig.update_xaxes(visible=False,range=(0,10),showline=False,showgrid=False,showticklabels=False,row=i,col=1)\n",
    "        fig.update_yaxes(visible=False,range=(0,10),showline=False,showgrid=False,showticklabels=False,row=i,col=1)\n",
    "   \n",
    "\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    fig.update_layout(height=200*len(top_node_edges_df), \n",
    "                      width=340,\n",
    "                      #yaxis=dict(scaleanchor=\"x\", scaleratio=1/len(top_node_edges_df)),\n",
    "                      #title_text=\"Inputs to Node\",\n",
    "                      #xaxis=dict(visible=False),\n",
    "                      #yaxis=dict(visible=False),\n",
    "                      coloraxis_showscale=False,\n",
    "                      coloraxis2 = dict(showscale=False,\n",
    "                                        colorscale='inferno',\n",
    "                                        colorbar = dict(\n",
    "                                                        thicknessmode = \"fraction\",thickness=.05, \n",
    "                                                        lenmode='fraction',len=.7)),\n",
    "                      margin=dict(\n",
    "                                    l=0,\n",
    "                                    r=0,\n",
    "                                    b=0,\n",
    "                                    t=0,\n",
    "                                    pad=0)\n",
    "                     )\n",
    "    fig.update_coloraxes(colorscale='inferno',colorbar = dict(\n",
    "                                                              thicknessmode = \"fraction\",thickness=.05, \n",
    "                                                              lenmode='fraction',len=.7)\n",
    "                        )\n",
    "#     fig.update_coloraxes2(colorscale='inferno',colorbar = dict(\n",
    "#                                                               thicknessmode = \"fraction\",thickness=.05, \n",
    "#                                                               lenmode='fraction',len=.7)\n",
    "#                        )\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#image graph\n",
    "@app.callback(\n",
    "    Output('img-actmap-graph', 'figure'),\n",
    "    [Input('dynamic-input-image-dropdown', 'value'),\n",
    "     Input('node-actmap-graph','clickData'),\n",
    "     Input('node-actmap-graph','figure')],\n",
    "    [State('img-actmap-graph', 'figure'),\n",
    "     State('node-actmap-dropdown', 'value')])\n",
    "def update_inputimg_actmap(image_name,click_data,node_actmap_fig,image_fig,nodeid): \n",
    "    print('CALLED: update_inputimg_actmap')\n",
    "    #if os.path.exists(params['input_image_directory']+image_name):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        raise Exception('no figure updates yet')\n",
    "    else:\n",
    "        trigger = ctx.triggered[0]['prop_id']\n",
    "    if trigger == 'dynamic-input-image-dropdown.value':\n",
    "        return image2plot(get_image_path(image_name,params)[1],input_image_layout)\n",
    "    elif receptive_fields is None:\n",
    "        return image2plot(get_image_path(image_name,params)[1],input_image_layout)\n",
    "    elif click_data is None:\n",
    "        return image2plot(get_image_path(image_name,params)[1],input_image_layout)\n",
    "    else:\n",
    "        #nodeid = node_actmap_fig['data'][0]['name']\n",
    "        layer_name = nodeid_2_perlayerid(nodeid,params)[2]\n",
    "        if layer_name == 'img':\n",
    "            raise Exception('no receptive fields for input image actmap')\n",
    "        heatmap_dim_y = len(node_actmap_fig['data'][0]['z'])\n",
    "        heatmap_dim_x = len(node_actmap_fig['data'][0]['z'][0]) \n",
    "        x_click = click_data['points'][0]['x']\n",
    "        y_click = heatmap_dim_y - click_data['points'][0]['y']-1\n",
    "        print('x_click')\n",
    "        print(x_click)\n",
    "        print('y_click')\n",
    "        print(y_click)\n",
    "        recep_field = receptive_field_for_unit(receptive_fields, layer_name, (x_click,y_click))\n",
    "        recep_field_normed = [[recep_field[0][0]*10/input_image_size,recep_field[0][1]*10/input_image_size],\n",
    "                              [recep_field[1][0]*10/input_image_size,recep_field[1][1]*10/input_image_size]]\n",
    "        print('normalized')\n",
    "        print(recep_field_normed)\n",
    "        x_points = [recep_field_normed[0][0],recep_field_normed[0][0],recep_field_normed[0][1],recep_field_normed[0][1],recep_field_normed[0][0]]\n",
    "        y_points = [10 - recep_field_normed[1][0],10 - recep_field_normed[1][1],10 - recep_field_normed[1][1],10 - recep_field_normed[1][0],10 - recep_field_normed[1][0]]\n",
    "        print('x points')\n",
    "        print(x_points)\n",
    "        print('y points')\n",
    "        print(y_points)\n",
    "        image_fig['data'] = [{'mode': 'lines', 'x': x_points, 'y': y_points, 'type': 'scatter'}]\n",
    "        return image_fig\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #else:\n",
    "        #return image2plot(params['prepped_model_path']+'/visualizations/'+image_name,input_image_layout)\n",
    "    \n",
    "# #image dropdown\n",
    "# @app.callback(\n",
    "#     Output('input-image-dropdown', 'options'),\n",
    "#     [Input('node-deepviz-image', 'figure'),\n",
    "#      Input('edge-deepviz-image', 'figure')])\n",
    "# def update_inputimg_dropdown(node_fig,edge_fig): \n",
    "#     print('CALLED: update_inputimg_dropdown options')\n",
    "#     return [{'label': i, 'value': i} for i in params['input_image_list']+os.listdir(params['prepped_model_path']+'/visualizations/images/')]\n",
    "\n",
    "#dynamic dropdown\n",
    "@app.callback(\n",
    "    dash.dependencies.Output(\"dynamic-input-image-dropdown\", \"options\"),\n",
    "    [dash.dependencies.Input(\"dynamic-input-image-dropdown\", \"search_value\")],\n",
    ")\n",
    "def update_options(search_value):\n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    return [{'label': i, 'value': i} for i in params['input_image_list']+os.listdir(params['prepped_model_path']+'/visualizations/images/') if search_value in i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#kernel\n",
    "@app.callback(\n",
    "    Output('edge-kernel-graph', 'figure'),\n",
    "    [Input('edge-actmaps-input','value')],\n",
    "    [State('edge-kernel-graph','figure')])\n",
    "def update_edge_kernelmap(edge_name,figure):\n",
    "    print('CALLED: update_edge_kernelmap')\n",
    "    kernel,inmap,outmap = edgename_2_edge_figures(edge_name, None, kernels, None,params)\n",
    "    if kernel is not None:\n",
    "        return go.Figure(data=go.Heatmap(z = kernel,\n",
    "                                         #zmin=-.5,\n",
    "                                         #zmax=.5,\n",
    "                                         colorbar = dict(thicknessmode = \"fraction\",thickness=.1)),\n",
    "                         layout=kernel_layout)\n",
    "    else:\n",
    "        return figure\n",
    "                \n",
    "\n",
    "#edge in        \n",
    "@app.callback(\n",
    "    Output('edge-inmap-graph', 'figure'),\n",
    "    [Input('edge-actmaps-input','value'),\n",
    "     Input('input-image-signal', 'children')],\n",
    "    [State('edge-inmap-graph','figure'),\n",
    "     State('ablations-signal', 'children')])\n",
    "def update_edge_inmap(edge_name,image_name,figure,ablation_list):\n",
    "    print('CALLED: update_edge_inmap')\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations = activations_store(image_name, ablation_list)\n",
    "        \n",
    "    kernel,inmap,outmap = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)\n",
    "    if inmap is not None:\n",
    "        return go.Figure(data=go.Heatmap(z = inmap,\n",
    "                                         #zmin=-2,zmax=2,\n",
    "                                         colorbar = dict(thicknessmode = \"fraction\",thickness=.1)\n",
    "                                        ),\n",
    "                         layout=edge_inmap_layout)\n",
    "    else:\n",
    "        print('edge inmap error')\n",
    "        return figure\n",
    "\n",
    "@app.callback(\n",
    "    Output('edgein-sum', 'children'),\n",
    "    [Input('edge-inmap-graph', 'figure')])\n",
    "def update_node_sum(fig):\n",
    "    mean = np.mean(fig['data'][0]['z'])\n",
    "    return 'mean: %s'%str(mean)    \n",
    "\n",
    "#edge out\n",
    "@app.callback(\n",
    "    Output('edge-outmap-graph', 'figure'),\n",
    "    [Input('edge-actmaps-input','value'),\n",
    "     Input('input-image-signal', 'children')],\n",
    "    [State('edge-outmap-graph','figure'),\n",
    "     State('ablations-signal', 'children')])\n",
    "def update_edge_outmap(edge_name,image_name,figure, ablation_list):\n",
    "    print('CALLED: update_edge_outmap')\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations = activations_store(image_name,ablation_list)\n",
    "        \n",
    "    kernel,inmap,outmap = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)\n",
    "    if outmap is not None:\n",
    "        return go.Figure(data=go.Heatmap(z = outmap,\n",
    "                                         #zmin=-11,\n",
    "                                         #zmax=14,\n",
    "                                         colorbar = dict(thicknessmode = \"fraction\",thickness=.1)\n",
    "                                        ),\n",
    "                         layout=edge_outmap_layout)\n",
    "    else:\n",
    "        print('edge outmap error')\n",
    "        return figure\n",
    "        \n",
    "@app.callback(\n",
    "    Output('edgeout-sum', 'children'),\n",
    "    [Input('edge-outmap-graph', 'figure')])\n",
    "def update_node_sum(fig):\n",
    "    mean = np.mean(fig['data'][0]['z'])\n",
    "    return 'mean: %s'%str(mean)\n",
    "\n",
    "\n",
    " \n",
    "#feature viz graph\n",
    "@app.callback(\n",
    "    Output('featviz-image', 'figure'),\n",
    "    [Input('featviz-button','n_clicks')],\n",
    "    [State('featviz-nodeedge-toggle', 'value'),\n",
    "     State('featviz-channelneuron-toggle', 'value'),\n",
    "     State('node-actmap-dropdown','value'),\n",
    "     State('edge-actmaps-input','value')],\n",
    "    prevent_initial_call=True)\n",
    "def update_featviz_image(n_clicks,edge,neuron,nodeid,edgeid):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_featviz')\n",
    "    if edge:\n",
    "        image_name = regen_visualization(model_dis,edgeid,neuron,params)\n",
    "    else:\n",
    "        layer,within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)    \n",
    "        if layer == 'img': \n",
    "            return figure_init\n",
    "        image_name = regen_visualization(model_dis,nodeid,neuron,params)\n",
    "        \n",
    "    image_path = params['prepped_model_path']+'/visualizations/images/'+image_name\n",
    "    return image2plot(image_path,input_image_layout)\n",
    "\n",
    "\n",
    "# #JSON INFO\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('hover-data', 'children'),\n",
    "#     [Input('node-actmap-graph', 'hoverData')])\n",
    "# def display_hover_data(hoverData):\n",
    "#     return json.dumps(hoverData, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('click-data', 'children'),\n",
    "#     [Input('network-graph', 'clickData')])\n",
    "# def display_click_data(clickData):\n",
    "#     return json.dumps(clickData, indent=2)\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('selected-data', 'children'),\n",
    "#     [Input('network-graph', 'selectedData')])\n",
    "# def display_selected_data(selectedData):\n",
    "#     return json.dumps(selectedData, indent=2)\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('figure-data', 'children'),\n",
    "#     [Input('input-category', 'value'),\n",
    "#      Input('network-graph', 'clickData'),\n",
    "#      Input('edge-thresh-slider','value'),\n",
    "#      Input('memory','data')])\n",
    "# def display_trigger(target_category,clickData,edge_thresh,state):\n",
    "#     ctx = dash.callback_context\n",
    "#     if not ctx.triggered:\n",
    "#         raise Exception('no figure updates yet')\n",
    "#     else:\n",
    "#         trigger = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "#     ctx_msg = json.dumps({\n",
    "#         'states': ctx.states,\n",
    "#         'triggered': ctx.triggered,\n",
    "#         'inputs': ctx.inputs,\n",
    "#         'full_state':state\n",
    "#     }, indent=2)\n",
    "#     return ctx_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Subgraph Size DF\n",
    "\n",
    "\n",
    "# model_dis.to('cuda:1')\n",
    "# subgraph_sizes={}\n",
    "# start = time.time()\n",
    "# for node in range(256,1151):\n",
    "#     n_df,e_df=ranksdf_store('small_SPAN', str(node), [],model_dis=model_dis)\n",
    "#     n_df = minmax_normalize_ranks_df(n_df,params)\n",
    "#     threshed_n_df,threshed_e_df = hierarchical_accum_threshold(.9,.9,rank_type,e_df,n_df)\n",
    "#     subgraph_sizes[node] = (len(threshed_n_df),len(threshed_e_df))\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(subgraph_sizes,open('prepped_models/alexnet_sparse/subgraphs/info/subgraph_sizes_.9.9.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph_sizes = pickle.load(open('prepped_models/alexnet_sparse/subgraphs/info/subgraph_sizes_.9.9.pkl','rb'))\n",
    "\n",
    "# big_list = []\n",
    "# columns = ['node','layer','node_size','edge_size']\n",
    "# node_sizes = []\n",
    "# edge_sizes = []\n",
    "# for nodes in params['layer_nodes'][2:]:\n",
    "#     layer = nodes[0]\n",
    "#     for node in nodes[1]:\n",
    "#         try:\n",
    "#             node_size= subgraph_sizes[node][0]\n",
    "#             edge_size= subgraph_sizes[node][1]\n",
    "#             big_list.append([node,layer,node_size,edge_size])\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "        \n",
    "# subgraph_sizes_df = pd.DataFrame(big_list,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 255, 'features_10')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "nodeid_2_perlayerid(1151,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".9.9\n",
      "0.80.9\n",
      "0.60.8\n",
      "0.40.7\n",
      "0.20.6\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = {1:3*64+64,\n",
    "               2:3*64+64*192+192,\n",
    "               3:3*64+64*192+192*384+384,\n",
    "               4:3*64+64*192+192*384+384*256+256}\n",
    "\n",
    "\n",
    "subgraph_size_ratios = {\n",
    "                '.9.9':[],\n",
    "                '0.80.9':[],\n",
    "                '0.60.8':[],\n",
    "                '0.40.7':[],\n",
    "                '0.20.6':[]\n",
    "            }\n",
    "for size in subgraph_size_ratios:\n",
    "    print(size)\n",
    "    for node in range(64,1152):\n",
    "        try:\n",
    "            sub_dict_path = 'prepped_models/alexnet_sparse/subgraphs/models/%s_%s.pt'%(str(node),size)\n",
    "            submodel_dict = torch.load(sub_dict_path)\n",
    "            layer,within_layer_id,layer_name = nodeid_2_perlayerid(node,params)\n",
    "            subgraph_size_ratios[size].append(len(submodel_dict['edge_df'])/layer_sizes[layer])\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_size_ratios = []\n",
    "for size in subgraph_size_ratios:\n",
    "    average_size_ratios.append(np.mean(np.array(subgraph_size_ratios[size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2110308423689826,\n",
       " 0.14482404578884533,\n",
       " 0.059269118604168274,\n",
       " 0.024244886870054386,\n",
       " 0.009123183812157348]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_size_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating sized subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_sizes_from_df(df):\n",
    "    '''takes a df with a \"layer\" column and returns a list of layerwise sizes '''\n",
    "    layers = df['layer'].unique()\n",
    "    layers.sort()\n",
    "    output = []\n",
    "    for layer in layers:\n",
    "        output.append(len(df.loc[df['layer']==layer]))\n",
    "    return output\n",
    "\n",
    "#best_size_n_df,best_size_e_df = hierarchical_size_threshold(get_layer_sizes_from_df(sub_dict['node_df']),get_layer_sizes_from_df(sub_dict['edge_df']),rank_type,n_df,e_df,selection='worst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that runs\n",
    "\n",
    "def make_same_sized_subgraph(sub_dict_path,model,selection='random',node=None,save=False):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    sub_dict = torch.load(sub_dict_path)\n",
    "    if 'input' in sub_dict['gen_params'].keys():\n",
    "        inputs = sub_dict['gen_params']['input']\n",
    "    else:\n",
    "        inputs = 'small_SPAN'\n",
    "    if 'output' in sub_dict['gen_params'].keys():\n",
    "        output = int(sub_dict['gen_params']['output'])\n",
    "    elif node is None:\n",
    "        int(sub_dict_path.split('/')[-1].split('_')[0])\n",
    "    else:\n",
    "        output = int(node)\n",
    "    n_df,e_df=ranksdf_store(inputs, output, [], model_dis=model_dis)\n",
    "    n_df = minmax_normalize_ranks_df(n_df,params)\n",
    "    n_sizes = get_layer_sizes_from_df(sub_dict['node_df'])\n",
    "    e_sizes = get_layer_sizes_from_df(sub_dict['edge_df'])\n",
    "    size_n_df,size_e_df = hierarchical_size_threshold(n_sizes,e_sizes,rank_type,n_df,e_df,selection=selection)\n",
    "    size_model = extract_subgraph(model,size_n_df,size_e_df,params)\n",
    "    save_object = {\n",
    "                   'model':size_model,\n",
    "                   'gen_params':\n",
    "                        {'node_sizes':n_sizes,\n",
    "                         'edge_sizes':e_sizes,\n",
    "                         'input':inputs,\n",
    "                         'output':output,\n",
    "                         'selection':selection,\n",
    "                         'from_model':sub_dict_path\n",
    "                        },\n",
    "                    'node_df':size_n_df,\n",
    "                    'edge_df':size_e_df\n",
    "                  }\n",
    "    if save:\n",
    "        print('saving model to %s'%save)\n",
    "        torch.save(save_object,save)\n",
    "    return save_object\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"825\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.1005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.3161, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.0966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.7845, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-0.9672, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.3588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.1817, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "185\n",
      "tensor(-1.5101, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 825 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000007       0.000004  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/825_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/825_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"826\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.5102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.6744, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.6930, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.4741, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.7009, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.5185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(-0.7136, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "186\n",
      "tensor(0.0559, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 826 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000010  \n",
      "1        0.000005       0.000017  \n",
      "2        0.000005       0.000005  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/826_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/826_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"827\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(0.2717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-0.8873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-2.0726, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-0.2738, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-2.2139, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-1.7782, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-1.3679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "187\n",
      "tensor(-0.5046, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 827 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000021  \n",
      "1        0.000010       0.000037  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000014       0.000007  \n",
      "4        0.000014       0.000030  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/827_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/827_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"828\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-0.7416, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-0.7112, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-1.1948, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-0.6322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-0.7392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-1.1574, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-0.5358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "188\n",
      "tensor(-1.7141, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 828 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/828_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/828_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"829\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.6992, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.4409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-0.6272, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.0695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-0.8951, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.0296, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.2539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.4153, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000025  \n",
      "1        0.000011       0.000042  \n",
      "2        0.000011       0.000014  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/829_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"829\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-0.5551, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-0.7831, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.7184, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.5005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.2870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.2541, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-1.0821, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "189\n",
      "tensor(-0.2607, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 829 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000023  \n",
      "1         0.00001       0.000039  \n",
      "2         0.00001       0.000012  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000021  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/829_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"830\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(0.6660, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(0.3490, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(0.2269, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(0.6158, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(0.2693, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(0.5213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(1.1482, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "190\n",
      "tensor(1.1054, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 830 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/830_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/830_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"831\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(-0.8535, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(0.1926, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(-0.2181, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(-0.5308, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(0.0774, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(0.0232, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(0.0633, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "191\n",
      "tensor(0.5718, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 831 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000020  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/831_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/831_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"832\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-3.1957, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-2.8111, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-2.2364, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-1.5503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-1.5091, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-2.3014, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-2.0728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "192\n",
      "tensor(-2.4741, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 832 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/832_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/832_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"833\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-0.6253, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-0.4785, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-1.4580, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-0.6105, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-0.6473, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-0.7565, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(-0.5637, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "193\n",
      "tensor(0.6096, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 833 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000019  \n",
      "1        0.000010       0.000032  \n",
      "2        0.000010       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/833_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/833_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"834\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-0.6210, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-1.4303, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-0.0595, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-0.7880, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-0.3404, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-0.1950, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 834 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(-1.2327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "194\n",
      "tensor(0.3349, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 834 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000012  \n",
      "1        0.000005       0.000020  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/834_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/834_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"835\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-2.0275, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-1.1794, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-0.8761, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-0.8938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-1.5398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-0.8572, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-1.5083, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "195\n",
      "tensor(-2.0033, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 835 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/835_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/835_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"836\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-1.4289, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-0.7828, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-0.1346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-1.3189, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-1.9274, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-1.1126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(-0.5211, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "196\n",
      "tensor(1.6830, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 836 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/836_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/836_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"837\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-3.0462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-3.9751, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-2.9900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-3.8763, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-4.2235, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-2.9713, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-2.6789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "197\n",
      "tensor(-1.9339, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 837 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000014       0.000029  \n",
      "1        0.000014       0.000049  \n",
      "2        0.000014       0.000015  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/837_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/837_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"838\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-0.9903, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-3.1312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-2.8647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-1.3568, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-0.9559, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-1.8288, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-1.7112, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "198\n",
      "tensor(-2.5355, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 838 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000027  \n",
      "1        0.000012       0.000044  \n",
      "2        0.000012       0.000013  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000027  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/838_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/838_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"839\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-2.3251, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-3.1149, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-3.0895, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-3.2309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-1.6372, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-3.1622, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 839 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-3.7908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "199\n",
      "tensor(-1.6728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 839 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000022  \n",
      "1        0.000010       0.000037  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000029  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/839_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/839_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"840\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.7634, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.2808, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.7082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.0213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.6054, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.6869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.3936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "200\n",
      "tensor(-1.8687, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 840 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/840_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/840_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"841\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-2.5923, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-1.0448, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-3.9372, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-1.9392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-2.8282, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-1.4622, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-1.6873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "201\n",
      "tensor(-1.9619, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 841 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000026  \n",
      "1        0.000012       0.000044  \n",
      "2        0.000012       0.000013  \n",
      "3        0.000014       0.000007  \n",
      "4        0.000014       0.000032  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/841_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/841_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"842\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-1.5469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-2.0409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-1.8627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-2.0327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-1.7500, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-1.1746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-2.9140, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "202\n",
      "tensor(-3.2229, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 842 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/842_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/842_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"843\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-1.1152, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-2.2113, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-0.8286, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(0.0866, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-0.5680, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-1.2625, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-0.4501, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "203\n",
      "tensor(-4.8024, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 843 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000020  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/843_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/843_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"844\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-0.3746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-1.2698, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-0.7543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-0.7919, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-1.9095, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-1.9870, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 844 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-1.3701, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "204\n",
      "tensor(-7.2891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 844 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000020  \n",
      "1        0.000008       0.000033  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000005  \n",
      "4        0.000009       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/844_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/844_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"845\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-1.0419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-0.8525, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-1.7360, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-1.7989, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(0.0835, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-1.1978, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-2.0091, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "205\n",
      "tensor(-1.2312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 845 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/845_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/845_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"846\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-0.4803, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-0.7382, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-1.2950, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-1.3328, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-1.2205, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-0.6709, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-1.7229, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "206\n",
      "tensor(-0.0065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 846 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/846_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/846_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"847\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.2755, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.7499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.9037, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.0997, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.7946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.9259, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-1.2747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "207\n",
      "tensor(-2.0511, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 847 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/847_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/847_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"848\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-2.7430, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-3.7865, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-3.1561, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-4.3629, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-3.4830, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-2.1606, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-3.4262, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "208\n",
      "tensor(-2.1252, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 848 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000014       0.000032  \n",
      "1        0.000014       0.000053  \n",
      "2        0.000014       0.000016  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/848_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/848_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"849\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-7.1312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-4.7837, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-5.4341, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-4.4746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-5.6219, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-5.5074, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 849 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-5.5978, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "209\n",
      "tensor(-3.2382, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 849 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000025  \n",
      "1        0.000012       0.000044  \n",
      "2        0.000012       0.000013  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000028  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/849_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/849_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"850\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.3643, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(0.3751, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.2691, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-1.6213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-1.3980, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-1.5285, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.3342, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(0.5377, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/850_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"850\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.7150, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.6678, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-1.0372, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-1.4496, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.2132, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.2168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.7189, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "210\n",
      "tensor(-0.3152, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 850 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000030  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/850_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"851\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-2.6220, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-2.3152, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-2.7680, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-2.1468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-1.3230, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-2.4984, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-1.8108, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "211\n",
      "tensor(-2.1246, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 851 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000023  \n",
      "1        0.000011       0.000039  \n",
      "2        0.000011       0.000012  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/851_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/851_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"852\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-1.9641, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-2.2545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-2.7162, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-2.1533, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-2.0700, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-3.1387, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-2.6983, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "212\n",
      "tensor(-1.7919, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 852 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/852_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/852_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"853\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-0.7968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-1.0012, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-1.2716, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-0.4728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-0.5543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-0.2930, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(-0.2221, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 853 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "213\n",
      "tensor(0.1545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 853 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/853_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/853_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"854\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-4.3604, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-2.5895, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-2.5373, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-2.6625, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-2.2395, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-2.2885, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-0.5859, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "214\n",
      "tensor(-5.5382, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 854 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000027  \n",
      "1        0.000010       0.000044  \n",
      "2        0.000010       0.000013  \n",
      "3        0.000011       0.000006  \n",
      "4        0.000011       0.000026  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/854_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/854_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"855\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(-0.6279, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(-0.1080, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(-0.3131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(-0.9045, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(-0.2060, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(0.0024, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(-0.1443, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "215\n",
      "tensor(0.4462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 855 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/855_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/855_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"856\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(-0.0303, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(-0.0672, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(-0.0247, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(0.1553, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(-0.0949, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(0.2073, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(0.2073, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "216\n",
      "tensor(0.6788, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 856 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000012  \n",
      "1        0.000005       0.000020  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/856_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/856_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"857\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(-0.6119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(-0.0373, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(0.0989, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(0.2753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(0.0577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(-0.3160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(-0.1554, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "217\n",
      "tensor(-0.6298, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 857 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/857_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/857_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"858\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.5503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.8943, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.3026, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.3961, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.4580, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.8126, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 858 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.8965, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "218\n",
      "tensor(-0.0197, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 858 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000008  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/858_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/858_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"859\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(0.0770, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(-0.2941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(-0.1447, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(0.0187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(-0.1096, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(-0.4424, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(-0.5419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "219\n",
      "tensor(-1.6932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 859 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000036  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/859_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/859_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"860\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-1.1395, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-2.1772, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-1.3419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-1.0389, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-1.1219, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-2.4392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-1.7098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "220\n",
      "tensor(-0.8718, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 860 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000013       0.000029  \n",
      "1        0.000013       0.000050  \n",
      "2        0.000013       0.000016  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/860_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/860_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"861\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-0.7831, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-0.4268, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-0.7208, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-0.9492, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-0.8429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-1.8948, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(-2.3672, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "221\n",
      "tensor(0.2312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 861 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/861_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/861_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"862\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-1.8684, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-0.9572, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-1.5649, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-1.3833, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-1.5667, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-1.0586, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-2.1419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "222\n",
      "tensor(-0.2581, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 862 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/862_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/862_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"863\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-1.5595, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-0.9264, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-0.9470, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-0.4940, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-1.0900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-1.0095, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 863 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-1.4617, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "223\n",
      "tensor(-1.9974, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 863 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000015  \n",
      "1        0.000006       0.000025  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/863_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/863_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"864\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-1.9402, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-0.9935, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-1.1508, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-0.0747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-0.1793, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-1.1618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-0.9338, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "224\n",
      "tensor(-0.1750, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 864 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/864_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/864_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"865\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(-0.1492, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(-0.0614, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(0.0705, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(0.1335, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(0.3226, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(-0.3051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(-0.2070, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "225\n",
      "tensor(-0.1623, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 865 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/865_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/865_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"866\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-1.3320, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-1.2804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-0.9399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-1.8343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-1.2614, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-1.4097, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-0.9771, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "226\n",
      "tensor(-0.9392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 866 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000015  \n",
      "1        0.000006       0.000025  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/866_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/866_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"867\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(-0.1494, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(-0.1330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(-0.3999, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(-0.6669, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(-0.7736, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(0.0717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(-0.6125, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "227\n",
      "tensor(0.1330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 867 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000020  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/867_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/867_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"868\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-0.3369, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-0.1590, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-0.8977, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-0.9708, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-0.8545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-0.2449, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 868 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(-1.1565, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "228\n",
      "tensor(0.9856, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 868 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/868_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/868_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"869\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.3165, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-1.5042, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.4680, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.1178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.1119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.9908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.2778, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "229\n",
      "tensor(-0.5587, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 869 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000020  \n",
      "1        0.000008       0.000034  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/869_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/869_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"870\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.5947, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.5758, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(0.6565, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.3498, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.3556, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.0257, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.3615, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "230\n",
      "tensor(-0.5189, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 870 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/870_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/870_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"871\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.2322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(0.0260, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.6970, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.2003, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.1076, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.1368, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.2624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-1.2804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000012  \n",
      "1        0.000005       0.000020  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000005       0.000002  \n",
      "4        0.000005       0.000012  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/871_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"871\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.2937, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(0.0076, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.5241, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.2103, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.3772, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.4344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(0.0630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "231\n",
      "tensor(-0.1697, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 871 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000010  \n",
      "1        0.000005       0.000018  \n",
      "2        0.000005       0.000005  \n",
      "3        0.000005       0.000003  \n",
      "4        0.000005       0.000012  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/871_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"872\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-0.0412, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-1.5322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-0.7927, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-0.9753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(0.0182, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-0.3787, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-0.6801, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "232\n",
      "tensor(-0.5194, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 872 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/872_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/872_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"873\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-0.1290, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-0.0172, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-0.6995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(0.6239, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-1.0258, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-0.1323, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-1.0050, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "233\n",
      "tensor(-1.7738, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 873 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/873_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/873_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"874\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-1.4545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-0.9051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-1.2294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(0.0905, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-1.0084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-0.0942, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-0.7859, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "234\n",
      "tensor(-0.9579, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 874 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/874_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/874_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"875\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(0.5695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(-0.3096, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(-0.3989, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(-0.6084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(-0.3260, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(-0.0382, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 875 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(0.0918, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "235\n",
      "tensor(-0.2394, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 875 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/875_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/875_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"876\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-1.1183, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-1.3569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-1.2482, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-2.1238, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-1.5225, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-1.2339, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-0.8187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "236\n",
      "tensor(-1.2630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 876 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000022  \n",
      "1        0.000010       0.000038  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000026  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/876_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/876_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"877\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-0.6171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.4611, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.0790, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.7929, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.0325, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.5730, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.1183, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "237\n",
      "tensor(-1.4119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 877 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/877_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/877_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"878\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-0.8574, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-0.9336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-0.2655, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(0.0631, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-1.5471, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-0.6577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-1.2427, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "238\n",
      "tensor(-0.3918, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 878 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/878_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/878_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"879\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-1.5799, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-1.2400, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-2.0104, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-1.5228, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-1.4679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-1.0272, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(-1.0240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "239\n",
      "tensor(0.6800, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 879 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000037  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/879_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/879_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"880\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(-0.7220, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(-0.5617, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(-0.1488, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(-0.9591, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(0.0930, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(0.1775, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 880 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(-0.4267, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "240\n",
      "tensor(-1.1380, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 880 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000021  \n",
      "1        0.000011       0.000036  \n",
      "2        0.000011       0.000012  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/880_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/880_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"881\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-1.0106, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-0.2484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-1.1897, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-1.0786, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-0.6522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-1.0789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-0.4515, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "241\n",
      "tensor(-1.8351, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 881 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/881_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/881_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"882\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(0.1312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(0.2698, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(-0.6659, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(0.4750, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(-0.3634, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(0.0980, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(0.0515, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "242\n",
      "tensor(1.1263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 882 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/882_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/882_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"883\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(-0.2996, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(-0.0956, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(-0.7051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(0.1260, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(0.4232, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(0.2257, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(0.8926, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "243\n",
      "tensor(0.2723, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 883 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/883_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/883_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"884\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-1.2500, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(0.4123, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-0.1008, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-1.1407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-0.5035, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-1.6988, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-0.4263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "244\n",
      "tensor(-0.0132, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 884 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000023  \n",
      "1        0.000010       0.000039  \n",
      "2        0.000010       0.000013  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/884_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/884_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"885\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.1719, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.3352, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.4180, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.7453, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(0.0238, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.9541, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 885 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.7840, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "245\n",
      "tensor(-0.5351, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 885 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/885_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/885_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"886\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.3084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(-0.2469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.8424, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.1051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.4996, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.2802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.7443, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "246\n",
      "tensor(0.8618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 886 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/886_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/886_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"887\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(-0.8192, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(-0.0769, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(0.0092, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(-0.8604, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(0.0404, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(0.2344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(-0.5593, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "247\n",
      "tensor(0.5005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 887 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000024  \n",
      "1        0.000009       0.000038  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/887_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/887_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"888\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-1.1561, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-1.2884, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-0.6206, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-0.7764, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-0.9703, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-0.1567, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(-0.5902, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "248\n",
      "tensor(1.0427, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 888 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000020  \n",
      "1        0.000008       0.000034  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/888_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/888_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"889\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(0.4397, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(0.1155, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(0.1123, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(-0.0742, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(-0.3478, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(0.2119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(-0.2176, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "249\n",
      "tensor(-0.0360, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 889 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/889_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/889_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"890\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-2.2979, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-0.5660, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-0.7647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-2.1936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-3.7917, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-2.5717, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 890 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-2.0579, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "250\n",
      "tensor(-2.7641, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 890 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000014       0.000030  \n",
      "1        0.000014       0.000050  \n",
      "2        0.000014       0.000015  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000026  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/890_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/890_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"891\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-3.1630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-3.3216, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-1.7829, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-1.3512, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-2.8518, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-2.2469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(-2.5539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "251\n",
      "tensor(1.6937, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 891 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000020  \n",
      "1        0.000010       0.000034  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/891_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/891_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"892\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.0701, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.1384, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.6800, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.8115, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.6877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.1588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.1190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.0361, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/892_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"892\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.0334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.2926, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.5437, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.7185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.4738, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.2322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.2660, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "252\n",
      "tensor(-1.7718, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 892 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/892_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"893\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-1.8736, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-1.2562, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-1.9991, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-2.3587, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-2.1507, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-2.2938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-2.1159, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "253\n",
      "tensor(-2.8309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 893 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/893_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/893_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"894\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(1.1541, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.3627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.7564, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.8693, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.4975, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.4883, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.4528, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "254\n",
      "tensor(0.2285, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 894 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000012  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/894_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/894_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"895\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-1.2747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-0.7127, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-1.7561, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-1.1016, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-1.5119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-1.6327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-1.0496, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_8\n",
      "255\n",
      "tensor(-4.9380, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 895 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000009  \n",
      "3        0.000007       0.000004  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/895_.9.9.pt\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/895_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"896\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-1.9399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-2.4558, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-2.1480, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-2.2748, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-2.3046, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-2.2749, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-3.0770, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "0\n",
      "tensor(-1.0936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 896 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/896_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/896_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"897\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.8732, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.6556, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.9817, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.3675, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.4793, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.6001, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-1.0098, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 897 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "1\n",
      "tensor(-2.7801, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 897 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/897_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/897_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"898\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-1.1487, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-1.5349, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-1.8304, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-1.0728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-1.5456, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-2.6077, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-1.2144, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "2\n",
      "tensor(-0.8184, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 898 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/898_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/898_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"899\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-2.3116, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-1.5810, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-1.0225, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-1.2160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-1.7097, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-0.3873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(-1.3368, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "3\n",
      "tensor(0.5772, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 899 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/899_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/899_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"900\"\n",
      "using device cuda:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.5566, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.0931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.3347, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.5470, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.2470, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.0003, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(-1.0870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "4\n",
      "tensor(0.9332, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 900 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/900_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/900_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"901\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-0.4630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-1.3670, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-1.2603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-1.4667, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-1.0673, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-1.0536, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-0.5054, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "5\n",
      "tensor(-2.3171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 901 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/901_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/901_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"902\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-3.0717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-3.4321, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-2.6921, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-3.4588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-2.3539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-2.8600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-2.4950, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "6\n",
      "tensor(-2.8325, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 902 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000021  \n",
      "1        0.000010       0.000036  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000027  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/902_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/902_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"903\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-1.9002, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-2.1835, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-2.7289, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-2.2447, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-2.2248, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-2.5383, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-2.5363, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "7\n",
      "tensor(-3.3650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 903 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000029  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/903_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/903_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"904\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-1.3644, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-1.7886, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-1.0490, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-2.1133, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-1.4301, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-1.2777, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-1.1092, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "8\n",
      "tensor(-2.1774, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 904 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/904_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/904_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"905\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-2.4764, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-1.8008, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-2.3073, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-1.9008, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-1.4057, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-1.8582, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-2.7071, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "9\n",
      "tensor(-2.9499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 905 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000020  \n",
      "1        0.000010       0.000035  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/905_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/905_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"906\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-1.8479, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-2.2227, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-1.4471, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-1.4969, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-1.9941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-1.9640, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-2.1410, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "10\n",
      "tensor(-2.4845, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 906 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000026  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/906_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/906_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"907\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-2.0712, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-1.8987, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-1.6098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-2.0734, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-1.2330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-1.3914, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-2.0068, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "11\n",
      "tensor(-0.1780, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 907 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/907_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/907_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"908\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.9209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.6305, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.6934, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.1824, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.5994, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-2.0562, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.6516, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "12\n",
      "tensor(-1.0718, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 908 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/908_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/908_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"909\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.5522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.0721, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.8150, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.0178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-1.6592, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.9535, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.0355, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "13\n",
      "tensor(-2.9315, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 909 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000011       0.000006  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/909_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/909_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"910\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-2.7661, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-2.4340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-2.6720, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-3.2029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-3.1937, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-3.1450, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-3.0279, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "14\n",
      "tensor(-1.4144, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 910 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/910_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/910_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"911\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-1.2891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-0.9013, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-0.9890, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-1.7609, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-1.0973, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-1.6458, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-0.5747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "15\n",
      "tensor(-1.3499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 911 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/911_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/911_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"912\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-1.6634, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-1.2330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-1.0346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-1.6272, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-1.4923, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-2.4159, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-1.2567, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "16\n",
      "tensor(-2.0596, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 912 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/912_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/912_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"913\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-2.6793, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-2.8829, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-2.6184, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-3.3407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-2.9538, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-2.7981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-2.4491, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "17\n",
      "tensor(-4.2877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 913 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/913_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/913_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"914\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-1.7396, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-1.7861, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-2.6528, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-2.2885, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-2.4315, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-3.2717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-1.6226, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "18\n",
      "tensor(-1.5714, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 914 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/914_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/914_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"915\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.2719, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.1017, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.0423, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.9456, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.2249, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.8974, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.8570, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "19\n",
      "tensor(-1.0750, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 915 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509351   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000027  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/915_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/915_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"916\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-2.2235, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-1.5321, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-1.8297, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-1.2899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-1.9379, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-1.8075, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-2.3118, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "20\n",
      "tensor(-2.6848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 916 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/916_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/916_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"917\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-1.1798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-1.8131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-1.1163, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-1.0917, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-2.0046, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-1.2587, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(-1.6332, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "21\n",
      "tensor(0.1776, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 917 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/917_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/917_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"918\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-0.8753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-0.7394, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-0.5178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-0.8583, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-0.8756, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-1.1054, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-1.5233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "22\n",
      "tensor(-0.9893, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 918 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/918_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/918_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"919\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-2.1000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-1.0173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-1.3093, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-2.0100, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-1.3775, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-1.7917, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-1.8309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "23\n",
      "tensor(-1.9025, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 919 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000022  \n",
      "1        0.000011       0.000037  \n",
      "2        0.000011       0.000012  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/919_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/919_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"920\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-1.1104, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-0.3340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-0.4707, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-0.1193, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-0.6697, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-0.6120, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-0.0186, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "24\n",
      "tensor(-1.0315, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 920 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/920_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/920_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"921\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-0.8757, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-1.3393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-1.6563, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-1.5811, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-1.6956, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-1.2326, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-0.8271, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "25\n",
      "tensor(-2.0134, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 921 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/921_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/921_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"922\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-1.3409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-1.7076, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-2.1779, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-1.7386, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-1.2759, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-2.7961, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-2.9521, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "26\n",
      "tensor(-2.5051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 922 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/922_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/922_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"923\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-2.4053, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-1.7344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-1.7979, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-1.6523, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-2.3228, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-1.9793, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-1.3791, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "27\n",
      "tensor(-2.0789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 923 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000021  \n",
      "1        0.000010       0.000036  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/923_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/923_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"924\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-2.0539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-2.5542, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-2.7055, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-2.7187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-2.0898, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-1.8628, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-2.0588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "28\n",
      "tensor(-1.6477, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 924 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/924_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/924_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"925\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-2.2990, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-2.7705, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-2.5214, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-1.8455, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-1.9698, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-1.7212, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-1.3251, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "29\n",
      "tensor(-3.2039, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 925 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000023  \n",
      "1        0.000010       0.000039  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/925_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/925_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"926\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-2.1623, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-1.5389, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-2.5507, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-1.6172, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-2.7874, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-2.0940, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-2.1316, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "30\n",
      "tensor(-3.3176, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 926 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509351   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/926_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/926_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"927\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-0.6429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-1.6399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-1.0283, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-0.8941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-1.3968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-1.2094, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-0.5868, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "31\n",
      "tensor(-0.1359, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 927 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/927_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/927_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"928\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-1.6061, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-0.6000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-0.8319, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-1.2835, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-1.3109, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-1.4731, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-1.3498, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "32\n",
      "tensor(-2.6167, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 928 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/928_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/928_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"929\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.6674, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.9068, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.4345, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.5580, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.3651, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.3799, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(-1.0625, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "33\n",
      "tensor(1.6936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 929 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000024  \n",
      "1         0.00001       0.000041  \n",
      "2         0.00001       0.000013  \n",
      "3         0.00001       0.000005  \n",
      "4         0.00001       0.000023  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/929_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/929_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"930\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-1.7102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-1.5473, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-1.8503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-2.0936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-1.5671, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-1.5190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-2.4496, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "34\n",
      "tensor(-2.7797, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 930 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/930_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/930_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"931\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-1.5343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-1.0294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-1.5916, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-0.8828, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-1.3833, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-1.3755, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-0.8968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "35\n",
      "tensor(-0.0077, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 931 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/931_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/931_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"932\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-0.9597, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-1.8023, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-0.9160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-0.7498, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-1.6381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-1.3967, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-1.2527, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "36\n",
      "tensor(-0.0620, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 932 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/932_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/932_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"933\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.3458, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.1202, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.3444, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.3085, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.5062, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.2276, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-0.8607, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "37\n",
      "tensor(-1.0001, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 933 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/933_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/933_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"934\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-1.8497, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-1.2383, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-1.8852, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-1.6466, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-2.0484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-1.6833, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-1.7073, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "38\n",
      "tensor(-2.1352, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 934 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000005  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/934_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/934_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"935\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.7542, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.6914, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.1577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.5790, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.0414, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.3346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.0803, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "39\n",
      "tensor(-0.9587, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 935 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000010  \n",
      "1        0.000005       0.000017  \n",
      "2        0.000005       0.000005  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/935_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/935_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"936\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-0.8265, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-0.9099, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-0.9173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-0.3429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-0.8116, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-1.3702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-0.7318, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "40\n",
      "tensor(-1.2293, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 936 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/936_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/936_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"937\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.4384, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-0.5540, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-0.8512, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-2.0377, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-0.9185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.3421, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-0.7374, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-2.6310, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000004  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/937_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"937\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.1721, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.1419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.5331, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-0.6357, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.1642, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.1798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-1.1035, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "41\n",
      "tensor(-2.2746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 937 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/937_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"938\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-1.0629, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-1.6095, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-1.4898, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-0.6171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-1.0396, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-0.5870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-0.9513, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "42\n",
      "tensor(-1.0302, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 938 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000025  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/938_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/938_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"939\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-2.6208, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-2.7220, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-2.0635, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-2.0364, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-1.6352, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-2.2053, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-2.6211, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "43\n",
      "tensor(-4.0198, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 939 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000020  \n",
      "1         0.00001       0.000035  \n",
      "2         0.00001       0.000011  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000021  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/939_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/939_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"940\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-1.1717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-2.1113, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-1.1584, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-1.5208, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-1.9487, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-1.0626, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-1.4657, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "44\n",
      "tensor(-0.8066, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 940 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/940_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/940_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"941\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-1.2966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-1.5857, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-1.2330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-1.3286, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-1.6900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-2.0946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-0.8080, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "45\n",
      "tensor(-1.5069, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 941 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000015  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/941_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/941_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"942\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-1.9709, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-1.0506, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-1.6153, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-1.2906, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-1.3959, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-1.3900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-0.5991, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "46\n",
      "tensor(-0.5618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 942 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000027  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/942_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/942_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"943\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-0.1679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-1.1352, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-0.8970, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-0.9988, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-1.0427, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-1.8468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(-0.4776, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "47\n",
      "tensor(1.4992, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 943 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/943_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/943_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"944\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-0.8507, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-1.0568, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-0.4985, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-0.6914, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-0.7775, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-0.6001, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(-0.9120, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "48\n",
      "tensor(0.1548, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 944 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000011  \n",
      "1        0.000005       0.000018  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/944_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/944_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"945\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.2185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.4972, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.6532, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.4503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-2.0183, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.8388, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.6588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "49\n",
      "tensor(-1.9476, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 945 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/945_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/945_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"946\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-1.6398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-1.2068, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-1.7255, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-1.6725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-2.1346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-1.8522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-0.9676, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "50\n",
      "tensor(-3.8931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 946 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/946_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/946_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"947\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.7629, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.9696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.7888, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.9788, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.0774, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.5539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-1.6687, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "51\n",
      "tensor(-2.4686, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 947 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/947_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/947_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"948\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-0.3425, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-0.9794, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-0.8640, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-1.1836, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-1.1833, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-1.0894, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-0.3617, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "52\n",
      "tensor(-0.7566, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 948 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/948_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/948_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"949\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-0.5936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-1.0958, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-0.8351, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-1.0437, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-1.0220, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-0.7994, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-0.6642, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "53\n",
      "tensor(-1.4932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 949 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/949_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/949_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"950\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-1.3510, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-0.7802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-0.1911, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-0.5500, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-1.0505, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-0.8031, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-0.4197, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "54\n",
      "tensor(-0.0055, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 950 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/950_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/950_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"951\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-2.2073, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-2.1495, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-2.1781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-2.0335, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-1.7804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-2.1846, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-1.9504, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "55\n",
      "tensor(-3.4534, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 951 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/951_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/951_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"952\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-1.1218, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-1.2844, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-0.8838, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-0.8116, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-0.9407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(0.4638, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-0.5696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "56\n",
      "tensor(-2.3366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 952 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/952_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/952_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"953\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-1.2919, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-1.9011, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-1.2325, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-1.6264, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-0.9028, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-1.4075, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-0.8684, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "57\n",
      "tensor(-1.1023, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 953 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000015  \n",
      "1        0.000006       0.000025  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/953_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/953_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"954\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(0.0390, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-1.1345, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-0.4462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-0.8278, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-0.9007, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-0.5770, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-1.1652, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "58\n",
      "tensor(-1.2990, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 954 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/954_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/954_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"955\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-3.9295, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-3.3569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-1.7463, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-3.5314, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-2.6805, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-2.9276, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-3.5409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "59\n",
      "tensor(-3.5765, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 955 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/955_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/955_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"956\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-1.1213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-1.5936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-1.2891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-1.0454, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-0.9259, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-0.7650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-0.9579, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "60\n",
      "tensor(-1.7048, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 956 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/956_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/956_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"957\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-1.1766, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-0.7322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-1.4065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-0.7460, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-0.9294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-0.6784, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-0.5921, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "61\n",
      "tensor(-0.8420, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 957 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000027  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/957_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/957_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"958\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.0187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.0655, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.4336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.8045, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.0285, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.2868, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-1.3052, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "62\n",
      "tensor(-2.1135, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 958 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000004  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/958_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/958_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"959\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-1.7287, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-2.7653, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-2.2243, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-2.1361, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-1.7068, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-2.1011, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-2.4390, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "63\n",
      "tensor(-2.8125, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 959 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/959_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/959_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"960\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-2.9414, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-3.5074, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-2.5597, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-3.0444, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-2.8790, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-2.4999, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-2.1418, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "64\n",
      "tensor(-2.5292, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 960 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000023  \n",
      "1         0.00001       0.000039  \n",
      "2         0.00001       0.000012  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000022  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/960_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/960_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"961\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-1.5954, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-1.8511, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-1.7176, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-0.8493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-1.5968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-1.6426, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-2.1244, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "65\n",
      "tensor(-2.5087, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 961 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/961_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/961_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"962\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-2.6695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-3.3656, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-2.3813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-1.3067, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-2.9270, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-2.7807, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-3.3001, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "66\n",
      "tensor(-2.5045, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 962 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/962_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/962_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"963\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-0.5927, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-0.2101, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-1.6806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-0.7178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-1.1073, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-1.0130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-1.1399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "67\n",
      "tensor(-0.2358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 963 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000022  \n",
      "1        0.000010       0.000036  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/963_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/963_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"964\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-1.4334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-1.3174, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-1.0499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-0.7567, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-0.5696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-0.9873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-0.8488, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "68\n",
      "tensor(-0.2812, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 964 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000029  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000007       0.000004  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/964_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/964_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"965\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-1.2917, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-1.5586, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-0.7147, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-1.7211, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-1.3097, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-1.3332, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-1.4232, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "69\n",
      "tensor(-3.1358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 965 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000023  \n",
      "1        0.000010       0.000039  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/965_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/965_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"966\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.8250, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.6182, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-1.8209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.6015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.8057, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.9085, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.3892, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-4.0027, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/966_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"966\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.8524, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.6573, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-3.0605, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-3.0848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.2900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.0630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.2314, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "70\n",
      "tensor(-2.1101, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 966 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/966_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"967\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.5869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.3859, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.8727, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.3220, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.7193, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.4741, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-1.8692, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "71\n",
      "tensor(-2.7257, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 967 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/967_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/967_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"968\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-2.0879, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.6133, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.2924, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.9640, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.3269, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.4044, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.4000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "72\n",
      "tensor(-1.4044, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 968 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/968_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/968_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"969\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-1.7215, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-1.7961, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-1.9934, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-1.9639, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-2.0393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-2.2527, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-1.8284, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "73\n",
      "tensor(-1.1458, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 969 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/969_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/969_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"970\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-1.8559, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-1.9181, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-2.0848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-1.3977, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-2.1664, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-1.6479, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-2.2276, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "74\n",
      "tensor(-3.1528, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 970 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/970_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/970_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"971\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-2.7042, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-1.5727, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-1.8892, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-1.8527, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-2.1642, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-1.4519, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-1.9680, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "75\n",
      "tensor(-2.9196, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 971 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000033  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/971_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/971_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"972\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-2.0820, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-1.7635, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-1.8328, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-2.0764, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-1.0836, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-1.6774, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-2.2644, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "76\n",
      "tensor(-0.8900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 972 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/972_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/972_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"973\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.9029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.7202, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-2.2297, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.3249, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.3251, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.6151, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.9889, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "77\n",
      "tensor(-1.0899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 973 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000025  \n",
      "1        0.000012       0.000044  \n",
      "2        0.000012       0.000014  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/973_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/973_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"974\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-1.5811, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-1.1152, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-1.5832, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-0.8750, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-1.5725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-1.7911, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(-1.2387, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "78\n",
      "tensor(0.0827, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 974 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/974_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/974_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"975\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-1.8732, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(0.0983, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-0.2724, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-1.8266, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-0.8690, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-1.2051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-0.8713, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "79\n",
      "tensor(-0.6719, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 975 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000023  \n",
      "1        0.000009       0.000040  \n",
      "2        0.000009       0.000012  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/975_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/975_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"976\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-1.3051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-2.0838, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-1.6085, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-1.6513, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-1.4618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-1.9324, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-1.7381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "80\n",
      "tensor(-2.4280, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 976 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/976_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/976_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"977\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-1.3132, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-1.2686, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-0.8400, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-0.8693, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-0.6803, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-1.4729, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(-1.0984, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "81\n",
      "tensor(0.0492, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 977 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/977_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/977_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"978\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-1.0145, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-1.9545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-1.3798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-1.4573, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-1.0625, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-2.2336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-1.3401, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "82\n",
      "tensor(-0.5905, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 978 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/978_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/978_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"979\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.1974, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.8177, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.9813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.2326, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.4789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.8169, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(-1.4584, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "83\n",
      "tensor(0.2365, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 979 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/979_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/979_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"980\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-1.4661, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-1.8651, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-1.4102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-2.1448, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-1.8000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-2.1932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-2.0393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "84\n",
      "tensor(-1.3119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 980 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/980_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/980_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"981\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-1.7489, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-2.7550, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-2.3005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-2.7896, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-2.0918, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-2.7142, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-2.0461, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "85\n",
      "tensor(-1.0774, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 981 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000023  \n",
      "1        0.000010       0.000039  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/981_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/981_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"982\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-1.7416, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-2.4202, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-1.5921, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-2.1655, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-2.4029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-2.6863, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-1.7146, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "86\n",
      "tensor(-3.5505, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 982 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/982_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/982_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"983\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-0.5518, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-1.5022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-1.6028, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-1.9717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-2.3811, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-1.5952, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-1.7311, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "87\n",
      "tensor(-2.4861, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 983 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000027  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/983_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/983_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"984\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-1.3761, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-0.8976, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-1.3375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-1.6209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-1.5356, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-1.7299, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-1.2871, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "88\n",
      "tensor(-0.1582, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 984 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/984_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/984_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"985\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.7255, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.3710, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.9151, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.9016, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.5660, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-2.5694, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.1870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "89\n",
      "tensor(-1.8014, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 985 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/985_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/985_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"986\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.4007, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.7976, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.1578, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.8358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.3399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-1.7639, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.2710, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "90\n",
      "tensor(-2.0823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 986 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000030  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/986_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/986_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"987\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-0.9390, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-1.6351, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-1.1764, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-1.2386, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-1.0755, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-0.7071, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-0.9588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "91\n",
      "tensor(-0.0802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 987 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/987_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/987_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"988\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-1.5131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-1.4472, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-1.0069, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-1.2693, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-2.0334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-1.1443, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-1.0847, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "92\n",
      "tensor(-2.7895, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 988 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000025  \n",
      "1        0.000011       0.000043  \n",
      "2        0.000011       0.000014  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/988_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/988_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"989\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-2.0934, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-2.2564, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-2.0171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-2.0707, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-1.6410, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-2.6685, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-2.2707, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "93\n",
      "tensor(-1.3824, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 989 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/989_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/989_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"990\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-1.3630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-1.4663, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-1.6738, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-2.2727, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-1.2528, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-1.4935, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-1.7146, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "94\n",
      "tensor(-3.8815, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 990 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/990_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/990_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"991\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-1.9865, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-2.0173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-0.2537, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-1.6168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-2.6148, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-1.8835, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(-1.6670, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "95\n",
      "tensor(0.3404, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 991 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/991_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/991_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"992\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.5895, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.6071, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.1972, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.1022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.2776, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.0362, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-1.7284, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "96\n",
      "tensor(-0.0110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 992 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000028  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/992_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/992_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"993\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-1.5679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-1.1085, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-1.1944, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-2.0904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-1.0278, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-2.0691, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-1.7465, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "97\n",
      "tensor(-1.9243, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 993 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000013  \n",
      "1        0.000007       0.000023  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/993_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/993_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"994\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.5757, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.5949, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.7343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.3402, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.4149, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.0633, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-2.2751, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "98\n",
      "tensor(-1.9005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 994 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/994_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/994_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"995\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.4408, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.8250, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-0.4354, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-0.9413, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.3877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.0172, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.0530, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-2.3037, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/995_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"995\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.5244, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-0.8891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.6569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.2886, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-1.8820, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-0.1160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-0.7493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "99\n",
      "tensor(-2.2624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 995 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000011       0.000006  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/995_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"996\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.2005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.8364, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.0057, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-0.9938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.2524, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.7339, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.8648, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "100\n",
      "tensor(-1.4913, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 996 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000027  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/996_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/996_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"997\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-0.8300, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-1.0102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-1.1775, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-0.9753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-0.5820, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-1.4074, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(-1.8569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "101\n",
      "tensor(0.3761, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 997 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000020  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/997_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/997_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"998\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-2.5228, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-2.0981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-2.8305, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-2.6071, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-1.7959, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-1.5739, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-3.2020, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "102\n",
      "tensor(-1.5074, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 998 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/998_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/998_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"999\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-1.6199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-2.4716, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-0.7330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-0.8940, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-1.3108, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-1.8358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-1.0309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "103\n",
      "tensor(-3.0683, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 999 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/999_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/999_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1000\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-2.0514, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-2.0961, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-1.7199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-1.5052, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-1.3510, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-2.4431, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-1.5914, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "104\n",
      "tensor(-2.1128, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1000 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509351   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1000_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1000_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1001\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-2.1015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-1.8342, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-1.7806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-1.1434, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-1.7710, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-0.9393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-1.8496, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "105\n",
      "tensor(-1.6135, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1001 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1001_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1001_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1002\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.4968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.0925, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.1455, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.8766, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.3603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.3088, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-1.3358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "106\n",
      "tensor(-2.7566, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1002 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004       0.000010  \n",
      "1        0.000004       0.000017  \n",
      "2        0.000004       0.000005  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1002_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1002_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1003\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.4912, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.8690, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.2849, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.2176, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.8806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-0.9624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.1802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "107\n",
      "tensor(-1.5077, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1003 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1003_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1003_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1004\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-1.5274, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-1.5022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-1.8117, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-2.0682, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-1.4839, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-0.9555, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-1.0095, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "108\n",
      "tensor(-1.4445, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1004 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1004_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1004_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1005\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-1.8796, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-3.0908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-2.6128, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-3.0759, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-2.8366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-2.4688, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-3.6837, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "109\n",
      "tensor(-2.8100, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1005 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1005_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1005_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1006\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-0.9448, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-1.7386, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-0.8163, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-0.7658, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-1.4545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-0.7255, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-1.6179, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "110\n",
      "tensor(-1.1327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1006 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1006_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1006_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1007\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-1.8141, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-2.0497, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-1.8469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-2.8663, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-2.7444, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-1.8034, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-2.0627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "111\n",
      "tensor(-2.7539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1007 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1007_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1007_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1008\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-1.0221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-1.2236, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-2.2851, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-2.0522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-1.8618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-2.2512, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-2.2141, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "112\n",
      "tensor(-2.0869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1008 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1008_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1008_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1009\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.3641, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.3818, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.7201, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.1921, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.4904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.3393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.1650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "113\n",
      "tensor(-1.5812, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1009 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000005  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1009_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1009_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1010\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.9755, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.4856, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.8575, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.5614, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.7852, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.9243, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(-0.7508, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "114\n",
      "tensor(0.1082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1010 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1010_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1010_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1011\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-2.7938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-2.4746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-3.3188, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-2.3705, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-2.3710, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-2.8796, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-2.1787, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "115\n",
      "tensor(-3.9344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1011 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000033  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1011_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1011_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1012\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-1.4547, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-1.9056, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-1.4819, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-2.4305, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-1.3476, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-2.3190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-1.1591, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "116\n",
      "tensor(-2.8630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1012 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1012_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1012_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1013\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-1.6228, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-2.0255, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-1.6747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-0.4446, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-1.3981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-0.8353, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-1.3221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "117\n",
      "tensor(-0.2766, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1013 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000023  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1013_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1013_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1014\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-2.4432, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-2.3873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-2.5040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-3.0398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-1.4981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-2.1408, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-0.8733, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "118\n",
      "tensor(-1.1966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1014 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000020  \n",
      "1         0.00001       0.000035  \n",
      "2         0.00001       0.000011  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000021  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1014_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1014_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1015\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-1.2806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-1.8451, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-1.6217, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-2.2075, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-2.2366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-2.3555, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-1.7050, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "119\n",
      "tensor(-0.3034, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1015 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1015_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1015_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1016\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-1.8856, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-2.6781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-1.6824, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-1.8961, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-2.0180, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-1.6659, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-2.1792, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "120\n",
      "tensor(-1.3603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1016 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000030  \n",
      "2        0.000009       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1016_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1016_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1017\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-2.1392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-2.2908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-1.6059, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-1.5136, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-1.4005, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-2.0869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-2.6106, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "121\n",
      "tensor(-0.8611, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1017 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1017_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1017_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1018\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-1.1737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-1.1661, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-0.6469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-0.7008, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-0.4391, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-0.8823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-0.9641, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "122\n",
      "tensor(-1.0384, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1018 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1018_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1018_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1019\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-0.9053, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-1.8655, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-1.9596, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-1.1190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-1.3234, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-1.8115, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-1.4415, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "123\n",
      "tensor(-2.7430, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1019 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1019_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1019_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1020\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-2.3074, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-3.0649, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-1.7472, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-2.2773, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-2.3627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-2.0351, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-2.1075, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "124\n",
      "tensor(-2.5510, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1020 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1020_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1020_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1021\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(0.2562, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(0.2613, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(0.6638, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(-0.3407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(0.3131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(0.5933, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(-0.2808, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "125\n",
      "tensor(-0.3522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1021 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000012  \n",
      "1        0.000005       0.000021  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1021_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1021_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1022\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-0.5657, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-0.5453, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-0.7926, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-0.4945, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-0.3299, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-1.3538, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-1.0869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "126\n",
      "tensor(-0.3748, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1022 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1022_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1022_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1023\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-1.8187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-2.3892, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-2.3072, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-2.3395, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-2.0329, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-2.2015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-1.9872, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "127\n",
      "tensor(-2.7154, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1023 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000033  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1023_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1023_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1024\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-3.7751, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-2.7617, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-3.6175, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-2.7397, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-2.7728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-2.8341, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-2.5891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "128\n",
      "tensor(-2.8780, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1024 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1024_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1024_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1025\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.2529, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.3907, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.0838, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.4128, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.3618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.4654, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-1.9334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "129\n",
      "tensor(-2.2207, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1025 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1025_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1025_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1026\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-3.0171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-2.8974, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-2.1746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-2.8768, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-2.4122, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-3.3552, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-3.2922, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "130\n",
      "tensor(-2.8720, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1026 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1026_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1026_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1027\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-2.0475, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-2.3535, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-1.3143, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-2.9522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-2.5121, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-1.6718, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-1.9816, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "131\n",
      "tensor(-0.4838, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1027 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1027_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1027_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1028\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-2.7703, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-2.3486, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-2.3878, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-1.7407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-1.4167, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-0.8554, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-2.0713, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "132\n",
      "tensor(-3.4754, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1028 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1028_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1028_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1029\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-1.5374, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-1.6092, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-1.6173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-1.8287, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-1.2363, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-2.1041, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-2.7249, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "133\n",
      "tensor(-2.4754, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1029 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1029_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1029_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1030\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-1.0474, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-1.0869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-0.3071, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-1.2448, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-0.5022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-1.2059, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-0.8829, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "134\n",
      "tensor(-0.3311, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1030 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000019  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1030_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1030_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1031\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-2.8261, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-3.2407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-2.5326, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-2.4386, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-2.6524, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-1.9696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-3.2197, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "135\n",
      "tensor(-4.6660, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1031 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000021  \n",
      "1        0.000010       0.000036  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000012       0.000005  \n",
      "4        0.000012       0.000027  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1031_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1031_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1032\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-1.6201, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-1.9114, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-1.6708, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-1.2798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-0.8692, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-1.4039, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-1.3543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "136\n",
      "tensor(-0.8468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1032 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1032_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1032_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1033\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-1.7172, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-2.0016, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-1.6623, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-1.4983, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-0.9315, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-1.5698, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-1.1530, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "137\n",
      "tensor(-1.7579, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1033 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000036  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1033_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1033_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1034\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.6909, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.4946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-2.2200, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.9731, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.5416, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.8752, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.7781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "138\n",
      "tensor(-1.4659, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1034 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1034_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1034_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1035\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-2.8275, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-1.2415, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-2.2403, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-1.4222, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-2.7942, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-1.9159, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-1.5328, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "139\n",
      "tensor(-2.6681, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1035 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1035_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1035_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1036\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-1.3894, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-1.7425, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-2.1100, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-0.9525, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-2.5610, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-1.5294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-2.9423, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "140\n",
      "tensor(-2.8145, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1036 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1036_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1036_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1037\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-0.7040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-0.8901, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-1.1086, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-1.2666, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-1.1535, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-1.0264, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-1.1468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "141\n",
      "tensor(-2.4964, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1037 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1037_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1037_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1038\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.4033, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.5889, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.0360, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.5792, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-0.5461, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.7615, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.1554, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "142\n",
      "tensor(-1.9296, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1038 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000022  \n",
      "1         0.00001       0.000038  \n",
      "2         0.00001       0.000012  \n",
      "3         0.00001       0.000005  \n",
      "4         0.00001       0.000023  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1038_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1038_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1039\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-0.9789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.8886, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.3019, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.6434, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.1879, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-2.1164, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.6521, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-0.5517, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1039_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1039\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-2.1185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.3148, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.4084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.5900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-0.5894, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-2.5055, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.1353, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "143\n",
      "tensor(-1.3015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1039 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1039_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1040\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-0.9878, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-1.3094, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-1.1798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-1.0678, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-1.2803, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-1.2462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-0.9783, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "144\n",
      "tensor(-0.2040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1040 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1040_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1040_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1041\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-1.1000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.5982, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.5953, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.4801, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.8493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.2130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.3009, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "145\n",
      "tensor(-0.3363, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1041 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000021  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1041_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1041_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1042\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-2.0574, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-1.1425, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-1.6258, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-1.2330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-0.7084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-1.5788, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-0.9518, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "146\n",
      "tensor(-1.3449, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1042 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000024  \n",
      "1        0.000011       0.000040  \n",
      "2        0.000011       0.000013  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1042_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1042_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1043\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-2.7510, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-1.9147, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-3.0352, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-1.7767, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-2.8695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-3.0432, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-2.4417, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "147\n",
      "tensor(-2.2395, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1043 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1043_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1043_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1044\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-2.1279, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-2.1946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-1.5168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-1.8278, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-1.4648, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-1.3429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-1.6169, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "148\n",
      "tensor(-0.3292, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1044 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000021  \n",
      "1        0.000010       0.000037  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1044_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1044_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1045\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.1875, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.4476, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.2744, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.0576, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.4206, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.6154, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-0.9799, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "149\n",
      "tensor(-1.1058, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1045 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000020  \n",
      "2        0.000006       0.000006  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1045_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1045_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1046\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-1.7372, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-1.8032, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-1.8796, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-1.3902, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-1.8679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-1.7937, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-2.1695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "150\n",
      "tensor(-2.0499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1046 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000019  \n",
      "1         0.00001       0.000033  \n",
      "2         0.00001       0.000011  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000021  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1046_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1046_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1047\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-1.7875, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-1.7891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-1.9036, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-1.2303, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-1.3414, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-2.3377, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-1.5643, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "151\n",
      "tensor(-0.4788, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1047 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1047_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1047_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1048\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-1.3972, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-1.4249, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-1.6359, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-0.9841, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-0.9327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-1.0892, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-1.8293, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "152\n",
      "tensor(-0.6385, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1048 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1048_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1048_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1049\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-1.0675, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-0.9407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-1.4807, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-1.6737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-0.6935, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-1.2696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(-1.2205, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "153\n",
      "tensor(0.3772, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1049 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1049_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1049_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1050\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-1.2171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-1.3525, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-0.5800, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-2.2523, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-1.5125, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-1.4950, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-1.3931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "154\n",
      "tensor(-1.6429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1050 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1050_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1050_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1051\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-1.9578, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-2.3245, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-1.5256, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-1.5702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-1.4762, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-0.9569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-0.9294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "155\n",
      "tensor(-2.1376, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1051 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1051_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1051_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1052\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-0.4235, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-0.9895, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-0.7466, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-1.1742, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-1.0715, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-1.2003, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-0.9627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "156\n",
      "tensor(-0.6409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1052 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000012  \n",
      "1        0.000006       0.000021  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1052_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1052_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1053\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.6722, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.1238, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.0230, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.5247, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.7648, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.0688, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.0108, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-3.4829, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1053_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1053\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.9358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.7685, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.4416, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.4976, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.9822, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-1.8489, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.9126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "157\n",
      "tensor(-2.0892, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1053 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000019  \n",
      "1        0.000010       0.000033  \n",
      "2        0.000010       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1053_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1054\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-1.1168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-0.9965, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-1.1638, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-0.8931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-0.9121, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-1.0842, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-0.9886, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "158\n",
      "tensor(-1.0841, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1054 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004       0.000009  \n",
      "1        0.000004       0.000015  \n",
      "2        0.000004       0.000005  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1054_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1054_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1055\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-1.2848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-1.4088, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-1.7801, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-2.1729, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-2.0126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-2.0036, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-1.7667, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "159\n",
      "tensor(-1.9298, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1055 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1055_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1055_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1056\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-1.8643, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-1.9084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-1.6793, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-1.6904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-1.6981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-2.1428, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-2.3423, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "160\n",
      "tensor(-1.0953, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1056 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1056_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1056_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1057\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-2.0516, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-1.9026, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-2.0230, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-0.8992, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-1.3516, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-0.8967, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-1.5394, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "161\n",
      "tensor(-2.3396, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1057 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1057_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1057_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1058\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-0.6659, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-1.3444, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-1.7135, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-1.4806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-1.3941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(0.0341, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-1.4377, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "162\n",
      "tensor(-0.8102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1058 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1058_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1058_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1059\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-2.2344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-1.2674, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-1.9126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-2.5886, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-2.5909, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-2.7170, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-1.5696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "163\n",
      "tensor(-1.3801, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1059 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1059_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1059_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1060\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-0.3228, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-0.7110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-0.9343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-0.1591, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-0.6130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-0.6734, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-1.0198, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "164\n",
      "tensor(-1.1632, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1060 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000012  \n",
      "1        0.000005       0.000020  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1060_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1060_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1061\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-1.1527, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-1.2570, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-2.1489, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-1.5899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-0.9491, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-2.0852, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-0.7519, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "165\n",
      "tensor(-2.4151, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1061 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000017  \n",
      "1        0.000009       0.000029  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1061_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1061_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1062\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-1.5777, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-1.3714, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-0.5240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-1.1551, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-0.9649, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-1.3978, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-0.8593, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "166\n",
      "tensor(-2.3137, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1062 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1062_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1062_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1063\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-1.3366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-0.4837, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-0.5867, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-1.7922, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-1.2175, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-0.5646, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-1.3298, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "167\n",
      "tensor(-2.4439, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1063 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1063_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1063_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1064\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-0.4469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-1.4013, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-1.3693, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-1.3795, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-0.4257, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-1.2165, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-0.6182, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "168\n",
      "tensor(-1.1823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1064 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1064_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1064_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1065\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-2.4339, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-1.5083, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-2.1311, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-1.8201, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-1.6706, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-2.2060, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-2.1993, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "169\n",
      "tensor(-2.9669, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1065 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1065_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1065_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1066\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.0910, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.3154, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.8856, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.1545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.6871, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.2130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-2.8802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "170\n",
      "tensor(-1.5334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1066 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1066_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1066_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1067\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-2.3381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-1.1024, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-1.9958, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-2.2684, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-1.2505, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-2.8343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-1.6439, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "171\n",
      "tensor(-1.2000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1067 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1067_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1067_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1068\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-0.4415, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-1.0335, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-0.8585, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-0.5566, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-0.1150, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-0.8451, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-1.1549, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "172\n",
      "tensor(-1.2375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1068 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1068_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1068_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1069\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-2.2769, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-2.9285, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-2.6680, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-2.3938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-2.4218, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-1.9884, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-2.3897, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "173\n",
      "tensor(-4.5652, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1069 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1069_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1069_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1070\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-1.9497, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-3.0029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-1.8884, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-2.0893, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-3.1921, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-2.1218, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-2.4522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "174\n",
      "tensor(-0.7026, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1070 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1070_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1070_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1071\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-1.7992, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-1.9466, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-2.7090, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-1.2063, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-2.4376, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-1.5411, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-1.5141, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "175\n",
      "tensor(-0.4628, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1071 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000020  \n",
      "1         0.00001       0.000034  \n",
      "2         0.00001       0.000011  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000021  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1071_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1071_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1072\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-4.1374, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-3.1981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-3.3599, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-3.0055, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-3.9789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-3.5908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-2.0647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "176\n",
      "tensor(-5.3375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1072 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1072_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1072_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1073\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-0.9979, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-0.8602, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-1.2151, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-1.2797, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-1.3781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-1.4407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-0.4022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "177\n",
      "tensor(-0.3691, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1073 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1073_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1073_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1074\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-0.8221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-2.1126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-2.1152, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-1.8720, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-2.1223, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-1.5421, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-1.6448, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "178\n",
      "tensor(-0.8775, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1074 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000033  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1074_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1074_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1075\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-2.6595, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-1.5202, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-1.9228, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-1.5539, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-2.2764, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-2.5204, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-1.1424, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "179\n",
      "tensor(-2.3581, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1075 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1075_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1075_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1076\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-1.6746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-2.2498, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-1.7526, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-2.0463, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-2.0115, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-1.7577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-2.0859, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "180\n",
      "tensor(-2.1339, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1076 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000017  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1076_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1076_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1077\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.7520, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.1770, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.7608, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-2.1549, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.9811, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.7702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.7804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "181\n",
      "tensor(-1.5004, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1077 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509351   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1077_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1077_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1078\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-1.3156, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-1.8065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-0.9057, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-1.0608, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-1.1360, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-0.9164, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-1.5846, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "182\n",
      "tensor(-0.8603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1078 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1078_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1078_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1079\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-1.8121, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-1.7702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-1.7157, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-2.3663, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-2.1375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-2.3625, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-1.8922, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "183\n",
      "tensor(-0.5070, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1079 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1079_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1079_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1080\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-2.9808, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-3.0260, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-2.8484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-3.2763, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-2.9514, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-2.2319, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-2.9654, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "184\n",
      "tensor(-2.4420, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1080 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1080_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1080_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1081\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-0.6326, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-0.6351, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-1.4174, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(0.3431, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-0.4518, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-0.9079, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-0.7457, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "185\n",
      "tensor(-2.2240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1081 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1081_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1081_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1082\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.2765, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.9927, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.1882, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.6116, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.8287, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.1185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.1340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.1823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1082_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1082\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.8454, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.2875, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.3795, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.0627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-1.7392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.7199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.0978, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "186\n",
      "tensor(-2.3102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1082 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1082_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1083\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-1.1069, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-2.4859, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-2.0630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-1.7870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-1.5304, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-1.9137, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-1.1261, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "187\n",
      "tensor(-1.8180, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1083 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1083_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1083_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1084\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-2.4387, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-2.4877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-2.1810, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-1.8316, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-2.2723, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-2.5168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-2.1822, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "188\n",
      "tensor(-4.5201, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1084 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1084_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1084_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1085\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-1.1429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-0.4797, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-0.8479, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-1.0060, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-0.4488, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-1.0811, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-0.2401, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "189\n",
      "tensor(-1.4493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1085 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1085_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1085_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1086\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-1.3731, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-2.8524, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-1.4097, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-2.1170, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-1.0509, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-1.5471, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-2.2076, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "190\n",
      "tensor(-1.1601, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1086 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1086_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1086_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1087\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.6662, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.5331, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.0503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.7848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.3610, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.5862, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.1980, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "191\n",
      "tensor(-1.0827, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1087 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000026  \n",
      "2        0.000008       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1087_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1087_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1088\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-2.4787, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-2.0746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-1.7504, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-2.3685, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-1.8575, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-2.1100, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-3.0527, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "192\n",
      "tensor(-3.4350, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1088 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1088_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1088_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1089\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-3.1051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-1.6089, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-2.7960, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-3.5920, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-3.9776, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-2.5473, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-3.5501, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "193\n",
      "tensor(-3.2494, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1089 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000034  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000028  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1089_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1089_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1090\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-0.8727, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.0832, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.4330, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.5431, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.4935, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.7287, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.5162, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "194\n",
      "tensor(-1.7236, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1090 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1090_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1090_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1091\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-2.4366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-2.5957, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-1.7956, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-1.5414, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-2.9779, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-2.4488, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-2.6583, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "195\n",
      "tensor(-2.5077, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1091 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1091_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1091_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1092\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-3.1481, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-2.2980, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-2.7786, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-3.4015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-3.2807, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-2.0064, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-2.3609, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "196\n",
      "tensor(-2.0346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1092 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1092_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1092_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1093\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-1.9440, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-2.1300, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-1.9603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-2.0571, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-1.3136, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-1.2725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-1.3840, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "197\n",
      "tensor(-0.3037, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1093 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1093_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1093_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1094\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-0.5968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-1.3242, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-1.1862, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-0.6130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-0.4465, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-1.4840, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-0.9127, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "198\n",
      "tensor(-1.0328, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1094 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1094_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1094_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1095\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-0.8590, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-0.9541, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-1.1428, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-1.6169, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-0.9235, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-0.7543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-1.2644, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "199\n",
      "tensor(-1.1647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1095 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1095_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1095_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1096\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-1.1640, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-1.3199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-0.4265, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-1.2652, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-1.3027, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-1.4468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(-1.5784, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "200\n",
      "tensor(0.5432, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1096 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1096_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1096_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1097\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-0.8350, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-0.7657, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-1.1876, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-1.2362, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-1.5783, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-1.5375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-1.2090, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "201\n",
      "tensor(-2.0959, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1097 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000020  \n",
      "1        0.000008       0.000033  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1097_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1097_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1098\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-0.9275, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-1.1737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-1.0041, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-0.9037, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-1.1160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-1.1025, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-1.2381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "202\n",
      "tensor(-1.8437, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1098 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1098_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1098_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1099\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-0.9630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-1.6082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-1.6499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-1.8807, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-2.3617, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-2.1393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-1.4956, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "203\n",
      "tensor(-1.8666, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1099 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1099_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1099_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1100\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.6449, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.9752, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.4819, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.4266, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.6540, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.8212, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(-0.3791, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "204\n",
      "tensor(0.6891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1100 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1100_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1100_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1101\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-0.8188, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-1.9940, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-2.3155, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-1.0721, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-1.3902, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-1.4739, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-1.7607, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "205\n",
      "tensor(-2.5455, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1101 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1101_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1101_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1102\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.1968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.4221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.2122, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.2864, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.0617, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.4654, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-1.4083, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "206\n",
      "tensor(-4.1308, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1102 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000013       0.000024  \n",
      "1        0.000013       0.000042  \n",
      "2        0.000013       0.000013  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1102_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1102_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1103\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-2.3288, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-1.9163, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-2.1468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-2.2724, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-1.7515, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-2.4635, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-1.3902, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "207\n",
      "tensor(-2.6261, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1103 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000012       0.000005  \n",
      "4        0.000012       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1103_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1103_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1104\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-2.0836, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-2.1806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-2.4827, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-1.5451, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-2.4102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-2.1462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-1.2987, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "208\n",
      "tensor(-3.7123, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1104 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1104_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1104_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1105\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.3317, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.2484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.5713, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.3855, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.3582, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.0458, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.9517, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "209\n",
      "tensor(-1.9356, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1105 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000008       0.000003  \n",
      "4        0.000008       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1105_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1105_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1106\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-0.8735, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-1.4470, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-1.3396, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-1.3249, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-1.3179, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-1.0235, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-1.6218, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "210\n",
      "tensor(-0.5438, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1106 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000015  \n",
      "1        0.000006       0.000025  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1106_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1106_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1107\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.3410, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.0650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.2312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.6915, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.6712, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.6931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-2.3145, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "211\n",
      "tensor(-1.5131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1107 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1107_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1107_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1108\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-1.6543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-1.8579, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-1.2211, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-1.7651, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-1.2024, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-1.6501, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-2.0844, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "212\n",
      "tensor(-3.8287, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1108 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1108_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1108_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1109\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-2.2810, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-0.6111, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-1.2538, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-1.6881, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-1.5630, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-1.5311, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-1.5248, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "213\n",
      "tensor(-1.9126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1109 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000019  \n",
      "1        0.000007       0.000030  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1109_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1109_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1110\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-1.0581, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-0.4022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-0.4870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-1.4085, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-0.7412, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-0.4883, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-1.4392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "214\n",
      "tensor(-2.1446, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1110 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1110_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1110_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1111\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.7208, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.6118, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-0.9981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.9339, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.2233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-0.4971, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.0170, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-0.0699, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1111_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1111\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-0.9680, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.1747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.6536, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.2871, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.4118, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-1.3932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-0.5966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "215\n",
      "tensor(-3.6894, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1111 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1111_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1112\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-1.8117, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-1.6613, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-0.7541, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-1.7697, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-1.3366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-1.8327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-1.6719, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "216\n",
      "tensor(-2.3268, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1112 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000033  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1112_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1112_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1113\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-2.9601, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-2.6613, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-2.0877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-1.9668, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-2.5866, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-1.9540, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-1.9358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "217\n",
      "tensor(-1.3891, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1113 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1113_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1113_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1114\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-0.9893, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-1.9974, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-1.3518, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-2.1346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-1.6510, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-1.0792, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-0.6309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "218\n",
      "tensor(-1.6297, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1114 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1114_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1114_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1115\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.3497, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-2.1531, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.3407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.2243, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.3124, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.1696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.9311, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "219\n",
      "tensor(-1.0257, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1115 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1115_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1115_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1116\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-0.4742, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-0.3938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-1.3333, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-1.2729, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-0.6603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-1.5160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-0.8334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "220\n",
      "tensor(-0.5888, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1116 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1116_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1116_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1117\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-1.1938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-1.9896, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-2.8139, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-1.6262, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-1.8223, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-2.6664, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-3.2361, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "221\n",
      "tensor(-2.5942, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1117 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0         0.00001       0.000020  \n",
      "1         0.00001       0.000035  \n",
      "2         0.00001       0.000011  \n",
      "3         0.00001       0.000004  \n",
      "4         0.00001       0.000022  \n",
      "...           ...            ...  \n",
      "250043    0.00000       0.000000  \n",
      "250044    0.00000       0.000000  \n",
      "250045    0.00000       0.000000  \n",
      "250046    0.00000       0.000000  \n",
      "250047    0.00000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1117_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1117_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1118\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-1.7043, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-2.0785, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-1.4669, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-1.9899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-1.9687, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-2.2390, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-2.0418, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "222\n",
      "tensor(-0.9646, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1118 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1118_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1118_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1119\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.8942, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.3301, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.8094, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.1709, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.1309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.2046, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.5208, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "223\n",
      "tensor(-1.4160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1119 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1119_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1119_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1120\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-1.9626, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-2.0765, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-2.4247, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-3.0082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-1.8880, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-1.2737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-2.8650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "224\n",
      "tensor(-2.6025, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1120 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1120_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1120_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1121\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-0.6441, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-1.7256, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-1.5381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-1.5832, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-1.6638, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-1.2068, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-1.4290, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "225\n",
      "tensor(-2.6608, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1121 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1121_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1121_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1122\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-1.6286, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-0.0954, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-0.4448, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-1.1421, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-0.9059, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-0.3065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-0.9723, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "226\n",
      "tensor(-1.9040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1122 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1122_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1122_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1123\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-2.0197, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-2.4760, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-1.8318, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-2.5365, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-1.7851, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-2.2958, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-2.1233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "227\n",
      "tensor(-2.1392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1123 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000033  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000012       0.000005  \n",
      "4        0.000012       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1123_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1123_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1124\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-0.7518, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-2.0240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-1.5002, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-0.9633, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-1.1493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-1.5488, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-1.8264, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "228\n",
      "tensor(-1.5650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1124 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000017  \n",
      "1        0.000009       0.000029  \n",
      "2        0.000009       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1124_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1124_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1125\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-0.8865, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.2624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-0.9545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.3017, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-0.9221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.3467, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.5766, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.9533, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1125_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1125\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.0885, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-0.8753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.0614, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.3731, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.3231, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.4725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.1384, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "229\n",
      "tensor(-1.3805, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1125 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000027  \n",
      "2        0.000008       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1125_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1126\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-0.8160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-1.1675, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-1.2142, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-1.8461, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-1.1577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-0.8871, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-0.5557, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "230\n",
      "tensor(-0.1282, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1126 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1126_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1126_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1127\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-2.3126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-1.7884, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-2.0186, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-2.0215, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-1.5762, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-1.9516, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-3.4426, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "231\n",
      "tensor(-2.7167, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1127 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000032  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1127_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1127_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1128\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-0.8509, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-1.5615, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-1.5959, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-1.7971, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-1.1336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-1.3724, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-1.5200, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "232\n",
      "tensor(-2.0555, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1128 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1128_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1128_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1129\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.4966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.8885, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.1749, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.0392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.0533, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.0250, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-1.1050, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "233\n",
      "tensor(-2.2702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1129 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1129_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1129_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1130\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-0.8045, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-1.1477, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-1.4955, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-0.6197, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-1.3573, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-0.7635, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(-1.5798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "234\n",
      "tensor(0.0781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1130 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1130_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1130_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1131\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-2.8505, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-3.5457, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-2.3334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-2.8493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-3.2615, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-3.7344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-3.9532, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "235\n",
      "tensor(-4.9131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1131 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000022  \n",
      "1        0.000010       0.000037  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1131_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1131_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1132\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.4908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-0.8304, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.0598, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.5781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.4711, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.3082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.4900, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "236\n",
      "tensor(-1.6110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1132 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1132_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1132_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1133\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-1.4841, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-2.0842, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-1.1239, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-2.1839, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-1.9683, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-0.8893, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-0.9936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "237\n",
      "tensor(-1.3646, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1133 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000025  \n",
      "1        0.000011       0.000042  \n",
      "2        0.000011       0.000013  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1133_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1133_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1134\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-2.1374, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-0.9565, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-1.4413, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-1.3346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-1.6804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-1.5236, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-1.4961, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "238\n",
      "tensor(-1.5655, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1134 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000011  \n",
      "1        0.000005       0.000019  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1134_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1134_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1135\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-1.9098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-2.1845, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-1.6927, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-1.6603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-1.8213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-1.5879, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-1.8471, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "239\n",
      "tensor(-0.3429, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1135 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000025  \n",
      "1        0.000011       0.000042  \n",
      "2        0.000011       0.000013  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1135_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1135_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1136\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.5057, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.5019, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.6600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.7015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.7687, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.9720, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.2612, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "240\n",
      "tensor(-1.3093, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1136 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1136_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1136_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1137\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-1.0800, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-1.6150, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-2.4324, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-1.1466, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-1.9522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-1.4737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-2.2848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "241\n",
      "tensor(-2.7878, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1137 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1137_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1137_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1138\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-1.8199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-1.5913, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-1.4935, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-2.4750, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-1.3176, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-1.5476, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-1.2928, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "242\n",
      "tensor(-2.3092, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1138 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1138_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1138_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1139\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.1677, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.4485, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.6851, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.0852, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.7794, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.4873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.0656, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-0.4889, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1139_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1139\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-0.7178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.9128, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.2730, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.6272, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.8776, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-1.5348, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-0.7825, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "243\n",
      "tensor(-0.4407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1139 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000026  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1139_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1140\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.9361, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.4075, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.2946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.0182, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.8029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.7500, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-1.9411, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "244\n",
      "tensor(-0.4794, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1140 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000015  \n",
      "1        0.000007       0.000025  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1140_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1140_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1141\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-1.6823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-1.7106, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-1.8643, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-1.9748, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-1.7017, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-1.6960, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-2.2179, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "245\n",
      "tensor(-0.2793, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1141 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1141_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1141_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1142\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-2.1434, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-2.1711, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-2.0996, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-1.6181, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-2.6263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-2.7347, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-1.9322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "246\n",
      "tensor(-3.2008, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1142 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000022  \n",
      "1        0.000011       0.000038  \n",
      "2        0.000011       0.000012  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1142_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1142_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1143\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-2.9114, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-2.8883, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-4.0019, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-3.4432, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-3.2316, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-3.1784, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-3.1218, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "247\n",
      "tensor(-2.3674, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1143 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509351   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000019  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000012       0.000005  \n",
      "4        0.000012       0.000026  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1143_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1143_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1144\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-2.0832, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-1.9909, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-2.0887, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-1.6233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-2.2309, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-1.9503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(-2.0674, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "248\n",
      "tensor(1.1924, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1144 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000018  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1144_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1144_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1145\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-1.9634, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-1.8265, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-1.2318, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-2.4126, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-1.8019, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-1.2555, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-2.0070, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "249\n",
      "tensor(-1.8702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1145 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000016  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1145_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1145_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1146\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-1.2364, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-1.3931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-0.5175, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-1.2312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-1.2526, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-0.6469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-0.4364, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "250\n",
      "tensor(-2.6709, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1146 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1146_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1146_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1147\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.0836, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.3095, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.3709, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.0554, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.2176, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-0.4892, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.1658, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "251\n",
      "tensor(-1.8591, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1147 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000019  \n",
      "1        0.000008       0.000031  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1147_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1147_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1148\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.6855, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.6483, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.1997, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.0252, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.7379, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.8110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-0.6959, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "252\n",
      "tensor(-1.1788, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1148 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000013  \n",
      "1        0.000005       0.000021  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1148_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1148_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1149\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.5446, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.3482, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.4077, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.8043, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.2389, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.0656, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.5791, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "253\n",
      "tensor(-1.7605, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1149 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1149_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1149_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1150\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-1.6159, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-1.7571, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-1.4455, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-2.1407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-1.4764, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-1.4029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-1.8899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "254\n",
      "tensor(-2.2214, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1150 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000030  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1150_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1150_.9.9.pt\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1151\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-2.4470, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-1.9526, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-2.1843, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-2.3120, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-2.2692, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-2.2422, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-1.9857, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_10\n",
      "255\n",
      "tensor(-2.7815, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1151 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.107067   \n",
      "250044    250044  features_10      4          255         252  0.061349   \n",
      "250045    250045  features_10      4          255         253  0.000004   \n",
      "250046    250046  features_10      4          255         254  0.051553   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010   1.907432e-05  \n",
      "1        0.000010   3.276491e-05  \n",
      "2        0.000010   1.058566e-05  \n",
      "3        0.000008   3.880954e-06  \n",
      "4        0.000008   1.837709e-05  \n",
      "...           ...            ...  \n",
      "250043   0.000947   9.748273e-05  \n",
      "250044   0.000947   5.504198e-05  \n",
      "250045   0.000947   3.686450e-09  \n",
      "250046   0.000947   4.641523e-05  \n",
      "250047   0.000947   3.661142e-08  \n",
      "\n",
      "[250048 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/random_models/1151_.9.9.pt\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n",
      "layer: 4\n",
      "saving model to prepped_models/alexnet_sparse/subgraphs/models/worst_models/1151_.9.9.pt\n",
      "6439.322687625885\n"
     ]
    }
   ],
   "source": [
    "#run through all subgraphs generating same size subgraphs\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for node in range(825,1152):\n",
    "    try:\n",
    "        sub_dict_path = 'prepped_models/alexnet_sparse/subgraphs/models/%s_.9.9.pt'%str(node)\n",
    "        for version in ['random','worst']:\n",
    "            save_path = 'prepped_models/alexnet_sparse/subgraphs/models/%s_models/%s_.9.9.pt'%(version,str(node))\n",
    "            make_same_sized_subgraph(sub_dict_path,model,selection=version,node=node,save=save_path)\n",
    "    except:\n",
    "        print('node %s failed'%str(node))\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "\n",
    "scripts for generating plots that compare the difference in neural responses to different images across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_node_subgraph_responses(node,model,submodel, category, params,batch_size = params['batch_size']):\n",
    "    '''model is model from which subgraph was extracted, terminating in \"node\" (use unique node id)'''\n",
    "    device = params['device']\n",
    "    node_layer,node_within_layer_id,node_layer_name = nodeid_2_perlayerid(node,params)\n",
    "    model.to(device)\n",
    "    submodel.to(device)\n",
    "    \n",
    "    ###Hook model\n",
    "    model_activations = []\n",
    "    def get_activation(node_within_layer_id=node_within_layer_id):\n",
    "        def hook(model, input, output):\n",
    "            model_activations.append(output[:,node_within_layer_id,:,:].detach())\n",
    "            #if model_activations is None:\n",
    "            #    model_activations = output[:,node,:,:].detach()\n",
    "            #else:\n",
    "            #    model_activations = torch.cat((model_activations,output[:,node,:,:].detach()), 0)\n",
    "        return hook\n",
    "    \n",
    "    ##### THIS IS NOT MODEL GENERAL, ASSUMING 'FEATURES', basically alexnet only right now\n",
    "    handle = model.features[int(node_layer_name.split('_')[-1])].register_forward_hook(get_activation())\n",
    "    \n",
    "    submodel_activations = None\n",
    "    \n",
    "    ####SET UP DATALOADER\n",
    "    kwargs = {'num_workers': params['num_workers'], 'pin_memory': True} if ('cuda' in params['device']) else {}\n",
    "    \n",
    "    if category =='overall':\n",
    "        categories = os.listdir(params['rank_img_path'])\n",
    "    else:\n",
    "        categories = [category]\n",
    "    for cat in categories:\n",
    "\n",
    "        image_loader = torch.utils.data.DataLoader(\n",
    "                rank_image_data(params['rank_img_path']+'/'+cat,params['preprocess'],params['label_file_path']),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                **kwargs)\n",
    "        ###run images through\n",
    "        for i, (batch, target) in enumerate(image_loader):\n",
    "            #print('batch %s'%i)\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "            model_output = model(batch)    #running forward pass sets up hooks and stores activations in each dissected_Conv2d module\n",
    "            submodel_output = submodel(batch)\n",
    "            if submodel_activations is None:\n",
    "                submodel_activations = submodel_output.detach()\n",
    "            else:\n",
    "                submodel_activations = torch.cat((submodel_activations,submodel_output.detach()), 0)\n",
    "    relu = nn.ReLU(inplace=True)          \n",
    "    model_activations = relu(torch.cat(model_activations, 0))\n",
    "    submodel_activations = relu(torch.squeeze(submodel_activations,1))\n",
    "    #print(model_activations.shape)\n",
    "    #print(submodel_activations.shape)\n",
    "    handle.remove()\n",
    "    return torch.flatten(model_activations),torch.flatten(submodel_activations)\n",
    "            \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778\n",
      "0.7745696660048859  ,  0.5116  ,  0.7652\n",
      "0.13940580799706243  ,  0.7978  ,  1.0169\n",
      "0.19354182284293464  ,  0.7515  ,  1.0987\n",
      "779\n",
      "0.806221110504077  ,  0.4545  ,  0.6532\n",
      "0.29132016007305794  ,  0.9409  ,  0.8724\n",
      "0.06219288175060243  ,  0.9074  ,  1.1058\n",
      "780\n",
      "0.860918179185226  ,  0.6756  ,  0.8713\n",
      "0.41384233491230316  ,  0.7715  ,  0.9377\n",
      "nan  ,  0.7059  ,  1.3333\n",
      "781\n",
      "0.7826688953639427  ,  0.4977  ,  0.6873\n",
      "0.15808855253604095  ,  0.8612  ,  1.2801\n",
      "-0.13888289048990415  ,  0.8888  ,  1.1705\n",
      "782\n",
      "0.8080083964659365  ,  0.4836  ,  0.8277\n",
      "0.16659495393149842  ,  0.8738  ,  1.5586\n",
      "0.04293929789584785  ,  0.8845  ,  1.5739\n",
      "783\n",
      "0.8342742972534697  ,  0.4751  ,  0.88\n",
      "0.16307719851268304  ,  0.8639  ,  1.679\n",
      "-0.0287325324723664  ,  0.9457  ,  1.5815\n",
      "784\n",
      "0.8183514755503213  ,  0.4999  ,  0.7163\n",
      "-0.0069905626832210445  ,  1.0062  ,  1.3648\n",
      "0.4012826766232229  ,  1.0404  ,  1.166\n",
      "785\n",
      "0.7087562345056948  ,  0.3569  ,  0.7949\n",
      "0.3242167397725074  ,  0.4997  ,  1.0838\n",
      "0.28418274473516425  ,  0.68  ,  0.9954\n",
      "786\n",
      "0.833824031310668  ,  0.3865  ,  0.6208\n",
      "0.29694864156670286  ,  0.7603  ,  1.0706\n",
      "0.2620596135712844  ,  0.8181  ,  1.1027\n",
      "787\n",
      "0.8017730836411177  ,  0.4263  ,  0.777\n",
      "0.17789695893606836  ,  0.7332  ,  1.4034\n",
      "-0.07156380915497348  ,  0.7784  ,  1.3663\n",
      "788\n",
      "0.8539503977160618  ,  0.4365  ,  0.855\n",
      "0.004218467041649706  ,  0.6158  ,  1.4354\n",
      "0.027502470084070765  ,  0.6695  ,  1.3636\n",
      "789\n",
      "0.7802179228881228  ,  0.7792  ,  1.177\n",
      "0.037820899612502415  ,  0.9737  ,  1.1323\n",
      "-0.02459696322471316  ,  0.82  ,  1.3009\n",
      "790\n",
      "0.5646565317409711  ,  0.2756  ,  0.7867\n",
      "0.08639013546934599  ,  0.3772  ,  0.8445\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "791\n",
      "0.8281869326024722  ,  0.4973  ,  0.7307\n",
      "0.12808859473028994  ,  0.8858  ,  1.5218\n",
      "-0.004033719607374413  ,  0.9325  ,  1.3776\n",
      "792\n",
      "0.773543399257545  ,  0.4505  ,  0.8783\n",
      "0.08460095326969382  ,  0.877  ,  1.0307\n",
      "0.034867979587166746  ,  0.6832  ,  1.2136\n",
      "793\n",
      "0.8450145094158732  ,  0.3462  ,  0.5377\n",
      "0.14571829542799186  ,  0.6589  ,  0.9828\n",
      "0.04268089169218298  ,  0.6396  ,  1.0675\n",
      "794\n",
      "0.776812418053489  ,  0.4989  ,  0.9873\n",
      "0.18317872048222744  ,  0.7418  ,  1.0176\n",
      "0.19427090413984724  ,  0.5615  ,  1.0898\n",
      "795\n",
      "0.8717355402387265  ,  0.5714  ,  0.9521\n",
      "0.39434144659108356  ,  0.9309  ,  1.6738\n",
      "nan  ,  0.9408  ,  1.7\n",
      "796\n",
      "0.8474123373200226  ,  0.4234  ,  0.6979\n",
      "0.3283073752138674  ,  0.7973  ,  1.4081\n",
      "nan  ,  0.828  ,  1.4744\n",
      "797\n",
      "0.8561149361793252  ,  0.5317  ,  0.833\n",
      "0.08807962595619455  ,  0.7664  ,  1.5182\n",
      "-0.05612352606234133  ,  0.8395  ,  1.407\n",
      "798\n",
      "0.8467336764642599  ,  0.5689  ,  0.6795\n",
      "0.40276320142860145  ,  0.9319  ,  1.2713\n",
      "-0.0027574123059320227  ,  1.0054  ,  1.5072\n",
      "799\n",
      "0.875647032989206  ,  0.3544  ,  0.5751\n",
      "0.11783295454124114  ,  0.6603  ,  1.3367\n",
      "nan  ,  0.6569  ,  1.3666\n",
      "800\n",
      "0.8770180148045543  ,  0.3708  ,  0.5519\n",
      "0.3422999007151646  ,  0.7529  ,  1.0188\n",
      "-0.025681177504516067  ,  0.8535  ,  1.0314\n",
      "801\n",
      "0.7456908790501715  ,  0.8634  ,  0.9867\n",
      "0.340077202219354  ,  1.0354  ,  1.4514\n",
      "nan  ,  1.0765  ,  1.5242\n",
      "802\n",
      "0.8289684783966926  ,  0.1971  ,  0.5206\n",
      "0.01893883243237832  ,  0.3346  ,  0.9704\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "803\n",
      "0.7822614961326713  ,  0.3654  ,  1.0455\n",
      "0.36879696221329733  ,  0.512  ,  1.6921\n",
      "nan  ,  0.5134  ,  1.7097\n",
      "804\n",
      "0.8291665725690116  ,  0.4777  ,  0.7972\n",
      "0.20728331286298152  ,  0.7576  ,  1.2594\n",
      "0.11508869298904723  ,  0.7974  ,  1.2668\n",
      "805\n",
      "0.7849225995425844  ,  0.4702  ,  0.6887\n",
      "0.07356471614995898  ,  1.1671  ,  0.8164\n",
      "nan  ,  0.7444  ,  1.268\n",
      "806\n",
      "0.8186216470152923  ,  0.3283  ,  0.669\n",
      "0.288261849210368  ,  0.6611  ,  1.0561\n",
      "0.041399742737538284  ,  0.6665  ,  1.1138\n",
      "807\n",
      "0.7507969749673333  ,  0.7006  ,  0.9447\n",
      "0.17682661303351702  ,  1.2918  ,  1.156\n",
      "0.012034623534448244  ,  1.2455  ,  1.2589\n",
      "808\n",
      "0.7632417587418868  ,  0.5348  ,  0.9181\n",
      "0.31554463929648274  ,  0.8311  ,  1.419\n",
      "nan  ,  0.8413  ,  1.5434\n",
      "809\n",
      "0.8431621443394637  ,  0.4981  ,  0.9676\n",
      "0.2900340033096487  ,  0.8497  ,  0.9562\n",
      "0.026932260177102534  ,  0.6487  ,  1.0682\n",
      "810\n",
      "0.7283055886576253  ,  0.3827  ,  0.707\n",
      "0.00893737180323088  ,  0.7651  ,  0.8913\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "811\n",
      "0.8505880752124328  ,  0.3955  ,  0.6325\n",
      "0.16648281430772371  ,  0.7426  ,  1.3766\n",
      "nan  ,  0.7441  ,  1.4173\n",
      "812\n",
      "0.7043982373452392  ,  0.5127  ,  0.8391\n",
      "0.13646546393337367  ,  0.6923  ,  0.8356\n",
      "-0.10176009580216536  ,  0.5948  ,  0.8848\n",
      "813\n",
      "0.7814818385326223  ,  0.3338  ,  0.6699\n",
      "0.21944572977529947  ,  0.8031  ,  0.8292\n",
      "0.042159897541064695  ,  0.6547  ,  0.9925\n",
      "814\n",
      "0.8671337057124502  ,  0.4659  ,  0.7311\n",
      "0.22816012706137972  ,  0.9215  ,  1.5122\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "815\n",
      "0.7692405432403141  ,  0.5159  ,  0.7915\n",
      "0.10016070642561187  ,  0.6568  ,  1.0687\n",
      "nan  ,  0.6384  ,  1.1517\n",
      "816\n",
      "0.7995483508851318  ,  0.4052  ,  0.7949\n",
      "0.06694094398402475  ,  0.6562  ,  1.3967\n",
      "0.018456652932843296  ,  0.604  ,  1.4496\n",
      "817\n",
      "0.83500232315656  ,  0.3699  ,  0.5848\n",
      "0.2529109425321806  ,  0.7025  ,  1.0186\n",
      "0.19879970599389968  ,  0.8092  ,  0.9065\n",
      "818\n",
      "0.7561292606656504  ,  0.4107  ,  0.6812\n",
      "0.20229168184830215  ,  0.9116  ,  0.7853\n",
      "0.05540099069910355  ,  0.5013  ,  0.8778\n",
      "819\n",
      "0.7088908798674217  ,  0.4371  ,  0.8493\n",
      "0.04747875723711379  ,  0.396  ,  1.0466\n",
      "0.00716130035752062  ,  0.4342  ,  1.0103\n",
      "820\n",
      "0.7798179326923567  ,  0.282  ,  0.6607\n",
      "0.1039149237087009  ,  0.5258  ,  1.0772\n",
      "-0.1176144293497885  ,  0.6038  ,  0.9748\n",
      "821\n",
      "0.8452144681888933  ,  0.7054  ,  1.044\n",
      "0.0765163591374366  ,  0.8163  ,  1.5011\n",
      "nan  ,  0.817  ,  1.5046\n",
      "822\n",
      "0.8181431797414336  ,  0.4746  ,  0.877\n",
      "0.33731200603010325  ,  0.7488  ,  1.4473\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "823\n",
      "0.8942535432651769  ,  0.5018  ,  0.7253\n",
      "0.23228868053090196  ,  0.989  ,  1.8173\n",
      "nan  ,  1.0013  ,  1.8392\n",
      "824\n",
      "0.811053942591116  ,  0.631  ,  0.8475\n",
      "0.11618139253683607  ,  0.8059  ,  1.3705\n",
      "0.09224674579717357  ,  0.8181  ,  1.3855\n",
      "825\n",
      "0.8834391089664229  ,  0.3391  ,  0.7403\n",
      "0.09814925438003591  ,  0.6339  ,  1.6703\n",
      "nan  ,  0.6377  ,  1.6835\n",
      "826\n",
      "0.855221086036013  ,  0.3588  ,  0.7037\n",
      "0.11933664366162153  ,  0.6066  ,  1.4943\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "827\n",
      "0.8032443985154443  ,  0.7088  ,  1.0782\n",
      "0.14052061710530958  ,  1.1258  ,  1.6431\n",
      "0.04864016010491632  ,  1.1315  ,  1.7183\n",
      "828\n",
      "0.9086549675011313  ,  0.3154  ,  0.6397\n",
      "0.3202028108936265  ,  0.7084  ,  1.6346\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "829\n",
      "0.6959351674529981  ,  0.3933  ,  0.6862\n",
      "0.08441114902940579  ,  0.6191  ,  0.8393\n",
      "nan  ,  0.5398  ,  0.9663\n",
      "830\n",
      "0.81702305794693  ,  0.5488  ,  0.7058\n",
      "0.041404493464575906  ,  1.0192  ,  1.4028\n",
      "nan  ,  1.0213  ,  1.4041\n",
      "831\n",
      "0.8302029263049016  ,  0.6472  ,  0.8576\n",
      "0.35877676355799276  ,  1.0563  ,  1.6053\n",
      "0.10703309534042978  ,  1.2  ,  1.3062\n",
      "832\n",
      "0.7321669213533003  ,  0.1986  ,  0.6026\n",
      "-0.017540057081465447  ,  0.3106  ,  0.903\n",
      "0.16017841050292791  ,  0.3773  ,  0.8313\n",
      "833\n",
      "0.8246479037649143  ,  0.7527  ,  1.19\n",
      "0.034803539183333794  ,  0.9617  ,  1.754\n",
      "0.05620890277725568  ,  1.0299  ,  1.569\n",
      "834\n",
      "0.8541990548186211  ,  0.419  ,  0.6959\n",
      "0.02827445112484852  ,  0.725  ,  0.9975\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "835\n",
      "0.8285083881208216  ,  0.496  ,  0.8313\n",
      "0.24220770305307568  ,  0.5639  ,  1.2291\n",
      "0.010877706367740998  ,  0.5882  ,  1.2527\n",
      "836\n",
      "0.8183032521567931  ,  0.4669  ,  0.7518\n",
      "0.05911937188440481  ,  0.8558  ,  1.439\n",
      "0.017054985426543885  ,  0.8792  ,  1.3729\n",
      "837\n",
      "0.8982283819553518  ,  0.2687  ,  0.6833\n",
      "0.023763708716875897  ,  0.5105  ,  1.5905\n",
      "0.018059393728388707  ,  0.6631  ,  1.4691\n",
      "838\n",
      "0.75723731690696  ,  0.3454  ,  0.7166\n",
      "0.04254571470552249  ,  0.4914  ,  1.1723\n",
      "0.07920847845849463  ,  0.5039  ,  1.1578\n",
      "839\n",
      "0.7742868285273459  ,  0.2784  ,  0.6581\n",
      "0.1648514716334401  ,  0.4398  ,  1.0526\n",
      "-0.04474810395708946  ,  0.4882  ,  1.0304\n",
      "840\n",
      "0.635345468876571  ,  0.464  ,  0.9572\n",
      "0.04181350086278948  ,  0.5367  ,  1.1596\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "841\n",
      "0.7958074000548969  ,  0.3951  ,  0.8182\n",
      "-0.016545529721348314  ,  0.6782  ,  1.4331\n",
      "-0.0906395281053247  ,  0.7252  ,  1.3558\n",
      "842\n",
      "0.8701644784605311  ,  0.2534  ,  0.5269\n",
      "0.16782426884136237  ,  0.5174  ,  1.1094\n",
      "-0.08032881782706955  ,  0.5614  ,  1.0855\n",
      "843\n",
      "0.8228176319433983  ,  0.4564  ,  0.7742\n",
      "0.01111973853821831  ,  0.7997  ,  1.5226\n",
      "nan  ,  0.7999  ,  1.523\n",
      "844\n",
      "0.8774602401645069  ,  0.477  ,  0.7763\n",
      "0.1408074217166675  ,  1.161  ,  1.1484\n",
      "nan  ,  0.8372  ,  1.5933\n",
      "845\n",
      "0.8782870740310285  ,  0.367  ,  0.8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2888667084003023  ,  0.978  ,  1.265\n",
      "nan  ,  0.6834  ,  1.6465\n",
      "846\n",
      "0.8102136690513437  ,  0.3387  ,  0.6211\n",
      "0.29220400488617576  ,  0.5776  ,  1.1426\n",
      "-0.013164140786358164  ,  0.6358  ,  1.0945\n",
      "847\n",
      "0.8599663091406242  ,  0.1971  ,  0.5112\n",
      "0.004599782830023859  ,  0.3995  ,  0.986\n",
      "nan  ,  0.3444  ,  1.0146\n",
      "848\n",
      "0.8721450908408872  ,  0.2114  ,  0.608\n",
      "0.24682812284095634  ,  0.3718  ,  1.2982\n",
      "nan  ,  0.3713  ,  1.3116\n",
      "849\n",
      "0.8268125374860223  ,  0.1566  ,  0.5499\n",
      "0.0694728629267908  ,  1.3811  ,  1.0566\n",
      "0.03831083087786079  ,  0.2927  ,  0.9255\n",
      "850\n",
      "0.7581710197817373  ,  0.466  ,  0.6887\n",
      "0.00715820284378593  ,  0.5799  ,  1.0905\n",
      "0.001310820187532792  ,  0.5854  ,  1.0741\n",
      "851\n",
      "0.8759220070556203  ,  0.2469  ,  0.5951\n",
      "0.039034039974787875  ,  0.512  ,  1.2352\n",
      "-0.05466223269508644  ,  0.4832  ,  1.2471\n",
      "852\n",
      "0.7337337406100306  ,  0.3451  ,  0.8229\n",
      "0.3253254416994815  ,  0.6224  ,  1.011\n",
      "0.016538935878056098  ,  0.6542  ,  1.0674\n",
      "853\n",
      "0.80723358782689  ,  0.4933  ,  0.8507\n",
      "0.30964075634681604  ,  0.8456  ,  1.2436\n",
      "0.050063494957260396  ,  0.8413  ,  1.4111\n",
      "854\n",
      "0.8589554179330323  ,  0.4099  ,  1.0156\n",
      "0.17168137531031122  ,  0.6963  ,  1.694\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "855\n",
      "0.9010362357463753  ,  0.3417  ,  0.4999\n",
      "0.05348181498975075  ,  0.7802  ,  1.271\n",
      "0.0565352759179078  ,  0.799  ,  1.2046\n",
      "856\n",
      "0.7679765950633889  ,  0.4789  ,  0.6638\n",
      "0.11638169617118796  ,  0.7903  ,  1.1273\n",
      "0.1387207590864725  ,  0.8063  ,  1.1629\n",
      "857\n",
      "0.8071170625388302  ,  0.4852  ,  0.796\n",
      "0.08801947581822792  ,  0.8306  ,  1.3874\n",
      "0.34357815613668  ,  0.8631  ,  1.2297\n",
      "858\n",
      "0.8598043017218271  ,  0.4475  ,  0.7263\n",
      "0.20999563023545448  ,  0.9049  ,  1.1718\n",
      "0.10503623913851631  ,  0.7738  ,  1.4496\n",
      "859\n",
      "0.8625109011059977  ,  0.3776  ,  0.5979\n",
      "0.14374102208661593  ,  0.7744  ,  1.3642\n",
      "nan  ,  0.7753  ,  1.3673\n",
      "860\n",
      "0.9323846047747955  ,  0.247  ,  0.5192\n",
      "0.14084625311078808  ,  0.6184  ,  1.5392\n",
      "-0.07519665138170466  ,  0.6194  ,  1.5578\n",
      "861\n",
      "0.895069184261432  ,  0.3196  ,  0.6868\n",
      "0.33226567552762576  ,  1.3117  ,  1.2561\n",
      "nan  ,  0.5276  ,  1.5139\n",
      "862\n",
      "0.8308490130343952  ,  0.3609  ,  0.7807\n",
      "0.32478482491826605  ,  0.5436  ,  1.0794\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "863\n",
      "0.7200622264960157  ,  0.4127  ,  0.7991\n",
      "0.07449941637118629  ,  0.5623  ,  1.2742\n",
      "0.02032684626669328  ,  0.6321  ,  1.1745\n",
      "864\n",
      "0.8393446764842558  ,  0.4716  ,  0.7754\n",
      "0.12324295674889885  ,  0.8479  ,  1.5229\n",
      "0.00581375044612566  ,  0.8955  ,  1.4396\n",
      "865\n",
      "0.8561989750181584  ,  0.4739  ,  0.6585\n",
      "0.11768655206416617  ,  0.8817  ,  1.4821\n",
      "-0.10883503103448178  ,  0.8927  ,  1.4073\n",
      "866\n",
      "0.6056097930029187  ,  0.3472  ,  0.791\n",
      "-0.009870606016950756  ,  0.4326  ,  1.0199\n",
      "0.24583378796656025  ,  0.4438  ,  1.0044\n",
      "867\n",
      "0.8292999901933464  ,  0.6556  ,  0.8534\n",
      "0.12978092872029612  ,  0.9093  ,  1.6565\n",
      "nan  ,  0.9191  ,  1.6931\n",
      "868\n",
      "0.8653249027093816  ,  0.5663  ,  0.7556\n",
      "0.35608109380781544  ,  1.0621  ,  1.2727\n",
      "0.344001101529316  ,  1.1253  ,  1.3433\n",
      "869\n",
      "0.7737951505778266  ,  0.4757  ,  0.885\n",
      "0.15103740464727095  ,  0.8713  ,  1.2168\n",
      "nan  ,  0.6916  ,  1.477\n",
      "870\n",
      "0.8487356395519045  ,  0.4984  ,  0.6925\n",
      "0.1764522596864966  ,  1.0133  ,  1.2431\n",
      "-0.2539278082193638  ,  1.0589  ,  1.2687\n",
      "871\n",
      "0.8943555798642648  ,  0.3276  ,  0.5011\n",
      "0.2061126270135495  ,  0.7894  ,  1.0926\n",
      "-0.09859049143058723  ,  0.8027  ,  1.1637\n",
      "872\n",
      "0.8105206942648422  ,  0.6417  ,  0.9481\n",
      "0.451139665232955  ,  0.9716  ,  1.4746\n",
      "0.27135657815440284  ,  1.054  ,  1.6643\n",
      "873\n",
      "0.843527475098583  ,  0.4536  ,  0.7595\n",
      "nan  ,  0.8965  ,  1.543\n",
      "nan  ,  0.8965  ,  1.543\n",
      "874\n",
      "0.8272585373981156  ,  0.4464  ,  0.7292\n",
      "0.1864981230616386  ,  0.5984  ,  1.1518\n",
      "nan  ,  0.586  ,  1.2262\n",
      "875\n",
      "0.8261032238130931  ,  0.4256  ,  0.5836\n",
      "0.07801286765928092  ,  0.782  ,  1.2566\n",
      "0.0097782807951006  ,  0.7933  ,  1.1899\n",
      "876\n",
      "0.802236556051368  ,  0.3436  ,  0.7143\n",
      "0.22954852530069128  ,  0.708  ,  0.9884\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "877\n",
      "0.7578239666523385  ,  0.4141  ,  0.7534\n",
      "0.1399954011608911  ,  0.6488  ,  1.0945\n",
      "0.13689286712729312  ,  0.7303  ,  1.0001\n",
      "878\n",
      "0.8245062335049697  ,  0.4732  ,  0.7473\n",
      "0.18380264419637246  ,  0.9961  ,  1.1904\n",
      "-0.06648058661606498  ,  0.977  ,  1.2959\n",
      "879\n",
      "0.7460780323244001  ,  0.4087  ,  0.7961\n",
      "0.04593012154420362  ,  0.552  ,  1.2696\n",
      "nan  ,  0.5423  ,  1.2861\n",
      "880\n",
      "0.821873837782293  ,  0.6287  ,  0.98\n",
      "0.022533232929627146  ,  0.8185  ,  1.5152\n",
      "-0.014387608599076958  ,  0.8269  ,  1.4909\n",
      "881\n",
      "0.8125693358032865  ,  0.5227  ,  0.8105\n",
      "0.1411972992481726  ,  0.8962  ,  1.4128\n",
      "0.06140215009945994  ,  0.9183  ,  1.4335\n",
      "882\n",
      "0.8748978470323424  ,  0.4551  ,  0.6034\n",
      "0.3327342083972104  ,  0.9834  ,  1.359\n",
      "-0.01842370410221203  ,  1.0366  ,  1.3955\n",
      "883\n",
      "0.7408885738580525  ,  0.6806  ,  0.9773\n",
      "0.26377077021907214  ,  1.0039  ,  1.4202\n",
      "-0.007789608327712479  ,  1.0514  ,  1.3326\n",
      "884\n",
      "0.7800156850654949  ,  1.0309  ,  1.1645\n",
      "0.16497899451233514  ,  0.7886  ,  1.2028\n",
      "0.22301323269464704  ,  0.815  ,  1.0995\n",
      "885\n",
      "0.8169995520996648  ,  0.5104  ,  0.812\n",
      "0.2247549061899745  ,  0.7683  ,  1.2618\n",
      "nan  ,  0.7796  ,  1.3437\n",
      "886\n",
      "0.8435825789631884  ,  0.5119  ,  0.6524\n",
      "0.20348488907267284  ,  0.9906  ,  1.3431\n",
      "-0.0010298717559882277  ,  1.0319  ,  1.4319\n",
      "887\n",
      "0.78801342920898  ,  0.4088  ,  0.7312\n",
      "0.04114702917975377  ,  0.6771  ,  1.3027\n",
      "nan  ,  0.6772  ,  1.3083\n",
      "888\n",
      "0.7587354229318838  ,  0.4465  ,  0.796\n",
      "0.18346955324119832  ,  0.7352  ,  1.3406\n",
      "0.13826920169637508  ,  0.7754  ,  1.2838\n",
      "889\n",
      "0.7626449837981604  ,  0.6213  ,  0.7616\n",
      "0.2002944048915841  ,  0.9223  ,  1.3765\n",
      "-0.02831037506355661  ,  0.9862  ,  1.189\n",
      "890\n",
      "0.8658456514847728  ,  0.4378  ,  0.8388\n",
      "-0.0074629080363549614  ,  0.9224  ,  1.8477\n",
      "0.13187240795988253  ,  0.9464  ,  1.8014\n",
      "891\n",
      "0.8268686813966373  ,  0.3803  ,  0.843\n",
      "0.0753205455140226  ,  0.5203  ,  1.293\n",
      "nan  ,  0.5204  ,  1.2951\n",
      "892\n",
      "0.8444026161130898  ,  0.3955  ,  0.7013\n",
      "0.30908737780736484  ,  0.6698  ,  1.3394\n",
      "-0.048243912155820856  ,  0.7851  ,  1.2942\n",
      "893\n",
      "0.8352894978315257  ,  0.2773  ,  0.5893\n",
      "-0.028229424270675416  ,  0.9355  ,  0.7292\n",
      "-0.050169498256881745  ,  0.503  ,  1.0451\n",
      "894\n",
      "0.7892755320109178  ,  0.617  ,  0.7442\n",
      "0.08242629152874148  ,  1.1567  ,  1.4199\n",
      "0.04220714964318561  ,  1.1072  ,  1.283\n",
      "895\n",
      "0.8240631067800523  ,  0.3249  ,  0.6444\n",
      "0.282575691329636  ,  0.6488  ,  0.9865\n",
      "-0.05947461711375529  ,  0.617  ,  1.1301\n",
      "896\n",
      "0.8819914770253257  ,  0.2612  ,  0.8587\n",
      "0.40482711896850704  ,  0.2165  ,  0.8875\n",
      "-0.051492549150862085  ,  0.2354  ,  0.911\n",
      "897\n",
      "0.7015485342428693  ,  0.2966  ,  0.662\n",
      "-0.0021323602552861384  ,  0.4319  ,  0.9537\n",
      "0.0073826725499166815  ,  0.6015  ,  0.8021\n",
      "898\n",
      "0.6827023694282022  ,  0.1935  ,  0.5131\n",
      "0.09178602175358375  ,  0.3182  ,  0.6122\n",
      "-0.07481463296872704  ,  0.3511  ,  0.5889\n",
      "899\n",
      "0.8073154837151496  ,  0.219  ,  0.4904\n",
      "0.2675382679165973  ,  0.4081  ,  0.7996\n",
      "-0.13137682009890533  ,  0.6188  ,  0.6435\n",
      "900\n",
      "0.7837062124626912  ,  0.272  ,  0.6567\n",
      "-0.013918372646765417  ,  0.3622  ,  0.9627\n",
      "-0.03149686090586499  ,  0.4399  ,  0.8884\n",
      "901\n",
      "0.8376829395497476  ,  0.1957  ,  0.4864\n",
      "0.14048357582928794  ,  0.326  ,  0.934\n",
      "0.08941726883855161  ,  0.3492  ,  0.914\n",
      "902\n",
      "0.7273002981138476  ,  0.1719  ,  0.4798\n",
      "0.04180862406574131  ,  0.3032  ,  0.6597\n",
      "-0.027646169526188265  ,  0.235  ,  0.6844\n",
      "903\n",
      "0.6381705944884684  ,  0.177  ,  0.5068\n",
      "-0.002687531594304777  ,  0.2194  ,  0.6761\n",
      "nan  ,  0.218  ,  0.6767\n",
      "904\n",
      "0.827445763242699  ,  0.152  ,  0.4057\n",
      "-0.012524313024190376  ,  0.2933  ,  0.6697\n",
      "-0.017825885248182655  ,  0.2957  ,  0.6626\n",
      "905\n",
      "0.6637938116026997  ,  0.1079  ,  0.4173\n",
      "0.04546551865220953  ,  0.2702  ,  0.5207\n",
      "0.0030801867221136245  ,  0.262  ,  0.4873\n",
      "906\n",
      "0.4869201714666789  ,  0.2022  ,  0.5929\n",
      "0.05957165855345069  ,  0.2667  ,  0.6601\n",
      "0.054501311984303046  ,  0.2505  ,  0.6679\n",
      "907\n",
      "0.810070918256864  ,  0.161  ,  0.4513\n",
      "0.05502781068081829  ,  0.5606  ,  0.639\n",
      "-0.031317527999640576  ,  0.5612  ,  0.6114\n",
      "908\n",
      "0.7358950428640809  ,  0.1926  ,  0.5156\n",
      "0.06428526273103029  ,  0.1935  ,  0.5382\n",
      "-0.0010950511313010105  ,  0.3194  ,  0.467\n",
      "909\n",
      "0.6852014175856146  ,  0.2533  ,  0.6598\n",
      "-0.0028805439114365826  ,  0.1593  ,  0.6018\n",
      "nan  ,  0.1593  ,  0.6018\n",
      "910\n",
      "0.5881493135128355  ,  0.0962  ,  0.4551\n",
      "0.003928343496188617  ,  0.1164  ,  0.5463\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "911\n",
      "0.8221129421961696  ,  0.3103  ,  0.7003\n",
      "0.22288868739499168  ,  0.3476  ,  1.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  ,  0.3275  ,  1.0499\n",
      "912\n",
      "0.6620495924874641  ,  0.2983  ,  0.6322\n",
      "0.13135805552089824  ,  0.4495  ,  0.786\n",
      "0.015319248406018381  ,  0.7106  ,  0.6008\n",
      "913\n",
      "0.8053247415757177  ,  0.1591  ,  0.5573\n",
      "0.04281058184005139  ,  0.2142  ,  0.8992\n",
      "0.034657856558911126  ,  0.2354  ,  0.8896\n",
      "914\n",
      "0.7959149323935295  ,  0.1467  ,  0.4646\n",
      "0.16506304960026508  ,  0.2204  ,  0.7768\n",
      "nan  ,  0.2208  ,  0.779\n",
      "915\n",
      "0.48119249778016093  ,  0.2595  ,  0.5927\n",
      "0.04078811910781729  ,  0.4274  ,  0.5951\n",
      "0.04713102649257808  ,  0.3852  ,  0.6002\n",
      "916\n",
      "0.4840845250597694  ,  0.2972  ,  0.7096\n",
      "0.06784225258659118  ,  0.2361  ,  0.7146\n",
      "-0.032526296128342  ,  0.3046  ,  0.666\n",
      "917\n",
      "0.8239569178854556  ,  0.1746  ,  0.4712\n",
      "-0.01927538085378559  ,  0.3196  ,  0.8403\n",
      "-0.0359118457098837  ,  0.4852  ,  0.7044\n",
      "918\n",
      "0.5465600658490842  ,  0.1893  ,  0.4216\n",
      "-0.009182820603163316  ,  0.9804  ,  0.3025\n",
      "0.005877578251859592  ,  0.9103  ,  0.2781\n",
      "919\n",
      "0.6571976587380403  ,  0.2082  ,  0.5126\n",
      "0.011829229580117402  ,  0.5693  ,  0.5182\n",
      "-0.058829002674565166  ,  0.3772  ,  0.6163\n",
      "920\n",
      "0.6752712780811667  ,  0.6341  ,  0.9524\n",
      "0.01437296877445592  ,  0.6895  ,  0.7555\n",
      "0.020724008776954076  ,  0.6556  ,  0.7475\n",
      "921\n",
      "0.7433534096301309  ,  0.273  ,  0.5796\n",
      "0.1442024074381844  ,  0.42  ,  0.8885\n",
      "-0.060725926347689904  ,  0.5241  ,  0.7928\n",
      "922\n",
      "0.7724184826229255  ,  0.2065  ,  0.5546\n",
      "0.03803339081561011  ,  0.3627  ,  0.8464\n",
      "0.06635690520489065  ,  0.3426  ,  0.8623\n",
      "923\n",
      "0.8057805569022587  ,  0.1814  ,  0.5971\n",
      "-0.06223062086153798  ,  0.3982  ,  0.9886\n",
      "0.056662998533501305  ,  0.2781  ,  1.0389\n",
      "924\n",
      "0.7658312289886874  ,  0.1342  ,  0.4349\n",
      "0.05834421719559604  ,  0.3542  ,  0.6318\n",
      "-0.0006332428471743012  ,  0.2719  ,  0.6292\n",
      "925\n",
      "0.5408021156126269  ,  0.1738  ,  0.5185\n",
      "0.07684483512598413  ,  0.5794  ,  0.4471\n",
      "0.038087892039113544  ,  0.3881  ,  0.5006\n",
      "926\n",
      "0.7766130988996742  ,  0.1523  ,  0.477\n",
      "-0.027943653897577518  ,  0.2339  ,  0.7719\n",
      "-0.03163538971746008  ,  0.2365  ,  0.7633\n",
      "927\n",
      "0.6402282564482957  ,  0.2422  ,  0.5594\n",
      "0.06095611124135013  ,  0.6289  ,  0.5046\n",
      "-0.028632830570138088  ,  0.4333  ,  0.6142\n",
      "928\n",
      "0.6628629097641605  ,  0.2322  ,  0.6233\n",
      "0.4213927114803261  ,  0.2973  ,  0.8331\n",
      "-0.020696322145116675  ,  0.3046  ,  0.8412\n",
      "929\n",
      "0.8097358755987952  ,  0.3255  ,  0.7128\n",
      "-0.09738157531419657  ,  0.5087  ,  0.8955\n",
      "0.06912194363526311  ,  0.5157  ,  0.858\n",
      "930\n",
      "0.7581636461728674  ,  0.1956  ,  0.5796\n",
      "0.023846081962695536  ,  0.29  ,  0.8917\n",
      "0.023665099160028846  ,  0.3598  ,  0.8449\n",
      "931\n",
      "0.7555077944231923  ,  0.2204  ,  0.4866\n",
      "-0.03136219922299564  ,  0.35  ,  0.6667\n",
      "0.0291809076499871  ,  0.3651  ,  0.6346\n",
      "932\n",
      "0.7367458752176024  ,  0.2529  ,  0.5749\n",
      "-0.021067613455608078  ,  0.364  ,  0.8897\n",
      "-0.012051698934856457  ,  0.3966  ,  0.8496\n",
      "933\n",
      "0.6394521844783827  ,  0.2384  ,  0.6186\n",
      "0.12426203817631641  ,  0.407  ,  0.7455\n",
      "-0.007599709389306874  ,  0.3534  ,  0.7943\n",
      "934\n",
      "0.7585837500622324  ,  0.1919  ,  0.5187\n",
      "0.047086666516297164  ,  0.2724  ,  0.8212\n",
      "-0.025791162527651873  ,  0.4312  ,  0.7001\n",
      "935\n",
      "0.7867330232107932  ,  0.345  ,  0.6656\n",
      "0.08749202497854226  ,  0.5007  ,  0.9585\n",
      "-0.14861721728349336  ,  0.5255  ,  0.9259\n",
      "936\n",
      "0.6661560966553808  ,  0.3194  ,  0.5525\n",
      "0.024985199106138768  ,  0.3387  ,  0.7775\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "937\n",
      "0.8512994934902964  ,  0.2104  ,  0.4939\n",
      "0.1541766561485731  ,  0.609  ,  0.8103\n",
      "0.013812319722632277  ,  0.6171  ,  0.8159\n",
      "938\n",
      "0.8491254145152072  ,  0.2631  ,  0.6091\n",
      "0.24152815604145486  ,  0.4392  ,  1.061\n",
      "-0.06985539909183919  ,  0.5054  ,  1.014\n",
      "939\n",
      "0.7126322673834753  ,  0.1364  ,  0.4013\n",
      "0.06193253728262614  ,  0.3134  ,  0.5143\n",
      "0.00761839419058785  ,  0.4765  ,  0.4166\n",
      "940\n",
      "0.7899757854084714  ,  0.1945  ,  0.5641\n",
      "0.06186824143604372  ,  0.4349  ,  0.8284\n",
      "-0.0019557193546010307  ,  0.4972  ,  0.7861\n",
      "941\n",
      "0.8059256243703006  ,  0.2069  ,  0.4936\n",
      "-0.05894750768216871  ,  0.4265  ,  0.7674\n",
      "-0.16396410478624027  ,  0.5403  ,  0.6468\n",
      "942\n",
      "0.6889282590091352  ,  0.7223  ,  1.2214\n",
      "0.030339904242219173  ,  0.3683  ,  0.9782\n",
      "nan  ,  0.3254  ,  1.012\n",
      "943\n",
      "0.567084232046108  ,  0.4039  ,  0.7612\n",
      "-0.029250515017778887  ,  0.8385  ,  0.6162\n",
      "0.016516576378063474  ,  0.9789  ,  0.5276\n",
      "944\n",
      "0.6179661890038466  ,  0.3686  ,  0.5863\n",
      "0.033664409029195534  ,  0.3913  ,  0.7349\n",
      "0.1476753435761052  ,  0.3578  ,  0.7588\n",
      "945\n",
      "0.6481744894746027  ,  0.224  ,  0.5439\n",
      "0.15131702359747465  ,  0.3055  ,  0.5588\n",
      "-0.05296441051684806  ,  0.402  ,  0.5018\n",
      "946\n",
      "0.7137692133534032  ,  0.2571  ,  0.655\n",
      "0.01394363739293426  ,  0.4879  ,  0.8329\n",
      "0.014617995483731083  ,  0.4818  ,  0.8245\n",
      "947\n",
      "0.7281064155989004  ,  0.2533  ,  0.5648\n",
      "0.19186290934572237  ,  0.4501  ,  0.6412\n",
      "0.05920634605897213  ,  0.5012  ,  0.6217\n",
      "948\n",
      "0.6590162046071326  ,  0.3887  ,  0.708\n",
      "0.002649997024389235  ,  0.687  ,  0.6125\n",
      "-0.08071489068086873  ,  0.5644  ,  0.6755\n",
      "949\n",
      "0.7396620701133152  ,  0.3185  ,  0.5606\n",
      "-0.024613659013146345  ,  0.3648  ,  0.8591\n",
      "0.019323520975200188  ,  0.4271  ,  0.7814\n",
      "950\n",
      "0.4366777497601768  ,  0.2893  ,  0.5005\n",
      "0.06309072597499828  ,  0.5569  ,  0.2757\n",
      "0.042319109875389456  ,  0.5546  ,  0.263\n",
      "951\n",
      "0.7275457330904044  ,  0.108  ,  0.4719\n",
      "-0.061807960190943576  ,  0.1766  ,  0.5364\n",
      "nan  ,  0.1238  ,  0.5465\n",
      "952\n",
      "0.8092271436534769  ,  0.5023  ,  0.8774\n",
      "-0.07422608875804025  ,  0.4634  ,  1.0731\n",
      "-0.0590590827358933  ,  0.5504  ,  0.9655\n",
      "953\n",
      "0.7229940124768043  ,  0.2014  ,  0.4777\n",
      "0.10264166769888874  ,  0.2925  ,  0.7011\n",
      "0.10834445135427713  ,  0.3778  ,  0.6297\n",
      "954\n",
      "0.7052364437679344  ,  0.41  ,  0.7556\n",
      "0.042604605123771525  ,  0.6418  ,  1.0489\n",
      "0.04525937012440931  ,  0.6825  ,  0.9923\n",
      "955\n",
      "0.7531452840363262  ,  0.1826  ,  0.6303\n",
      "-0.005482000067638909  ,  0.1438  ,  0.8979\n",
      "0.0021612414149556024  ,  0.1602  ,  0.8923\n",
      "956\n",
      "0.6204239689242277  ,  0.2194  ,  0.4925\n",
      "-0.07722692823004182  ,  0.5592  ,  0.4789\n",
      "0.174647992927663  ,  0.301  ,  0.5258\n",
      "957\n",
      "0.8437093637491038  ,  0.2563  ,  0.475\n",
      "-0.0287190658197454  ,  0.4346  ,  0.9572\n",
      "-0.012794583585090148  ,  0.5172  ,  0.8452\n",
      "958\n",
      "0.7188626153741723  ,  0.195  ,  0.4934\n",
      "0.25628909501563163  ,  0.3789  ,  0.5988\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "959\n",
      "0.7745125435578704  ,  0.1815  ,  0.5679\n",
      "-0.021719074823061395  ,  0.2549  ,  0.9267\n",
      "-0.04267308611157031  ,  0.2713  ,  0.9158\n",
      "960\n",
      "0.7348246792248831  ,  0.1684  ,  0.5713\n",
      "-0.02141552474585339  ,  0.2302  ,  0.8692\n",
      "-0.05186443301457055  ,  0.2764  ,  0.8408\n",
      "961\n",
      "0.6304028177338098  ,  0.2269  ,  0.6059\n",
      "0.03172287186702905  ,  0.5303  ,  0.5454\n",
      "0.008421567962835705  ,  0.3924  ,  0.5869\n",
      "962\n",
      "0.8050729370331557  ,  0.1646  ,  0.6512\n",
      "0.03899808824674167  ,  0.2432  ,  0.9631\n",
      "nan  ,  0.224  ,  0.9738\n",
      "963\n",
      "0.6314097925591474  ,  0.3211  ,  0.6007\n",
      "0.004942491907715957  ,  0.4958  ,  0.6675\n",
      "0.03138437639507913  ,  0.4766  ,  0.6808\n",
      "964\n",
      "0.8035016165593387  ,  0.276  ,  0.5491\n",
      "0.055192409207488725  ,  0.459  ,  0.91\n",
      "-0.04401223315252393  ,  0.5127  ,  0.8528\n",
      "965\n",
      "0.7947892356850181  ,  0.211  ,  0.5005\n",
      "-0.03190583195294199  ,  0.3543  ,  0.8138\n",
      "-0.0073625588898074915  ,  0.3457  ,  0.8094\n",
      "966\n",
      "0.8059772673608803  ,  0.0867  ,  0.4051\n",
      "0.01431078385619361  ,  0.129  ,  0.6684\n",
      "nan  ,  0.121  ,  0.6713\n",
      "967\n",
      "0.8256663251976453  ,  0.1125  ,  0.4851\n",
      "0.005690782425327175  ,  0.2313  ,  0.7597\n",
      "nan  ,  0.1578  ,  0.777\n",
      "968\n",
      "0.708645837987531  ,  0.206  ,  0.5671\n",
      "0.10109050084096646  ,  0.3765  ,  0.7247\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "969\n",
      "0.5558644873917453  ,  0.1512  ,  0.4793\n",
      "0.14197515339340563  ,  0.2463  ,  0.5171\n",
      "0.15240192129202113  ,  0.4473  ,  0.4136\n",
      "970\n",
      "0.747356871421834  ,  0.3512  ,  0.793\n",
      "0.16421459753843945  ,  0.5005  ,  0.5371\n",
      "-0.011123256931724855  ,  0.5063  ,  0.5318\n",
      "971\n",
      "0.7931138577635649  ,  0.17  ,  0.4574\n",
      "0.18018532743203428  ,  0.5623  ,  0.5787\n",
      "-0.04720554019001206  ,  0.4435  ,  0.6563\n",
      "972\n",
      "0.9088237074892622  ,  0.1543  ,  0.5389\n",
      "0.3123677608757558  ,  0.3105  ,  1.0573\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "973\n",
      "0.7637252178195939  ,  0.374  ,  0.7351\n",
      "-0.02361259058759968  ,  0.2801  ,  0.794\n",
      "-0.011120481836600327  ,  0.257  ,  0.7981\n",
      "974\n",
      "0.8000434735262738  ,  0.216  ,  0.5365\n",
      "0.04899788195220156  ,  0.3073  ,  0.8497\n",
      "-0.12268386986769533  ,  0.3596  ,  0.8047\n",
      "975\n",
      "0.6573062521082337  ,  0.3334  ,  0.8557\n",
      "0.08580119566937566  ,  0.3871  ,  1.0789\n",
      "0.01844690296221598  ,  0.3876  ,  1.0789\n",
      "976\n",
      "0.702426011866496  ,  0.4319  ,  0.8951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.003813834843631318  ,  0.2413  ,  0.7455\n",
      "nan  ,  0.2412  ,  0.7456\n",
      "977\n",
      "0.7513528144640182  ,  0.237  ,  0.4846\n",
      "0.05131837994105312  ,  0.5013  ,  0.6086\n",
      "-0.02132398155866287  ,  0.6506  ,  0.4768\n",
      "978\n",
      "0.6046537731225083  ,  0.1797  ,  0.4974\n",
      "0.062446708459775305  ,  0.2112  ,  0.6235\n",
      "nan  ,  0.2112  ,  0.6239\n",
      "979\n",
      "0.7701936369531646  ,  0.2242  ,  0.4911\n",
      "0.28953171131095634  ,  0.419  ,  0.6998\n",
      "-0.16457680517398876  ,  0.6664  ,  0.5406\n",
      "980\n",
      "0.5652514013997835  ,  0.2503  ,  0.7812\n",
      "0.06908586477591543  ,  0.2629  ,  0.3164\n",
      "0.025862239310551243  ,  0.1659  ,  0.3513\n",
      "981\n",
      "0.7378551175419392  ,  0.1889  ,  0.5759\n",
      "-0.024059247419170253  ,  0.2495  ,  0.8828\n",
      "nan  ,  0.2243  ,  0.8933\n",
      "982\n",
      "0.6877247395704267  ,  0.2418  ,  0.5594\n",
      "-0.05686627318477787  ,  0.4591  ,  0.6661\n",
      "-0.032584093655949706  ,  0.5507  ,  0.5664\n",
      "983\n",
      "0.6528648326772765  ,  0.4769  ,  0.7596\n",
      "0.07459320956833727  ,  0.7534  ,  0.4814\n",
      "0.005416204947894434  ,  0.6555  ,  0.4918\n",
      "984\n",
      "0.7161872402503584  ,  0.2188  ,  0.6087\n",
      "0.04359926106385187  ,  0.3127  ,  0.8776\n",
      "nan  ,  0.288  ,  0.8972\n",
      "985\n",
      "0.8225908269790165  ,  0.264  ,  0.6348\n",
      "0.02216502094330674  ,  0.3349  ,  0.8264\n",
      "0.04779185564677432  ,  0.3517  ,  0.8117\n",
      "986\n",
      "0.7018411078891441  ,  0.2078  ,  0.5621\n",
      "0.022633761819931646  ,  0.2229  ,  0.723\n",
      "0.04534752823579989  ,  0.2125  ,  0.7267\n",
      "987\n",
      "0.7597081274804409  ,  0.2388  ,  0.5597\n",
      "0.11584935847505566  ,  0.3666  ,  0.8854\n",
      "-0.053849375151407475  ,  0.4543  ,  0.7875\n",
      "988\n",
      "0.7560256048178093  ,  0.5807  ,  1.1274\n",
      "-0.06430058162250694  ,  0.4244  ,  0.9695\n",
      "-0.0678803725941442  ,  0.3528  ,  1.0066\n",
      "989\n",
      "0.7092537858983702  ,  0.1788  ,  0.52\n",
      "0.07235507630085419  ,  0.2636  ,  0.7055\n",
      "0.07877092818700183  ,  0.2655  ,  0.7068\n",
      "990\n",
      "0.7999861908988766  ,  0.1621  ,  0.4203\n",
      "nan  ,  0.2487  ,  0.7466\n",
      "-0.024776209765866423  ,  0.2578  ,  0.7388\n",
      "991\n",
      "0.8653225409362107  ,  0.1759  ,  0.4316\n",
      "0.262582546352926  ,  0.358  ,  0.8664\n",
      "-0.08627907395412839  ,  0.369  ,  0.8888\n",
      "992\n",
      "0.7189647583203873  ,  0.306  ,  0.6\n",
      "0.0556473592598537  ,  0.5173  ,  0.7208\n",
      "-0.09360876859303614  ,  0.4459  ,  0.782\n",
      "993\n",
      "0.6245681813632636  ,  0.1902  ,  0.514\n",
      "0.053638279165241096  ,  0.2551  ,  0.6474\n",
      "-0.000646496692367389  ,  0.3425  ,  0.5811\n",
      "994\n",
      "0.729943693573426  ,  0.161  ,  0.5417\n",
      "0.01686328342145102  ,  0.2245  ,  0.7934\n",
      "0.008495416556899402  ,  0.2215  ,  0.7952\n",
      "995\n",
      "0.7342380676544076  ,  0.2718  ,  0.622\n",
      "0.01722999499364135  ,  0.7945  ,  0.695\n",
      "0.0021367697799758905  ,  0.5821  ,  0.7844\n",
      "996\n",
      "0.7474938929747705  ,  0.2199  ,  0.5436\n",
      "0.051854953406282836  ,  0.4649  ,  0.7372\n",
      "-0.006648924799270509  ,  0.5274  ,  0.6871\n",
      "997\n",
      "0.7840242106291235  ,  0.2561  ,  0.6156\n",
      "-0.032543186706405235  ,  0.4629  ,  0.9165\n",
      "0.07201300942987887  ,  0.5492  ,  0.8174\n",
      "998\n",
      "0.7730500149244662  ,  0.1331  ,  0.4338\n",
      "0.1613106579065148  ,  0.2421  ,  0.665\n",
      "nan  ,  0.1738  ,  0.7109\n",
      "999\n",
      "0.8295749060739055  ,  0.2802  ,  0.6453\n",
      "-0.0030890135793225706  ,  0.5417  ,  1.0863\n",
      "0.10690424202896845  ,  0.7371  ,  0.8748\n",
      "1000\n",
      "0.6765202677616877  ,  0.1817  ,  0.5199\n",
      "-0.01654529932660676  ,  0.1981  ,  0.6722\n",
      "-0.013446343151665815  ,  0.1961  ,  0.673\n",
      "1001\n",
      "0.7322970880405298  ,  0.2306  ,  0.5751\n",
      "0.06527971228389289  ,  0.699  ,  0.4864\n",
      "-0.07656560752831948  ,  0.6283  ,  0.5037\n",
      "1002\n",
      "0.7013583215664627  ,  0.1961  ,  0.4025\n",
      "0.30917977883285774  ,  0.6022  ,  0.2844\n",
      "-0.08634445264850332  ,  0.7032  ,  0.2701\n",
      "1003\n",
      "0.83502300255261  ,  0.1541  ,  0.4003\n",
      "0.18077879731342744  ,  0.4075  ,  0.6264\n",
      "-0.06674125847684616  ,  0.5345  ,  0.5592\n",
      "1004\n",
      "0.733006301028851  ,  0.1954  ,  0.5484\n",
      "0.0421375859907823  ,  0.2812  ,  0.8159\n",
      "-0.017717202579381437  ,  0.3568  ,  0.7539\n",
      "1005\n",
      "0.5549146077973642  ,  0.3803  ,  0.9657\n",
      "-0.021369165936019317  ,  0.1383  ,  0.659\n",
      "0.061185583520923195  ,  0.1448  ,  0.6554\n",
      "1006\n",
      "0.7443348648759918  ,  0.2344  ,  0.5473\n",
      "0.07101488125383891  ,  0.3249  ,  0.86\n",
      "nan  ,  0.322  ,  0.8655\n",
      "1007\n",
      "0.6693956559156193  ,  0.2115  ,  0.593\n",
      "0.03675083083891989  ,  0.2956  ,  0.7177\n",
      "-0.07857339235339661  ,  0.2693  ,  0.7323\n",
      "1008\n",
      "0.6950641620084278  ,  0.1711  ,  0.5227\n",
      "0.08952997536205799  ,  0.4318  ,  0.6195\n",
      "-0.05584553818558262  ,  0.3146  ,  0.6837\n",
      "1009\n",
      "0.7450793745078047  ,  0.2013  ,  0.4818\n",
      "0.1353378257693266  ,  0.4423  ,  0.5292\n",
      "0.007653427824437189  ,  0.5792  ,  0.4392\n",
      "1010\n",
      "0.7085082815160295  ,  0.5233  ,  0.8422\n",
      "-0.017394198392116  ,  0.469  ,  0.7926\n",
      "0.08358310315692345  ,  0.4326  ,  0.8173\n",
      "1011\n",
      "0.7683019802787856  ,  0.1688  ,  0.5399\n",
      "-0.004778047580028431  ,  0.2134  ,  0.8026\n",
      "-0.025701245551485508  ,  0.3418  ,  0.7277\n",
      "1012\n",
      "0.6824153587520094  ,  0.2385  ,  0.6277\n",
      "-0.0557782642240534  ,  0.3264  ,  0.8942\n",
      "0.06934177107714842  ,  0.3353  ,  0.8822\n",
      "1013\n",
      "0.6620249989011909  ,  0.2154  ,  0.5503\n",
      "0.22734866021733818  ,  0.2654  ,  0.7369\n",
      "nan  ,  0.2627  ,  0.7517\n",
      "1014\n",
      "0.8709403626270407  ,  0.4457  ,  0.9607\n",
      "0.03593597388301605  ,  0.3287  ,  1.268\n",
      "0.05284314890123271  ,  0.4225  ,  1.2121\n",
      "1015\n",
      "0.5664113818593994  ,  0.2243  ,  0.5931\n",
      "-0.031459656002300815  ,  0.2786  ,  0.7291\n",
      "-0.07667376007674767  ,  0.299  ,  0.707\n",
      "1016\n",
      "0.7720722827897736  ,  0.3186  ,  0.7525\n",
      "0.21640104790238832  ,  0.2999  ,  0.8503\n",
      "0.06725500644671155  ,  0.4024  ,  0.8096\n",
      "1017\n",
      "0.8326428102874704  ,  0.1656  ,  0.5951\n",
      "0.06765568489588565  ,  0.163  ,  0.6402\n",
      "nan  ,  0.1577  ,  0.6445\n",
      "1018\n",
      "0.7950987277529845  ,  0.2614  ,  0.4826\n",
      "-0.00300100330985804  ,  0.5777  ,  0.6962\n",
      "-0.054640343167883125  ,  0.6257  ,  0.6303\n",
      "1019\n",
      "0.6357624007608172  ,  0.2632  ,  0.5896\n",
      "0.3019743749986282  ,  0.2195  ,  0.6557\n",
      "-0.10076143542346082  ,  0.2896  ,  0.6018\n",
      "1020\n",
      "0.702478300300336  ,  0.2161  ,  0.582\n",
      "0.11144532415012237  ,  0.3175  ,  0.8099\n",
      "0.08374177962731325  ,  0.2931  ,  0.8391\n",
      "1021\n",
      "0.7187563189982451  ,  0.3708  ,  0.3997\n",
      "0.01254691386950945  ,  1.7705  ,  0.6273\n",
      "-0.06844630589679265  ,  1.6516  ,  0.6161\n",
      "1022\n",
      "0.6948899008045041  ,  0.4492  ,  0.6134\n",
      "0.052493671046435084  ,  0.7708  ,  0.4355\n",
      "-0.13060138306134653  ,  0.5712  ,  0.4911\n",
      "1023\n",
      "0.6981810284790643  ,  0.198  ,  0.7048\n",
      "0.019467095498643935  ,  0.263  ,  0.9221\n",
      "nan  ,  0.2551  ,  0.9266\n",
      "1024\n",
      "0.7852346003362649  ,  0.1606  ,  0.5352\n",
      "0.10627716709272858  ,  0.2694  ,  0.8657\n",
      "-0.047845706989576034  ,  0.283  ,  0.8652\n",
      "1025\n",
      "0.47193350422199104  ,  0.1956  ,  0.6096\n",
      "0.053726362376790564  ,  0.362  ,  0.6269\n",
      "nan  ,  0.1971  ,  0.6991\n",
      "1026\n",
      "0.5931872967317529  ,  0.1572  ,  0.5733\n",
      "0.00811955206583956  ,  0.1595  ,  0.7073\n",
      "-0.0850527839796735  ,  0.1871  ,  0.6938\n",
      "1027\n",
      "0.6917473839703667  ,  0.3418  ,  0.9229\n",
      "0.06611704552520743  ,  0.4258  ,  0.9329\n",
      "0.03690899078999418  ,  0.4483  ,  0.9143\n",
      "1028\n",
      "0.8129064508842843  ,  0.1942  ,  0.6353\n",
      "0.018778426071125304  ,  0.3219  ,  1.0773\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "1029\n",
      "0.8230060668062569  ,  0.1614  ,  0.4627\n",
      "0.011115305532818788  ,  0.324  ,  0.8149\n",
      "-0.06954405522216715  ,  0.2274  ,  0.8555\n",
      "1030\n",
      "0.7907275115447548  ,  0.2133  ,  0.4837\n",
      "0.1648420765304845  ,  0.5705  ,  0.6061\n",
      "0.12584975485965608  ,  0.5823  ,  0.6083\n",
      "1031\n",
      "0.5820551038725543  ,  0.1972  ,  0.5898\n",
      "-0.01314666080151026  ,  0.2602  ,  0.7284\n",
      "0.042623432090016476  ,  0.5103  ,  0.5753\n",
      "1032\n",
      "0.7818159906958915  ,  0.2524  ,  0.6529\n",
      "0.14023589689763075  ,  0.4796  ,  0.881\n",
      "-0.002465419461292518  ,  0.355  ,  0.9877\n",
      "1033\n",
      "0.7537553738594931  ,  0.2088  ,  0.5524\n",
      "0.04931125655044363  ,  0.2884  ,  0.8331\n",
      "nan  ,  0.2671  ,  0.8508\n",
      "1034\n",
      "0.7097085382962642  ,  0.1571  ,  0.3975\n",
      "0.1550646197210989  ,  0.3576  ,  0.4691\n",
      "-0.13629186582081682  ,  0.2804  ,  0.5166\n",
      "1035\n",
      "0.9228558663874982  ,  0.1341  ,  0.464\n",
      "0.006008082704273249  ,  0.3381  ,  1.1334\n",
      "nan  ,  0.2858  ,  1.1571\n",
      "1036\n",
      "0.5674446793422527  ,  0.2671  ,  0.7223\n",
      "-0.032799739248846965  ,  0.4649  ,  0.8217\n",
      "0.030526539141263572  ,  0.4763  ,  0.7581\n",
      "1037\n",
      "0.6944202024663042  ,  0.2281  ,  0.4944\n",
      "-0.01602061546002931  ,  0.3614  ,  0.6852\n",
      "0.07175107361462933  ,  0.3202  ,  0.7132\n",
      "1038\n",
      "0.8860099746552476  ,  0.168  ,  0.4805\n",
      "0.05452621217866272  ,  0.4204  ,  1.013\n",
      "-0.02427207698478507  ,  0.3132  ,  1.0854\n",
      "1039\n",
      "0.781236678384406  ,  0.2103  ,  0.4737\n",
      "0.2248241686508871  ,  0.3847  ,  0.7057\n",
      "-0.06908874909010886  ,  0.6526  ,  0.5322\n",
      "1040\n",
      "0.5912298958625805  ,  0.2859  ,  0.6152\n",
      "0.014673306228134432  ,  0.3518  ,  0.7841\n",
      "-0.04901070171200845  ,  0.4342  ,  0.6923\n",
      "1041\n",
      "0.6476755693070377  ,  0.6238  ,  0.8364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0917554534459913  ,  0.6756  ,  0.4981\n",
      "-0.11974828397873323  ,  0.7586  ,  0.4323\n",
      "1042\n",
      "0.6305261214591823  ,  0.3003  ,  0.5832\n",
      "0.04322912865405094  ,  0.3795  ,  0.5608\n",
      "0.020619130115812682  ,  0.4772  ,  0.4634\n",
      "1043\n",
      "0.6619649841296089  ,  0.1558  ,  0.4955\n",
      "-0.028939919869113064  ,  0.1647  ,  0.6641\n",
      "0.07695667871359957  ,  0.1717  ,  0.6549\n",
      "1044\n",
      "0.37027895792164167  ,  0.2442  ,  0.6871\n",
      "-0.00489258338473559  ,  0.2575  ,  0.7464\n",
      "-0.007406675060150737  ,  0.3553  ,  0.6666\n",
      "1045\n",
      "0.764218371552041  ,  0.2107  ,  0.4681\n",
      "0.2766828477830463  ,  0.6236  ,  0.4888\n",
      "-0.06849999821752692  ,  0.8408  ,  0.3934\n",
      "1046\n",
      "0.5753692934359091  ,  0.2373  ,  0.6561\n",
      "-0.02390598305798699  ,  0.2518  ,  0.8408\n",
      "0.07411977677949971  ,  0.3381  ,  0.7799\n",
      "1047\n",
      "0.7925507322600804  ,  0.2472  ,  0.6709\n",
      "0.0195443589570164  ,  0.2896  ,  0.7305\n",
      "-0.028821943062436753  ,  0.4511  ,  0.6275\n",
      "1048\n",
      "0.7948513288235486  ,  0.2968  ,  0.5605\n",
      "0.2651029529659757  ,  0.4259  ,  0.6716\n",
      "-0.025971410024236787  ,  0.6957  ,  0.5248\n",
      "1049\n",
      "0.6216742700887864  ,  0.3169  ,  0.6953\n",
      "0.1995763519279506  ,  0.4605  ,  0.7916\n",
      "nan  ,  0.3799  ,  0.9186\n",
      "1050\n",
      "0.7414044486334139  ,  0.278  ,  0.5968\n",
      "0.11333267530854617  ,  0.493  ,  0.8356\n",
      "0.03525992286892259  ,  0.7001  ,  0.6934\n",
      "1051\n",
      "0.7689185103627072  ,  0.1885  ,  0.5765\n",
      "0.08927523463220491  ,  0.2935  ,  0.8242\n",
      "-0.016656761816793438  ,  0.3262  ,  0.8048\n",
      "1052\n",
      "0.6906403009302946  ,  0.6981  ,  0.8366\n",
      "0.186254823514939  ,  0.6965  ,  0.4702\n",
      "-0.014937824568466682  ,  0.4996  ,  0.5637\n",
      "1053\n",
      "0.850405853653423  ,  0.1173  ,  0.3829\n",
      "-0.00759407711430466  ,  0.1816  ,  0.6962\n",
      "0.004968529266779863  ,  0.259  ,  0.6519\n",
      "1054\n",
      "0.6845764777724976  ,  0.2467  ,  0.5295\n",
      "-0.06007068777063481  ,  0.7265  ,  0.4467\n",
      "-0.2719104999557389  ,  0.6911  ,  0.4406\n",
      "1055\n",
      "0.757679582783963  ,  0.1127  ,  0.4204\n",
      "-0.008651319665345584  ,  0.1986  ,  0.6471\n",
      "0.06040901706903331  ,  0.2557  ,  0.6113\n",
      "1056\n",
      "0.8206220446553478  ,  0.2907  ,  0.7869\n",
      "0.13760699815872984  ,  0.1881  ,  0.7093\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "1057\n",
      "0.5071729530161483  ,  0.1548  ,  0.4658\n",
      "0.011353890144738322  ,  0.6544  ,  0.3671\n",
      "0.11085463598234661  ,  0.48  ,  0.3761\n",
      "1058\n",
      "0.7452722071538922  ,  0.2172  ,  0.5084\n",
      "-0.0064368535243700935  ,  0.3028  ,  0.8091\n",
      "0.10586169773458223  ,  0.3282  ,  0.7821\n",
      "1059\n",
      "0.7835636753693516  ,  0.279  ,  0.6372\n",
      "-0.01322556989291553  ,  0.2725  ,  0.8663\n",
      "-0.048062273588286755  ,  0.3758  ,  0.7902\n",
      "1060\n",
      "0.788725192263062  ,  0.2697  ,  0.4741\n",
      "0.18215373492494835  ,  0.595  ,  0.5927\n",
      "0.06190305970518198  ,  0.6919  ,  0.5383\n",
      "1061\n",
      "0.7770494724841239  ,  0.2111  ,  0.4672\n",
      "0.09080391769589005  ,  0.4385  ,  0.6758\n",
      "0.10152625848045152  ,  0.4998  ,  0.6247\n",
      "1062\n",
      "0.7681607732677752  ,  0.2883  ,  0.6772\n",
      "-0.029993888417988168  ,  0.4069  ,  1.0549\n",
      "0.07606096774408683  ,  0.4644  ,  0.9938\n",
      "1063\n",
      "0.6845957002730416  ,  0.2757  ,  0.5562\n",
      "0.168397693557149  ,  0.5333  ,  0.5895\n",
      "0.04997338849268083  ,  0.361  ,  0.7994\n",
      "1064\n",
      "0.7169678487684981  ,  0.5274  ,  1.0213\n",
      "-0.06584939395453199  ,  0.4235  ,  0.7553\n",
      "0.021274063584966512  ,  0.5577  ,  0.5847\n",
      "1065\n",
      "0.6487509862908851  ,  0.3264  ,  0.7281\n",
      "0.11959871717646312  ,  0.677  ,  0.5816\n",
      "-0.038783062450961706  ,  0.3278  ,  0.7152\n",
      "1066\n",
      "0.669770674522193  ,  0.1475  ,  0.5433\n",
      "0.13620170085051944  ,  0.5717  ,  0.5048\n",
      "-0.061640938803613286  ,  0.244  ,  0.5903\n",
      "1067\n",
      "0.7931508487053265  ,  0.39  ,  0.7917\n",
      "-0.06282938630688378  ,  0.3371  ,  0.9577\n",
      "0.06854967494811678  ,  0.4552  ,  0.8563\n",
      "1068\n",
      "0.7244647392474148  ,  0.2608  ,  0.4668\n",
      "0.0735175668182222  ,  0.8882  ,  0.3991\n",
      "0.05733338536481554  ,  0.6727  ,  0.4392\n",
      "1069\n",
      "0.6821158347979567  ,  0.1629  ,  0.5725\n",
      "0.05858153486282937  ,  0.2463  ,  0.7691\n",
      "-0.04293496419501354  ,  0.2226  ,  0.7866\n",
      "1070\n",
      "0.6879252628940811  ,  0.3311  ,  0.8422\n",
      "0.03419711393797093  ,  0.248  ,  0.7583\n",
      "0.00848228749632276  ,  0.3137  ,  0.7189\n",
      "1071\n",
      "0.7824831301935339  ,  0.2626  ,  0.7499\n",
      "-0.03685833956818375  ,  0.3641  ,  1.114\n",
      "-0.08448238499771046  ,  0.4206  ,  1.0658\n",
      "1072\n",
      "0.685172784759144  ,  0.2456  ,  0.7653\n",
      "0.15812251442386194  ,  0.2174  ,  0.7678\n",
      "nan  ,  0.1737  ,  0.7998\n",
      "1073\n",
      "0.8024154736174904  ,  0.3225  ,  0.5838\n",
      "0.2139589941415953  ,  0.5153  ,  0.8879\n",
      "0.04742914109761974  ,  0.54  ,  0.8965\n",
      "1074\n",
      "0.6652370731022427  ,  0.1751  ,  0.5\n",
      "0.03295865489507223  ,  0.2165  ,  0.6727\n",
      "0.01697577512663899  ,  0.2574  ,  0.6414\n",
      "1075\n",
      "0.8898827806650558  ,  0.1628  ,  0.4792\n",
      "0.19224330350119795  ,  0.3995  ,  0.9934\n",
      "-0.056854581706653126  ,  0.433  ,  1.0008\n",
      "1076\n",
      "0.5489758818553062  ,  0.1986  ,  0.5902\n",
      "0.04798413674446351  ,  0.2958  ,  0.6351\n",
      "0.010437107910440365  ,  0.2046  ,  0.6684\n",
      "1077\n",
      "0.7454209118121986  ,  0.3775  ,  0.7521\n",
      "0.1165750931439284  ,  0.4583  ,  0.6318\n",
      "0.01868463605236621  ,  0.393  ,  0.6753\n",
      "1078\n",
      "0.7225476373409947  ,  0.224  ,  0.5226\n",
      "0.05500019801093839  ,  0.3696  ,  0.734\n",
      "0.04524642023997248  ,  0.4816  ,  0.632\n",
      "1079\n",
      "0.727245385369963  ,  0.1823  ,  0.5411\n",
      "-0.009584948641285769  ,  0.2648  ,  0.8021\n",
      "-0.048869358835229824  ,  0.2824  ,  0.7866\n",
      "1080\n",
      "0.5314508561322336  ,  0.1565  ,  0.5423\n",
      "-0.002167886500432945  ,  0.1147  ,  0.5755\n",
      "-0.043527773697791226  ,  0.1876  ,  0.5448\n",
      "1081\n",
      "0.7595407812334203  ,  0.4502  ,  0.7372\n",
      "0.11390297826229086  ,  0.6417  ,  1.2443\n",
      "0.07088679849357823  ,  0.7242  ,  1.0995\n",
      "1082\n",
      "0.7553787724875851  ,  0.1792  ,  0.5028\n",
      "-0.00020823020072002491  ,  0.258  ,  0.7916\n",
      "-0.06306390751690542  ,  0.3389  ,  0.728\n",
      "1083\n",
      "0.8590432023100707  ,  0.1099  ,  0.3677\n",
      "-0.017860136560349203  ,  0.1905  ,  0.7358\n",
      "nan  ,  0.1893  ,  0.7359\n",
      "1084\n",
      "0.5784084040328189  ,  0.1829  ,  0.5908\n",
      "-0.010379084542679924  ,  0.2159  ,  0.7105\n",
      "0.025664580281005118  ,  0.3166  ,  0.6419\n",
      "1085\n",
      "0.663282114863969  ,  0.2696  ,  0.5448\n",
      "0.10752696024908798  ,  0.3715  ,  0.7391\n",
      "nan  ,  0.3489  ,  0.7851\n",
      "1086\n",
      "0.7750476449646797  ,  0.1446  ,  0.5112\n",
      "-0.09023258857525213  ,  0.2547  ,  0.7764\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "1087\n",
      "0.6386167260493432  ,  0.2014  ,  0.5916\n",
      "-0.05036137246953021  ,  0.2436  ,  0.6684\n",
      "0.057256481099043494  ,  0.2888  ,  0.6275\n",
      "1088\n",
      "0.7104668190146759  ,  0.1413  ,  0.4729\n",
      "0.10069318367384256  ,  0.1855  ,  0.676\n",
      "-0.028905029828739066  ,  0.2698  ,  0.6307\n",
      "1089\n",
      "0.7026323257486241  ,  0.1993  ,  0.6708\n",
      "-0.009209464420375443  ,  0.2501  ,  0.9639\n",
      "nan  ,  0.2501  ,  0.9639\n",
      "1090\n",
      "0.7517408823218494  ,  0.2768  ,  0.5749\n",
      "-0.04965798238365612  ,  0.366  ,  0.8805\n",
      "0.04284681093596991  ,  0.3679  ,  0.863\n",
      "1091\n",
      "0.7802514965429233  ,  0.1714  ,  0.5661\n",
      "0.2589234992088579  ,  0.3256  ,  0.641\n",
      "nan  ,  0.1792  ,  0.7435\n",
      "1092\n",
      "0.8085085290599056  ,  0.1909  ,  0.6202\n",
      "-0.00998738347989193  ,  0.2319  ,  0.9879\n",
      "-0.033393114812276005  ,  0.2622  ,  0.9713\n",
      "1093\n",
      "0.7098314854437606  ,  0.2081  ,  0.6237\n",
      "0.18226811424435618  ,  0.5002  ,  0.6036\n",
      "-0.0011238212575007734  ,  0.3268  ,  0.6987\n",
      "1094\n",
      "0.7857016898488507  ,  0.2744  ,  0.537\n",
      "-0.054247441783511034  ,  0.4498  ,  0.9236\n",
      "0.01876309844916645  ,  0.597  ,  0.7483\n",
      "1095\n",
      "0.7748010118591921  ,  0.2272  ,  0.4499\n",
      "0.04541517086513937  ,  0.397  ,  0.6645\n",
      "-0.005000798064272994  ,  0.3466  ,  0.6944\n",
      "1096\n",
      "0.7584964036892596  ,  0.6224  ,  0.9908\n",
      "-0.021473844726864293  ,  0.4282  ,  0.8423\n",
      "0.06725506941402551  ,  0.5408  ,  0.7122\n",
      "1097\n",
      "0.7157919992419868  ,  0.2512  ,  0.488\n",
      "0.23677349412727955  ,  0.7044  ,  0.419\n",
      "-0.10151968130150163  ,  0.7611  ,  0.3935\n",
      "1098\n",
      "0.8509359125254826  ,  0.3262  ,  0.7597\n",
      "-0.11054254862793324  ,  0.3711  ,  0.8799\n",
      "0.05811451935313417  ,  0.4534  ,  0.8025\n",
      "1099\n",
      "0.43619551604585516  ,  0.2504  ,  0.8104\n",
      "0.05758715754604876  ,  0.2772  ,  0.9078\n",
      "0.016678682210393255  ,  0.338  ,  0.8657\n",
      "1100\n",
      "0.7698279362931038  ,  0.3113  ,  0.5825\n",
      "0.05985162307814413  ,  0.4718  ,  0.937\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "1101\n",
      "0.7614381933470771  ,  0.3165  ,  0.6735\n",
      "0.19597352778242472  ,  0.6475  ,  0.6059\n",
      "0.01140564124930049  ,  0.2706  ,  0.8094\n",
      "1102\n",
      "0.7087922175769575  ,  0.5195  ,  1.0707\n",
      "0.2639198044409334  ,  0.6973  ,  0.5682\n",
      "-0.0007450839845062097  ,  0.3891  ,  0.7882\n",
      "1103\n",
      "0.6224658509435588  ,  0.2468  ,  0.5983\n",
      "0.11265747236869998  ,  0.2742  ,  0.7696\n",
      "0.007187775338690535  ,  0.3815  ,  0.6868\n",
      "1104\n",
      "0.6064778062857592  ,  0.3507  ,  0.8632\n",
      "0.12845303174875394  ,  0.4297  ,  1.0733\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "1105\n",
      "0.7554232872185073  ,  0.285  ,  0.5978\n",
      "0.2112795270794803  ,  0.3905  ,  0.6052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005985473240630302  ,  0.5891  ,  0.4752\n",
      "1106\n",
      "0.6271079902981846  ,  0.218  ,  0.4879\n",
      "-0.019290182225686375  ,  1.0198  ,  0.5402\n",
      "-0.10900640847432638  ,  0.5519  ,  0.4348\n",
      "1107\n",
      "0.829863091098689  ,  0.1652  ,  0.4599\n",
      "-0.001753116075861154  ,  0.4048  ,  0.7118\n",
      "0.045022000649323435  ,  0.5227  ,  0.6391\n",
      "1108\n",
      "0.6953938188308703  ,  0.1916  ,  0.4581\n",
      "0.210678266449431  ,  0.3623  ,  0.5537\n",
      "0.016710938660603844  ,  0.5476  ,  0.4453\n",
      "1109\n",
      "0.8560328639097124  ,  0.207  ,  0.5805\n",
      "-0.08015514873298782  ,  0.6946  ,  0.6383\n",
      "-0.041969875963822505  ,  0.4773  ,  0.7019\n",
      "1110\n",
      "0.7669749378033996  ,  0.282  ,  0.6019\n",
      "0.1544553262417626  ,  0.6729  ,  0.7112\n",
      "-0.011249794812554233  ,  0.6626  ,  0.7324\n",
      "1111\n",
      "0.74681246828045  ,  0.2085  ,  0.4531\n",
      "0.15364214240303803  ,  0.6894  ,  0.4417\n",
      "-0.13407547902589095  ,  0.5625  ,  0.4933\n",
      "1112\n",
      "0.7096705504283385  ,  0.2392  ,  0.5944\n",
      "0.20750074991673131  ,  0.5304  ,  0.6347\n",
      "-0.006825322324566925  ,  0.4271  ,  0.736\n",
      "1113\n",
      "0.5841213586295243  ,  0.2068  ,  0.5351\n",
      "-0.027013901713554302  ,  0.4821  ,  0.5259\n",
      "-0.005269519585910883  ,  0.4262  ,  0.4735\n",
      "1114\n",
      "0.6142377761880862  ,  0.3028  ,  0.682\n",
      "0.09006129506550385  ,  0.3281  ,  0.5959\n",
      "-0.00476251137753652  ,  0.581  ,  0.439\n",
      "1115\n",
      "0.8820105758360968  ,  0.4408  ,  0.9376\n",
      "0.3327128332605955  ,  0.4998  ,  1.011\n",
      "nan  ,  0.3843  ,  1.1772\n",
      "1116\n",
      "0.7915923400923475  ,  0.2593  ,  0.6234\n",
      "0.13688796719415  ,  0.4512  ,  0.92\n",
      "0.02808789918559646  ,  0.3862  ,  1.0012\n",
      "1117\n",
      "0.8035688422681436  ,  0.1681  ,  0.5529\n",
      "0.1740777519629423  ,  0.3316  ,  0.8669\n",
      "nan  ,  0.2654  ,  0.9269\n",
      "1118\n",
      "0.6439950828995424  ,  0.2067  ,  0.5425\n",
      "0.011695500993236855  ,  0.3515  ,  0.6679\n",
      "0.04026857084228688  ,  0.2602  ,  0.7001\n",
      "1119\n",
      "0.745529309908711  ,  0.1726  ,  0.3981\n",
      "0.197794115806973  ,  0.6488  ,  0.3763\n",
      "0.15699703712788277  ,  0.6236  ,  0.3772\n",
      "1120\n",
      "0.7678052853378312  ,  0.2265  ,  0.5796\n",
      "0.1249292887577882  ,  0.5966  ,  0.7462\n",
      "-0.05131487448261238  ,  0.4376  ,  0.8378\n",
      "1121\n",
      "0.8322597980200619  ,  0.1852  ,  0.5217\n",
      "0.028228953379969265  ,  0.2436  ,  0.8045\n",
      "-0.04408227294787924  ,  0.3149  ,  0.7576\n",
      "1122\n",
      "0.5317737707461847  ,  0.3334  ,  0.6216\n",
      "0.09326902061669316  ,  0.6428  ,  0.492\n",
      "0.11338606877291166  ,  0.635  ,  0.4913\n",
      "1123\n",
      "0.7752852080001482  ,  0.1281  ,  0.4602\n",
      "0.08333777468380858  ,  0.3942  ,  0.6674\n",
      "nan  ,  0.1698  ,  0.7426\n",
      "1124\n",
      "0.7110367973097773  ,  0.2303  ,  0.5295\n",
      "0.16985068395074898  ,  0.6891  ,  0.5505\n",
      "-0.02630672496917482  ,  0.6247  ,  0.5726\n",
      "1125\n",
      "0.664965519188744  ,  0.2183  ,  0.5283\n",
      "0.014629881954296762  ,  0.2979  ,  0.6668\n",
      "0.059764784577275104  ,  0.4074  ,  0.5841\n",
      "1126\n",
      "0.7058676507756774  ,  0.2346  ,  0.4973\n",
      "0.25220119064226837  ,  0.6268  ,  0.4451\n",
      "-0.030408958282319574  ,  0.6388  ,  0.452\n",
      "1127\n",
      "0.7188597434509524  ,  0.4131  ,  0.9308\n",
      "0.050563135564764966  ,  0.5077  ,  0.721\n",
      "-0.027549128011430786  ,  0.4581  ,  0.7386\n",
      "1128\n",
      "0.7607074167787312  ,  0.2035  ,  0.5998\n",
      "0.02110281672652726  ,  0.2826  ,  0.8461\n",
      "0.02359298849027107  ,  0.3223  ,  0.8152\n",
      "1129\n",
      "0.6767428868137069  ,  0.2939  ,  0.5973\n",
      "-0.04439343453838351  ,  0.3834  ,  0.8425\n",
      "-0.02222155233109947  ,  0.5613  ,  0.6617\n",
      "1130\n",
      "0.7546935673362465  ,  0.3284  ,  0.5871\n",
      "0.03320954024514383  ,  0.4411  ,  0.8295\n",
      "0.06825439667887033  ,  0.6302  ,  0.6618\n",
      "1131\n",
      "0.7567169446078363  ,  0.3468  ,  0.9771\n",
      "0.010087968220804402  ,  0.2453  ,  0.7362\n",
      "0.07125546408216982  ,  0.3014  ,  0.7049\n",
      "1132\n",
      "0.8310115664614194  ,  0.2355  ,  0.4831\n",
      "0.15206265646985465  ,  0.3729  ,  0.6654\n",
      "-0.01043281144962695  ,  0.3753  ,  0.6744\n",
      "1133\n",
      "0.7475405183323669  ,  0.2785  ,  0.5512\n",
      "0.11421814281423737  ,  0.3503  ,  0.7717\n",
      "0.0058691495459375735  ,  0.3245  ,  0.8065\n",
      "1134\n",
      "0.8716466446783975  ,  0.1493  ,  0.3885\n",
      "0.0750955151870735  ,  0.3228  ,  0.7539\n",
      "-0.08591600556033535  ,  0.2983  ,  0.7723\n",
      "1135\n",
      "0.6122312830033724  ,  0.1722  ,  0.5198\n",
      "0.07270449521404013  ,  0.274  ,  0.6193\n",
      "0.08158290300915846  ,  0.3164  ,  0.5895\n",
      "1136\n",
      "0.8322929561092043  ,  0.114  ,  0.3918\n",
      "-0.0309341755641584  ,  0.2041  ,  0.7204\n",
      "0.002654264250215103  ,  0.2509  ,  0.6902\n",
      "1137\n",
      "0.7191780509502006  ,  0.2797  ,  0.7661\n",
      "-0.034380768999690975  ,  0.242  ,  0.7172\n",
      "0.019914414335190783  ,  0.4991  ,  0.5655\n",
      "1138\n",
      "0.7908886934185707  ,  0.2268  ,  0.6534\n",
      "0.048500336528808606  ,  0.2465  ,  0.8036\n",
      "-0.056717502320401174  ,  0.2628  ,  0.793\n",
      "1139\n",
      "0.7758073787090849  ,  0.2175  ,  0.5242\n",
      "-0.013193358594362157  ,  0.2986  ,  0.8266\n",
      "nan  ,  0.2982  ,  0.8267\n",
      "1140\n",
      "0.7682136482980026  ,  0.2014  ,  0.5541\n",
      "0.1303741459563769  ,  0.3063  ,  0.8246\n",
      "-0.04557544254864854  ,  0.3637  ,  0.7909\n",
      "1141\n",
      "0.8190900661541729  ,  0.3354  ,  0.905\n",
      "0.04574419546592608  ,  0.2209  ,  0.8123\n",
      "nan  ,  0.2207  ,  0.8129\n",
      "1142\n",
      "0.774403242531241  ,  0.2163  ,  0.6324\n",
      "-0.1202591814082466  ,  0.4275  ,  0.9173\n",
      "-0.04298641056236212  ,  0.556  ,  0.8132\n",
      "1143\n",
      "0.7273106232583488  ,  0.2011  ,  0.631\n",
      "-0.003354908822897359  ,  0.1664  ,  0.7488\n",
      "nan  ,  0.1664  ,  0.7488\n",
      "1144\n",
      "0.7364479258403465  ,  0.327  ,  0.8782\n",
      "0.06494916808939136  ,  0.4133  ,  0.6279\n",
      "0.07363336499244465  ,  0.3345  ,  0.6661\n",
      "1145\n",
      "0.6423515308208987  ,  0.1934  ,  0.4975\n",
      "-0.009634073165174162  ,  0.3342  ,  0.6014\n",
      "-0.044224562454108156  ,  0.5657  ,  0.4329\n",
      "1146\n",
      "0.7335686365546634  ,  0.2189  ,  0.5228\n",
      "0.03567330353885987  ,  0.5078  ,  0.6721\n",
      "-0.01942768293149022  ,  0.5954  ,  0.5807\n",
      "1147\n",
      "0.7014279286709599  ,  0.4995  ,  0.8946\n",
      "0.11403642352913654  ,  0.3945  ,  0.6739\n",
      "-0.03712260554048484  ,  0.4884  ,  0.5899\n",
      "1148\n",
      "0.8636216832927629  ,  0.2355  ,  0.4277\n",
      "0.010360535231263386  ,  0.5546  ,  0.7888\n",
      "-0.00810096889017109  ,  0.5384  ,  0.796\n",
      "1149\n",
      "0.8281797929000841  ,  0.1843  ,  0.4541\n",
      "0.089441606435128  ,  0.3609  ,  0.7757\n",
      "0.05986404908713708  ,  0.6241  ,  0.597\n",
      "1150\n",
      "0.6723943530163555  ,  0.3409  ,  0.7481\n",
      "0.0008123872514813335  ,  0.3738  ,  0.6644\n",
      "-0.04994926942922916  ,  0.2109  ,  0.7144\n",
      "1151\n",
      "0.4546095672931478  ,  0.1466  ,  0.6138\n",
      "0.016114097397876174  ,  0.1594  ,  0.691\n",
      "nan  ,  0.1587  ,  0.6915\n",
      "64\n",
      "0.8967804012569901  ,  0.3137  ,  0.8865\n",
      "0.8046410651184367  ,  0.4215  ,  0.9519\n",
      "0.5690420003910469  ,  0.7658  ,  1.2587\n",
      "65\n",
      "0.931802044870409  ,  0.3909  ,  1.1942\n",
      "0.542424091622188  ,  3.7336  ,  3.8918\n",
      "0.03001460905883093  ,  0.6743  ,  2.3718\n",
      "66\n",
      "0.8992960090926503  ,  0.7903  ,  1.5968\n",
      "0.8784490429345249  ,  0.7756  ,  1.3729\n",
      "0.8246938014893194  ,  1.0508  ,  2.0795\n",
      "67\n",
      "0.9350919958640351  ,  1.275  ,  1.5927\n",
      "0.6618457281357025  ,  1.9336  ,  2.1978\n",
      "0.6817359957093935  ,  2.5067  ,  3.0591\n",
      "68\n",
      "0.783562402127888  ,  0.2544  ,  0.9259\n",
      "0.6563284678912541  ,  0.3009  ,  1.0605\n",
      "0.14401647613982094  ,  0.3767  ,  1.2172\n",
      "69\n",
      "0.7478277136510684  ,  0.4775  ,  1.0884\n",
      "0.5609379037398221  ,  0.6351  ,  1.1975\n",
      "0.15350585952493692  ,  0.8163  ,  1.4147\n",
      "70\n",
      "0.9237405746387366  ,  0.1677  ,  0.5693\n",
      "-0.0059990879218517305  ,  0.3985  ,  1.5459\n",
      "nan  ,  0.3984  ,  1.546\n",
      "71\n",
      "0.9142110556962424  ,  0.2566  ,  0.6892\n",
      "0.17032079221798035  ,  1.0687  ,  1.5121\n",
      "0.07323971430420514  ,  0.7889  ,  1.6965\n",
      "72\n",
      "0.8118923747951238  ,  0.6779  ,  1.5007\n",
      "0.5405933217125778  ,  2.1895  ,  2.7042\n",
      "0.07240129368135767  ,  0.7429  ,  1.6856\n",
      "73\n",
      "0.7723563130269318  ,  0.4704  ,  1.0016\n",
      "0.16322698076612122  ,  0.7676  ,  1.6412\n",
      "0.10853658077605616  ,  0.8197  ,  1.5479\n",
      "74\n",
      "0.9350545889377639  ,  0.3025  ,  0.7519\n",
      "0.8030579985484781  ,  0.5757  ,  1.4825\n",
      "0.01667626601873191  ,  0.9562  ,  1.8027\n",
      "75\n",
      "0.9838211910132229  ,  0.2228  ,  0.4991\n",
      "0.6730625284233889  ,  2.4856  ,  3.4916\n",
      "nan  ,  0.8849  ,  3.0265\n",
      "76\n",
      "0.9298701457269445  ,  0.3665  ,  0.9522\n",
      "0.16983210812843957  ,  0.8245  ,  2.6945\n",
      "-0.03920152621692167  ,  0.9797  ,  2.6739\n",
      "77\n",
      "0.8902849187738433  ,  0.5723  ,  0.9541\n",
      "-0.03282714795803837  ,  1.2101  ,  2.2129\n",
      "-0.02881571425651056  ,  1.2301  ,  2.1393\n",
      "78\n",
      "0.8360696084898736  ,  0.7254  ,  1.2479\n",
      "0.323319828608984  ,  1.0903  ,  1.9739\n",
      "0.24661712791494458  ,  1.1055  ,  1.9835\n",
      "79\n",
      "0.847343094611142  ,  0.5364  ,  1.1032\n",
      "0.41482522541561884  ,  0.7783  ,  1.8254\n",
      "0.14122497398545714  ,  0.9625  ,  1.7083\n",
      "80\n",
      "0.8513199490109544  ,  0.2938  ,  0.8942\n",
      "0.5643618961379215  ,  0.8738  ,  1.5274\n",
      "0.1055622768070144  ,  0.4852  ,  1.4627\n",
      "81\n",
      "0.7951082452653687  ,  0.4547  ,  1.0642\n",
      "0.33719111469043395  ,  2.1065  ,  1.7851\n",
      "0.27876558672045343  ,  0.7172  ,  1.2679\n",
      "82\n",
      "0.7293697761960536  ,  0.0991  ,  0.5444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9002343671863619  ,  0.089  ,  0.4535\n",
      "0.0761696217260024  ,  0.3961  ,  0.5768\n",
      "83\n",
      "0.853178604804777  ,  0.4121  ,  1.0066\n",
      "0.4397133366216281  ,  0.7195  ,  1.5651\n",
      "0.3628463869399144  ,  0.9544  ,  1.478\n",
      "84\n",
      "0.9028358771340617  ,  0.8562  ,  1.0998\n",
      "0.6026782155859298  ,  1.2352  ,  1.5804\n",
      "-0.1955819385024561  ,  1.8901  ,  2.1556\n",
      "85\n",
      "0.9512228222559294  ,  0.3848  ,  0.7883\n",
      "0.8851355138113233  ,  0.6605  ,  1.357\n",
      "-0.12680430407480506  ,  1.3988  ,  2.7749\n",
      "86\n",
      "0.9324159143188702  ,  0.3269  ,  0.719\n",
      "0.2775428448673363  ,  0.8352  ,  1.9732\n",
      "nan  ,  0.6588  ,  2.1379\n",
      "87\n",
      "0.7496139287264036  ,  0.3337  ,  0.989\n",
      "0.021388285938276064  ,  0.4689  ,  1.4154\n",
      "0.07087012226320369  ,  0.5437  ,  1.3507\n",
      "88\n",
      "0.9703266771057553  ,  0.4416  ,  0.9291\n",
      "0.9406345977884791  ,  0.5972  ,  1.3154\n",
      "0.8391029037412083  ,  0.7373  ,  1.5958\n",
      "89\n",
      "0.8600946097741897  ,  0.5104  ,  0.9485\n",
      "0.3106409998832353  ,  0.9307  ,  1.7745\n",
      "0.11298580735873921  ,  1.0311  ,  1.8402\n",
      "90\n",
      "0.8176777978225837  ,  0.1393  ,  0.7044\n",
      "0.6461108693913423  ,  0.3945  ,  0.9342\n",
      "0.04354881967396937  ,  0.2286  ,  1.1084\n",
      "91\n",
      "0.8746571284671315  ,  0.3077  ,  0.8375\n",
      "0.6374017190431784  ,  0.4822  ,  1.31\n",
      "0.0808672130721532  ,  0.6396  ,  1.6609\n",
      "92\n",
      "0.8516264419155901  ,  0.202  ,  0.5296\n",
      "0.4512947529567119  ,  0.4376  ,  0.8946\n",
      "nan  ,  0.3927  ,  1.0555\n",
      "93\n",
      "0.8733893930327838  ,  0.5841  ,  1.3603\n",
      "0.6845206106289105  ,  1.7546  ,  1.7096\n",
      "0.20834570809024644  ,  1.14  ,  2.3213\n",
      "94\n",
      "0.9122433713777675  ,  0.4923  ,  1.0284\n",
      "0.8203642253357788  ,  0.5988  ,  1.4074\n",
      "nan  ,  1.1148  ,  2.4814\n",
      "95\n",
      "0.8751952990931551  ,  0.9727  ,  1.7986\n",
      "0.5437651500576826  ,  2.1273  ,  2.4455\n",
      "0.12231324951640135  ,  1.4275  ,  3.0703\n",
      "96\n",
      "0.8561923205722519  ,  0.3154  ,  0.7201\n",
      "0.6311440745448141  ,  0.6042  ,  1.0089\n",
      "0.08922219506791422  ,  0.6964  ,  1.4111\n",
      "97\n",
      "0.9169997317011612  ,  0.3641  ,  0.8348\n",
      "0.3954369883372497  ,  0.8564  ,  2.2065\n",
      "0.6872633335284586  ,  0.761  ,  1.7534\n",
      "98\n",
      "0.8671173597044204  ,  0.498  ,  1.1119\n",
      "0.13057291596602105  ,  1.0723  ,  1.9125\n",
      "0.14001228492722753  ,  1.0301  ,  1.7405\n",
      "99\n",
      "0.9231549861032028  ,  0.3029  ,  0.7806\n",
      "0.5655090805556042  ,  0.5611  ,  1.7862\n",
      "0.027280132479266354  ,  0.7452  ,  1.9813\n",
      "100\n",
      "0.9674009959799621  ,  0.2514  ,  0.534\n",
      "0.28544486086558807  ,  0.5813  ,  1.9175\n",
      "nan  ,  0.5917  ,  2.0212\n",
      "101\n",
      "0.8549806232629339  ,  0.4221  ,  1.0628\n",
      "0.5531297241421671  ,  0.6568  ,  1.7932\n",
      "0.3160271356890535  ,  0.7483  ,  1.9577\n",
      "102\n",
      "0.9495425359483471  ,  0.298  ,  0.5016\n",
      "0.3497915820155372  ,  2.0327  ,  1.6348\n",
      "0.21013731328997712  ,  1.1202  ,  1.6711\n",
      "103\n",
      "0.959124658744826  ,  0.7024  ,  0.9974\n",
      "0.6848797176343544  ,  1.3256  ,  2.2035\n",
      "0.4737591372857503  ,  1.4591  ,  2.34\n",
      "104\n",
      "0.9666284977934414  ,  0.363  ,  0.7643\n",
      "0.48664794030451974  ,  1.0976  ,  2.3441\n",
      "0.6355556828231006  ,  1.1365  ,  2.6642\n",
      "105\n",
      "0.6562461474857485  ,  0.2637  ,  0.7939\n",
      "0.24695766186881304  ,  0.3362  ,  1.0496\n",
      "0.18844826707987802  ,  0.8785  ,  0.9903\n",
      "106\n",
      "0.9118933668575004  ,  0.386  ,  0.8756\n",
      "0.3815993615949481  ,  2.4562  ,  2.1552\n",
      "-0.006190279423362415  ,  0.7329  ,  2.0004\n",
      "107\n",
      "0.8872600931879087  ,  0.6816  ,  1.5591\n",
      "0.795650752427892  ,  0.7629  ,  1.479\n",
      "-0.08603231773510148  ,  1.1221  ,  2.6019\n",
      "108\n",
      "0.7463558337831976  ,  0.3463  ,  1.1315\n",
      "0.7520376924721239  ,  0.3424  ,  1.0903\n",
      "0.5811739705089021  ,  0.754  ,  1.1648\n",
      "109\n",
      "0.899751124359335  ,  0.3846  ,  0.9127\n",
      "0.7102960003731932  ,  0.5029  ,  1.3032\n",
      "0.13571607650254963  ,  1.2033  ,  1.3602\n",
      "110\n",
      "0.9497307272680839  ,  0.2604  ,  0.8177\n",
      "0.8418488462737119  ,  0.3864  ,  1.1468\n",
      "-0.01223392873307943  ,  0.591  ,  2.0326\n",
      "111\n",
      "0.858206244447631  ,  0.398  ,  0.81\n",
      "0.37420151832609194  ,  0.7253  ,  1.477\n",
      "0.05560177353694036  ,  0.9095  ,  1.5093\n",
      "112\n",
      "0.9671388008368219  ,  0.258  ,  0.7276\n",
      "0.7088281236425711  ,  0.589  ,  1.7065\n",
      "0.528596894342968  ,  0.6829  ,  1.9377\n",
      "113\n",
      "0.9468940527229239  ,  0.2747  ,  0.8136\n",
      "0.1122720065696886  ,  0.6348  ,  2.1051\n",
      "-0.08257070774584938  ,  0.7631  ,  2.0767\n",
      "114\n",
      "0.9567478787112095  ,  0.2391  ,  0.6024\n",
      "0.651985375711327  ,  0.6316  ,  1.5103\n",
      "0.2537070933355853  ,  0.7904  ,  1.9222\n",
      "115\n",
      "0.9138712429603129  ,  0.1634  ,  0.5481\n",
      "0.5265831387342946  ,  0.2869  ,  0.9473\n",
      "0.27266664921513933  ,  0.3248  ,  1.0891\n",
      "116\n",
      "0.9737960113283202  ,  0.2293  ,  0.5355\n",
      "0.6247189807478785  ,  0.8837  ,  1.9806\n",
      "0.19865685011846285  ,  0.9336  ,  2.4481\n",
      "117\n",
      "0.8980328947034734  ,  0.528  ,  1.1255\n",
      "0.18725526115822597  ,  0.9218  ,  2.1083\n",
      "0.2651457191157445  ,  0.9601  ,  2.0607\n",
      "118\n",
      "0.7437574628012485  ,  0.4376  ,  1.0911\n",
      "0.41357836960580935  ,  1.0221  ,  1.8457\n",
      "0.0045969843537289785  ,  0.5788  ,  1.7346\n",
      "119\n",
      "0.9485844666622282  ,  0.1556  ,  0.4291\n",
      "0.025517400754771283  ,  0.4658  ,  1.3226\n",
      "0.11085710298798859  ,  0.5536  ,  1.2449\n",
      "120\n",
      "0.9254360389186824  ,  0.1929  ,  0.4868\n",
      "0.5129289110538215  ,  0.7684  ,  1.1532\n",
      "0.11438222345552768  ,  0.5635  ,  1.3129\n",
      "121\n",
      "0.9925387452253  ,  0.1572  ,  0.6736\n",
      "0.9303786317090978  ,  0.3319  ,  1.27\n",
      "0.5502928827237985  ,  0.6725  ,  2.2034\n",
      "122\n",
      "0.8822686513845821  ,  0.3375  ,  0.6922\n",
      "0.5681057592576546  ,  0.7713  ,  1.1651\n",
      "-0.0017631033073010486  ,  0.9592  ,  1.489\n",
      "123\n",
      "0.7774634187793903  ,  0.2018  ,  0.7631\n",
      "0.7696779480002488  ,  0.2632  ,  0.7031\n",
      "0.29334992290142814  ,  0.5411  ,  0.963\n",
      "124\n",
      "0.9106588968551651  ,  0.2801  ,  0.7441\n",
      "0.7451458121085829  ,  0.5467  ,  1.0305\n",
      "0.4207431613207123  ,  0.6406  ,  1.4591\n",
      "125\n",
      "0.7552212500767662  ,  0.4859  ,  1.2729\n",
      "0.461456140582861  ,  0.5849  ,  1.5792\n",
      "0.09895676948064014  ,  0.8243  ,  1.5148\n",
      "126\n",
      "0.9248675001214645  ,  0.5639  ,  0.8173\n",
      "0.3530859721189301  ,  2.095  ,  1.6144\n",
      "0.17425679133626473  ,  1.7041  ,  2.4015\n",
      "127\n",
      "0.8935921984944805  ,  0.0843  ,  0.3824\n",
      "0.20207584848671745  ,  0.3276  ,  0.7953\n",
      "0.19608606095045764  ,  0.3209  ,  0.7132\n",
      "128\n",
      "0.8757403326976108  ,  0.1452  ,  0.4883\n",
      "0.6920882759247966  ,  0.2378  ,  0.6959\n",
      "0.04438414539015355  ,  0.6155  ,  0.841\n",
      "129\n",
      "0.904450056994008  ,  0.293  ,  0.603\n",
      "0.4135826288529565  ,  0.6203  ,  1.2697\n",
      "0.012275534575797224  ,  0.7253  ,  1.4065\n",
      "130\n",
      "0.9508254425985809  ,  0.2498  ,  0.6002\n",
      "0.18023720736442844  ,  0.7653  ,  1.9541\n",
      "-0.010542593734112118  ,  0.8159  ,  1.9943\n",
      "131\n",
      "0.9318216588516935  ,  0.6506  ,  1.132\n",
      "0.6570370759634618  ,  1.1932  ,  2.0625\n",
      "0.051638468914881996  ,  1.4072  ,  2.5076\n",
      "132\n",
      "0.9069173587267623  ,  0.5568  ,  0.8116\n",
      "0.5493185839150662  ,  1.7023  ,  1.9611\n",
      "0.1603597906703014  ,  1.492  ,  2.1543\n",
      "133\n",
      "0.8373108743306734  ,  0.7705  ,  1.1919\n",
      "0.6064976823585262  ,  1.1587  ,  1.5864\n",
      "0.3644555993278928  ,  1.1084  ,  2.2082\n",
      "134\n",
      "0.6963872964092359  ,  0.3917  ,  1.0818\n",
      "0.5409492097941445  ,  0.4932  ,  1.0944\n",
      "0.18637264791723288  ,  0.8031  ,  1.2139\n",
      "135\n",
      "0.9542999870337815  ,  0.387  ,  0.8901\n",
      "0.8473461654066202  ,  0.5792  ,  1.0838\n",
      "0.3848736226615366  ,  0.8778  ,  2.0981\n",
      "136\n",
      "0.8334938698996047  ,  0.2407  ,  0.7347\n",
      "0.3472829244633342  ,  1.1652  ,  1.3155\n",
      "nan  ,  0.3371  ,  1.1911\n",
      "137\n",
      "0.9055324502205804  ,  0.2246  ,  0.6542\n",
      "0.544154156165698  ,  0.748  ,  1.1934\n",
      "0.2694028520827379  ,  0.5173  ,  1.1749\n",
      "138\n",
      "0.947808361235794  ,  0.4091  ,  0.8383\n",
      "0.6477685796012087  ,  1.2872  ,  1.6517\n",
      "0.2503250877607389  ,  1.1892  ,  2.6535\n",
      "139\n",
      "0.8769966852298703  ,  0.2959  ,  0.8857\n",
      "0.7936438196846036  ,  0.3672  ,  1.0567\n",
      "0.4088069886003271  ,  0.7555  ,  1.259\n",
      "140\n",
      "0.8207525459263153  ,  0.3682  ,  1.0247\n",
      "0.624562196615518  ,  0.6563  ,  1.2543\n",
      "0.5700010606180181  ,  0.6207  ,  1.3602\n",
      "141\n",
      "0.8439048190816911  ,  0.4222  ,  0.8064\n",
      "0.15804309806699837  ,  0.729  ,  1.5583\n",
      "0.24721311988560235  ,  0.8631  ,  1.3126\n",
      "142\n",
      "0.8302427022908003  ,  0.3076  ,  0.8375\n",
      "0.6287625185321543  ,  0.5768  ,  0.9254\n",
      "0.05699521578037631  ,  0.8039  ,  1.1344\n",
      "143\n",
      "0.7007458465079841  ,  0.614  ,  1.3247\n",
      "0.6727245640112701  ,  0.721  ,  1.4366\n",
      "0.2471857907386482  ,  1.0724  ,  1.2909\n",
      "144\n",
      "0.9611974822790423  ,  0.3192  ,  0.6834\n",
      "0.875918480324265  ,  0.5865  ,  1.3296\n",
      "0.3081786111200835  ,  0.9923  ,  2.3129\n",
      "145\n",
      "0.7390843421857252  ,  0.3443  ,  1.035\n",
      "0.46494894334183573  ,  0.6935  ,  1.3657\n",
      "0.09284985580600867  ,  0.6463  ,  1.4569\n",
      "146\n",
      "0.9488791295994055  ,  0.3307  ,  1.0449\n",
      "0.8482064756135533  ,  0.4619  ,  1.5173\n",
      "0.5596966071944643  ,  0.6087  ,  1.8318\n",
      "147\n",
      "0.8717102647375846  ,  0.233  ,  0.7639\n",
      "0.21819445023877004  ,  0.4731  ,  1.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23481513594421788  ,  0.9909  ,  1.4166\n",
      "148\n",
      "0.8255842705237312  ,  0.448  ,  1.0932\n",
      "0.6507707794562722  ,  1.4665  ,  1.8883\n",
      "0.08008149840767055  ,  0.785  ,  2.0302\n",
      "149\n",
      "0.8733628898533046  ,  0.6419  ,  1.7798\n",
      "-0.014363171475354763  ,  0.9683  ,  2.6364\n",
      "0.009512516601128342  ,  0.9103  ,  2.6677\n",
      "150\n",
      "0.8630025752251873  ,  0.2228  ,  0.6762\n",
      "0.6529100514077826  ,  0.3623  ,  1.0082\n",
      "0.1775240780124582  ,  0.7736  ,  1.3243\n",
      "151\n",
      "0.9195172900561946  ,  0.3074  ,  0.7078\n",
      "0.5656369151581633  ,  0.699  ,  1.4586\n",
      "0.07897015990579397  ,  0.8331  ,  1.8436\n",
      "152\n",
      "0.9413426653808155  ,  0.2597  ,  0.6438\n",
      "0.524658597481603  ,  0.8945  ,  1.4189\n",
      "0.38467110908336144  ,  0.879  ,  1.524\n",
      "153\n",
      "0.9446277496160523  ,  0.3397  ,  0.8095\n",
      "0.7499604520481903  ,  0.7498  ,  1.2131\n",
      "0.45807923301033976  ,  0.9103  ,  1.6492\n",
      "154\n",
      "0.9326124359961581  ,  0.5416  ,  1.4489\n",
      "0.6639302309707537  ,  1.4321  ,  1.9117\n",
      "-0.016889182160981373  ,  1.0159  ,  2.9239\n",
      "155\n",
      "0.7666856744885009  ,  0.3759  ,  1.0188\n",
      "0.32451220971475736  ,  0.7034  ,  1.396\n",
      "0.21660149271031018  ,  0.8282  ,  1.4762\n",
      "156\n",
      "0.7931742994056286  ,  0.3535  ,  0.8698\n",
      "0.6462946875638952  ,  0.4566  ,  1.1259\n",
      "0.34889783537959124  ,  0.6035  ,  1.2016\n",
      "157\n",
      "0.8362840282488719  ,  0.3771  ,  1.0149\n",
      "0.237146283571747  ,  1.0342  ,  1.6994\n",
      "nan  ,  0.5469  ,  1.8715\n",
      "158\n",
      "0.9146810994332841  ,  0.2796  ,  0.9127\n",
      "0.40027799291288213  ,  0.5123  ,  1.7769\n",
      "0.4323893855374326  ,  0.5454  ,  1.6219\n",
      "159\n",
      "0.8963389664928727  ,  0.2906  ,  0.8605\n",
      "0.4764606738518474  ,  0.4671  ,  1.427\n",
      "0.33355395995972015  ,  0.766  ,  1.3968\n",
      "160\n",
      "0.952368272779762  ,  0.212  ,  0.7332\n",
      "0.7008492726729735  ,  0.5415  ,  1.3325\n",
      "0.12907082837792413  ,  0.6038  ,  1.9031\n",
      "161\n",
      "0.9337440973276558  ,  0.3469  ,  0.7844\n",
      "0.6580521123631662  ,  0.7065  ,  1.9207\n",
      "0.17811058872183155  ,  0.8001  ,  2.1586\n",
      "162\n",
      "0.9187902278145649  ,  0.3492  ,  0.9833\n",
      "0.6490928379094487  ,  0.7411  ,  1.4458\n",
      "0.10188860304138236  ,  0.7076  ,  2.0432\n",
      "163\n",
      "0.8775649172805244  ,  0.3433  ,  0.9319\n",
      "0.6775937237253431  ,  0.44  ,  1.1048\n",
      "0.4647647747561776  ,  0.5869  ,  1.292\n",
      "164\n",
      "0.9360303367904195  ,  0.3563  ,  0.8014\n",
      "0.19207683656862215  ,  0.8634  ,  2.0922\n",
      "0.2210331458126093  ,  0.9237  ,  1.9832\n",
      "165\n",
      "0.8078353953712905  ,  0.4295  ,  1.1099\n",
      "0.5430485855594743  ,  0.7081  ,  1.545\n",
      "0.19880861229414573  ,  1.015  ,  1.6374\n",
      "166\n",
      "0.9634293300768295  ,  0.2535  ,  0.5913\n",
      "0.6467467514481726  ,  0.6857  ,  1.718\n",
      "0.017759281979794546  ,  0.9059  ,  2.179\n",
      "167\n",
      "0.9640267643717204  ,  0.0946  ,  0.3489\n",
      "0.6877779786684679  ,  0.2745  ,  0.9344\n",
      "0.14298977294998513  ,  0.3759  ,  1.2493\n",
      "168\n",
      "0.8050075291633247  ,  0.8629  ,  1.6837\n",
      "0.3087786262211766  ,  5.4883  ,  4.6778\n",
      "0.03074648779099539  ,  0.6898  ,  1.7274\n",
      "169\n",
      "0.9463352998489138  ,  0.4309  ,  0.8482\n",
      "0.6675434215237869  ,  1.0101  ,  2.1324\n",
      "0.18965840564720093  ,  1.1707  ,  2.3863\n",
      "170\n",
      "0.846563320490522  ,  0.5788  ,  1.2188\n",
      "0.2754577262735967  ,  0.9164  ,  1.987\n",
      "0.4775900222634938  ,  0.9216  ,  1.7261\n",
      "171\n",
      "0.7930195859428758  ,  0.8171  ,  1.325\n",
      "0.4044834132134518  ,  1.6749  ,  1.8203\n",
      "0.4483506168358711  ,  1.388  ,  1.8153\n",
      "172\n",
      "0.7719501467806977  ,  1.0534  ,  1.5478\n",
      "0.5860307852573962  ,  1.1112  ,  1.3957\n",
      "0.27200697080866365  ,  1.0548  ,  1.84\n",
      "173\n",
      "0.9033274569426581  ,  0.5945  ,  0.9186\n",
      "0.05600162066063453  ,  1.1358  ,  1.9724\n",
      "0.3399497526704891  ,  1.1909  ,  1.5213\n",
      "174\n",
      "0.7491177036379856  ,  0.5514  ,  1.4122\n",
      "0.5238164677460315  ,  0.7431  ,  1.6451\n",
      "0.30247749083745246  ,  0.7567  ,  1.9813\n",
      "175\n",
      "0.8491171108256551  ,  0.4656  ,  1.1338\n",
      "0.6666272712568022  ,  0.7344  ,  1.5657\n",
      "0.40926577975077016  ,  0.8194  ,  1.9537\n",
      "176\n",
      "0.9720332820178407  ,  0.2303  ,  0.5309\n",
      "0.33579934766862707  ,  0.9493  ,  2.3371\n",
      "nan  ,  0.9643  ,  2.3843\n",
      "177\n",
      "0.7467594601861852  ,  0.3671  ,  1.0936\n",
      "0.364366335121125  ,  1.315  ,  2.0881\n",
      "0.30465093384013053  ,  0.6477  ,  1.415\n",
      "178\n",
      "0.9346697118799159  ,  0.436  ,  0.8952\n",
      "0.18372823292042975  ,  1.137  ,  2.2847\n",
      "nan  ,  0.8999  ,  2.5554\n",
      "179\n",
      "0.8415332235922437  ,  0.2489  ,  0.6761\n",
      "0.5528648570185217  ,  0.3556  ,  1.037\n",
      "0.0894434672349892  ,  0.5705  ,  1.1198\n",
      "180\n",
      "0.9689506631834374  ,  0.2589  ,  0.6477\n",
      "0.5590300130827028  ,  2.509  ,  2.7239\n",
      "0.18625523498796182  ,  1.4302  ,  2.3564\n",
      "181\n",
      "0.8641506079055331  ,  0.5673  ,  1.0005\n",
      "0.0394463462848906  ,  1.2137  ,  2.2439\n",
      "0.7051093268084251  ,  0.8938  ,  1.4308\n",
      "182\n",
      "0.9715579770389223  ,  0.1478  ,  0.5615\n",
      "0.09434481560788498  ,  0.4871  ,  1.8988\n",
      "nan  ,  0.4909  ,  1.9072\n",
      "183\n",
      "0.9189026280423775  ,  0.338  ,  1.005\n",
      "0.7918188594496419  ,  0.6778  ,  1.3494\n",
      "0.5132636808714601  ,  0.6971  ,  2.0584\n",
      "184\n",
      "0.9746882211812373  ,  0.2266  ,  0.5565\n",
      "0.632072327733364  ,  1.097  ,  1.5884\n",
      "0.11169930308722517  ,  0.9108  ,  2.2653\n",
      "185\n",
      "0.962323478296265  ,  0.0455  ,  0.1704\n",
      "0.7176350023276665  ,  0.3647  ,  0.7366\n",
      "0.08846756052706553  ,  0.2436  ,  0.5487\n",
      "186\n",
      "0.8789479151656803  ,  0.6791  ,  1.0159\n",
      "0.4482203185170165  ,  1.6779  ,  2.1413\n",
      "0.15730666133402413  ,  1.7826  ,  2.1454\n",
      "187\n",
      "0.8554672318943988  ,  0.2047  ,  0.6811\n",
      "0.5195634168497878  ,  0.3461  ,  1.075\n",
      "-0.08057656519140037  ,  0.5656  ,  1.0543\n",
      "188\n",
      "0.9636435801377211  ,  0.2988  ,  0.7662\n",
      "0.7306187671735257  ,  0.7213  ,  1.9323\n",
      "0.5397170762095543  ,  0.7844  ,  2.0821\n",
      "189\n",
      "0.8789455184044531  ,  0.5309  ,  0.8425\n",
      "0.2925363033413341  ,  1.2143  ,  1.6009\n",
      "0.1397652787293096  ,  1.2349  ,  1.6233\n",
      "190\n",
      "0.7919131083439801  ,  0.3234  ,  0.8769\n",
      "0.39261184626552853  ,  0.6437  ,  1.0525\n",
      "0.14154351998366185  ,  0.4903  ,  1.2181\n",
      "191\n",
      "0.9802552959575127  ,  0.1906  ,  0.5207\n",
      "0.48239426209242214  ,  0.708  ,  2.1967\n",
      "0.06533289018280991  ,  0.7243  ,  2.3821\n",
      "192\n",
      "0.7274361647038032  ,  0.8878  ,  1.2653\n",
      "0.6423168115049538  ,  0.8616  ,  1.2487\n",
      "0.12802707250676848  ,  1.188  ,  1.3289\n",
      "193\n",
      "0.9457204784978358  ,  0.6024  ,  0.8364\n",
      "0.5773772956754561  ,  1.3962  ,  2.2039\n",
      "0.09561517851509262  ,  1.52  ,  2.2144\n",
      "194\n",
      "0.8369514771613727  ,  0.4163  ,  0.7841\n",
      "0.11018623050373816  ,  0.8255  ,  1.5282\n",
      "0.07553964871880273  ,  0.8925  ,  1.4477\n",
      "195\n",
      "0.9338126690051736  ,  0.2843  ,  0.8739\n",
      "0.4557651619292011  ,  0.623  ,  1.6453\n",
      "0.3374106074840518  ,  0.7282  ,  1.6915\n",
      "196\n",
      "0.9588715850907034  ,  0.3298  ,  1.4756\n",
      "0.9628593508241204  ,  0.3521  ,  1.5824\n",
      "0.4907773404523924  ,  0.7827  ,  2.1905\n",
      "197\n",
      "0.9659219230698306  ,  0.4095  ,  1.5251\n",
      "0.9584181139508319  ,  0.4676  ,  1.7305\n",
      "0.5995696293780131  ,  0.9899  ,  2.1331\n",
      "198\n",
      "0.8682971252204007  ,  0.9837  ,  1.1735\n",
      "0.41536608706967615  ,  2.392  ,  1.5239\n",
      "0.30631507160362115  ,  1.7519  ,  2.0008\n",
      "199\n",
      "0.9532854790020375  ,  0.3126  ,  0.7492\n",
      "0.5626024108259678  ,  0.8047  ,  1.8458\n",
      "0.43581146874294213  ,  0.9153  ,  2.0307\n",
      "200\n",
      "0.9540308677834546  ,  0.3477  ,  0.69\n",
      "0.23356942452232304  ,  2.2777  ,  2.5989\n",
      "nan  ,  1.0263  ,  2.4059\n",
      "201\n",
      "0.9221955384060294  ,  0.3528  ,  0.8562\n",
      "0.582873846914456  ,  0.7199  ,  2.0514\n",
      "0.12240731289797734  ,  1.1432  ,  2.1296\n",
      "202\n",
      "0.8368712482510845  ,  0.5767  ,  1.1273\n",
      "0.4706766149202437  ,  1.8392  ,  2.7513\n",
      "0.07646265093894729  ,  1.3032  ,  1.8505\n",
      "203\n",
      "0.7700645258607588  ,  0.5276  ,  1.143\n",
      "0.4453676089468578  ,  0.9731  ,  1.2122\n",
      "0.1942285147256229  ,  0.9425  ,  1.3544\n",
      "204\n",
      "0.8755144232250173  ,  0.3663  ,  0.9638\n",
      "0.5493755803214236  ,  0.5332  ,  1.4253\n",
      "0.04205319177672955  ,  0.6561  ,  1.7311\n",
      "205\n",
      "0.7824763685938774  ,  0.2678  ,  0.9344\n",
      "0.49167427726065177  ,  0.4113  ,  1.1688\n",
      "0.38480083857410247  ,  0.9057  ,  1.6339\n",
      "206\n",
      "0.9118203258692432  ,  0.3357  ,  0.8106\n",
      "0.7718284185920075  ,  0.4517  ,  1.0279\n",
      "0.27987282738010794  ,  1.0538  ,  1.2034\n",
      "207\n",
      "0.988493030618003  ,  0.1432  ,  0.3037\n",
      "0.6581250832073859  ,  0.6954  ,  1.6885\n",
      "nan  ,  0.7919  ,  2.1901\n",
      "208\n",
      "0.8724399617444502  ,  0.2993  ,  0.8796\n",
      "0.71343727841537  ,  0.5117  ,  1.0405\n",
      "0.38958921480748365  ,  0.872  ,  1.2408\n",
      "209\n",
      "0.916320243039888  ,  0.3475  ,  0.7685\n",
      "0.44123845352730473  ,  0.8245  ,  1.7993\n",
      "-0.12884611359382067  ,  0.844  ,  1.827\n",
      "210\n",
      "0.8922989514755151  ,  0.8423  ,  1.3193\n",
      "0.6320280945881177  ,  1.2468  ,  2.0138\n",
      "0.020365916678259193  ,  1.5499  ,  2.7652\n",
      "211\n",
      "0.9624216916278239  ,  0.2843  ,  0.6314\n",
      "0.7215806253485597  ,  0.7402  ,  1.3357\n",
      "0.20690689594194955  ,  0.904  ,  2.0501\n",
      "212\n",
      "0.7473913987674023  ,  0.3495  ,  0.8544\n",
      "0.32202466574527266  ,  0.4808  ,  1.2131\n",
      "-0.004032582123929842  ,  0.6767  ,  1.1826\n",
      "213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930254627586883  ,  0.6582  ,  1.0481\n",
      "0.6953187212681161  ,  1.5996  ,  2.2743\n",
      "0.02733674712753818  ,  1.9673  ,  2.656\n",
      "214\n",
      "0.9549297080144656  ,  0.2852  ,  0.5409\n",
      "0.25341480818621576  ,  0.8389  ,  1.826\n",
      "0.043487327189592556  ,  0.8797  ,  1.8985\n",
      "215\n",
      "0.7520959312327828  ,  0.4925  ,  1.1167\n",
      "0.5521446682882071  ,  1.0713  ,  1.3689\n",
      "0.12573457797781606  ,  0.8762  ,  1.3537\n",
      "216\n",
      "0.9161007376720853  ,  0.3016  ,  0.8328\n",
      "0.8308538111020186  ,  0.5165  ,  1.1379\n",
      "0.22208784967682946  ,  0.5593  ,  2.0939\n",
      "217\n",
      "0.8916835425789287  ,  0.2725  ,  0.8608\n",
      "0.588554569895728  ,  0.4462  ,  1.5077\n",
      "0.2138350429712541  ,  1.6858  ,  1.9648\n",
      "218\n",
      "0.8672383242503792  ,  1.2  ,  1.6669\n",
      "0.4876254591573205  ,  1.8378  ,  2.5882\n",
      "0.24900723508312286  ,  2.0198  ,  2.0783\n",
      "219\n",
      "0.9134162164034327  ,  0.2869  ,  0.7579\n",
      "0.6665200909079437  ,  0.5021  ,  1.4946\n",
      "0.3650416332359784  ,  0.669  ,  1.6948\n",
      "220\n",
      "0.8725342035146427  ,  0.5107  ,  0.8318\n",
      "0.04271177213970455  ,  0.985  ,  1.5631\n",
      "0.1163533674913019  ,  0.9989  ,  1.507\n",
      "221\n",
      "0.9488746779080928  ,  0.2423  ,  0.6693\n",
      "0.7759464806804445  ,  0.3975  ,  0.9762\n",
      "nan  ,  0.5078  ,  1.6611\n",
      "222\n",
      "0.9493432022096113  ,  0.3676  ,  0.8207\n",
      "0.013791390671435241  ,  1.0967  ,  2.734\n",
      "nan  ,  0.8296  ,  2.723\n",
      "223\n",
      "0.9612815941763271  ,  0.3304  ,  0.9064\n",
      "0.7870487551718076  ,  0.6621  ,  2.1028\n",
      "0.13374057647670728  ,  0.8771  ,  2.7287\n",
      "224\n",
      "0.8297682125590573  ,  0.2391  ,  0.7653\n",
      "0.6388846667320176  ,  0.5296  ,  0.9747\n",
      "0.15249856075210963  ,  0.8533  ,  0.8389\n",
      "225\n",
      "0.8545029739076976  ,  1.1506  ,  1.743\n",
      "0.24633106536222799  ,  7.7911  ,  5.7093\n",
      "0.11042954929346954  ,  1.8368  ,  2.9423\n",
      "226\n",
      "0.8389714636563687  ,  0.303  ,  0.7708\n",
      "0.5225708652040219  ,  0.4983  ,  1.1817\n",
      "0.14641801619743489  ,  0.6819  ,  1.2878\n",
      "227\n",
      "0.8909920253228547  ,  0.3436  ,  0.9779\n",
      "0.6773176123615455  ,  0.5138  ,  1.3981\n",
      "0.4836117665498193  ,  0.8934  ,  1.4332\n",
      "228\n",
      "0.8838694948273952  ,  0.239  ,  0.6277\n",
      "0.49979000127725304  ,  0.4027  ,  0.9945\n",
      "0.05577636799973454  ,  0.5426  ,  1.0804\n",
      "229\n",
      "0.8340456202169135  ,  0.2179  ,  0.4997\n",
      "0.2208699773979815  ,  0.3429  ,  0.9286\n",
      "0.21693387119670646  ,  0.528  ,  0.7891\n",
      "230\n",
      "0.837061146592672  ,  0.4434  ,  0.8667\n",
      "0.5858364478213244  ,  0.5725  ,  1.0061\n",
      "0.2797801081707143  ,  0.7118  ,  1.28\n",
      "231\n",
      "0.8390230568157548  ,  0.3769  ,  1.0255\n",
      "0.5733181910669929  ,  0.7682  ,  1.5087\n",
      "0.18102673069874903  ,  0.8809  ,  1.8188\n",
      "232\n",
      "0.5446353214635296  ,  0.4435  ,  1.4262\n",
      "0.7261918256773523  ,  0.467  ,  1.0705\n",
      "0.5152219628695007  ,  1.3044  ,  2.205\n",
      "233\n",
      "0.9522347956899816  ,  0.2401  ,  0.5331\n",
      "0.3253144936076097  ,  0.6229  ,  1.7229\n",
      "0.4100473310104104  ,  0.6752  ,  1.5712\n",
      "234\n",
      "0.9499059672761053  ,  0.2496  ,  0.5717\n",
      "0.7673265491555831  ,  0.5556  ,  1.3092\n",
      "0.3676914630109829  ,  0.804  ,  1.7537\n",
      "235\n",
      "0.7677373827624373  ,  1.0955  ,  1.5201\n",
      "0.48522091020239116  ,  2.0536  ,  2.353\n",
      "0.432202629563799  ,  1.9296  ,  1.9354\n",
      "236\n",
      "0.7872380035527036  ,  0.6062  ,  1.0394\n",
      "0.6593327365746182  ,  0.7915  ,  1.321\n",
      "0.18103606227855412  ,  1.2146  ,  1.4806\n",
      "237\n",
      "0.8356288056226006  ,  0.2289  ,  0.5915\n",
      "0.45913752567827887  ,  0.3428  ,  0.8059\n",
      "-0.08430356634402127  ,  0.4732  ,  0.8028\n",
      "238\n",
      "0.9438714858787354  ,  0.1486  ,  0.4839\n",
      "0.25717028401827113  ,  0.4281  ,  1.3888\n",
      "nan  ,  0.3944  ,  1.4473\n",
      "239\n",
      "0.5984497050058835  ,  0.4078  ,  1.1896\n",
      "0.3937775017134157  ,  1.126  ,  1.3743\n",
      "0.2762443248568047  ,  0.549  ,  1.2072\n",
      "240\n",
      "0.5744610613881402  ,  0.4557  ,  1.7052\n",
      "0.3801042189631121  ,  0.5987  ,  1.786\n",
      "-0.04401399045705447  ,  0.5913  ,  1.9651\n",
      "241\n",
      "0.890287213578091  ,  0.3122  ,  0.8614\n",
      "0.6371176588881252  ,  0.5324  ,  1.2477\n",
      "0.7086606279984067  ,  0.5015  ,  1.3383\n",
      "242\n",
      "0.9028885820118643  ,  0.2505  ,  0.6873\n",
      "0.6308807730953226  ,  0.8028  ,  1.1791\n",
      "nan  ,  0.5249  ,  1.5302\n",
      "243\n",
      "0.8853450700928422  ,  0.1443  ,  0.7343\n",
      "0.8245565339111046  ,  0.1829  ,  0.8438\n",
      "nan  ,  0.2065  ,  1.1515\n",
      "244\n",
      "0.9903278925153733  ,  0.1456  ,  0.3601\n",
      "-0.016780738540660495  ,  0.9938  ,  2.6719\n",
      "nan  ,  0.9269  ,  2.7168\n",
      "245\n",
      "0.7902788224918289  ,  1.04  ,  1.5999\n",
      "0.5306327495501131  ,  1.9256  ,  1.8447\n",
      "0.2173750611834988  ,  1.2881  ,  2.0073\n",
      "246\n",
      "0.9583248854765758  ,  0.2942  ,  0.6595\n",
      "0.7740107801138089  ,  0.6092  ,  1.4045\n",
      "0.40106709533636975  ,  0.9314  ,  1.9808\n",
      "247\n",
      "0.8250694476534729  ,  0.5004  ,  1.0115\n",
      "0.4922604798701045  ,  0.79  ,  1.4486\n",
      "0.12176808301679762  ,  0.8758  ,  1.585\n",
      "248\n",
      "0.7225885147980271  ,  0.7228  ,  1.7862\n",
      "0.3561370020692882  ,  1.0432  ,  2.072\n",
      "0.008859508508073911  ,  0.9153  ,  2.3922\n",
      "249\n",
      "0.8968823041985643  ,  0.3954  ,  1.3152\n",
      "0.7670011030028658  ,  0.5231  ,  1.4651\n",
      "0.490513537015154  ,  0.8924  ,  1.5055\n",
      "250\n",
      "0.8292094036584541  ,  0.5635  ,  1.1795\n",
      "0.5301260506250144  ,  0.9101  ,  1.4205\n",
      "0.44500868795855714  ,  0.9146  ,  1.6851\n",
      "251\n",
      "0.9078814645231904  ,  0.2966  ,  0.7382\n",
      "0.7608933425088387  ,  0.4072  ,  0.8541\n",
      "0.25223939688658203  ,  0.8484  ,  1.1309\n",
      "252\n",
      "0.8928771716412438  ,  0.3491  ,  0.9369\n",
      "0.7009412710193743  ,  0.5341  ,  1.478\n",
      "0.10900810454285449  ,  1.0245  ,  1.6251\n",
      "253\n",
      "0.9199706537042375  ,  0.348  ,  0.8608\n",
      "0.667580076041678  ,  0.7247  ,  1.3719\n",
      "0.37545173931707604  ,  0.8801  ,  1.713\n",
      "254\n",
      "0.7943621784374852  ,  0.2433  ,  0.7756\n",
      "0.7485617897661901  ,  0.284  ,  0.7874\n",
      "0.16976145160312428  ,  0.5353  ,  1.1316\n",
      "255\n",
      "0.8616763134783889  ,  0.0941  ,  0.3846\n",
      "0.2726886331948643  ,  0.4277  ,  1.2109\n",
      "0.00983037930700968  ,  0.1965  ,  0.6618\n",
      "256\n",
      "0.7937499907380599  ,  0.5454  ,  0.9398\n",
      "0.16352055943058474  ,  0.8432  ,  1.6634\n",
      "-0.21501106698572603  ,  0.8545  ,  1.6689\n",
      "257\n",
      "0.943220106071716  ,  0.3292  ,  0.718\n",
      "0.41181074156310005  ,  0.9514  ,  2.1526\n",
      "0.18557283835493077  ,  1.0381  ,  2.2873\n",
      "258\n",
      "0.8072734233318176  ,  0.5824  ,  1.174\n",
      "0.04884019277748626  ,  0.8653  ,  1.7291\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "259\n",
      "0.6516232345171563  ,  0.3527  ,  0.6966\n",
      "0.06988992789714074  ,  0.4586  ,  1.0034\n",
      "0.049621625962780955  ,  0.5083  ,  0.937\n",
      "260\n",
      "0.7512851954061643  ,  0.5805  ,  0.8464\n",
      "0.0888355498787689  ,  0.7518  ,  1.4935\n",
      "nan  ,  0.7539  ,  1.5164\n",
      "261\n",
      "0.7786528265498773  ,  0.5505  ,  1.1788\n",
      "0.38387317773720814  ,  0.9626  ,  1.6244\n",
      "nan  ,  0.8415  ,  2.0292\n",
      "262\n",
      "0.8939034883613173  ,  0.5432  ,  1.1311\n",
      "0.10161596296439895  ,  1.2285  ,  1.8537\n",
      "-0.16492719367390188  ,  1.0406  ,  2.1358\n",
      "263\n",
      "0.7504566463096096  ,  0.3803  ,  1.0873\n",
      "-0.008867484109834194  ,  0.5668  ,  1.6209\n",
      "nan  ,  0.5552  ,  1.6264\n",
      "264\n",
      "0.7666546827881745  ,  0.2971  ,  0.866\n",
      "0.2807661331642485  ,  0.9983  ,  1.2462\n",
      "-0.079427792118144  ,  0.451  ,  1.3252\n",
      "265\n",
      "0.816779650411594  ,  0.6209  ,  1.2474\n",
      "0.2503686351595489  ,  1.2712  ,  1.6171\n",
      "nan  ,  0.8632  ,  1.9664\n",
      "266\n",
      "0.48948504107112395  ,  0.6424  ,  1.2435\n",
      "0.3856298345594331  ,  0.8465  ,  0.9887\n",
      "nan  ,  0.7208  ,  1.3886\n",
      "267\n",
      "0.7636450894859546  ,  0.572  ,  1.2155\n",
      "0.1532940142676244  ,  0.8317  ,  1.5946\n",
      "-0.07588524258084689  ,  0.7931  ,  1.7018\n",
      "268\n",
      "0.8446969146944913  ,  0.682  ,  0.9344\n",
      "0.4014155682211564  ,  1.2255  ,  2.0623\n",
      "nan  ,  1.2628  ,  2.1513\n",
      "269\n",
      "0.8542634536334535  ,  0.5034  ,  0.8562\n",
      "0.3335873811478002  ,  1.0412  ,  1.4172\n",
      "0.05866456772961608  ,  0.9779  ,  1.8103\n",
      "270\n",
      "0.8928386407345573  ,  0.8994  ,  1.033\n",
      "0.5752984574894516  ,  1.7586  ,  2.4108\n",
      "nan  ,  1.9837  ,  2.7294\n",
      "271\n",
      "0.7153274725180347  ,  0.4091  ,  1.0217\n",
      "0.10394585891575131  ,  0.5563  ,  1.5413\n",
      "nan  ,  0.5583  ,  1.556\n",
      "272\n",
      "0.7594216320478029  ,  0.4637  ,  1.0726\n",
      "0.1775514847169341  ,  1.0089  ,  1.4506\n",
      "nan  ,  0.5416  ,  1.6211\n",
      "273\n",
      "0.7840701369475165  ,  0.5787  ,  1.2223\n",
      "0.11520373491552448  ,  0.857  ,  2.0396\n",
      "-0.003772936476441122  ,  0.8552  ,  2.0699\n",
      "274\n",
      "0.7731795089826847  ,  0.5733  ,  1.2382\n",
      "0.342368239668773  ,  1.0958  ,  1.6395\n",
      "nan  ,  0.8095  ,  2.077\n",
      "275\n",
      "0.7376589675965747  ,  0.4273  ,  0.804\n",
      "0.37080484092912475  ,  0.5992  ,  1.1208\n",
      "nan  ,  0.6126  ,  1.1486\n",
      "276\n",
      "0.8615266119275389  ,  0.4991  ,  0.9754\n",
      "0.4837720581213722  ,  0.9609  ,  1.8982\n",
      "nan  ,  1.0597  ,  2.107\n",
      "277\n",
      "0.8800058496383552  ,  0.5368  ,  1.0053\n",
      "0.4873801561786833  ,  1.035  ,  1.4754\n",
      "-0.04862652987289449  ,  1.0441  ,  1.9137\n",
      "278\n",
      "0.5572101456293928  ,  0.5954  ,  1.4324\n",
      "0.2650606118451593  ,  0.6925  ,  1.5975\n",
      "nan  ,  0.6337  ,  1.7583\n",
      "279\n",
      "0.8064495349446282  ,  0.3649  ,  0.8038\n",
      "0.32269802805342995  ,  0.6248  ,  1.4108\n",
      "-0.03145480295297985  ,  0.6504  ,  1.4368\n",
      "280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787383120482994  ,  0.4243  ,  0.6713\n",
      "0.3442154038367409  ,  0.8894  ,  1.1121\n",
      "nan  ,  0.7536  ,  1.5149\n",
      "281\n",
      "0.727471762657644  ,  0.7238  ,  1.5519\n",
      "0.19382913428997856  ,  1.4933  ,  1.7046\n",
      "-0.0495703656997821  ,  1.0592  ,  2.2316\n",
      "282\n",
      "0.6993429135576151  ,  0.5609  ,  0.9937\n",
      "0.30788611770764257  ,  0.8398  ,  1.0735\n",
      "0.05253508068713102  ,  0.7543  ,  1.2493\n",
      "283\n",
      "0.7290416184733933  ,  0.406  ,  1.2256\n",
      "nan  ,  0.5204  ,  1.7121\n",
      "-0.028606449296968893  ,  0.5205  ,  1.712\n",
      "284\n",
      "0.61194313470388  ,  0.4891  ,  0.9638\n",
      "0.0642942836846564  ,  0.5638  ,  1.1384\n",
      "0.05393954714738105  ,  0.5908  ,  1.1017\n",
      "285\n",
      "0.7956716848584696  ,  0.5204  ,  0.783\n",
      "0.3543584928218941  ,  0.9238  ,  1.1412\n",
      "-0.07085634294516413  ,  0.9914  ,  1.3827\n",
      "286\n",
      "0.8373033255977997  ,  0.6041  ,  0.9016\n",
      "-0.010590239765752631  ,  1.2811  ,  1.8753\n",
      "0.006886833407319621  ,  1.2788  ,  1.8391\n",
      "287\n",
      "0.7374863573467798  ,  0.7537  ,  1.638\n",
      "0.19700475176448695  ,  1.3948  ,  1.4504\n",
      "nan  ,  0.8943  ,  2.0395\n",
      "288\n",
      "0.9228930864329489  ,  0.5515  ,  0.7334\n",
      "0.06752108760089753  ,  1.5625  ,  2.3643\n",
      "-0.40707449534844486  ,  1.5614  ,  2.342\n",
      "289\n",
      "0.8888026200373366  ,  0.3986  ,  0.8313\n",
      "0.19159297650891194  ,  0.7829  ,  1.9751\n",
      "0.031232505992242286  ,  0.7875  ,  2.0053\n",
      "290\n",
      "0.8544774684828204  ,  0.6318  ,  1.0106\n",
      "0.07629091019341183  ,  1.2454  ,  2.0471\n",
      "0.13002655683029424  ,  1.1825  ,  2.2263\n",
      "291\n",
      "0.9021522907141216  ,  0.4158  ,  0.859\n",
      "0.4766217275698691  ,  1.1341  ,  1.4713\n",
      "nan  ,  0.8753  ,  2.0967\n",
      "292\n",
      "0.7131795421496412  ,  0.8294  ,  0.9988\n",
      "0.06770571553922326  ,  1.3533  ,  1.2523\n",
      "0.21959393568227537  ,  1.3168  ,  1.6666\n",
      "293\n",
      "0.894128400109514  ,  0.5314  ,  0.9496\n",
      "-0.013213921596444446  ,  1.0476  ,  2.1086\n",
      "0.02514004287934522  ,  1.0616  ,  2.0692\n",
      "294\n",
      "0.9541237378656298  ,  0.3088  ,  0.8176\n",
      "0.2240634611676381  ,  0.9749  ,  2.369\n",
      "nan  ,  0.7176  ,  2.6151\n",
      "295\n",
      "0.8609179299413293  ,  0.4774  ,  0.9087\n",
      "0.3836465289236073  ,  0.9009  ,  1.6956\n",
      "0.010110677872871258  ,  0.9401  ,  1.9282\n",
      "296\n",
      "0.8212281918703079  ,  0.4142  ,  0.7806\n",
      "0.484267024275096  ,  0.6693  ,  1.2448\n",
      "0.2122589718709469  ,  0.6885  ,  1.5036\n",
      "297\n",
      "0.6354921598032104  ,  0.8566  ,  1.4273\n",
      "0.13225351235096883  ,  1.1388  ,  1.9351\n",
      "0.04550061683541291  ,  1.1877  ,  1.8415\n",
      "298\n",
      "0.7504012491691692  ,  1.032  ,  1.9669\n",
      "0.2752705436314876  ,  1.4092  ,  2.8074\n",
      "0.22836694196803017  ,  1.4385  ,  2.8037\n",
      "299\n",
      "0.6427033291848365  ,  0.4736  ,  0.9336\n",
      "0.07056839590989597  ,  0.4317  ,  1.1248\n",
      "0.06539945387832193  ,  0.4746  ,  1.0845\n",
      "300\n",
      "0.6706196494885218  ,  0.6393  ,  1.7183\n",
      "0.03532462140171325  ,  0.7737  ,  2.2231\n",
      "nan  ,  0.7732  ,  2.2247\n",
      "301\n",
      "0.7897805165016418  ,  0.7063  ,  1.0268\n",
      "0.27417862048739355  ,  1.2557  ,  1.4208\n",
      "0.16572381259280777  ,  1.2399  ,  1.8628\n",
      "302\n",
      "0.5697479593973479  ,  0.4137  ,  1.0662\n",
      "0.2911266791506236  ,  0.6193  ,  1.0855\n",
      "-0.1189018375921609  ,  0.5186  ,  1.257\n",
      "303\n",
      "0.7337923836715312  ,  0.8296  ,  1.3257\n",
      "0.04571748321743841  ,  1.0371  ,  1.6574\n",
      "-0.1374427789874001  ,  1.0623  ,  1.5857\n",
      "304\n",
      "0.7230816272154508  ,  1.1747  ,  1.6015\n",
      "0.3554832517153916  ,  1.4918  ,  1.7904\n",
      "-0.07970236848188121  ,  1.5934  ,  2.146\n",
      "305\n",
      "0.4435026558291175  ,  0.6925  ,  1.7395\n",
      "0.0723384971361887  ,  0.7609  ,  1.9004\n",
      "nan  ,  0.761  ,  1.907\n",
      "306\n",
      "0.9729021127900768  ,  0.1959  ,  0.5157\n",
      "0.02401339450523057  ,  0.5357  ,  2.361\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "307\n",
      "0.7338012368254891  ,  0.4411  ,  0.8661\n",
      "0.06167676541057676  ,  0.5622  ,  1.1945\n",
      "nan  ,  0.563  ,  1.1967\n",
      "308\n",
      "0.6710932811077285  ,  0.4282  ,  1.4326\n",
      "9.123512427266882e-05  ,  0.4968  ,  1.7206\n",
      "nan  ,  0.4949  ,  1.7215\n",
      "309\n",
      "0.8322593947075494  ,  0.8093  ,  0.9216\n",
      "0.2252877111341037  ,  1.1612  ,  1.7901\n",
      "0.06771077150573147  ,  1.1772  ,  1.7821\n",
      "310\n",
      "0.8755719953260448  ,  0.4181  ,  0.8521\n",
      "0.27114479332258845  ,  0.811  ,  1.9017\n",
      "nan  ,  0.8173  ,  1.9267\n",
      "311\n",
      "0.7647816075035734  ,  0.5266  ,  0.9757\n",
      "0.09596338014162942  ,  0.76  ,  1.7048\n",
      "nan  ,  0.763  ,  1.7097\n",
      "312\n",
      "0.9730150865337626  ,  0.1916  ,  0.5212\n",
      "0.03495283371590455  ,  0.5507  ,  2.3147\n",
      "nan  ,  0.5086  ,  2.3385\n",
      "313\n",
      "0.6843745921108401  ,  0.3854  ,  0.9606\n",
      "0.00048371387660178637  ,  0.5117  ,  1.3124\n",
      "nan  ,  0.5113  ,  1.3129\n",
      "314\n",
      "0.811784662488827  ,  0.4159  ,  1.0762\n",
      "0.2519255298547415  ,  0.6966  ,  1.8751\n",
      "nan  ,  0.7027  ,  1.9405\n",
      "315\n",
      "0.5461283404320662  ,  0.3773  ,  0.9782\n",
      "0.09553656743478908  ,  0.4106  ,  1.0857\n",
      "0.16643840879140978  ,  0.4279  ,  1.0694\n",
      "316\n",
      "0.8062065652123044  ,  0.4101  ,  0.9708\n",
      "0.39250807873817994  ,  0.7431  ,  1.4009\n",
      "0.000996477047760071  ,  0.6946  ,  1.6557\n",
      "317\n",
      "0.8377847914952942  ,  0.6561  ,  1.2193\n",
      "0.5343374397351579  ,  1.0821  ,  2.0043\n",
      "nan  ,  1.1661  ,  2.4048\n",
      "318\n",
      "0.5955933971745366  ,  0.2662  ,  0.7208\n",
      "0.15668925248523485  ,  0.3665  ,  0.7731\n",
      "-0.07811484381191858  ,  0.3585  ,  0.7887\n",
      "319\n",
      "0.9163434427484574  ,  0.683  ,  0.9568\n",
      "0.4844704486576055  ,  1.3396  ,  2.5871\n",
      "0.11686051219655047  ,  1.4826  ,  2.6519\n",
      "320\n",
      "0.8560100683063967  ,  0.6423  ,  1.0001\n",
      "0.11866274009393482  ,  1.2895  ,  1.65\n",
      "0.2546965418037101  ,  1.2294  ,  1.9173\n",
      "321\n",
      "0.661671719140357  ,  0.2348  ,  0.9945\n",
      "0.10262179093980897  ,  0.3386  ,  1.1694\n",
      "nan  ,  0.2651  ,  1.2055\n",
      "322\n",
      "0.8054144109193334  ,  0.7526  ,  1.0227\n",
      "0.17166378592939768  ,  1.4339  ,  1.9227\n",
      "nan  ,  1.4461  ,  1.935\n",
      "323\n",
      "0.7424343152938351  ,  0.575  ,  1.315\n",
      "0.29734560039071134  ,  1.6105  ,  1.3666\n",
      "-0.05108281949904837  ,  0.7677  ,  1.8125\n",
      "324\n",
      "0.7501404813863191  ,  0.8448  ,  1.7439\n",
      "0.004826141351712308  ,  1.1964  ,  2.2593\n",
      "0.01579064462734383  ,  1.1264  ,  2.3767\n",
      "325\n",
      "0.6614721493917397  ,  0.6321  ,  1.0974\n",
      "0.05114898004744003  ,  0.7114  ,  1.4981\n",
      "nan  ,  0.6899  ,  1.5352\n",
      "326\n",
      "0.7715723216502979  ,  0.4732  ,  1.1926\n",
      "0.23137496518951267  ,  0.7145  ,  1.7742\n",
      "nan  ,  0.6536  ,  1.8912\n",
      "327\n",
      "0.7852388261282714  ,  0.5534  ,  1.0228\n",
      "0.3460358265143782  ,  0.7143  ,  1.3583\n",
      "nan  ,  0.7293  ,  1.4415\n",
      "328\n",
      "0.6284890488343007  ,  0.411  ,  0.9652\n",
      "0.1761219659077662  ,  0.5091  ,  1.2369\n",
      "0.10501598400837316  ,  0.7109  ,  1.0625\n",
      "329\n",
      "0.9011699764141092  ,  0.2893  ,  0.621\n",
      "0.11674291313703498  ,  0.6777  ,  1.5108\n",
      "nan  ,  0.6631  ,  1.5563\n",
      "330\n",
      "0.9084343742428276  ,  0.3682  ,  0.7608\n",
      "0.11192095884429808  ,  0.8055  ,  2.0032\n",
      "nan  ,  0.8079  ,  2.0201\n",
      "331\n",
      "0.881080214298364  ,  0.8234  ,  1.078\n",
      "0.4031126852879643  ,  1.2708  ,  2.1215\n",
      "-0.09020839540486947  ,  1.3155  ,  2.3208\n",
      "332\n",
      "0.8180873254260249  ,  0.4661  ,  0.7538\n",
      "0.2800131682977894  ,  0.9199  ,  1.1764\n",
      "-0.140521293355094  ,  0.9548  ,  1.2945\n",
      "333\n",
      "0.751368914027497  ,  0.6358  ,  1.0367\n",
      "0.2612369029548107  ,  0.9869  ,  1.1897\n",
      "0.0704463841784834  ,  0.8135  ,  1.437\n",
      "334\n",
      "0.6752715704000976  ,  0.6067  ,  1.0988\n",
      "0.20477691150628388  ,  0.8991  ,  1.4316\n",
      "0.08696137870549392  ,  0.8841  ,  1.5414\n",
      "335\n",
      "0.6865619352031029  ,  0.5801  ,  0.7642\n",
      "0.08488222788951492  ,  0.6221  ,  0.8846\n",
      "-0.018176750257226326  ,  0.5586  ,  0.9695\n",
      "336\n",
      "0.7254958516706753  ,  0.663  ,  1.2559\n",
      "0.2560610444845393  ,  0.9487  ,  1.4082\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "337\n",
      "0.7127957804685201  ,  1.2017  ,  1.2522\n",
      "0.14119152074665242  ,  0.5872  ,  1.2043\n",
      "0.024343026649752825  ,  0.6232  ,  1.1585\n",
      "338\n",
      "0.8076750228903604  ,  0.6379  ,  0.9015\n",
      "0.3152738959453336  ,  2.1174  ,  1.7225\n",
      "nan  ,  1.1207  ,  1.8448\n",
      "339\n",
      "0.572470525218236  ,  0.2623  ,  0.8623\n",
      "0.20932792315385196  ,  0.3753  ,  0.9116\n",
      "nan  ,  0.2825  ,  0.9596\n",
      "340\n",
      "0.861562449655721  ,  0.5292  ,  0.8901\n",
      "0.41999949399136527  ,  0.9323  ,  1.2199\n",
      "0.11207084264635495  ,  0.9585  ,  1.5537\n",
      "341\n",
      "0.73388968322265  ,  0.2659  ,  0.7035\n",
      "0.26634141349483287  ,  0.5286  ,  0.9117\n",
      "0.021084112925869404  ,  0.5782  ,  0.9023\n",
      "342\n",
      "0.7725594179254539  ,  0.8874  ,  1.4243\n",
      "0.427832249610939  ,  1.2129  ,  1.5031\n",
      "0.08728856654841816  ,  1.2483  ,  1.9943\n",
      "343\n",
      "0.972124308527273  ,  0.391  ,  0.9942\n",
      "0.9146095060435653  ,  0.7529  ,  1.7866\n",
      "0.7118340165361465  ,  1.3577  ,  2.773\n",
      "344\n",
      "0.8337319647302506  ,  0.3347  ,  0.908\n",
      "0.014583708822656707  ,  0.3589  ,  1.4628\n",
      "nan  ,  0.358  ,  1.4638\n",
      "345\n",
      "0.8232081029769674  ,  0.3772  ,  0.6977\n",
      "0.09601978630200263  ,  0.8929  ,  1.0996\n",
      "0.1404005191242091  ,  0.7036  ,  1.3097\n",
      "346\n",
      "0.840408095060273  ,  0.4451  ,  0.778\n",
      "0.03244956791864986  ,  0.7683  ,  1.4948\n",
      "nan  ,  0.7692  ,  1.4957\n",
      "347\n",
      "0.8080733111075112  ,  0.5742  ,  0.993\n",
      "0.4430671021189534  ,  0.8568  ,  1.6254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17630833311126537  ,  0.9691  ,  1.7654\n",
      "348\n",
      "0.8189384914775046  ,  0.6605  ,  1.0408\n",
      "0.5907261416519982  ,  1.0006  ,  1.4643\n",
      "nan  ,  1.1876  ,  2.0974\n",
      "349\n",
      "0.7016762229952661  ,  0.6117  ,  1.081\n",
      "0.3317690723227187  ,  0.8635  ,  1.5303\n",
      "nan  ,  0.8818  ,  1.5942\n",
      "350\n",
      "0.8780408218545362  ,  0.4732  ,  0.9857\n",
      "0.5441341498981453  ,  0.8273  ,  1.6612\n",
      "0.07797499177400145  ,  0.8929  ,  1.959\n",
      "351\n",
      "0.7800510065628032  ,  0.8089  ,  1.3335\n",
      "0.07917797489247173  ,  1.2319  ,  2.0541\n",
      "nan  ,  1.2285  ,  2.1302\n",
      "352\n",
      "0.8244631311042577  ,  0.5186  ,  0.9951\n",
      "0.312482047991795  ,  0.8709  ,  1.6804\n",
      "nan  ,  0.888  ,  1.7709\n",
      "353\n",
      "0.9274917924357033  ,  0.2025  ,  0.6487\n",
      "0.025739476158039294  ,  0.5567  ,  1.3597\n",
      "nan  ,  0.4044  ,  1.446\n",
      "354\n",
      "0.7617016167895626  ,  0.5725  ,  0.9459\n",
      "0.0837831491782262  ,  0.9674  ,  1.595\n",
      "0.1903418946171941  ,  1.0029  ,  1.5084\n",
      "355\n",
      "0.5422128207819911  ,  0.679  ,  1.2224\n",
      "0.18118595330586823  ,  0.7623  ,  1.46\n",
      "0.0053906253076377985  ,  0.78  ,  1.4625\n",
      "356\n",
      "0.8202091621183443  ,  0.4359  ,  1.0264\n",
      "0.3133720030342577  ,  0.7807  ,  1.5996\n",
      "nan  ,  0.6586  ,  1.8511\n",
      "357\n",
      "0.8301267216014783  ,  0.2642  ,  0.7784\n",
      "0.19567003899602156  ,  1.4524  ,  1.2016\n",
      "-0.006948803968347735  ,  0.4725  ,  1.3232\n",
      "358\n",
      "0.6404008282808358  ,  0.5304  ,  0.9489\n",
      "0.31939943631544065  ,  0.6052  ,  0.9887\n",
      "0.07043054935220883  ,  0.6489  ,  1.0585\n",
      "359\n",
      "0.7614127424153805  ,  0.7549  ,  0.9613\n",
      "0.06585044088127132  ,  1.322  ,  0.986\n",
      "-0.08390964833136627  ,  1.1501  ,  1.3428\n",
      "360\n",
      "0.8747567930744813  ,  0.698  ,  0.985\n",
      "0.3074041147359503  ,  1.2409  ,  2.3573\n",
      "nan  ,  1.26  ,  2.4055\n",
      "361\n",
      "0.8325827776968563  ,  0.5593  ,  0.9923\n",
      "0.22640788155933989  ,  1.0713  ,  1.6241\n",
      "nan  ,  1.0051  ,  1.8886\n",
      "362\n",
      "0.4288578642841111  ,  0.5613  ,  1.1158\n",
      "0.16275751948435335  ,  1.6415  ,  1.4456\n",
      "0.037850744159618  ,  0.6354  ,  1.2255\n",
      "363\n",
      "0.9046403451864136  ,  0.5254  ,  0.9706\n",
      "0.600252809149186  ,  0.9987  ,  1.7896\n",
      "nan  ,  1.0609  ,  2.1441\n",
      "364\n",
      "0.8149678044536912  ,  0.3371  ,  0.7065\n",
      "0.35486727007324415  ,  0.6703  ,  1.0373\n",
      "nan  ,  0.4108  ,  1.3093\n",
      "365\n",
      "0.734043272237012  ,  0.2227  ,  0.6683\n",
      "0.2775434373669085  ,  0.2996  ,  0.9735\n",
      "-0.011388374242116438  ,  0.2978  ,  1.029\n",
      "366\n",
      "0.8449348996325396  ,  0.387  ,  1.0084\n",
      "0.4978582738336963  ,  0.5876  ,  1.6014\n",
      "nan  ,  0.6372  ,  1.8039\n",
      "367\n",
      "0.72483061349973  ,  0.4343  ,  0.7411\n",
      "0.17205680608588791  ,  0.6757  ,  1.0655\n",
      "0.015140078061099432  ,  0.6335  ,  1.1777\n",
      "368\n",
      "0.6405397093361442  ,  0.6602  ,  1.298\n",
      "0.1475389507737021  ,  1.3198  ,  1.5347\n",
      "nan  ,  0.8054  ,  1.6351\n",
      "369\n",
      "0.8167892802967929  ,  0.6671  ,  1.3385\n",
      "0.2876909626735812  ,  0.9738  ,  2.0702\n",
      "nan  ,  0.982  ,  2.0937\n",
      "370\n",
      "0.6755117825460497  ,  0.6309  ,  1.2346\n",
      "0.0886559908081982  ,  0.8165  ,  1.8007\n",
      "nan  ,  0.8211  ,  1.8119\n",
      "371\n",
      "0.8715833466082533  ,  0.6131  ,  1.0861\n",
      "0.16638986039001635  ,  1.4845  ,  2.0355\n",
      "0.13702630846445374  ,  1.0186  ,  2.4022\n",
      "372\n",
      "0.8526143731968611  ,  0.3377  ,  0.8987\n",
      "0.44214843115265406  ,  0.5438  ,  1.599\n",
      "nan  ,  0.564  ,  1.7359\n",
      "373\n",
      "0.6254687211561558  ,  0.6001  ,  1.106\n",
      "0.06670649073124535  ,  1.5379  ,  1.1217\n",
      "0.09535699763868614  ,  0.7701  ,  1.2723\n",
      "374\n",
      "0.7980885258511496  ,  0.9759  ,  1.3281\n",
      "0.34174744541080754  ,  1.7607  ,  1.9722\n",
      "0.12724826936351438  ,  1.624  ,  2.731\n",
      "375\n",
      "0.8449787677275563  ,  0.8592  ,  1.3926\n",
      "0.520707218886932  ,  0.8533  ,  1.8832\n",
      "nan  ,  0.9041  ,  2.2136\n",
      "376\n",
      "0.573271130659881  ,  0.7948  ,  1.6297\n",
      "0.3944382069368547  ,  1.2011  ,  1.3922\n",
      "nan  ,  0.9349  ,  1.9727\n",
      "377\n",
      "0.5377672437360146  ,  0.6761  ,  1.335\n",
      "0.090416094695831  ,  0.918  ,  1.2638\n",
      "0.022172819658311888  ,  0.8167  ,  1.3894\n",
      "378\n",
      "0.7386971327002787  ,  0.6898  ,  0.8818\n",
      "0.510485904546375  ,  1.1652  ,  1.4861\n",
      "-0.2252458632599741  ,  1.2695  ,  1.2729\n",
      "379\n",
      "0.6621642509296276  ,  0.6342  ,  1.1673\n",
      "0.3817149405174395  ,  0.8638  ,  1.2037\n",
      "nan  ,  0.856  ,  1.5604\n",
      "380\n",
      "0.7558873657585  ,  0.9433  ,  1.5466\n",
      "0.4493961389500493  ,  1.3732  ,  1.7862\n",
      "nan  ,  1.2932  ,  2.507\n",
      "381\n",
      "0.5672275061409853  ,  0.4123  ,  0.9905\n",
      "0.022153892107054644  ,  0.4868  ,  1.2584\n",
      "-0.0008047223703594852  ,  0.5338  ,  1.2064\n",
      "382\n",
      "0.884949592138839  ,  0.661  ,  1.169\n",
      "0.43533078055109686  ,  1.3449  ,  2.1212\n",
      "nan  ,  1.3618  ,  2.6171\n",
      "383\n",
      "0.6794813549018819  ,  1.0709  ,  1.3467\n",
      "0.2645844333369749  ,  1.1409  ,  1.2747\n",
      "nan  ,  0.6506  ,  1.4881\n",
      "384\n",
      "0.7468880996013336  ,  0.7952  ,  1.2067\n",
      "0.274915146970363  ,  0.7031  ,  1.2915\n",
      "0.1426887352841028  ,  0.6683  ,  1.4305\n",
      "385\n",
      "0.7193825488399366  ,  0.756  ,  1.0441\n",
      "0.4370906465112644  ,  1.081  ,  1.1721\n",
      "-0.14286867812660872  ,  0.9787  ,  1.7555\n",
      "386\n",
      "0.7703275247508439  ,  0.3556  ,  0.7947\n",
      "-0.0005582792726375671  ,  0.6746  ,  1.1911\n",
      "0.15920183471667027  ,  0.8036  ,  1.0492\n",
      "387\n",
      "0.7729381994359776  ,  0.621  ,  1.1004\n",
      "0.4025742297226419  ,  1.0104  ,  1.5828\n",
      "-0.15431573027308257  ,  1.1024  ,  1.7763\n",
      "388\n",
      "0.8115255004188904  ,  0.5423  ,  0.7896\n",
      "0.40064865487340073  ,  0.8854  ,  1.2698\n",
      "0.13657100459900548  ,  0.9674  ,  1.44\n",
      "389\n",
      "0.6941521547060374  ,  0.9604  ,  1.1385\n",
      "0.22640570443413655  ,  1.2677  ,  1.7272\n",
      "-0.13372039584085743  ,  1.3428  ,  1.7456\n",
      "390\n",
      "0.8219175787095259  ,  0.5094  ,  1.0784\n",
      "0.10971578038925263  ,  0.7478  ,  1.6551\n",
      "nan  ,  0.7476  ,  1.6644\n",
      "391\n",
      "0.6851775337798406  ,  0.5367  ,  1.3126\n",
      "0.06542642629755761  ,  0.7209  ,  1.4765\n",
      "-0.006292022635029738  ,  0.6301  ,  1.5625\n",
      "392\n",
      "0.8836125488671582  ,  0.586  ,  0.8268\n",
      "0.2779178318546924  ,  0.931  ,  1.7187\n",
      "nan  ,  0.9138  ,  1.9164\n",
      "393\n",
      "0.9703362091806974  ,  0.168  ,  0.746\n",
      "-0.010820552001860688  ,  0.4755  ,  2.2902\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "394\n",
      "0.7947509585442312  ,  0.5765  ,  1.1427\n",
      "0.09993104305562574  ,  0.888  ,  2.055\n",
      "nan  ,  0.8851  ,  2.083\n",
      "395\n",
      "0.8691543528326193  ,  0.5309  ,  0.9605\n",
      "0.23664238579846544  ,  0.9604  ,  1.9612\n",
      "nan  ,  0.962  ,  2.1165\n",
      "396\n",
      "0.2568546098256414  ,  0.9268  ,  1.76\n",
      "0.24471169716284025  ,  0.9518  ,  1.6445\n",
      "0.06052593694496312  ,  0.9696  ,  1.781\n",
      "397\n",
      "0.7497855163598521  ,  0.5497  ,  0.9874\n",
      "0.3352701847441222  ,  0.8682  ,  1.5053\n",
      "nan  ,  0.8937  ,  1.6115\n",
      "398\n",
      "0.8534918629741096  ,  0.4696  ,  0.9836\n",
      "0.06777161574492405  ,  0.7655  ,  1.8232\n",
      "nan  ,  0.7659  ,  1.8275\n",
      "399\n",
      "0.8303467097255667  ,  0.8084  ,  1.5569\n",
      "0.1597835662808595  ,  0.6601  ,  2.2057\n",
      "nan  ,  0.6587  ,  2.2224\n",
      "400\n",
      "0.9324771257321215  ,  0.3988  ,  0.7565\n",
      "0.03839791227787636  ,  0.927  ,  2.1903\n",
      "nan  ,  0.9001  ,  2.2427\n",
      "401\n",
      "0.8780641446343552  ,  0.3294  ,  0.622\n",
      "0.30760027619713093  ,  0.7768  ,  1.1774\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "402\n",
      "0.8406865111481001  ,  0.723  ,  0.9845\n",
      "0.06468880823990777  ,  1.5165  ,  2.0278\n",
      "0.13060090386737722  ,  1.5315  ,  2.0772\n",
      "403\n",
      "0.9436596874297896  ,  0.4099  ,  1.1088\n",
      "0.890096716332243  ,  0.9266  ,  2.3335\n",
      "0.7485138838170462  ,  1.4086  ,  2.7461\n",
      "404\n",
      "0.7933197413649034  ,  0.5595  ,  0.909\n",
      "0.3152434417203352  ,  0.9751  ,  1.3641\n",
      "nan  ,  0.9597  ,  1.7002\n",
      "405\n",
      "0.7541696110896476  ,  0.7199  ,  1.4085\n",
      "0.062017249360065516  ,  0.951  ,  2.0174\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "406\n",
      "0.7882194568801959  ,  0.6321  ,  1.2384\n",
      "0.5247985599838879  ,  0.9062  ,  1.9696\n",
      "0.13643610112630378  ,  0.9647  ,  2.2321\n",
      "407\n",
      "0.6801972944163244  ,  1.0935  ,  2.1957\n",
      "0.5251367664823912  ,  1.2809  ,  2.1712\n",
      "nan  ,  1.2703  ,  2.6999\n",
      "408\n",
      "0.7986954291184273  ,  0.5367  ,  1.086\n",
      "0.12638388892350738  ,  0.8337  ,  1.7361\n",
      "nan  ,  0.8393  ,  1.7605\n",
      "409\n",
      "0.5915860546542426  ,  0.9968  ,  1.5755\n",
      "0.29790580273704903  ,  1.506  ,  1.2389\n",
      "0.06671966559360407  ,  1.3063  ,  2.0381\n",
      "410\n",
      "0.7433571659961333  ,  0.3546  ,  1.0023\n",
      "0.06747496285173332  ,  0.4251  ,  1.3331\n",
      "nan  ,  0.3307  ,  1.3698\n",
      "411\n",
      "0.7064550344933639  ,  0.8753  ,  1.2255\n",
      "0.20515538794638255  ,  0.9386  ,  1.3204\n",
      "-0.0073317895957052326  ,  0.859  ,  1.5772\n",
      "412\n",
      "0.8625441521274875  ,  0.3482  ,  0.6853\n",
      "0.22877660242484377  ,  1.1641  ,  1.0826\n",
      "-0.11587357192093144  ,  0.7879  ,  1.428\n",
      "413\n",
      "0.6650936217729899  ,  0.6083  ,  1.3219\n",
      "0.0522113836428621  ,  0.7368  ,  1.5832\n",
      "nan  ,  0.7292  ,  1.6047\n",
      "414\n",
      "0.46786134145927166  ,  0.3888  ,  0.9938\n",
      "0.29223394894741994  ,  0.516  ,  0.9889\n",
      "0.09144155481357999  ,  0.5103  ,  1.0712\n",
      "415\n",
      "0.7605280807075246  ,  0.6715  ,  0.9153\n",
      "0.1687490584790488  ,  0.9739  ,  1.6279\n",
      "-0.14267877973359536  ,  0.9913  ,  1.658\n",
      "416\n",
      "0.6628504448054344  ,  0.7137  ,  1.3564\n",
      "0.25535380584780026  ,  0.8685  ,  1.6987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00021874768840234428  ,  0.904  ,  1.753\n",
      "417\n",
      "0.7672484437484394  ,  0.395  ,  0.9409\n",
      "0.31676281005876095  ,  0.6334  ,  1.2313\n",
      "nan  ,  0.5942  ,  1.4205\n",
      "418\n",
      "0.7227949598146369  ,  0.5476  ,  1.5128\n",
      "0.1327014850194666  ,  0.7117  ,  2.1677\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "419\n",
      "0.8251242187377348  ,  0.576  ,  0.8932\n",
      "0.29949009332656235  ,  0.9978  ,  1.4694\n",
      "nan  ,  0.9621  ,  1.7865\n",
      "420\n",
      "0.47128851811913297  ,  0.4167  ,  1.1283\n",
      "0.0951941834017382  ,  0.4561  ,  1.2336\n",
      "-0.02000654392418523  ,  0.4727  ,  1.2195\n",
      "421\n",
      "0.6842502134577153  ,  0.5704  ,  1.0104\n",
      "0.13914761530001432  ,  0.5158  ,  1.0774\n",
      "-0.12370070588588948  ,  0.459  ,  1.1263\n",
      "422\n",
      "0.26246765612088174  ,  0.9167  ,  1.2658\n",
      "0.2563090638143324  ,  0.9614  ,  0.839\n",
      "0.05830885592003794  ,  0.9405  ,  1.2267\n",
      "423\n",
      "0.8097939246909189  ,  0.479  ,  1.0257\n",
      "0.24261700420302004  ,  0.7727  ,  1.5719\n",
      "-0.0754533896552485  ,  0.8013  ,  1.6114\n",
      "424\n",
      "0.8582174438272778  ,  0.5181  ,  0.924\n",
      "-0.02697078552976667  ,  0.6244  ,  1.5298\n",
      "-0.17549452788686776  ,  0.6392  ,  1.5105\n",
      "425\n",
      "0.7952139049285614  ,  0.8336  ,  1.1007\n",
      "0.18784100538133008  ,  1.4245  ,  1.2505\n",
      "0.2770389079176326  ,  1.3834  ,  1.8654\n",
      "426\n",
      "0.7383010143897769  ,  0.2568  ,  0.7169\n",
      "0.34595568477052085  ,  0.544  ,  0.9025\n",
      "-0.1686278152133986  ,  0.6167  ,  0.9108\n",
      "427\n",
      "0.6340162412437607  ,  0.2636  ,  0.7574\n",
      "0.27639912903724867  ,  0.3748  ,  0.92\n",
      "-0.09512550273529906  ,  0.3572  ,  0.9987\n",
      "428\n",
      "0.8887309303981857  ,  0.3077  ,  0.6569\n",
      "-0.03368626031986942  ,  0.7414  ,  1.2067\n",
      "nan  ,  0.6046  ,  1.3573\n",
      "429\n",
      "0.7875132712524299  ,  0.3322  ,  1.0972\n",
      "0.3503284897216318  ,  0.4879  ,  1.6122\n",
      "nan  ,  0.4602  ,  1.7395\n",
      "430\n",
      "0.48743173201410844  ,  1.0058  ,  1.6526\n",
      "0.21764037109742976  ,  1.1201  ,  1.7059\n",
      "-0.1855028572973324  ,  1.1564  ,  1.7398\n",
      "431\n",
      "0.7850232970435087  ,  0.1909  ,  0.5286\n",
      "0.014445005790722169  ,  0.2638  ,  0.8948\n",
      "0.0077465941653335904  ,  0.2952  ,  0.8731\n",
      "432\n",
      "0.7031903078184534  ,  0.7847  ,  1.1793\n",
      "0.3937028754333751  ,  1.0582  ,  1.4684\n",
      "-0.2002359251975722  ,  1.17  ,  1.6542\n",
      "433\n",
      "0.6957771705166285  ,  0.5323  ,  1.4718\n",
      "0.10392232909659013  ,  0.7481  ,  2.048\n",
      "nan  ,  0.7174  ,  2.0959\n",
      "434\n",
      "0.5612354263908894  ,  0.6102  ,  1.3822\n",
      "0.41535157344261114  ,  0.221  ,  0.6555\n",
      "-0.18330712979849817  ,  0.3889  ,  0.6323\n",
      "435\n",
      "0.8087351439066673  ,  0.3726  ,  0.7159\n",
      "-0.12150436748877677  ,  0.9784  ,  0.8459\n",
      "nan  ,  0.5723  ,  1.0996\n",
      "436\n",
      "0.8643704785574752  ,  0.5261  ,  0.8066\n",
      "0.5154446368076474  ,  0.9104  ,  1.4677\n",
      "-0.25251199006788494  ,  0.9766  ,  1.891\n",
      "437\n",
      "0.5911261648739372  ,  0.4196  ,  0.9959\n",
      "0.08571332614581378  ,  0.5439  ,  1.2511\n",
      "nan  ,  0.5194  ,  1.2783\n",
      "438\n",
      "0.7366023218160438  ,  0.3933  ,  0.8346\n",
      "0.0060429983286900725  ,  0.5398  ,  1.2958\n",
      "-0.08762382502662153  ,  0.5784  ,  1.2424\n",
      "439\n",
      "0.8729649154402774  ,  0.4981  ,  0.7966\n",
      "0.2082706105631959  ,  1.0533  ,  1.6377\n",
      "nan  ,  0.9366  ,  1.8831\n",
      "440\n",
      "0.6256743782559986  ,  0.4313  ,  1.1178\n",
      "-0.003247463230943672  ,  0.3609  ,  1.2092\n",
      "nan  ,  0.3609  ,  1.2092\n",
      "441\n",
      "0.5747596934265653  ,  0.5955  ,  1.1215\n",
      "0.234135162313337  ,  0.7034  ,  1.2802\n",
      "0.041699157611162316  ,  0.7752  ,  1.2599\n",
      "442\n",
      "0.7385327385446959  ,  0.5282  ,  1.4916\n",
      "0.004568703012583265  ,  0.6797  ,  2.1393\n",
      "nan  ,  0.6747  ,  2.143\n",
      "443\n",
      "0.7081500932066165  ,  0.9371  ,  1.6014\n",
      "0.39902168092267437  ,  1.0353  ,  1.7334\n",
      "nan  ,  1.0097  ,  2.1361\n",
      "444\n",
      "0.8444920334389212  ,  0.5281  ,  0.9245\n",
      "0.49458505617316495  ,  0.7382  ,  1.5552\n",
      "nan  ,  0.7703  ,  1.6875\n",
      "445\n",
      "0.7839300800985197  ,  0.2073  ,  0.7762\n",
      "0.18164375831495772  ,  0.2996  ,  1.2628\n",
      "nan  ,  0.2958  ,  1.2878\n",
      "446\n",
      "0.8534537283423408  ,  0.3956  ,  1.1146\n",
      "0.1458227851705791  ,  0.7125  ,  2.1333\n",
      "nan  ,  0.6548  ,  2.2088\n",
      "447\n",
      "0.8576223137975498  ,  0.594  ,  1.2659\n",
      "0.17402824201089606  ,  1.1684  ,  2.3919\n",
      "-0.06889345152958418  ,  1.1647  ,  2.4583\n",
      "448\n",
      "0.5501953432286992  ,  0.2828  ,  0.8705\n",
      "0.09147251096743672  ,  0.6003  ,  0.9391\n",
      "-0.10607354015874143  ,  0.4151  ,  0.9699\n",
      "449\n",
      "0.8083034116169627  ,  0.3693  ,  0.8607\n",
      "0.3908362344823325  ,  0.6106  ,  1.339\n",
      "nan  ,  0.5997  ,  1.5091\n",
      "450\n",
      "0.5744400920431196  ,  0.7967  ,  2.149\n",
      "0.38914106320971387  ,  2.088  ,  2.0385\n",
      "nan  ,  0.8619  ,  2.4096\n",
      "451\n",
      "0.8111633514865167  ,  0.5276  ,  1.1501\n",
      "0.40816531853471144  ,  0.7437  ,  1.9645\n",
      "nan  ,  0.753  ,  2.0771\n",
      "452\n",
      "0.8125860573694168  ,  0.5745  ,  0.793\n",
      "0.21264774936511877  ,  1.1347  ,  1.3394\n",
      "nan  ,  1.1735  ,  1.6495\n",
      "453\n",
      "0.8766651233308121  ,  0.4826  ,  0.7877\n",
      "0.185180184137787  ,  0.7769  ,  1.811\n",
      "-0.0751912466511628  ,  0.8187  ,  1.7899\n",
      "454\n",
      "0.8632560943795591  ,  0.3837  ,  0.9657\n",
      "0.2223756600309375  ,  0.5745  ,  1.8959\n",
      "nan  ,  0.5747  ,  1.9301\n",
      "455\n",
      "0.6205548791764333  ,  0.6216  ,  1.0555\n",
      "0.1869047578899355  ,  1.1047  ,  0.9884\n",
      "0.1593456163905281  ,  0.8909  ,  1.3565\n",
      "456\n",
      "0.6626166886893806  ,  0.7143  ,  0.936\n",
      "0.277982872003234  ,  1.0946  ,  0.9911\n",
      "0.023882459311089843  ,  1.0172  ,  1.3785\n",
      "457\n",
      "0.6399816784017442  ,  0.7077  ,  1.1757\n",
      "0.18962321172177513  ,  0.6248  ,  1.0809\n",
      "0.0015521273411017202  ,  0.6129  ,  1.1369\n",
      "458\n",
      "0.8123006623568496  ,  0.5204  ,  0.8991\n",
      "0.49830172752022067  ,  0.7366  ,  1.3272\n",
      "-0.1337940072389962  ,  0.8046  ,  1.6048\n",
      "459\n",
      "0.855463981489496  ,  0.4865  ,  0.89\n",
      "0.12002491303166136  ,  0.8991  ,  1.6327\n",
      "nan  ,  0.9004  ,  1.6364\n",
      "460\n",
      "0.637747467154217  ,  0.442  ,  1.0577\n",
      "0.30653327385938867  ,  0.6763  ,  1.1265\n",
      "0.05293189134319713  ,  0.6971  ,  1.2168\n",
      "461\n",
      "0.7721811628541634  ,  0.3209  ,  0.7235\n",
      "0.24318420294372153  ,  0.5411  ,  1.0384\n",
      "0.03208425304748309  ,  0.5295  ,  1.1143\n",
      "462\n",
      "0.6850361930083171  ,  0.4757  ,  1.0894\n",
      "0.05442282093517248  ,  0.8483  ,  1.1727\n",
      "-0.13417907885829367  ,  0.6142  ,  1.3937\n",
      "463\n",
      "0.5997998829121899  ,  1.0716  ,  1.5672\n",
      "0.09927926923143439  ,  2.3979  ,  1.4102\n",
      "0.13870515138588804  ,  0.6537  ,  1.1651\n",
      "464\n",
      "0.6370001117057644  ,  0.8517  ,  1.4211\n",
      "0.28226234552276674  ,  0.9627  ,  1.561\n",
      "-0.19084980727662101  ,  1.0943  ,  1.4613\n",
      "465\n",
      "0.6354153112544982  ,  0.8143  ,  1.2858\n",
      "-0.12701984400143176  ,  1.5772  ,  1.0249\n",
      "-0.22726449153257666  ,  1.0483  ,  1.3798\n",
      "466\n",
      "0.7369335814863796  ,  0.397  ,  0.9495\n",
      "0.2487572676407261  ,  0.5576  ,  1.3525\n",
      "nan  ,  0.5033  ,  1.4638\n",
      "467\n",
      "0.7690036253790753  ,  0.7918  ,  1.0934\n",
      "0.08212699760282308  ,  1.2533  ,  1.8077\n",
      "nan  ,  1.2576  ,  1.8461\n",
      "468\n",
      "0.6299756944000439  ,  0.6076  ,  1.3328\n",
      "0.217113768097625  ,  0.7612  ,  1.7336\n",
      "-0.020071930085943334  ,  0.7282  ,  1.8275\n",
      "469\n",
      "0.8065808744246653  ,  0.5143  ,  1.1352\n",
      "0.41303917169108156  ,  0.7883  ,  1.8987\n",
      "nan  ,  0.7947  ,  2.0891\n",
      "470\n",
      "0.767097686971522  ,  0.5495  ,  0.9437\n",
      "0.2335866279880906  ,  0.8616  ,  1.5423\n",
      "0.14294830280036708  ,  0.9673  ,  1.4343\n",
      "471\n",
      "0.8370421634659997  ,  0.6334  ,  1.3308\n",
      "0.4681648146643326  ,  0.9617  ,  1.8234\n",
      "nan  ,  0.9403  ,  2.1437\n",
      "472\n",
      "0.808311625514812  ,  0.5366  ,  0.9428\n",
      "0.1885782877200401  ,  1.3838  ,  1.1109\n",
      "0.04821829749616727  ,  0.5526  ,  1.3701\n",
      "473\n",
      "0.8506004061079653  ,  0.4373  ,  0.7943\n",
      "0.27046312096650116  ,  0.8116  ,  1.6725\n",
      "nan  ,  0.8222  ,  1.7002\n",
      "474\n",
      "0.7316153517510224  ,  0.9717  ,  1.4798\n",
      "0.1533248967633719  ,  1.4565  ,  2.398\n",
      "nan  ,  1.4654  ,  2.4262\n",
      "475\n",
      "0.8619358740001636  ,  0.5602  ,  0.8692\n",
      "0.0831060677913402  ,  1.1511  ,  1.9524\n",
      "-0.20662468749890295  ,  1.1558  ,  1.9032\n",
      "476\n",
      "0.877064733004867  ,  0.5993  ,  0.9986\n",
      "0.37738629715905636  ,  1.0456  ,  2.1015\n",
      "nan  ,  1.0756  ,  2.1925\n",
      "477\n",
      "0.48609227226134055  ,  0.499  ,  1.2927\n",
      "0.26463945151552104  ,  1.3996  ,  1.0928\n",
      "nan  ,  0.5335  ,  1.4008\n",
      "478\n",
      "0.7292498137758594  ,  0.9013  ,  1.2264\n",
      "0.5969559903619797  ,  1.0739  ,  1.7258\n",
      "-0.15613834436330237  ,  1.2307  ,  2.0858\n",
      "479\n",
      "0.8542039107844764  ,  0.4786  ,  0.8125\n",
      "0.16408214638445892  ,  0.7942  ,  1.7503\n",
      "nan  ,  0.7886  ,  1.8062\n",
      "480\n",
      "0.8741955475865836  ,  0.8434  ,  0.8456\n",
      "0.16510637905530243  ,  2.0508  ,  2.3595\n",
      "0.25014942343983665  ,  2.0485  ,  2.362\n",
      "481\n",
      "0.5728865673786461  ,  0.8603  ,  1.4621\n",
      "0.320818172932041  ,  1.0452  ,  1.6839\n",
      "nan  ,  1.0687  ,  1.9416\n",
      "482\n",
      "0.5505689537138804  ,  0.5849  ,  1.159\n",
      "0.2087750060022854  ,  1.5187  ,  1.1178\n",
      "-0.05098085152648145  ,  0.6593  ,  1.2426\n",
      "483\n",
      "0.8320365389865676  ,  0.4001  ,  1.1213\n",
      "0.37521384796908086  ,  0.7825  ,  1.8312\n",
      "nan  ,  0.6811  ,  2.1043\n",
      "484\n",
      "0.7892263493219155  ,  0.4873  ,  1.0881\n",
      "0.40893929535436024  ,  1.0002  ,  1.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07429690862676325  ,  0.7145  ,  1.7914\n",
      "485\n",
      "0.7653084018871018  ,  0.8787  ,  1.28\n",
      "0.05398745597445288  ,  1.1423  ,  1.533\n",
      "0.005348857827074529  ,  1.1221  ,  1.6541\n",
      "486\n",
      "0.8071415870798726  ,  0.5154  ,  0.9944\n",
      "0.31567239210484044  ,  0.9013  ,  1.3447\n",
      "nan  ,  0.815  ,  1.6781\n",
      "487\n",
      "0.8803169982374659  ,  0.2552  ,  0.8367\n",
      "0.21181497617638353  ,  0.4826  ,  1.718\n",
      "nan  ,  0.4539  ,  1.7793\n",
      "488\n",
      "0.5428895587608195  ,  0.6918  ,  1.4811\n",
      "0.08557950510757928  ,  1.3599  ,  1.4758\n",
      "0.1518486368362706  ,  0.8964  ,  1.5035\n",
      "489\n",
      "0.7065577024191236  ,  1.1643  ,  1.6544\n",
      "0.2606614038593585  ,  2.7572  ,  2.1534\n",
      "nan  ,  1.7928  ,  2.5835\n",
      "490\n",
      "0.7094562338532004  ,  0.4967  ,  0.96\n",
      "0.389288842886053  ,  0.8808  ,  1.09\n",
      "-0.050268332494211684  ,  0.6999  ,  1.4808\n",
      "491\n",
      "0.8159672813540709  ,  0.7566  ,  0.9902\n",
      "0.3981316612722317  ,  1.3105  ,  1.8266\n",
      "0.1965735113782468  ,  1.441  ,  2.0163\n",
      "492\n",
      "0.8580150563183001  ,  0.2932  ,  0.7558\n",
      "0.3524067831789755  ,  0.5174  ,  1.5133\n",
      "nan  ,  0.5235  ,  1.5411\n",
      "493\n",
      "0.5905345528611518  ,  0.6887  ,  1.1105\n",
      "0.18066614468520134  ,  0.7914  ,  1.1966\n",
      "0.05441428889651079  ,  0.8022  ,  1.2775\n",
      "494\n",
      "0.6578488762282932  ,  0.4126  ,  1.1455\n",
      "0.01898107867334877  ,  0.4745  ,  1.3896\n",
      "0.026790176846663315  ,  0.4853  ,  1.3806\n",
      "495\n",
      "0.724501760064705  ,  0.7836  ,  1.5413\n",
      "0.008357924268867233  ,  0.4027  ,  1.4814\n",
      "nan  ,  0.4024  ,  1.4817\n",
      "496\n",
      "0.8014996038381312  ,  0.7966  ,  1.3814\n",
      "0.18510403008559342  ,  1.2152  ,  2.2028\n",
      "0.1251034480611408  ,  1.2591  ,  2.2057\n",
      "497\n",
      "0.8441308603151689  ,  0.4102  ,  0.7352\n",
      "0.03848314298026749  ,  0.7065  ,  1.3862\n",
      "-0.014760193013640678  ,  0.7345  ,  1.3338\n",
      "498\n",
      "0.8003946962735735  ,  0.4784  ,  1.2693\n",
      "0.35233176876327565  ,  0.6823  ,  1.8818\n",
      "nan  ,  0.6864  ,  1.9911\n",
      "499\n",
      "0.8628977475312927  ,  0.5522  ,  1.3589\n",
      "0.5517976551767235  ,  0.9524  ,  2.581\n",
      "0.08171503391092336  ,  1.022  ,  2.8279\n",
      "500\n",
      "0.8734452559491478  ,  0.4254  ,  0.9789\n",
      "0.3239850107976305  ,  0.8629  ,  1.9012\n",
      "nan  ,  0.7438  ,  2.1814\n",
      "501\n",
      "0.5934117966129393  ,  0.2899  ,  0.9655\n",
      "0.28601554761721215  ,  0.52  ,  0.9277\n",
      "-0.04480654293894541  ,  0.4062  ,  1.038\n",
      "502\n",
      "0.7916813725113081  ,  0.5957  ,  0.8274\n",
      "0.17671929918156798  ,  1.0975  ,  1.6125\n",
      "0.06295536443772724  ,  1.1037  ,  1.6125\n",
      "503\n",
      "0.6146017709069607  ,  0.2343  ,  0.8293\n",
      "0.0016641418797922218  ,  0.299  ,  1.0741\n",
      "-0.2152265141812288  ,  0.3039  ,  1.0672\n",
      "504\n",
      "0.31297343242724185  ,  0.5115  ,  1.3496\n",
      "0.42120978118388197  ,  0.5697  ,  1.1361\n",
      "0.07786832249115325  ,  0.6578  ,  1.252\n",
      "505\n",
      "0.8941189711568903  ,  0.3499  ,  0.6768\n",
      "0.35809026391759113  ,  0.7635  ,  1.4005\n",
      "0.0992316377143769  ,  0.8459  ,  1.4696\n",
      "506\n",
      "0.823925633613654  ,  0.7678  ,  1.1135\n",
      "0.3147083783585035  ,  1.346  ,  2.1658\n",
      "0.080865870767242  ,  1.4254  ,  2.2405\n",
      "507\n",
      "0.7856588463849925  ,  0.5012  ,  0.8857\n",
      "0.5049938354966532  ,  0.7876  ,  1.1047\n",
      "0.07666086861269132  ,  0.8391  ,  1.4598\n",
      "508\n",
      "0.739900408936951  ,  0.6824  ,  1.337\n",
      "0.17137870436465585  ,  0.9781  ,  1.9928\n",
      "0.10837726528819434  ,  1.0155  ,  1.9616\n",
      "509\n",
      "0.899587318768062  ,  0.4156  ,  0.8157\n",
      "0.3065177951212699  ,  0.6676  ,  1.69\n",
      "nan  ,  0.6606  ,  1.7862\n",
      "510\n",
      "0.8853245234732132  ,  0.4163  ,  0.9053\n",
      "0.63690420618961  ,  0.6979  ,  1.466\n",
      "0.11081715156286351  ,  0.7954  ,  1.8054\n",
      "511\n",
      "0.5716136497878445  ,  0.1779  ,  0.7858\n",
      "-0.0035165381844025883  ,  0.1244  ,  0.7857\n",
      "nan  ,  0.1237  ,  0.7853\n",
      "512\n",
      "0.7419712735379491  ,  0.3299  ,  0.8039\n",
      "0.21660394460644697  ,  0.5303  ,  1.1667\n",
      "0.10963857604641349  ,  0.6094  ,  1.1478\n",
      "513\n",
      "0.6971124306209913  ,  0.6069  ,  0.9527\n",
      "0.33969228804030993  ,  0.9021  ,  1.221\n",
      "nan  ,  0.8779  ,  1.5636\n",
      "514\n",
      "0.7205593517060698  ,  0.7282  ,  1.2827\n",
      "0.2256721987358989  ,  1.2422  ,  1.2878\n",
      "-0.0847766890036323  ,  0.6144  ,  1.4336\n",
      "515\n",
      "0.8312290418782965  ,  0.8251  ,  1.1416\n",
      "0.3885912736547875  ,  1.341  ,  1.8655\n",
      "-0.25077604072628057  ,  1.504  ,  2.2553\n",
      "516\n",
      "0.871029880725478  ,  0.7392  ,  1.0627\n",
      "0.4092013485073417  ,  0.932  ,  2.014\n",
      "nan  ,  0.9795  ,  2.1574\n",
      "517\n",
      "0.8906223942477607  ,  0.6268  ,  1.0266\n",
      "0.4095768617291255  ,  1.3255  ,  2.3643\n",
      "nan  ,  1.3938  ,  2.5139\n",
      "518\n",
      "0.8509325275207626  ,  0.4289  ,  0.7549\n",
      "0.38525496030406453  ,  0.8563  ,  1.3021\n",
      "0.035480689870706586  ,  0.7753  ,  1.576\n",
      "519\n",
      "0.6428526945012467  ,  0.3495  ,  0.8594\n",
      "0.1634717343189031  ,  0.3953  ,  1.1253\n",
      "0.0509438816796675  ,  0.4375  ,  1.109\n",
      "520\n",
      "0.8081179263783287  ,  0.4074  ,  0.7796\n",
      "0.2189283840532939  ,  0.6526  ,  1.3652\n",
      "nan  ,  0.6501  ,  1.4329\n",
      "521\n",
      "0.6374303216761703  ,  0.5146  ,  1.0449\n",
      "0.19736855265978165  ,  0.8561  ,  1.2654\n",
      "-0.08682697623350236  ,  0.7402  ,  1.3259\n",
      "522\n",
      "0.8403601569703127  ,  0.3877  ,  1.1027\n",
      "0.36066497660770913  ,  0.6608  ,  1.4102\n",
      "nan  ,  0.5151  ,  1.664\n",
      "523\n",
      "0.8325544793701356  ,  0.3967  ,  1.0951\n",
      "0.20314088309679876  ,  0.6309  ,  1.8882\n",
      "-0.057430816165334096  ,  0.6778  ,  1.8717\n",
      "524\n",
      "0.9018925865916737  ,  0.4374  ,  0.8647\n",
      "0.2006363195248151  ,  0.8368  ,  1.7599\n",
      "-0.08908826897653752  ,  0.7422  ,  1.9169\n",
      "525\n",
      "0.6575145391390452  ,  0.4698  ,  1.2589\n",
      "0.1115801432421005  ,  0.6326  ,  1.4374\n",
      "nan  ,  0.56  ,  1.5225\n",
      "526\n",
      "0.8453025753034  ,  0.483  ,  0.8857\n",
      "0.34846460509690275  ,  0.9119  ,  1.4082\n",
      "0.01329589524568104  ,  0.8993  ,  1.6515\n",
      "527\n",
      "0.8480765901378251  ,  0.5588  ,  1.0288\n",
      "0.2623066105247841  ,  0.9821  ,  2.089\n",
      "0.08571062916435797  ,  1.0094  ,  2.1473\n",
      "528\n",
      "0.7034336935405489  ,  0.3633  ,  0.6227\n",
      "0.06357390821290995  ,  0.4802  ,  0.9682\n",
      "nan  ,  0.4804  ,  0.9696\n",
      "529\n",
      "0.7841510230831595  ,  0.662  ,  0.889\n",
      "0.09209323267445879  ,  1.2496  ,  1.7254\n",
      "-0.06025771146259232  ,  1.2298  ,  1.6043\n",
      "530\n",
      "0.7671214207064837  ,  0.4718  ,  1.0741\n",
      "-0.012868753131220207  ,  0.7182  ,  1.6079\n",
      "-0.2206510930589784  ,  0.817  ,  1.4755\n",
      "531\n",
      "0.8562215182465167  ,  0.8229  ,  1.2608\n",
      "0.43124764012564176  ,  1.392  ,  2.0734\n",
      "nan  ,  1.5254  ,  2.2955\n",
      "532\n",
      "0.6342640295475125  ,  1.1436  ,  1.5833\n",
      "0.3945397189998435  ,  0.7327  ,  1.2583\n",
      "-0.1286950261454263  ,  0.8329  ,  1.363\n",
      "533\n",
      "0.8431981484250081  ,  0.3945  ,  1.0596\n",
      "0.33967306197382074  ,  0.8125  ,  1.6236\n",
      "nan  ,  0.6403  ,  1.9255\n",
      "534\n",
      "0.9085535741726506  ,  0.4927  ,  0.882\n",
      "0.4154427974934659  ,  1.0761  ,  2.2276\n",
      "nan  ,  1.1142  ,  2.3723\n",
      "535\n",
      "0.891421439531723  ,  0.5883  ,  1.2187\n",
      "0.4270420678307393  ,  1.2156  ,  2.522\n",
      "nan  ,  1.2035  ,  2.8847\n",
      "536\n",
      "0.7404806850108501  ,  0.71  ,  1.1602\n",
      "0.006483772247482481  ,  0.7208  ,  1.6116\n",
      "nan  ,  0.6937  ,  1.6342\n",
      "537\n",
      "0.7696138657097571  ,  0.5699  ,  1.0686\n",
      "0.33079876502769534  ,  0.8889  ,  1.5594\n",
      "-0.08574351614330117  ,  0.9148  ,  1.7408\n",
      "538\n",
      "0.6905848357922599  ,  0.3505  ,  0.9369\n",
      "0.06912675236986396  ,  2.4165  ,  1.2655\n",
      "-0.07175735824943341  ,  0.4461  ,  0.8878\n",
      "539\n",
      "0.6793405868755413  ,  0.4087  ,  1.1764\n",
      "0.1936084683356603  ,  0.4888  ,  1.4658\n",
      "-0.010252092587498977  ,  0.4963  ,  1.4835\n",
      "540\n",
      "0.8010963693039955  ,  0.5678  ,  1.1139\n",
      "0.1970702779486063  ,  0.8101  ,  1.5668\n",
      "0.13996111112633403  ,  0.8593  ,  1.5755\n",
      "541\n",
      "0.7959738061282574  ,  0.4009  ,  0.995\n",
      "0.5658202465330231  ,  0.6527  ,  1.2358\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "542\n",
      "0.8108922169799514  ,  0.6506  ,  0.8536\n",
      "0.06772143133653553  ,  1.3038  ,  1.6883\n",
      "-0.028206319195523813  ,  1.2921  ,  1.6421\n",
      "543\n",
      "0.6477214922341572  ,  0.6628  ,  1.3052\n",
      "0.278512057033353  ,  0.8002  ,  1.4109\n",
      "-0.013195829140075546  ,  0.8461  ,  1.4651\n",
      "544\n",
      "0.726466146356306  ,  0.6954  ,  1.1517\n",
      "0.1151365753387943  ,  0.6129  ,  1.2392\n",
      "-0.12548905337614674  ,  0.7564  ,  1.0619\n",
      "545\n",
      "0.6914692607872936  ,  1.1941  ,  1.4841\n",
      "0.20859733382301401  ,  1.7539  ,  1.2624\n",
      "-0.03936463130295185  ,  0.9695  ,  1.6387\n",
      "546\n",
      "0.7323320070054271  ,  0.3764  ,  0.9429\n",
      "0.02850536416555578  ,  0.4939  ,  1.4655\n",
      "nan  ,  0.4942  ,  1.4661\n",
      "547\n",
      "0.8329517470171162  ,  0.4228  ,  0.9395\n",
      "0.2420389327614066  ,  0.64  ,  1.6188\n",
      "nan  ,  0.6447  ,  1.6726\n",
      "548\n",
      "0.8428970906517579  ,  0.594  ,  0.9223\n",
      "0.5318778211061356  ,  1.0657  ,  1.4178\n",
      "nan  ,  1.187  ,  1.9868\n",
      "549\n",
      "0.7982250229706722  ,  0.9002  ,  1.1265\n",
      "0.12354781569659495  ,  0.9984  ,  1.8744\n",
      "0.0679941809433843  ,  1.0245  ,  1.8319\n",
      "550\n",
      "0.8693643161377629  ,  0.6014  ,  1.3179\n",
      "0.6390538109397292  ,  0.9109  ,  1.715\n",
      "nan  ,  0.9584  ,  2.2766\n",
      "551\n",
      "0.8466629171907585  ,  0.5707  ,  1.1226\n",
      "0.0859047866985078  ,  0.9646  ,  1.8839\n",
      "-0.2803827909499679  ,  1.0697  ,  1.7056\n",
      "552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9316627317705349  ,  0.2393  ,  0.5398\n",
      "-0.0012005445939469186  ,  0.5836  ,  1.5087\n",
      "nan  ,  0.5836  ,  1.509\n",
      "553\n",
      "0.7078631869853154  ,  1.1405  ,  1.8224\n",
      "0.20005466946998335  ,  2.0511  ,  1.666\n",
      "nan  ,  0.778  ,  1.6827\n",
      "554\n",
      "0.648835024852682  ,  0.4349  ,  0.8435\n",
      "0.44658364050635946  ,  0.6018  ,  0.8758\n",
      "-0.32691514939223565  ,  0.6497  ,  1.0402\n",
      "555\n",
      "0.737263897959489  ,  0.2432  ,  0.7475\n",
      "0.05767915581925605  ,  0.3258  ,  1.0619\n",
      "-0.04142596022091169  ,  0.4215  ,  0.9992\n",
      "556\n",
      "0.8280419861558762  ,  0.5591  ,  1.096\n",
      "0.3812074799542825  ,  1.2637  ,  1.528\n",
      "nan  ,  0.9815  ,  2.095\n",
      "557\n",
      "0.9077339095235293  ,  0.207  ,  0.7434\n",
      "0.04670915904104366  ,  0.402  ,  1.4223\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "558\n",
      "0.8780326934266542  ,  0.5465  ,  0.9759\n",
      "0.4505329312896544  ,  1.0107  ,  1.8852\n",
      "nan  ,  1.0988  ,  2.2739\n",
      "559\n",
      "0.7650325153219254  ,  0.6548  ,  1.2101\n",
      "0.2996647942770645  ,  0.8951  ,  1.8192\n",
      "nan  ,  0.8602  ,  2.0446\n",
      "560\n",
      "0.8187066464545674  ,  0.3695  ,  0.9937\n",
      "0.24097276696001554  ,  0.627  ,  1.6451\n",
      "nan  ,  0.5586  ,  1.7751\n",
      "561\n",
      "0.7890461469484906  ,  0.5246  ,  1.4362\n",
      "0.18851288615754966  ,  1.7318  ,  1.8566\n",
      "nan  ,  0.7374  ,  2.3059\n",
      "562\n",
      "0.6176274322051022  ,  0.4551  ,  1.0986\n",
      "0.31360306447850134  ,  0.3879  ,  1.2201\n",
      "-0.09436172500079296  ,  0.3934  ,  1.2386\n",
      "563\n",
      "0.760797019293379  ,  0.7943  ,  1.3678\n",
      "0.3255044687625235  ,  1.2019  ,  2.0759\n",
      "nan  ,  1.2265  ,  2.1348\n",
      "564\n",
      "0.6784842706199797  ,  0.3534  ,  0.8234\n",
      "0.09595138558853204  ,  0.7871  ,  0.9119\n",
      "0.02252828134843563  ,  0.5224  ,  0.9995\n",
      "565\n",
      "0.8370354052292165  ,  0.3922  ,  0.7661\n",
      "0.30044134359143704  ,  0.7386  ,  1.3888\n",
      "-0.07809044448413535  ,  0.7907  ,  1.4652\n",
      "566\n",
      "0.8336495861207797  ,  0.3939  ,  0.8051\n",
      "0.31243368933834004  ,  0.6982  ,  1.5295\n",
      "0.0034597943954106612  ,  0.7867  ,  1.4755\n",
      "567\n",
      "0.7797032901956679  ,  0.3728  ,  0.8636\n",
      "0.06686731539147857  ,  0.711  ,  1.2398\n",
      "nan  ,  0.5278  ,  1.4074\n",
      "568\n",
      "0.862911743474873  ,  0.4113  ,  0.7908\n",
      "0.3595880688155102  ,  0.8183  ,  1.3967\n",
      "0.3276975178395322  ,  0.7642  ,  1.6485\n",
      "569\n",
      "0.9492095237216427  ,  0.3837  ,  0.648\n",
      "-0.007531297215115022  ,  0.9158  ,  2.3807\n",
      "nan  ,  0.9157  ,  2.3808\n",
      "570\n",
      "0.8216602961746566  ,  0.9478  ,  1.2476\n",
      "0.1484547625311926  ,  1.136  ,  1.7397\n",
      "-0.24338274750834896  ,  1.1565  ,  1.6695\n",
      "571\n",
      "0.7103220845514384  ,  0.9891  ,  1.269\n",
      "0.20034392629220588  ,  0.7076  ,  1.4836\n",
      "nan  ,  0.7106  ,  1.4938\n",
      "572\n",
      "0.9257476979123407  ,  0.3966  ,  0.9438\n",
      "0.6318597851992409  ,  0.7544  ,  1.9052\n",
      "nan  ,  0.8035  ,  2.0864\n",
      "573\n",
      "0.8674324699671883  ,  0.489  ,  0.9092\n",
      "0.28685670301906985  ,  0.8039  ,  1.5634\n",
      "0.1247511750540224  ,  0.8106  ,  1.6517\n",
      "574\n",
      "0.7557733187489293  ,  0.4804  ,  0.9563\n",
      "0.34806838285362235  ,  0.682  ,  1.433\n",
      "0.0038061338879975416  ,  0.7476  ,  1.4817\n",
      "575\n",
      "0.8890362285927074  ,  0.4936  ,  0.9734\n",
      "0.2669629711982471  ,  0.9457  ,  1.963\n",
      "nan  ,  0.9529  ,  1.9767\n",
      "576\n",
      "0.7350661240495999  ,  0.4633  ,  1.0345\n",
      "0.16592505472196348  ,  0.6568  ,  1.5646\n",
      "0.0010378893569181927  ,  0.7037  ,  1.5365\n",
      "577\n",
      "0.8499927956906133  ,  0.3636  ,  0.7896\n",
      "0.30378867331918047  ,  0.6677  ,  1.5039\n",
      "nan  ,  0.6627  ,  1.6222\n",
      "578\n",
      "0.7138289558830604  ,  0.8564  ,  0.987\n",
      "0.03333826750375694  ,  1.4764  ,  1.2152\n",
      "-0.24140516037993814  ,  1.3981  ,  1.4992\n",
      "579\n",
      "0.832813782222805  ,  0.4429  ,  1.1787\n",
      "0.16004919378993948  ,  0.7362  ,  1.6888\n",
      "nan  ,  0.6545  ,  1.8015\n",
      "580\n",
      "0.9288798027872052  ,  0.4462  ,  0.8268\n",
      "0.0860945537070209  ,  1.0946  ,  2.3598\n",
      "nan  ,  1.0957  ,  2.3638\n",
      "581\n",
      "0.6903759009762973  ,  0.5846  ,  0.9756\n",
      "0.3776926235561451  ,  0.6466  ,  1.0721\n",
      "0.020788885007798796  ,  0.6806  ,  1.2066\n",
      "582\n",
      "0.7874040715205317  ,  0.8097  ,  1.3924\n",
      "0.23652988508929756  ,  0.5933  ,  1.8473\n",
      "nan  ,  0.556  ,  1.9375\n",
      "583\n",
      "0.7721022901523045  ,  0.736  ,  1.3953\n",
      "0.343095653290437  ,  1.2657  ,  1.5125\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "584\n",
      "0.6544336659232619  ,  0.2309  ,  0.7218\n",
      "0.014093586696953047  ,  0.2706  ,  0.9408\n",
      "0.019973195442175525  ,  0.5163  ,  0.7951\n",
      "585\n",
      "0.5260439518441431  ,  0.425  ,  0.9646\n",
      "0.014320503283890233  ,  0.4728  ,  1.1926\n",
      "-0.041095410019474324  ,  0.512  ,  1.1489\n",
      "586\n",
      "0.8274803038193529  ,  0.756  ,  0.9321\n",
      "0.4066352874475568  ,  1.2128  ,  1.6897\n",
      "0.11027365780505331  ,  1.3708  ,  2.0217\n",
      "587\n",
      "0.5625933669561123  ,  0.1659  ,  0.7017\n",
      "0.22106998621632126  ,  0.2282  ,  0.7815\n",
      "0.014626974923782416  ,  0.2323  ,  0.8008\n",
      "588\n",
      "0.8477265781251897  ,  0.4748  ,  0.7218\n",
      "0.2683267113572929  ,  0.9769  ,  1.591\n",
      "-0.15433393992214564  ,  0.9986  ,  1.5971\n",
      "589\n",
      "0.8082684333069005  ,  0.5426  ,  1.2649\n",
      "0.21906814967028287  ,  0.8879  ,  2.0377\n",
      "0.05664705719399277  ,  0.872  ,  2.1596\n",
      "590\n",
      "0.8440865609163665  ,  0.3928  ,  0.9814\n",
      "-0.007712846707194182  ,  0.571  ,  1.6386\n",
      "0.030903043445800353  ,  0.6657  ,  1.5464\n",
      "591\n",
      "0.6752986610351701  ,  0.367  ,  0.9281\n",
      "0.16925228040326298  ,  0.5246  ,  1.1615\n",
      "0.028139930071688184  ,  0.5343  ,  1.1853\n",
      "592\n",
      "0.7316330905007213  ,  0.4305  ,  0.8134\n",
      "-0.026124926935664615  ,  0.6544  ,  1.2921\n",
      "nan  ,  0.654  ,  1.2922\n",
      "593\n",
      "0.779706938596048  ,  0.5287  ,  1.0856\n",
      "0.5094865217418966  ,  0.8296  ,  1.4943\n",
      "nan  ,  0.9043  ,  1.7954\n",
      "594\n",
      "0.22036293852802283  ,  0.6483  ,  1.418\n",
      "0.10609750926479802  ,  0.74  ,  1.3\n",
      "0.1670143552421065  ,  0.8201  ,  1.223\n",
      "595\n",
      "0.888771992540099  ,  0.4466  ,  1.0199\n",
      "0.5819022795289928  ,  0.8551  ,  1.5636\n",
      "-0.08807289295050284  ,  0.8523  ,  2.1192\n",
      "596\n",
      "0.7775497777693068  ,  0.646  ,  0.954\n",
      "0.03075795765465141  ,  1.1563  ,  1.7561\n",
      "-0.18966235591367606  ,  1.1461  ,  1.7317\n",
      "597\n",
      "0.8913231270819851  ,  0.3959  ,  0.8139\n",
      "0.46391502904911036  ,  1.1243  ,  1.3197\n",
      "nan  ,  0.5984  ,  1.6989\n",
      "598\n",
      "0.7492875524097129  ,  1.4399  ,  1.8569\n",
      "0.22539564093804335  ,  1.0935  ,  2.1142\n",
      "-0.2804731834684796  ,  1.1149  ,  2.1846\n",
      "599\n",
      "0.8173741224362361  ,  0.8557  ,  1.1928\n",
      "0.37371051954486645  ,  1.4356  ,  2.1907\n",
      "nan  ,  1.52  ,  2.5242\n",
      "600\n",
      "0.7468253268649975  ,  0.7209  ,  0.8368\n",
      "0.09111000936622993  ,  1.0457  ,  1.3763\n",
      "nan  ,  1.0466  ,  1.3783\n",
      "601\n",
      "0.798789926790881  ,  0.5273  ,  1.0901\n",
      "0.3237141497597997  ,  0.8075  ,  1.7185\n",
      "-0.07756890926132406  ,  0.8286  ,  1.8136\n",
      "602\n",
      "0.6515975772428498  ,  0.7435  ,  1.2125\n",
      "0.28664882817200626  ,  0.9582  ,  1.5886\n",
      "-0.20396266934000307  ,  0.9681  ,  1.6812\n",
      "603\n",
      "0.7354089557969412  ,  0.5686  ,  0.7348\n",
      "0.11233473993856755  ,  0.831  ,  0.8294\n",
      "-0.052846277629278446  ,  0.7137  ,  1.0558\n",
      "604\n",
      "0.8321311492844805  ,  0.6477  ,  0.8754\n",
      "0.38906109663282495  ,  1.0624  ,  1.3194\n",
      "0.05007347745445533  ,  1.2049  ,  1.6308\n",
      "605\n",
      "0.8469899000680576  ,  0.6967  ,  1.3182\n",
      "-0.04355045459242928  ,  0.8835  ,  1.9499\n",
      "0.1279911622008961  ,  0.7884  ,  1.9785\n",
      "606\n",
      "0.8472148737926983  ,  0.8326  ,  1.4523\n",
      "0.18783174586334384  ,  0.9318  ,  2.0569\n",
      "nan  ,  0.9249  ,  2.1226\n",
      "607\n",
      "0.852568014275072  ,  0.4474  ,  0.8338\n",
      "0.04857459444709955  ,  0.5471  ,  1.2475\n",
      "0.10198592276023283  ,  0.5719  ,  1.2173\n",
      "608\n",
      "0.7946407848888102  ,  0.5281  ,  0.7918\n",
      "0.154333823488521  ,  0.8626  ,  1.348\n",
      "nan  ,  0.8378  ,  1.4816\n",
      "609\n",
      "0.8624441683761509  ,  0.3479  ,  0.6411\n",
      "0.1533400421112852  ,  0.664  ,  1.3047\n",
      "-0.12556115817996394  ,  0.6778  ,  1.3219\n",
      "610\n",
      "0.8548227211228557  ,  0.2517  ,  0.6311\n",
      "0.23339810187769938  ,  0.4116  ,  1.2683\n",
      "0.005224165540676919  ,  0.4407  ,  1.2684\n",
      "611\n",
      "0.47176139365052233  ,  1.0305  ,  1.6576\n",
      "0.2872390624387344  ,  1.175  ,  1.3496\n",
      "-0.14599503857081103  ,  1.1286  ,  1.7929\n",
      "612\n",
      "0.7312131290778723  ,  0.8765  ,  1.1485\n",
      "0.1987372556492371  ,  1.4532  ,  1.8288\n",
      "-0.012461789746498038  ,  1.5014  ,  1.9596\n",
      "613\n",
      "0.8288273361990754  ,  0.5901  ,  1.1922\n",
      "0.36430427306585456  ,  0.9768  ,  1.5996\n",
      "0.06048860331874162  ,  0.8216  ,  1.9744\n",
      "614\n",
      "0.8109328811272017  ,  0.3512  ,  0.8502\n",
      "-0.017818702289644932  ,  0.7746  ,  1.4527\n",
      "nan  ,  0.5544  ,  1.5537\n",
      "615\n",
      "0.461893895023692  ,  0.0809  ,  0.4614\n",
      "0.5202745977696572  ,  0.0874  ,  0.4082\n",
      "0.05026794780660296  ,  0.1952  ,  0.4373\n",
      "616\n",
      "0.7649124074661706  ,  0.5781  ,  0.8934\n",
      "0.03536690553938231  ,  1.0088  ,  1.582\n",
      "0.05562411135301008  ,  1.0305  ,  1.4619\n",
      "617\n",
      "0.867260010554675  ,  0.5432  ,  0.9887\n",
      "0.49161533465607876  ,  1.9174  ,  1.6388\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "618\n",
      "0.8859133316313319  ,  0.5116  ,  0.9133\n",
      "0.3897975799733988  ,  1.0715  ,  2.121\n",
      "0.08827749452878432  ,  1.1111  ,  2.2078\n",
      "619\n",
      "0.8040331623671714  ,  0.5611  ,  0.8939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5018692923598184  ,  0.9395  ,  1.5641\n",
      "-0.17252981777498438  ,  1.0208  ,  1.7174\n",
      "620\n",
      "0.8758706917060104  ,  0.4556  ,  0.9252\n",
      "0.12474567587396126  ,  0.8207  ,  1.7635\n",
      "nan  ,  0.8192  ,  1.7778\n",
      "621\n",
      "0.8385596719041594  ,  0.4946  ,  0.9072\n",
      "0.16968934955028517  ,  0.91  ,  1.7178\n",
      "nan  ,  0.8865  ,  1.8439\n",
      "622\n",
      "0.8857914538514663  ,  0.4796  ,  0.991\n",
      "0.48433682790372007  ,  1.0239  ,  1.4627\n",
      "nan  ,  0.8699  ,  2.0202\n",
      "623\n",
      "0.5704153165843083  ,  0.612  ,  1.3135\n",
      "0.2632788475361896  ,  0.8208  ,  1.2846\n",
      "nan  ,  0.705  ,  1.5479\n",
      "624\n",
      "0.6975641147622427  ,  0.6144  ,  1.0079\n",
      "0.3741215467961986  ,  0.9952  ,  1.1071\n",
      "0.030427711089801336  ,  0.8776  ,  1.5159\n",
      "625\n",
      "0.9165889259684974  ,  0.2769  ,  0.8056\n",
      "nan  ,  0.5148  ,  1.7248\n",
      "nan  ,  0.5148  ,  1.7248\n",
      "626\n",
      "0.6308347664572299  ,  0.3867  ,  1.0281\n",
      "0.2534184774254414  ,  0.7352  ,  1.2983\n",
      "nan  ,  0.4256  ,  1.3574\n",
      "627\n",
      "0.8986924321753064  ,  0.4153  ,  0.7232\n",
      "0.21304995202026178  ,  0.8583  ,  1.8609\n",
      "0.1096518514278734  ,  0.8753  ,  1.89\n",
      "628\n",
      "0.7512283729029583  ,  0.4346  ,  0.8008\n",
      "0.15505398791262173  ,  0.7049  ,  1.3117\n",
      "0.14309834717809256  ,  0.7402  ,  1.2536\n",
      "629\n",
      "0.7400521453632716  ,  0.5666  ,  0.9155\n",
      "0.3764186645896538  ,  0.8208  ,  1.3391\n",
      "-0.0473883930687443  ,  0.8836  ,  1.4563\n",
      "630\n",
      "0.8811064586463289  ,  0.7155  ,  1.0144\n",
      "0.3795342423048878  ,  1.2556  ,  2.2461\n",
      "nan  ,  1.3036  ,  2.4833\n",
      "631\n",
      "0.9474689931030988  ,  0.3231  ,  0.8132\n",
      "0.8719150882050404  ,  0.7454  ,  1.4291\n",
      "0.7491359562038244  ,  1.3657  ,  2.3862\n",
      "632\n",
      "0.7929600917961783  ,  0.3704  ,  0.9662\n",
      "-0.005333176128764585  ,  0.5398  ,  1.5432\n",
      "nan  ,  0.5064  ,  1.5653\n",
      "633\n",
      "0.884011253408016  ,  0.4727  ,  0.8295\n",
      "0.35893685621562244  ,  0.9249  ,  1.5055\n",
      "-0.0008719191049632175  ,  0.959  ,  1.6945\n",
      "634\n",
      "0.7325356793467603  ,  0.4886  ,  0.9962\n",
      "0.3344230962663686  ,  0.6925  ,  1.4021\n",
      "-0.11625244035507884  ,  0.7556  ,  1.4341\n",
      "635\n",
      "0.7843996466004926  ,  0.4604  ,  1.0092\n",
      "0.41229195919273987  ,  0.7186  ,  1.5264\n",
      "0.13879721223020347  ,  0.7604  ,  1.6841\n",
      "636\n",
      "0.9766925540260912  ,  0.6081  ,  1.5081\n",
      "0.6804814624510961  ,  1.4759  ,  3.6066\n",
      "0.2767866347096872  ,  1.5468  ,  3.8162\n",
      "637\n",
      "0.7454903062462447  ,  0.9127  ,  1.4758\n",
      "0.2132718019578915  ,  1.2681  ,  2.0643\n",
      "nan  ,  1.2821  ,  2.1346\n",
      "638\n",
      "0.6809410997992063  ,  0.6259  ,  0.9686\n",
      "0.42884327250579246  ,  0.787  ,  1.1063\n",
      "0.07796848537348279  ,  0.8502  ,  1.3946\n",
      "639\n",
      "0.8187675461018379  ,  0.9326  ,  1.125\n",
      "0.479505272555879  ,  1.5574  ,  1.9952\n",
      "nan  ,  1.8033  ,  2.3966\n",
      "640\n",
      "0.5565911386974856  ,  0.8809  ,  1.3349\n",
      "-0.06737019979020606  ,  1.2637  ,  1.3395\n",
      "nan  ,  1.085  ,  1.7216\n",
      "641\n",
      "0.6309261318444966  ,  0.689  ,  1.0651\n",
      "0.28631227798073766  ,  0.8395  ,  1.3302\n",
      "-0.019488332858094766  ,  0.8231  ,  1.4896\n",
      "642\n",
      "0.6418050467105223  ,  0.7207  ,  1.0051\n",
      "-0.06737219569037178  ,  1.0868  ,  1.1842\n",
      "-0.23584863172956674  ,  1.0582  ,  1.2977\n",
      "643\n",
      "0.48060304752657124  ,  1.0229  ,  1.254\n",
      "0.06881461457389672  ,  1.1335  ,  1.3272\n",
      "-0.076363830263542  ,  1.1537  ,  1.3629\n",
      "644\n",
      "0.592450797378862  ,  0.6384  ,  1.0753\n",
      "0.12343667730027205  ,  0.765  ,  1.4622\n",
      "-0.1188637806590226  ,  0.8407  ,  1.3204\n",
      "645\n",
      "0.7502179460584675  ,  0.6789  ,  0.984\n",
      "0.16114157207647323  ,  0.8202  ,  1.3957\n",
      "0.18815192616259524  ,  0.8534  ,  1.4036\n",
      "646\n",
      "0.6507281500548513  ,  1.1905  ,  1.5368\n",
      "0.2589328820235737  ,  0.9735  ,  1.5\n",
      "-0.26953687705573687  ,  1.0166  ,  1.4481\n",
      "647\n",
      "0.6484604579765145  ,  0.4483  ,  0.9771\n",
      "0.14789130007886372  ,  0.6297  ,  1.1466\n",
      "nan  ,  0.556  ,  1.2765\n",
      "648\n",
      "0.5519099918545564  ,  0.7702  ,  0.9891\n",
      "0.2089211103361947  ,  0.9774  ,  1.1927\n",
      "0.09306309826903145  ,  1.0228  ,  1.0726\n",
      "649\n",
      "0.6769241473684598  ,  0.6594  ,  0.8701\n",
      "0.13247361919223893  ,  0.7795  ,  0.8197\n",
      "-0.011588664220270757  ,  0.7446  ,  1.0156\n",
      "650\n",
      "0.6588571995948891  ,  0.3823  ,  1.0657\n",
      "0.05010124255592972  ,  0.4568  ,  1.3375\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "651\n",
      "0.690609022711782  ,  0.8472  ,  1.2106\n",
      "0.3994003599463066  ,  0.96  ,  1.4768\n",
      "nan  ,  1.0137  ,  1.7047\n",
      "652\n",
      "0.6884293141819057  ,  0.5691  ,  1.0311\n",
      "0.1823394845409726  ,  0.6921  ,  1.4218\n",
      "-0.015245519671921857  ,  0.7904  ,  1.2786\n",
      "653\n",
      "0.5045670212886444  ,  0.6805  ,  1.2322\n",
      "0.023833877638888078  ,  0.7441  ,  1.5641\n",
      "0.05698859598878127  ,  0.7978  ,  1.4736\n",
      "654\n",
      "0.7637810599443319  ,  0.5327  ,  0.8884\n",
      "0.005646955200196981  ,  0.6891  ,  1.5665\n",
      "0.001530389459618536  ,  0.7767  ,  1.4387\n",
      "655\n",
      "0.6159082919800526  ,  0.3657  ,  1.074\n",
      "0.2773811361158784  ,  0.4758  ,  1.3028\n",
      "0.020761679356200113  ,  0.5851  ,  1.3008\n",
      "656\n",
      "0.8238185074274238  ,  0.3404  ,  0.6199\n",
      "0.07457691508736707  ,  0.519  ,  1.1954\n",
      "-0.016860203777662224  ,  0.5311  ,  1.1882\n",
      "657\n",
      "0.5600666848377284  ,  0.2824  ,  1.1213\n",
      "-0.005913181913226319  ,  0.3227  ,  1.3506\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "658\n",
      "0.4801704209943666  ,  0.4949  ,  0.9743\n",
      "0.06411342875884972  ,  0.5555  ,  1.1785\n",
      "0.23409130753701796  ,  0.797  ,  0.8752\n",
      "659\n",
      "0.7224286059554643  ,  0.421  ,  0.9541\n",
      "0.06946590186939369  ,  1.5246  ,  1.294\n",
      "-0.031671770707099964  ,  0.5801  ,  1.4338\n",
      "660\n",
      "0.6030726640067172  ,  0.2703  ,  0.8662\n",
      "0.16366549110818732  ,  0.3301  ,  1.0409\n",
      "0.0008422797342698633  ,  0.379  ,  1.0232\n",
      "661\n",
      "0.7032068073735694  ,  0.6788  ,  0.8962\n",
      "0.13986243593034808  ,  0.9248  ,  1.4175\n",
      "-0.21345925416018813  ,  0.9424  ,  1.4333\n",
      "662\n",
      "0.24854349813134902  ,  0.3258  ,  0.9424\n",
      "0.06642991540281705  ,  0.3334  ,  0.9642\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "663\n",
      "0.37749155586407146  ,  0.2968  ,  0.7939\n",
      "0.13528321183852768  ,  0.7342  ,  0.6052\n",
      "-0.04396380615223787  ,  0.3298  ,  0.7365\n",
      "664\n",
      "0.5771663768727365  ,  0.5399  ,  0.9023\n",
      "0.0044796774012646106  ,  0.5346  ,  1.1336\n",
      "-0.028410272922104865  ,  0.6083  ,  1.0224\n",
      "665\n",
      "0.6723044087164467  ,  0.7564  ,  0.977\n",
      "-0.009984246089949233  ,  0.9808  ,  1.4641\n",
      "0.04019790684695739  ,  0.976  ,  1.4453\n",
      "666\n",
      "0.6496858311200125  ,  0.3882  ,  1.0487\n",
      "0.14720691126459456  ,  0.2701  ,  0.8112\n",
      "0.020153431301278123  ,  0.204  ,  0.8524\n",
      "667\n",
      "0.5678552807055036  ,  0.8449  ,  1.4006\n",
      "0.21971410812040698  ,  1.0638  ,  1.6917\n",
      "nan  ,  1.072  ,  1.7601\n",
      "668\n",
      "0.6384311139228056  ,  0.8939  ,  1.1101\n",
      "0.11221568144642495  ,  0.7954  ,  1.3994\n",
      "0.02164334552655374  ,  0.7991  ,  1.4339\n",
      "669\n",
      "0.720961400608811  ,  0.6863  ,  0.9874\n",
      "0.07728078879969816  ,  1.0589  ,  1.4705\n",
      "-0.04619355029492463  ,  1.0921  ,  1.3989\n",
      "670\n",
      "0.6772746226978509  ,  0.9122  ,  1.2254\n",
      "0.17157844154168297  ,  0.691  ,  1.2377\n",
      "0.03767244886220717  ,  0.6825  ,  1.3003\n",
      "671\n",
      "0.6157994987558244  ,  0.4021  ,  0.9799\n",
      "0.054722061618062694  ,  0.4853  ,  1.2839\n",
      "nan  ,  0.485  ,  1.2857\n",
      "672\n",
      "0.7826832177487922  ,  0.4671  ,  0.8723\n",
      "0.09690874242136344  ,  0.4951  ,  1.1505\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "673\n",
      "0.7214971282726308  ,  0.7972  ,  1.0074\n",
      "0.3192270870018459  ,  1.2588  ,  1.1977\n",
      "0.20230758074520078  ,  1.3102  ,  1.8145\n",
      "674\n",
      "0.764183653725199  ,  0.4229  ,  0.781\n",
      "0.047199782737434526  ,  0.7187  ,  0.9746\n",
      "nan  ,  0.5411  ,  1.1629\n",
      "675\n",
      "0.6422258247448595  ,  0.7676  ,  1.029\n",
      "0.03498553899968584  ,  1.1221  ,  1.5466\n",
      "-0.2557256162256939  ,  1.1032  ,  1.464\n",
      "676\n",
      "0.6828647609708052  ,  0.462  ,  1.031\n",
      "0.00955919352201003  ,  0.5838  ,  1.3964\n",
      "-0.05454664161139491  ,  0.5836  ,  1.3968\n",
      "677\n",
      "0.5522801790088907  ,  0.8815  ,  1.1199\n",
      "-0.011454943189963717  ,  1.2281  ,  1.5283\n",
      "-0.06319674520441226  ,  1.2026  ,  1.4725\n",
      "678\n",
      "0.558479389594881  ,  0.7775  ,  1.0713\n",
      "0.15483139134588325  ,  0.9502  ,  1.1384\n",
      "0.05465827355358414  ,  0.9681  ,  1.2435\n",
      "679\n",
      "0.6834203759592972  ,  1.0121  ,  1.0669\n",
      "-0.007963333003684278  ,  1.0945  ,  1.5328\n",
      "nan  ,  1.0945  ,  1.5329\n",
      "680\n",
      "0.5230472833366504  ,  0.7123  ,  1.0171\n",
      "0.2740429669102139  ,  0.7944  ,  0.908\n",
      "-0.25830076249620443  ,  0.7468  ,  1.0484\n",
      "681\n",
      "0.6331753535390687  ,  1.0542  ,  1.2847\n",
      "0.03402274510958938  ,  1.3208  ,  1.5504\n",
      "-0.4785616816360009  ,  1.3212  ,  1.5208\n",
      "682\n",
      "0.7582634100983843  ,  0.573  ,  1.0637\n",
      "0.15994795537947495  ,  0.898  ,  1.6687\n",
      "0.09634278532768883  ,  0.9686  ,  1.5279\n",
      "683\n",
      "0.7142296540189363  ,  0.898  ,  1.0648\n",
      "0.07124999429555738  ,  1.0565  ,  1.6194\n",
      "-0.1200307323734203  ,  1.1236  ,  1.2937\n",
      "684\n",
      "0.5547684344129049  ,  0.3596  ,  0.7716\n",
      "0.09903408623821638  ,  0.5412  ,  0.8845\n",
      "0.11814577821338378  ,  0.4418  ,  0.9648\n",
      "685\n",
      "0.5221790244456381  ,  0.4114  ,  0.9568\n",
      "-0.01912708632093877  ,  0.7737  ,  0.8872\n",
      "0.020371051470683427  ,  0.4766  ,  1.0558\n",
      "686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5474276835724317  ,  0.9354  ,  1.1351\n",
      "0.29027769100610756  ,  0.7338  ,  1.2089\n",
      "-0.05285414656505049  ,  0.8521  ,  1.0721\n",
      "687\n",
      "0.7167924435484821  ,  0.9164  ,  1.0787\n",
      "0.4062161701632406  ,  1.4527  ,  1.5638\n",
      "-0.26177853278600205  ,  1.505  ,  1.5571\n",
      "688\n",
      "0.5846994507857434  ,  0.8441  ,  1.0252\n",
      "0.22089324226123921  ,  0.8698  ,  1.2815\n",
      "0.09059665494035637  ,  0.9806  ,  1.0188\n",
      "689\n",
      "0.6176082704285405  ,  0.4428  ,  0.8332\n",
      "0.04101258658155609  ,  0.5266  ,  1.1452\n",
      "nan  ,  0.526  ,  1.1493\n",
      "690\n",
      "0.4021785234639879  ,  0.5869  ,  1.2786\n",
      "0.12023843761973758  ,  0.573  ,  1.1448\n",
      "nan  ,  0.4915  ,  1.2401\n",
      "691\n",
      "0.5657336825043506  ,  0.5161  ,  1.0067\n",
      "0.06381798141270406  ,  0.4879  ,  1.2085\n",
      "0.003453234268397551  ,  0.6023  ,  1.0824\n",
      "692\n",
      "0.6590501019080707  ,  0.5373  ,  0.9361\n",
      "0.022001689910718363  ,  0.8101  ,  1.204\n",
      "0.27619093904867864  ,  0.7696  ,  1.2861\n",
      "693\n",
      "0.5957416731027769  ,  0.2968  ,  0.7799\n",
      "0.011816644258536756  ,  0.324  ,  0.9572\n",
      "nan  ,  0.3157  ,  0.9632\n",
      "694\n",
      "0.5610518978644713  ,  0.7178  ,  0.8979\n",
      "0.0476927550973946  ,  0.9278  ,  1.2156\n",
      "0.3383274236111146  ,  0.9407  ,  1.2062\n",
      "695\n",
      "0.7515501221531131  ,  0.4129  ,  0.8111\n",
      "0.07874656759793669  ,  0.8422  ,  1.0258\n",
      "0.01930230564231942  ,  0.7271  ,  1.077\n",
      "696\n",
      "0.5404661209000854  ,  0.7433  ,  1.0377\n",
      "0.1337132446487367  ,  0.7826  ,  1.2398\n",
      "-0.04522884760849369  ,  0.8177  ,  1.2196\n",
      "697\n",
      "0.7107421941205493  ,  0.2708  ,  0.7816\n",
      "0.018618390868055064  ,  1.264  ,  1.1172\n",
      "nan  ,  0.3362  ,  1.1518\n",
      "698\n",
      "0.51520545438884  ,  0.4565  ,  1.0402\n",
      "-0.016286991813531864  ,  0.5224  ,  1.2621\n",
      "nan  ,  0.522  ,  1.2622\n",
      "699\n",
      "0.4614676348187762  ,  0.4784  ,  1.0411\n",
      "0.12375402019445925  ,  0.5897  ,  1.1383\n",
      "-0.01044286976652093  ,  0.656  ,  1.0842\n",
      "700\n",
      "0.4075861397216226  ,  0.3361  ,  0.985\n",
      "0.03997632104053455  ,  0.3934  ,  1.0377\n",
      "0.05029460399890472  ,  0.5086  ,  0.9402\n",
      "701\n",
      "0.4408401427505263  ,  0.8752  ,  1.1799\n",
      "0.10969543487892022  ,  0.957  ,  1.2496\n",
      "0.013842534075092706  ,  0.9596  ,  1.1497\n",
      "702\n",
      "0.3012349429207878  ,  0.2035  ,  0.9253\n",
      "0.02737673127551817  ,  0.2067  ,  0.9759\n",
      "-0.0067755316607813225  ,  0.252  ,  0.9557\n",
      "703\n",
      "0.5360038186826878  ,  0.5357  ,  1.1582\n",
      "0.15355368446670659  ,  0.6098  ,  1.3061\n",
      "nan  ,  0.6046  ,  1.3289\n",
      "704\n",
      "0.7341915771586015  ,  0.7031  ,  0.8102\n",
      "0.17791366765093328  ,  1.1623  ,  1.4183\n",
      "nan  ,  1.191  ,  1.4689\n",
      "705\n",
      "0.7519983123327785  ,  0.4273  ,  0.7318\n",
      "-0.032832363097851466  ,  0.6697  ,  1.2422\n",
      "nan  ,  0.6675  ,  1.2446\n",
      "706\n",
      "0.7475166810262537  ,  0.7963  ,  1.1659\n",
      "0.19153041588038033  ,  1.2339  ,  1.9078\n",
      "nan  ,  1.2497  ,  1.9638\n",
      "707\n",
      "0.7962811982069997  ,  0.5365  ,  0.9773\n",
      "0.27999512390997017  ,  0.8185  ,  1.6615\n",
      "nan  ,  0.822  ,  1.673\n",
      "708\n",
      "0.7294341116147479  ,  0.7078  ,  0.9874\n",
      "0.06198975580948771  ,  0.6611  ,  1.298\n",
      "nan  ,  0.6219  ,  1.3491\n",
      "709\n",
      "0.645814042174325  ,  0.4426  ,  0.6607\n",
      "0.14911514822508598  ,  0.6219  ,  0.7415\n",
      "-0.1825297407747896  ,  0.5732  ,  0.8184\n",
      "710\n",
      "0.5565572776436383  ,  0.3701  ,  0.897\n",
      "0.0022230926861363373  ,  1.0975  ,  0.8661\n",
      "-0.15540748216256167  ,  0.5549  ,  1.0171\n",
      "711\n",
      "0.6107343864305828  ,  0.6991  ,  1.1448\n",
      "0.06379503046118687  ,  0.9298  ,  1.4377\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "712\n",
      "0.5167204197390376  ,  0.9929  ,  1.1326\n",
      "0.16892533685325778  ,  1.2572  ,  1.4118\n",
      "nan  ,  1.2859  ,  1.4483\n",
      "713\n",
      "0.6233923200138005  ,  0.7786  ,  0.9712\n",
      "0.17543112726600957  ,  1.0662  ,  1.0719\n",
      "0.009586052176901576  ,  1.1155  ,  1.0344\n",
      "714\n",
      "0.7629904413207067  ,  0.6526  ,  0.946\n",
      "0.16863905930737283  ,  1.0937  ,  1.6363\n",
      "nan  ,  1.1045  ,  1.679\n",
      "715\n",
      "0.6520290516432803  ,  0.697  ,  1.2051\n",
      "0.20583668051950768  ,  0.9202  ,  1.3993\n",
      "0.15438478216322288  ,  1.0434  ,  1.2771\n",
      "716\n",
      "0.7146980723786186  ,  0.5857  ,  1.0399\n",
      "0.18920306653596466  ,  0.8478  ,  1.4544\n",
      "-0.12805782315120404  ,  0.8956  ,  1.4409\n",
      "717\n",
      "0.4377565674753849  ,  0.5215  ,  0.9717\n",
      "0.022879455572258067  ,  0.578  ,  1.1014\n",
      "-0.012582765304703392  ,  0.6311  ,  0.9962\n",
      "718\n",
      "0.4560187761143788  ,  0.4112  ,  1.0553\n",
      "0.11042342567271934  ,  0.5075  ,  1.1395\n",
      "0.004587489964110946  ,  0.5806  ,  1.087\n",
      "719\n",
      "0.6824142548338705  ,  0.916  ,  0.9503\n",
      "-0.01568011347671466  ,  1.1324  ,  1.471\n",
      "nan  ,  1.1323  ,  1.4711\n",
      "720\n",
      "0.7042184352841103  ,  0.7661  ,  0.9238\n",
      "0.2907195914524558  ,  0.9542  ,  1.4517\n",
      "0.15638749849424005  ,  1.0073  ,  1.3915\n",
      "721\n",
      "0.5745107865498972  ,  0.8422  ,  1.0481\n",
      "-0.04260328568590792  ,  1.1579  ,  1.3938\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "722\n",
      "0.8285760682387691  ,  0.2864  ,  0.824\n",
      "0.2602610594793724  ,  0.5453  ,  1.3747\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "723\n",
      "0.7112554446176398  ,  0.5142  ,  0.8752\n",
      "0.0906895278115275  ,  0.7642  ,  1.3121\n",
      "0.03138361119316998  ,  0.7773  ,  1.306\n",
      "724\n",
      "0.5791350281335059  ,  0.6152  ,  0.9664\n",
      "0.2346872920817555  ,  0.7948  ,  1.1112\n",
      "0.18857866964631104  ,  0.8221  ,  1.1551\n",
      "725\n",
      "0.69929278208333  ,  0.4597  ,  0.7887\n",
      "0.15314866716350503  ,  0.8812  ,  0.9268\n",
      "0.15290165475145007  ,  0.6993  ,  1.0878\n",
      "726\n",
      "0.8612757366565054  ,  0.2702  ,  0.8522\n",
      "0.23029856153478043  ,  0.4702  ,  1.541\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "727\n",
      "0.6876781363507434  ,  0.4119  ,  0.8787\n",
      "0.21785837330949043  ,  0.5645  ,  1.1834\n",
      "nan  ,  0.5337  ,  1.277\n",
      "728\n",
      "0.6086627114409737  ,  0.5655  ,  1.0182\n",
      "0.1576691573789737  ,  0.9159  ,  1.0579\n",
      "-0.11885912199365022  ,  0.8187  ,  1.2492\n",
      "729\n",
      "0.6148210569551189  ,  0.4771  ,  0.7523\n",
      "0.26361349533254946  ,  0.6535  ,  0.8764\n",
      "nan  ,  0.6408  ,  1.0592\n",
      "730\n",
      "0.6926858308920535  ,  0.4092  ,  0.9611\n",
      "0.022817549610341183  ,  0.4898  ,  1.3642\n",
      "-0.001481822028299943  ,  0.513  ,  1.3416\n",
      "731\n",
      "0.5873722389264102  ,  0.6269  ,  1.094\n",
      "0.03362623564247966  ,  0.9577  ,  1.1557\n",
      "0.08086969386016304  ,  0.8775  ,  1.2533\n",
      "732\n",
      "0.6698404738052618  ,  0.6531  ,  0.8681\n",
      "0.03588022557178987  ,  0.7806  ,  1.3837\n",
      "-0.05410810821895881  ,  0.7779  ,  1.3989\n",
      "733\n",
      "0.4687942237302213  ,  0.3248  ,  0.976\n",
      "-0.0014026087517096482  ,  0.3519  ,  1.1178\n",
      "0.006264497143196705  ,  0.4449  ,  1.0459\n",
      "734\n",
      "0.636873255175314  ,  0.7798  ,  0.9103\n",
      "0.18041939822409492  ,  1.1666  ,  1.3916\n",
      "0.4194485772069687  ,  1.1712  ,  1.3768\n",
      "735\n",
      "0.5593646696112271  ,  0.1561  ,  0.5997\n",
      "0.019833712119831495  ,  0.1437  ,  0.6901\n",
      "0.0173676615849701  ,  0.1518  ,  0.6866\n",
      "736\n",
      "0.5713937789364911  ,  0.632  ,  0.9754\n",
      "0.049297419621086  ,  0.777  ,  1.1872\n",
      "nan  ,  0.7432  ,  1.2892\n",
      "737\n",
      "0.7208796689808163  ,  0.587  ,  1.222\n",
      "0.12980151828233735  ,  0.7696  ,  1.6631\n",
      "nan  ,  0.765  ,  1.6857\n",
      "738\n",
      "0.7331884194986921  ,  0.6444  ,  0.8031\n",
      "0.25111739968536806  ,  1.0438  ,  1.3664\n",
      "nan  ,  1.0551  ,  1.3859\n",
      "739\n",
      "0.5835119330709269  ,  0.6443  ,  1.1406\n",
      "0.00020275912459313036  ,  0.5774  ,  1.3509\n",
      "0.053740293984233266  ,  0.6367  ,  1.2714\n",
      "740\n",
      "0.6209801647917359  ,  0.6699  ,  1.1645\n",
      "0.29592368058022006  ,  0.892  ,  1.3408\n",
      "-0.11859218982274772  ,  0.8756  ,  1.5781\n",
      "741\n",
      "0.470507308589348  ,  0.6653  ,  1.3219\n",
      "0.04938764340500158  ,  0.7374  ,  1.4598\n",
      "0.004425055798045688  ,  0.7297  ,  1.4772\n",
      "742\n",
      "0.6075834467417895  ,  0.5223  ,  1.0258\n",
      "0.3155570609455442  ,  0.6363  ,  1.3097\n",
      "nan  ,  0.6517  ,  1.3606\n",
      "743\n",
      "0.7035795225644736  ,  0.5978  ,  0.8493\n",
      "0.1873015202854454  ,  0.9401  ,  1.3815\n",
      "0.1508654151902078  ,  0.9499  ,  1.3961\n",
      "744\n",
      "0.6416969629374487  ,  0.687  ,  0.7967\n",
      "0.08914624533011065  ,  0.978  ,  1.3038\n",
      "-0.1950480245525314  ,  0.9655  ,  1.1424\n",
      "745\n",
      "0.7055335291610035  ,  0.4769  ,  0.9073\n",
      "0.043819098873330097  ,  0.5152  ,  1.2088\n",
      "0.06214356942485529  ,  0.5657  ,  1.1579\n",
      "746\n",
      "0.5940587294077827  ,  0.7239  ,  1.0681\n",
      "0.12158785993172883  ,  0.9165  ,  1.363\n",
      "nan  ,  0.9238  ,  1.3964\n",
      "747\n",
      "0.45473966487022777  ,  0.4685  ,  0.9652\n",
      "-0.018561682597642376  ,  0.437  ,  1.0879\n",
      "-0.041284705171849685  ,  0.4668  ,  1.0526\n",
      "748\n",
      "0.4084029708240621  ,  0.5821  ,  0.9097\n",
      "0.29461716572284874  ,  0.6141  ,  1.0037\n",
      "0.0776522688187397  ,  0.6348  ,  1.0698\n",
      "749\n",
      "0.5746983991533512  ,  1.3167  ,  1.3373\n",
      "0.08615340472447043  ,  0.8965  ,  1.3193\n",
      "-0.16388369604603464  ,  0.9167  ,  1.2594\n",
      "750\n",
      "0.7840367249583421  ,  0.7262  ,  0.9423\n",
      "0.12504042601804927  ,  1.2422  ,  1.6638\n",
      "nan  ,  1.2599  ,  1.7359\n",
      "751\n",
      "0.6192858646919507  ,  0.5404  ,  1.1493\n",
      "-0.039553858417245166  ,  0.274  ,  0.926\n",
      "-0.049689410960949525  ,  0.4345  ,  0.8248\n",
      "752\n",
      "0.4722243059491407  ,  0.5122  ,  1.1013\n",
      "0.0053393819961019915  ,  0.3012  ,  0.9799\n",
      "nan  ,  0.2766  ,  0.9737\n",
      "753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47391836694665435  ,  0.9649  ,  0.9469\n",
      "0.0031185218087157428  ,  0.9585  ,  1.2553\n",
      "-0.15616604182402752  ,  0.9423  ,  1.193\n",
      "754\n",
      "0.6231860365835968  ,  0.5725  ,  0.8465\n",
      "-0.10406825551141244  ,  0.8848  ,  1.0731\n",
      "nan  ,  0.8034  ,  1.2534\n",
      "755\n",
      "0.5628821470676219  ,  0.5313  ,  1.018\n",
      "0.19788236123627087  ,  0.6904  ,  1.0808\n",
      "nan  ,  0.6401  ,  1.2414\n",
      "756\n",
      "0.6190753020739785  ,  0.6202  ,  1.2342\n",
      "0.06428659395845761  ,  0.6985  ,  1.3302\n",
      "nan  ,  0.6142  ,  1.4292\n",
      "757\n",
      "0.6087552520512984  ,  0.8549  ,  1.2105\n",
      "0.0934846814008809  ,  1.1351  ,  1.6413\n",
      "nan  ,  1.1373  ,  1.6481\n",
      "758\n",
      "0.44876711701551636  ,  0.706  ,  1.007\n",
      "-0.01876784918284237  ,  0.8269  ,  1.1753\n",
      "0.05039713157111156  ,  0.9122  ,  0.8801\n",
      "759\n",
      "0.6330108299519115  ,  1.1558  ,  1.3814\n",
      "0.08085748043353658  ,  1.1751  ,  1.3044\n",
      "0.2736548010684844  ,  1.1433  ,  1.6337\n",
      "760\n",
      "0.7486886347711258  ,  0.3664  ,  0.8239\n",
      "0.023847532620174174  ,  0.6029  ,  1.2457\n",
      "0.01111919171080957  ,  0.5374  ,  1.2975\n",
      "761\n",
      "0.5901353116073143  ,  0.5723  ,  0.9955\n",
      "-0.03492175373617847  ,  0.7425  ,  1.3428\n",
      "0.030283970471315633  ,  0.7751  ,  1.2508\n",
      "762\n",
      "0.6690459847318921  ,  0.633  ,  0.7611\n",
      "0.09368703726126337  ,  0.9627  ,  1.2042\n",
      "-0.18399242250033437  ,  0.9387  ,  1.1328\n",
      "763\n",
      "0.6844135903573403  ,  0.8288  ,  1.0197\n",
      "0.1741595717179231  ,  1.0442  ,  1.1701\n",
      "-0.10415248079998785  ,  1.0954  ,  1.4299\n",
      "764\n",
      "0.6222839763944505  ,  2.07  ,  1.7816\n",
      "0.12104961213678286  ,  0.9779  ,  1.4878\n",
      "0.01771135454373501  ,  0.9946  ,  1.4326\n",
      "765\n",
      "0.6168628290959346  ,  0.2988  ,  0.8503\n",
      "-0.019355897646619512  ,  0.7881  ,  0.903\n",
      "nan  ,  0.3926  ,  1.0833\n",
      "766\n",
      "0.5399569469054329  ,  0.5716  ,  1.1888\n",
      "0.20118729233234753  ,  0.4681  ,  1.0513\n",
      "-0.013263843995598466  ,  0.5748  ,  0.9972\n",
      "767\n",
      "0.5179101530955262  ,  0.1646  ,  0.6879\n",
      "0.056790131532303716  ,  0.273  ,  0.7633\n",
      "0.0038195688471585453  ,  0.3739  ,  0.6888\n",
      "768\n",
      "0.7310132345599936  ,  0.5862  ,  1.0936\n",
      "0.05320017906367584  ,  0.8298  ,  1.7601\n",
      "nan  ,  0.83  ,  1.7606\n",
      "769\n",
      "0.7377400269098872  ,  0.7218  ,  0.8989\n",
      "-0.04889734056152316  ,  1.2056  ,  1.5458\n",
      "-0.06877470234757169  ,  1.19  ,  1.4958\n",
      "770\n",
      "0.52535980727683  ,  0.5593  ,  1.0781\n",
      "-0.011222418870710476  ,  0.6651  ,  1.3169\n",
      "nan  ,  0.6643  ,  1.3178\n",
      "771\n",
      "0.6105923625421066  ,  0.6416  ,  0.9708\n",
      "0.024193736720059568  ,  0.9012  ,  1.2584\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "772\n",
      "0.6744083533766634  ,  0.7146  ,  1.3836\n",
      "0.01490349477782335  ,  0.9756  ,  2.0314\n",
      "-0.009665411784683345  ,  1.1213  ,  1.8234\n",
      "773\n",
      "0.5921793068284216  ,  0.784  ,  1.3631\n",
      "0.1567783207292584  ,  1.0445  ,  1.5724\n",
      "0.051199752865468275  ,  0.9916  ,  1.7661\n",
      "774\n",
      "0.448604298457183  ,  0.8308  ,  1.4367\n",
      "0.1708062721304549  ,  0.6601  ,  1.2387\n",
      "0.084803452521444  ,  0.721  ,  1.1924\n",
      "775\n",
      "0.6396160089872256  ,  1.6409  ,  1.6951\n",
      "0.12466327953508981  ,  1.1208  ,  1.3586\n",
      "-0.08491472633933969  ,  1.0395  ,  1.6587\n",
      "776\n",
      "0.7400975527610009  ,  0.9572  ,  1.1027\n",
      "0.15365805153191048  ,  1.3182  ,  1.7856\n",
      "0.1394201198078276  ,  1.3224  ,  1.7621\n",
      "777\n",
      "778\n",
      "0.5989623412420295  ,  0.7079  ,  0.9813\n",
      "0.15817670218663152  ,  0.698  ,  1.1882\n",
      "0.13733015956272576  ,  0.754  ,  1.0944\n",
      "779\n",
      "780\n",
      "0.7503566387645004  ,  1.2856  ,  1.6283\n",
      "0.2826503520446403  ,  0.7146  ,  1.1318\n",
      "nan  ,  0.7059  ,  1.3333\n",
      "781\n",
      "782\n",
      "0.6282682603578539  ,  0.6647  ,  1.1808\n",
      "0.3386904752979716  ,  0.8609  ,  1.5145\n",
      "0.00739173290856943  ,  0.8868  ,  1.567\n",
      "783\n",
      "784\n",
      "0.6838665704735224  ,  0.772  ,  0.9454\n",
      "0.32052997367339253  ,  0.9247  ,  1.3571\n",
      "0.3805848830382511  ,  1.0424  ,  1.1643\n",
      "785\n",
      "786\n",
      "0.7064212068844046  ,  0.5108  ,  0.8233\n",
      "0.2461167475792886  ,  0.7618  ,  1.1083\n",
      "-0.2632486245418125  ,  0.8203  ,  1.0984\n",
      "787\n",
      "788\n",
      "0.6192073874724664  ,  0.492  ,  1.0588\n",
      "-0.007756489176663894  ,  0.6186  ,  1.4336\n",
      "-0.018081982831221137  ,  0.6742  ,  1.3578\n",
      "789\n",
      "790\n",
      "0.17798622847681972  ,  1.6866  ,  2.663\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "791\n",
      "792\n",
      "0.6231628473910165  ,  0.4994  ,  0.979\n",
      "0.05893830076000103  ,  0.6397  ,  1.2839\n",
      "-0.05463493977304711  ,  0.6838  ,  1.2129\n",
      "793\n",
      "794\n",
      "0.6225629544752236  ,  0.7702  ,  1.2891\n",
      "0.21753431876667123  ,  0.5553  ,  1.0498\n",
      "-0.15813671063895496  ,  0.5763  ,  1.078\n",
      "795\n",
      "796\n",
      "0.670899689031493  ,  0.6106  ,  0.9347\n",
      "0.26432376179726985  ,  0.8141  ,  1.4468\n",
      "nan  ,  0.828  ,  1.4744\n",
      "797\n",
      "798\n",
      "0.7625496841604956  ,  0.6738  ,  0.8196\n",
      "0.21836217118400358  ,  0.9759  ,  1.3999\n",
      "-0.06797066691138562  ,  1.0053  ,  1.5044\n",
      "799\n",
      "800\n",
      "0.7503297509992665  ,  0.5482  ,  0.7864\n",
      "0.23438545763833613  ,  0.7414  ,  1.2028\n",
      "-0.08329916394740786  ,  0.8535  ,  1.0313\n",
      "801\n",
      "802\n",
      "0.7223235010650455  ,  0.259  ,  0.6369\n",
      "0.015035852301539029  ,  0.3348  ,  0.9702\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "803\n",
      "804\n",
      "0.7320727328393986  ,  0.5707  ,  0.839\n",
      "0.07547138434892811  ,  0.7801  ,  1.3041\n",
      "0.16084350050720028  ,  0.7971  ,  1.2685\n",
      "805\n",
      "806\n",
      "0.5704880503409189  ,  0.4569  ,  1.0475\n",
      "0.13978891963429527  ,  0.5539  ,  1.2229\n",
      "0.038242401118806  ,  0.6568  ,  1.1246\n",
      "807\n",
      "808\n",
      "0.61908157412275  ,  0.8074  ,  1.2022\n",
      "0.2421404377874757  ,  0.8351  ,  1.4555\n",
      "nan  ,  0.8413  ,  1.5434\n",
      "809\n",
      "810\n",
      "0.5173836636989004  ,  0.5352  ,  0.9208\n",
      "0.02807824407543972  ,  0.5774  ,  1.1194\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "811\n",
      "812\n",
      "0.5045978711697708  ,  1.01  ,  1.3694\n",
      "0.1262155248503006  ,  0.7535  ,  0.7255\n",
      "0.06788608466969386  ,  0.5936  ,  0.8841\n",
      "813\n",
      "814\n",
      "0.5993837961304899  ,  0.8226  ,  1.3287\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "815\n",
      "816\n",
      "0.6468034649901075  ,  0.5391  ,  0.9947\n",
      "0.07481614815561807  ,  0.7923  ,  1.2705\n",
      "-0.004894518601581739  ,  0.6187  ,  1.4321\n",
      "817\n",
      "818\n",
      "0.5095731643754641  ,  0.826  ,  1.0937\n",
      "-0.06848385835976369  ,  0.4272  ,  0.9748\n",
      "-0.07345967285388288  ,  0.5181  ,  0.8608\n",
      "819\n",
      "820\n",
      "0.5974219121085055  ,  0.3622  ,  0.8802\n",
      "0.09738634477359995  ,  0.4712  ,  1.091\n",
      "-0.07747894691591932  ,  0.5885  ,  0.9886\n",
      "821\n",
      "822\n",
      "0.6603541377457764  ,  0.5795  ,  1.0189\n",
      "0.13525395997297887  ,  0.7635  ,  1.4833\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "823\n",
      "824\n",
      "0.7036705219740018  ,  0.6466  ,  0.8627\n",
      "0.18720442126759781  ,  1.1649  ,  0.91\n",
      "0.03758963660493946  ,  0.8176  ,  1.3876\n",
      "825\n",
      "826\n",
      "0.7876731046029252  ,  0.4197  ,  0.8538\n",
      "0.11172143453446783  ,  0.606  ,  1.5044\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "827\n",
      "828\n",
      "0.8579386032609402  ,  0.4229  ,  0.7576\n",
      "0.4069349141462752  ,  0.7041  ,  1.5753\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "829\n",
      "830\n",
      "0.6806827563011267  ,  0.8214  ,  0.8606\n",
      "-0.013111304172044633  ,  1.0076  ,  1.3493\n",
      "nan  ,  1.0213  ,  1.4041\n",
      "831\n",
      "832\n",
      "0.456198129927191  ,  0.4573  ,  1.1621\n",
      "-0.017726217668149715  ,  0.2634  ,  0.9082\n",
      "0.17227598145473227  ,  0.3876  ,  0.8253\n",
      "833\n",
      "834\n",
      "0.7515455341456435  ,  0.3893  ,  0.6849\n",
      "0.004512068857471109  ,  0.6049  ,  1.1645\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "835\n",
      "836\n",
      "0.5726951356664645  ,  0.6716  ,  1.1331\n",
      "0.06620396093420766  ,  0.8924  ,  1.3061\n",
      "-0.037266397822577166  ,  0.8804  ,  1.3692\n",
      "837\n",
      "838\n",
      "0.609381157110813  ,  0.4357  ,  0.8922\n",
      "0.04571213571627594  ,  0.4875  ,  1.1749\n",
      "0.060153328148571106  ,  0.5027  ,  1.1599\n",
      "839\n",
      "840\n",
      "0.2501700309113638  ,  0.5321  ,  1.1424\n",
      "0.242545315105909  ,  0.5671  ,  1.0373\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "841\n",
      "842\n",
      "0.7568393199992667  ,  0.3447  ,  0.709\n",
      "0.12278702554809282  ,  0.4916  ,  1.1654\n",
      "0.034312641260936305  ,  0.5611  ,  1.0857\n",
      "843\n",
      "844\n",
      "0.6489672838630728  ,  1.5645  ,  1.8095\n",
      "0.024232119447237188  ,  0.8378  ,  1.5909\n",
      "nan  ,  0.8372  ,  1.5933\n",
      "845\n",
      "846\n",
      "0.5415873036596217  ,  0.558  ,  0.8826\n",
      "0.18301903890400942  ,  0.6111  ,  1.0949\n",
      "-0.018960124992811016  ,  0.6371  ,  1.0923\n",
      "847\n",
      "848\n",
      "0.7755592080434788  ,  0.3681  ,  0.8287\n",
      "0.02403789098655444  ,  0.3739  ,  1.3094\n",
      "nan  ,  0.3713  ,  1.3116\n",
      "849\n",
      "850\n",
      "0.5906384658142725  ,  0.7448  ,  0.9986\n",
      "0.08768898183423622  ,  0.5967  ,  1.0275\n",
      "-0.03225087176253773  ,  0.588  ,  1.0672\n",
      "851\n",
      "852\n",
      "0.5259670874737246  ,  0.4673  ,  1.0607\n",
      "0.030789200697158785  ,  0.6712  ,  1.1061\n",
      "-0.01743079517345946  ,  0.6616  ,  1.0625\n",
      "853\n",
      "854\n",
      "0.7540415063035134  ,  0.5047  ,  1.2795\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "855\n",
      "856\n",
      "0.5509892825550049  ,  0.6994  ,  1.0035\n",
      "0.09181877668795177  ,  0.8012  ,  1.1478\n",
      "0.16270122440084298  ,  0.8063  ,  1.162\n",
      "857\n",
      "858\n",
      "0.7361526228438879  ,  0.534  ,  0.8992\n",
      "0.029976971590641836  ,  0.7781  ,  1.4229\n",
      "0.14916844412887886  ,  0.7738  ,  1.4495\n",
      "859\n",
      "860\n",
      "0.8766523360856138  ,  0.3169  ,  0.7122\n",
      "0.3769909180509059  ,  0.5892  ,  1.5412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.052115143926439296  ,  0.6194  ,  1.5578\n",
      "861\n",
      "862\n",
      "0.631946716751532  ,  0.7336  ,  1.2087\n",
      "0.11704417525905357  ,  0.5302  ,  1.2032\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "863\n",
      "864\n",
      "0.7036507802579834  ,  0.5787  ,  0.9809\n",
      "0.16459410346054454  ,  0.8463  ,  1.5252\n",
      "-0.017774483917627995  ,  0.8937  ,  1.4442\n",
      "865\n",
      "866\n",
      "0.4183821931677114  ,  0.3958  ,  0.92\n",
      "0.17999350647481627  ,  0.4932  ,  0.9104\n",
      "0.24445770909875414  ,  0.4439  ,  1.0043\n",
      "867\n",
      "868\n",
      "0.7626850132269059  ,  0.7582  ,  0.9886\n",
      "0.6148563093023505  ,  0.8871  ,  1.4929\n",
      "0.44729170307868293  ,  1.1259  ,  1.343\n",
      "869\n",
      "870\n",
      "0.7431714171772533  ,  0.6215  ,  0.8345\n",
      "0.1414154607771559  ,  1.0311  ,  1.4876\n",
      "0.4050661381712871  ,  1.0587  ,  1.2688\n",
      "871\n",
      "872\n",
      "0.6470200215007205  ,  0.9424  ,  1.1752\n",
      "0.13781135460778476  ,  1.0458  ,  1.6604\n",
      "-0.32577680368704437  ,  1.061  ,  1.6437\n",
      "873\n",
      "874\n",
      "0.7557280629519268  ,  0.3991  ,  0.7487\n",
      "-0.005334281294946622  ,  0.5861  ,  1.2259\n",
      "nan  ,  0.586  ,  1.2262\n",
      "875\n",
      "876\n",
      "0.5010675691264139  ,  0.4396  ,  1.0663\n",
      "0.2621280693693047  ,  0.5305  ,  1.0835\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "877\n",
      "878\n",
      "0.6609039168660954  ,  0.887  ,  1.2126\n",
      "0.20963187725988647  ,  1.0065  ,  1.1599\n",
      "-0.06347916049477989  ,  0.9712  ,  1.3072\n",
      "879\n",
      "880\n",
      "0.6832231122642947  ,  1.8354  ,  1.9135\n",
      "0.10870158689160253  ,  0.8404  ,  1.4161\n",
      "0.04341632945885521  ,  0.8262  ,  1.4936\n",
      "881\n",
      "882\n",
      "0.746759716908149  ,  0.6997  ,  0.8481\n",
      "0.1922706274243623  ,  1.0218  ,  1.5076\n",
      "-0.024933318481328653  ,  1.0367  ,  1.3934\n",
      "883\n",
      "884\n",
      "0.7108239366502138  ,  0.6394  ,  0.7943\n",
      "-0.10386195838357012  ,  0.9266  ,  0.9276\n",
      "0.16627403440619928  ,  0.815  ,  1.0994\n",
      "885\n",
      "886\n",
      "0.7516792431990115  ,  0.6232  ,  0.7885\n",
      "0.17254968747903282  ,  0.9939  ,  1.2839\n",
      "0.07909693897916086  ,  1.0319  ,  1.4319\n",
      "887\n",
      "888\n",
      "0.49240597070984443  ,  0.7759  ,  1.1296\n",
      "0.16593360899037687  ,  0.7604  ,  1.2945\n",
      "-0.2456808753412575  ,  0.7762  ,  1.2822\n",
      "889\n",
      "890\n",
      "0.5062052902065011  ,  0.8334  ,  1.6697\n",
      "0.03620140586291627  ,  0.9246  ,  1.8332\n",
      "0.14914169394149307  ,  0.948  ,  1.8002\n",
      "891\n",
      "892\n",
      "0.6871646499399762  ,  0.4823  ,  0.9864\n",
      "0.22419367909146692  ,  0.7563  ,  1.2545\n",
      "-0.015021606133904235  ,  0.7887  ,  1.2877\n",
      "893\n",
      "894\n",
      "0.6207838110852737  ,  0.8814  ,  0.9859\n",
      "0.19907704866540352  ,  1.0698  ,  1.2593\n",
      "0.018773039730421315  ,  1.1072  ,  1.2829\n",
      "895\n",
      "896\n",
      "0.7611508983389856  ,  0.2661  ,  1.0151\n",
      "-0.05228040764975055  ,  0.2379  ,  0.9183\n",
      "-0.051204233628634965  ,  0.2358  ,  0.9108\n",
      "897\n",
      "898\n",
      "0.45171198787684935  ,  0.2714  ,  0.6478\n",
      "-0.07125536850022873  ,  0.2448  ,  0.6793\n",
      "-0.07687140928657432  ,  0.3513  ,  0.5887\n",
      "899\n",
      "900\n",
      "0.7374919935181151  ,  0.4667  ,  0.934\n",
      "-0.02589407485342384  ,  0.4788  ,  0.8639\n",
      "-0.0035161335731352314  ,  0.4399  ,  0.8884\n",
      "901\n",
      "902\n",
      "0.36110808173890324  ,  0.2865  ,  0.7022\n",
      "0.01756902697907123  ,  0.3131  ,  0.6493\n",
      "0.02288763278695239  ,  0.2467  ,  0.6773\n",
      "903\n",
      "904\n",
      "0.6470408993054917  ,  0.1974  ,  0.5402\n",
      "0.061957671564487345  ,  0.2221  ,  0.7156\n",
      "-0.011753536196338753  ,  0.2957  ,  0.6625\n",
      "905\n",
      "906\n",
      "0.2581532324469041  ,  0.2194  ,  0.6615\n",
      "0.04087815668983844  ,  0.3414  ,  0.6112\n",
      "0.03254610375320701  ,  0.25  ,  0.6683\n",
      "907\n",
      "908\n",
      "0.5276845923549108  ,  0.7724  ,  1.1585\n",
      "0.012677663491873072  ,  0.2333  ,  0.5184\n",
      "-0.0033654986997422097  ,  0.3191  ,  0.4671\n",
      "909\n",
      "910\n",
      "0.1654053492045031  ,  0.1108  ,  0.5395\n",
      "0.01764046694254095  ,  0.1114  ,  0.5476\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "911\n",
      "912\n",
      "0.6140330979085828  ,  0.3779  ,  0.6875\n",
      "-0.07024491865990602  ,  0.5285  ,  0.762\n",
      "0.01320682885593269  ,  0.7094  ,  0.6014\n",
      "913\n",
      "914\n",
      "0.3610931401259165  ,  0.2129  ,  0.7451\n",
      "nan  ,  0.2208  ,  0.779\n",
      "nan  ,  0.2208  ,  0.779\n",
      "915\n",
      "916\n",
      "0.25581323268162215  ,  0.4156  ,  0.8721\n",
      "0.06956183943126128  ,  0.4483  ,  0.5854\n",
      "-0.04554886905790055  ,  0.3058  ,  0.665\n",
      "917\n",
      "918\n",
      "0.2774075828447178  ,  0.218  ,  0.4795\n",
      "0.08249011574593548  ,  0.5339  ,  0.3003\n",
      "-0.0016415390284426818  ,  0.9102  ,  0.2781\n",
      "919\n",
      "920\n",
      "0.5905125459647517  ,  0.4137  ,  0.7256\n",
      "0.04227445446919123  ,  0.7643  ,  0.6558\n",
      "0.020173925561251558  ,  0.6549  ,  0.7482\n",
      "921\n",
      "922\n",
      "0.713079372842168  ,  0.2288  ,  0.59\n",
      "0.03424310884230523  ,  0.3287  ,  0.8746\n",
      "0.06073017744083604  ,  0.3425  ,  0.8624\n",
      "923\n",
      "924\n",
      "0.5802500050112376  ,  0.1475  ,  0.5477\n",
      "0.0424174264753482  ,  0.2005  ,  0.6671\n",
      "0.0029544108850290633  ,  0.2719  ,  0.6292\n",
      "925\n",
      "926\n",
      "0.34225253639891634  ,  0.5618  ,  1.3007\n",
      "0.07244816918176003  ,  0.6691  ,  0.5882\n",
      "-0.10163443765396322  ,  0.244  ,  0.7588\n",
      "927\n",
      "928\n",
      "0.417698678455957  ,  0.277  ,  0.7773\n",
      "0.1905114810342776  ,  0.3418  ,  0.7847\n",
      "0.03259945816756264  ,  0.3046  ,  0.8413\n",
      "929\n",
      "930\n",
      "0.5067844999309647  ,  0.4411  ,  0.9019\n",
      "-0.013504791331454775  ,  0.5373  ,  0.7549\n",
      "0.07144871312236117  ,  0.3591  ,  0.8453\n",
      "931\n",
      "932\n",
      "0.5492299923883242  ,  0.323  ,  0.7448\n",
      "-0.07061593260922827  ,  0.4089  ,  0.8493\n",
      "-0.04456336115704489  ,  0.395  ,  0.8514\n",
      "933\n",
      "934\n",
      "0.5612572100279916  ,  0.3673  ,  0.8731\n",
      "-0.015554522034719149  ,  0.2727  ,  0.8215\n",
      "-0.023571159875189658  ,  0.4313  ,  0.7\n",
      "935\n",
      "936\n",
      "0.3553686494007272  ,  0.3179  ,  0.7197\n",
      "-0.006332910052440793  ,  0.3389  ,  0.7775\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "937\n",
      "938\n",
      "0.7044762573251996  ,  0.3482  ,  0.8164\n",
      "0.04754752564420578  ,  0.4399  ,  1.0857\n",
      "-0.17937369657742885  ,  0.5047  ,  1.0146\n",
      "939\n",
      "940\n",
      "0.719785044206235  ,  0.277  ,  0.5992\n",
      "0.04465358052952004  ,  0.7631  ,  0.6629\n",
      "-0.030597122935287362  ,  0.497  ,  0.7862\n",
      "941\n",
      "942\n",
      "0.6402256842362747  ,  0.4531  ,  0.999\n",
      "0.030301775301256724  ,  0.328  ,  1.009\n",
      "nan  ,  0.3254  ,  1.012\n",
      "943\n",
      "944\n",
      "0.4160595682151183  ,  0.6275  ,  0.8324\n",
      "0.2803244654178816  ,  0.3231  ,  0.7832\n",
      "-0.16645795186197773  ,  0.3693  ,  0.7474\n",
      "945\n",
      "946\n",
      "0.5718591386063622  ,  0.3  ,  0.7511\n",
      "0.12607422069881594  ,  0.3656  ,  0.9305\n",
      "0.022528602901332156  ,  0.4796  ,  0.8265\n",
      "947\n",
      "948\n",
      "0.4502296165391135  ,  0.6869  ,  0.9862\n",
      "0.059509842852890835  ,  0.4397  ,  0.8126\n",
      "0.11963073753070771  ,  0.557  ,  0.6822\n",
      "949\n",
      "950\n",
      "0.2644644951486512  ,  0.3128  ,  0.5303\n",
      "0.0005740858929917476  ,  0.7448  ,  0.2709\n",
      "0.06901316360363889  ,  0.5547  ,  0.2629\n",
      "951\n",
      "952\n",
      "0.6966877771561195  ,  0.5244  ,  0.9075\n",
      "0.06515265264637221  ,  0.6573  ,  0.8739\n",
      "-0.05832202163137341  ,  0.5492  ,  0.9666\n",
      "953\n",
      "954\n",
      "0.6105412651873611  ,  0.477  ,  0.8341\n",
      "0.024972152776033804  ,  0.6914  ,  0.9851\n",
      "0.03795017136056583  ,  0.6823  ,  0.9925\n",
      "955\n",
      "956\n",
      "0.2906395274235163  ,  1.3033  ,  1.3584\n",
      "0.14346637609281568  ,  0.2243  ,  0.5939\n",
      "0.10769397906500087  ,  0.3012  ,  0.5256\n",
      "957\n",
      "958\n",
      "0.6031652730276054  ,  0.2758  ,  0.6293\n",
      "0.08930251955042993  ,  0.288  ,  0.7291\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "959\n",
      "960\n",
      "0.4028110291873631  ,  0.2234  ,  0.7841\n",
      "0.07119855201326988  ,  0.2719  ,  0.8415\n",
      "0.0501726821472147  ,  0.2855  ,  0.8352\n",
      "961\n",
      "962\n",
      "0.4781187065418464  ,  0.2204  ,  0.8376\n",
      "-0.025766572796912187  ,  0.2345  ,  0.9703\n",
      "nan  ,  0.224  ,  0.9738\n",
      "963\n",
      "964\n",
      "0.6543880373480168  ,  0.5365  ,  0.884\n",
      "-0.07636480518261918  ,  0.5993  ,  0.7857\n",
      "-0.020598767391789976  ,  0.5127  ,  0.8527\n",
      "965\n",
      "966\n",
      "0.40997494620924735  ,  0.1101  ,  0.6092\n",
      "-0.0021446227423379902  ,  0.121  ,  0.6713\n",
      "nan  ,  0.121  ,  0.6713\n",
      "967\n",
      "968\n",
      "0.6137529527947302  ,  0.9143  ,  1.58\n",
      "0.18382845083730748  ,  0.4832  ,  0.6483\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "969\n",
      "970\n",
      "0.5806466042861487  ,  0.39  ,  1.0044\n",
      "0.08114007170190994  ,  0.33  ,  0.6438\n",
      "-0.0037037547923874925  ,  0.5036  ,  0.5333\n",
      "971\n",
      "972\n",
      "0.8680714720184257  ,  0.1557  ,  0.5871\n",
      "0.01826477132448553  ,  0.304  ,  1.0873\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "973\n",
      "974\n",
      "0.6316148587420901  ,  0.2523  ,  0.6633\n",
      "0.26153781537620596  ,  0.3964  ,  0.7442\n",
      "-0.12053104205050917  ,  0.36  ,  0.8044\n",
      "975\n",
      "976\n",
      "0.5114478441172122  ,  1.3784  ,  1.633\n",
      "0.022863655890893113  ,  0.4097  ,  0.6409\n",
      "nan  ,  0.2412  ,  0.7456\n",
      "977\n",
      "978\n",
      "0.5389146494129726  ,  0.1842  ,  0.5163\n",
      "-0.03632251224272468  ,  0.2144  ,  0.6224\n",
      "nan  ,  0.2112  ,  0.6239\n",
      "979\n",
      "980\n",
      "0.3437267010631342  ,  0.1913  ,  0.5963\n",
      "-0.04152694783783998  ,  0.1369  ,  0.3733\n",
      "-0.015767656736742422  ,  0.1659  ,  0.3513\n",
      "981\n",
      "982\n",
      "0.34214769049430993  ,  0.2678  ,  0.7341\n",
      "-0.01103040994357548  ,  0.3174  ,  0.7536\n",
      "-0.03451952234057348  ,  0.5587  ,  0.5611\n",
      "983\n",
      "984\n",
      "0.4619546601137039  ,  0.3701  ,  0.9358\n",
      "-0.04015372178703009  ,  0.2891  ,  0.8968\n",
      "nan  ,  0.288  ,  0.8972\n",
      "985\n",
      "986\n",
      "0.5405763976151019  ,  0.2327  ,  0.6748\n",
      "0.13483695804565837  ,  0.2076  ,  0.7248\n",
      "-0.015278079943579867  ,  0.2113  ,  0.7276\n",
      "987\n",
      "988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6573536505616588  ,  0.3929  ,  0.7926\n",
      "0.1283041281367335  ,  0.4038  ,  0.9515\n",
      "-0.11558112324834345  ,  0.3527  ,  1.0067\n",
      "989\n",
      "990\n",
      "0.5624900911827371  ,  0.2091  ,  0.6204\n",
      "0.07038147246178963  ,  0.3002  ,  0.7017\n",
      "-0.03972890940597493  ,  0.2578  ,  0.7388\n",
      "991\n",
      "992\n",
      "0.5614507971974312  ,  0.43  ,  0.8373\n",
      "0.020582666815015173  ,  0.5439  ,  0.7054\n",
      "-0.08970319699272163  ,  0.446  ,  0.7819\n",
      "993\n",
      "994\n",
      "0.20823099425436686  ,  0.2203  ,  0.7909\n",
      "nan  ,  0.2211  ,  0.7955\n",
      "0.053459617786352547  ,  0.223  ,  0.7942\n",
      "995\n",
      "996\n",
      "0.47707279620188264  ,  0.2972  ,  0.7345\n",
      "-0.09531343297753533  ,  0.5756  ,  0.6729\n",
      "0.02267144271115496  ,  0.5231  ,  0.69\n",
      "997\n",
      "998\n",
      "0.47233759057572516  ,  0.1866  ,  0.637\n",
      "0.04669678084666302  ,  0.1737  ,  0.7107\n",
      "nan  ,  0.1738  ,  0.7109\n",
      "999\n",
      "1000\n",
      "0.388950754359652  ,  0.4703  ,  0.9453\n",
      "0.15270322503933334  ,  0.312  ,  0.5954\n",
      "-0.05587522207270419  ,  0.1994  ,  0.6706\n",
      "1001\n",
      "1002\n",
      "0.5071479771954399  ,  0.3189  ,  0.4992\n",
      "0.24325782633483628  ,  0.5954  ,  0.2982\n",
      "0.22107645526065262  ,  0.704  ,  0.2697\n",
      "1003\n",
      "1004\n",
      "0.6514007843931849  ,  0.2176  ,  0.6122\n",
      "-0.029109425171002797  ,  0.3412  ,  0.7744\n",
      "-0.009115048421479097  ,  0.3569  ,  0.7538\n",
      "1005\n",
      "1006\n",
      "0.4597528345434386  ,  0.2984  ,  0.7765\n",
      "-0.012287588459579658  ,  0.3747  ,  0.8233\n",
      "nan  ,  0.322  ,  0.8655\n",
      "1007\n",
      "1008\n",
      "0.2733284725649833  ,  0.2242  ,  0.72\n",
      "0.16190511516409478  ,  0.2384  ,  0.7283\n",
      "-0.0634412920654885  ,  0.3146  ,  0.6837\n",
      "1009\n",
      "1010\n",
      "0.6271192454032557  ,  0.382  ,  0.6426\n",
      "0.10743990536226128  ,  0.5198  ,  0.7233\n",
      "0.0829992369531226  ,  0.4319  ,  0.8182\n",
      "1011\n",
      "1012\n",
      "0.3852961873546715  ,  0.3173  ,  0.8096\n",
      "-0.00620541580343186  ,  0.3192  ,  0.8976\n",
      "-0.0356417897758178  ,  0.3352  ,  0.8823\n",
      "1013\n",
      "1014\n",
      "0.7225487131772618  ,  1.2286  ,  1.9229\n",
      "-0.07931574396871954  ,  0.575  ,  1.1513\n",
      "0.046149970607799705  ,  0.4224  ,  1.2122\n",
      "1015\n",
      "1016\n",
      "0.3916174631784028  ,  0.3319  ,  0.8957\n",
      "-0.11944873654815397  ,  0.3091  ,  0.8872\n",
      "0.06976093523330755  ,  0.4021  ,  0.8098\n",
      "1017\n",
      "1018\n",
      "0.57390613002652  ,  0.3539  ,  0.6632\n",
      "0.15588493716153295  ,  0.6169  ,  0.6247\n",
      "-0.047052266484575556  ,  0.6253  ,  0.6306\n",
      "1019\n",
      "1020\n",
      "0.35620058595382387  ,  0.264  ,  0.7925\n",
      "-0.019249755706199363  ,  0.279  ,  0.8509\n",
      "0.037681088924068074  ,  0.2929  ,  0.8392\n",
      "1021\n",
      "1022\n",
      "0.4946417697715665  ,  0.6567  ,  0.7516\n",
      "0.012484542001559143  ,  0.5737  ,  0.5198\n",
      "-0.11356660825454518  ,  0.5712  ,  0.4911\n",
      "1023\n",
      "1024\n",
      "0.3941768918757983  ,  0.2378  ,  0.8231\n",
      "-0.012031705977488323  ,  0.2321  ,  0.8941\n",
      "-0.0601753903557324  ,  0.2878  ,  0.8627\n",
      "1025\n",
      "1026\n",
      "0.3279333185810622  ,  0.223  ,  0.7393\n",
      "0.08707894678529668  ,  0.3592  ,  0.6518\n",
      "-0.008623711485405633  ,  0.1872  ,  0.6937\n",
      "1027\n",
      "1028\n",
      "0.6633679338988947  ,  0.556  ,  0.9983\n",
      "-0.010387877306128168  ,  0.3052  ,  1.0878\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "1029\n",
      "1030\n",
      "0.39209801615041917  ,  0.3236  ,  0.7697\n",
      "0.07314114536177907  ,  0.4167  ,  0.7434\n",
      "0.09013783806320141  ,  0.5824  ,  0.6083\n",
      "1031\n",
      "1032\n",
      "0.6026702017871706  ,  0.3161  ,  0.823\n",
      "0.05976484679335839  ,  0.3339  ,  1.0042\n",
      "0.05922582837706148  ,  0.3552  ,  0.9875\n",
      "1033\n",
      "1034\n",
      "0.4213936009707316  ,  0.1843  ,  0.5372\n",
      "0.07671502040356312  ,  0.1985  ,  0.5803\n",
      "-0.12162739400159063  ,  0.2802  ,  0.5168\n",
      "1035\n",
      "1036\n",
      "0.48640295957129037  ,  0.2922  ,  0.746\n",
      "-0.1413789365396745  ,  0.3867  ,  0.8633\n",
      "0.11658804225816313  ,  0.472  ,  0.7615\n",
      "1037\n",
      "1038\n",
      "0.7783434667899517  ,  0.255  ,  0.7287\n",
      "0.10156892042581679  ,  0.3894  ,  1.0269\n",
      "-0.03579599973965045  ,  0.3132  ,  1.0854\n",
      "1039\n",
      "1040\n",
      "0.39949819068397524  ,  0.3992  ,  0.8151\n",
      "0.060510990106456594  ,  0.5173  ,  0.6174\n",
      "0.09388294832808097  ,  0.435  ,  0.6912\n",
      "1041\n",
      "1042\n",
      "0.38082339566896295  ,  0.5259  ,  0.8004\n",
      "-0.029341275545405342  ,  0.5598  ,  0.449\n",
      "0.00796383325659068  ,  0.4771  ,  0.4635\n",
      "1043\n",
      "1044\n",
      "0.07661995723964338  ,  0.2624  ,  0.7526\n",
      "0.028395456333277776  ,  0.4634  ,  0.6178\n",
      "-0.03612462887081706  ,  0.3555  ,  0.6664\n",
      "1045\n",
      "1046\n",
      "0.501486267416551  ,  0.6124  ,  1.0613\n",
      "0.15143119700181162  ,  0.8673  ,  0.5761\n",
      "-0.031322535036112036  ,  0.338  ,  0.78\n",
      "1047\n",
      "1048\n",
      "0.5975909895261116  ,  0.3653  ,  0.6143\n",
      "0.11651675505353666  ,  0.5204  ,  0.631\n",
      "-0.1493839070509711  ,  0.6951  ,  0.525\n",
      "1049\n",
      "1050\n",
      "0.5132054927156928  ,  0.3475  ,  0.7695\n",
      "0.13892838565151291  ,  0.897  ,  0.6045\n",
      "0.028730241351920892  ,  0.6871  ,  0.7006\n",
      "1051\n",
      "1052\n",
      "0.5774098118922988  ,  0.417  ,  0.6471\n",
      "0.0768588730488355  ,  0.4711  ,  0.5977\n",
      "0.028161879188228326  ,  0.4989  ,  0.5644\n",
      "1053\n",
      "1054\n",
      "0.30554640730748145  ,  0.3168  ,  0.6892\n",
      "-0.10913908356181902  ,  0.6617  ,  0.4625\n",
      "-0.17270849740166472  ,  0.6909  ,  0.4407\n",
      "1055\n",
      "1056\n",
      "0.7084531457325381  ,  0.1757  ,  0.561\n",
      "0.017763038767143566  ,  0.1893  ,  0.718\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "1057\n",
      "1058\n",
      "0.5143768988865995  ,  0.2764  ,  0.699\n",
      "0.1119295090661714  ,  0.3027  ,  0.809\n",
      "0.07503654995665705  ,  0.3283  ,  0.7821\n",
      "1059\n",
      "1060\n",
      "0.5891191504242409  ,  0.337  ,  0.6654\n",
      "0.0596982052881853  ,  0.6036  ,  0.6022\n",
      "-0.024597070457298257  ,  0.6928  ,  0.5378\n",
      "1061\n",
      "1062\n",
      "0.5594375094511493  ,  0.4176  ,  0.9366\n",
      "0.17591511433757456  ,  0.5847  ,  0.8618\n",
      "0.08346772260773691  ,  0.4649  ,  0.9933\n",
      "1063\n",
      "1064\n",
      "0.5820475724838139  ,  0.6939  ,  1.1836\n",
      "-0.118628280438865  ,  0.5042  ,  0.6673\n",
      "0.019663682132443454  ,  0.5576  ,  0.5848\n",
      "1065\n",
      "1066\n",
      "0.48172685471855564  ,  0.1383  ,  0.5891\n",
      "-0.04080735514094328  ,  0.1649  ,  0.6327\n",
      "-0.060988836304364566  ,  0.2441  ,  0.5902\n",
      "1067\n",
      "1068\n",
      "0.451103009992334  ,  0.346  ,  0.6249\n",
      "0.08562016237695753  ,  0.5239  ,  0.5543\n",
      "-0.11392572234985507  ,  0.6728  ,  0.4391\n",
      "1069\n",
      "1070\n",
      "0.3321489253379048  ,  0.3673  ,  0.9654\n",
      "0.042167509651381184  ,  0.3555  ,  0.7053\n",
      "0.07560169909112376  ,  0.3135  ,  0.7191\n",
      "1071\n",
      "1072\n",
      "0.2534178573419625  ,  0.2189  ,  0.8128\n",
      "-0.04163406526439758  ,  0.1854  ,  0.7968\n",
      "nan  ,  0.1737  ,  0.7998\n",
      "1073\n",
      "1074\n",
      "0.4984892612257753  ,  0.2153  ,  0.5575\n",
      "-0.04928461934348525  ,  0.263  ,  0.6473\n",
      "-0.010100258076882395  ,  0.2575  ,  0.6413\n",
      "1075\n",
      "1076\n",
      "0.3203990386123371  ,  0.4038  ,  0.9785\n",
      "-0.006615000920125421  ,  0.1995  ,  0.6721\n",
      "-0.07408535149243395  ,  0.2077  ,  0.6663\n",
      "1077\n",
      "1078\n",
      "0.5221168615652041  ,  0.3519  ,  0.678\n",
      "-0.028084774848383082  ,  0.3882  ,  0.7216\n",
      "0.04174162355287673  ,  0.4815  ,  0.632\n",
      "1079\n",
      "1080\n",
      "0.48729302044779743  ,  0.1271  ,  0.5165\n",
      "0.1368221922728421  ,  0.1699  ,  0.5462\n",
      "-0.03361804352396592  ,  0.1876  ,  0.5448\n",
      "1081\n",
      "1082\n",
      "0.5542132645389106  ,  0.2395  ,  0.691\n",
      "-0.12331601097672992  ,  0.3166  ,  0.7603\n",
      "-0.06271665034259813  ,  0.3393  ,  0.7277\n",
      "1083\n",
      "1084\n",
      "0.15718325185438167  ,  0.2108  ,  0.703\n",
      "-0.050699884483042454  ,  0.2549  ,  0.6942\n",
      "-0.0342462187549544  ,  0.3167  ,  0.6418\n",
      "1085\n",
      "1086\n",
      "0.7230358684574244  ,  0.1709  ,  0.5965\n",
      "0.05062356900822373  ,  0.2987  ,  0.7396\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "1087\n",
      "1088\n",
      "0.5550612606789644  ,  0.1641  ,  0.5609\n",
      "0.24539797164095623  ,  0.1942  ,  0.6586\n",
      "-0.031224293399331082  ,  0.2694  ,  0.631\n",
      "1089\n",
      "1090\n",
      "0.6202832751164853  ,  0.3845  ,  0.8231\n",
      "-0.04538446245839109  ,  0.3686  ,  0.8707\n",
      "0.0395302073724685  ,  0.3674  ,  0.8635\n",
      "1091\n",
      "1092\n",
      "0.6151684320100437  ,  0.2234  ,  0.7557\n",
      "0.10783798604387414  ,  0.5176  ,  0.859\n",
      "0.004510443035419237  ,  0.2637  ,  0.9705\n",
      "1093\n",
      "1094\n",
      "0.578205698745419  ,  0.3648  ,  0.7191\n",
      "0.16917065556895006  ,  0.562  ,  0.7602\n",
      "0.0023404521086800127  ,  0.5969  ,  0.7484\n",
      "1095\n",
      "1096\n",
      "0.5341973351266739  ,  0.4384  ,  0.7595\n",
      "-0.07978429274249868  ,  0.5379  ,  0.7405\n",
      "0.06661596929103158  ,  0.5399  ,  0.7132\n",
      "1097\n",
      "1098\n",
      "0.6937366205897592  ,  0.7659  ,  1.4408\n",
      "-0.08488170661246078  ,  0.3942  ,  0.859\n",
      "0.05468272507506015  ,  0.4533  ,  0.8025\n",
      "1099\n",
      "1100\n",
      "0.39939178671494985  ,  0.4405  ,  0.8542\n",
      "-0.04238877995741825  ,  0.4497  ,  0.9836\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "1101\n",
      "1102\n",
      "0.5338412902754106  ,  0.9903  ,  1.5195\n",
      "0.20385216578031654  ,  0.4541  ,  0.7064\n",
      "0.011294006688098377  ,  0.3892  ,  0.7882\n",
      "1103\n",
      "1104\n",
      "0.31425349093845245  ,  0.4047  ,  1.0181\n",
      "-0.0012408298328018803  ,  0.4248  ,  1.0879\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "1105\n",
      "1106\n",
      "0.3546079155924954  ,  0.4407  ,  0.7669\n",
      "0.05125897425460668  ,  0.5504  ,  0.4441\n",
      "-0.08354884253095043  ,  0.5502  ,  0.4356\n",
      "1107\n",
      "1108\n",
      "0.5563998258338745  ,  0.2538  ,  0.5216\n",
      "-0.08145312257277941  ,  1.1362  ,  0.4\n",
      "0.15409534600117009  ,  0.5473  ,  0.4455\n",
      "1109\n",
      "1110\n",
      "0.49381722193570343  ,  0.3975  ,  0.8558\n",
      "-0.09934827674998249  ,  0.6043  ,  0.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006041678359557561  ,  0.6625  ,  0.7325\n",
      "1111\n",
      "1112\n",
      "0.36079399793167716  ,  0.3065  ,  0.7882\n",
      "0.1695337090302594  ,  0.6913  ,  0.5401\n",
      "-0.034594276459554346  ,  0.4267  ,  0.7364\n",
      "1113\n",
      "1114\n",
      "0.4046342339815998  ,  0.3876  ,  0.6864\n",
      "0.09065711865734546  ,  0.6129  ,  0.445\n",
      "-0.005162832959099136  ,  0.5805  ,  0.4392\n",
      "1115\n",
      "1116\n",
      "0.5220686318139335  ,  0.3479  ,  0.8705\n",
      "-0.03345953634212148  ,  0.4288  ,  0.966\n",
      "0.02859603316310003  ,  0.3859  ,  1.0015\n",
      "1117\n",
      "1118\n",
      "0.18994434068168964  ,  0.2491  ,  0.7217\n",
      "0.07130165468953059  ,  0.343  ,  0.6535\n",
      "0.019768703263834897  ,  0.2597  ,  0.7005\n",
      "1119\n",
      "1120\n",
      "0.3839486425322583  ,  0.4779  ,  1.0644\n",
      "0.1325512309752532  ,  0.4513  ,  0.8185\n",
      "0.03007222630566928  ,  0.4435  ,  0.8338\n",
      "1121\n",
      "1122\n",
      "0.20914530336963427  ,  0.412  ,  0.734\n",
      "0.08687072668274524  ,  0.6903  ,  0.4636\n",
      "0.0977888717213446  ,  0.6351  ,  0.4912\n",
      "1123\n",
      "1124\n",
      "0.23924114551970802  ,  0.2867  ,  0.7705\n",
      "-0.008169948496205294  ,  0.6966  ,  0.5674\n",
      "0.030400540989554917  ,  0.6262  ,  0.572\n",
      "1125\n",
      "1126\n",
      "0.4789137265012959  ,  0.305  ,  0.6177\n",
      "-0.06738704797467154  ,  0.8375  ,  0.3979\n",
      "0.06966430590113142  ,  0.6391  ,  0.4518\n",
      "1127\n",
      "1128\n",
      "0.4910764969854083  ,  0.2504  ,  0.7741\n",
      "-0.0352219514279904  ,  0.2685  ,  0.8575\n",
      "0.003069371969805971  ,  0.3241  ,  0.8139\n",
      "1129\n",
      "1130\n",
      "0.5603437138470875  ,  0.3366  ,  0.6915\n",
      "-0.04251622448078361  ,  0.6572  ,  0.6569\n",
      "0.07503729767750265  ,  0.6307  ,  0.6615\n",
      "1131\n",
      "1132\n",
      "0.7364096976527059  ,  0.1805  ,  0.5227\n",
      "0.05417891547469231  ,  0.2674  ,  0.7457\n",
      "-0.03533189291831073  ,  0.3753  ,  0.6744\n",
      "1133\n",
      "1134\n",
      "0.7801518388097591  ,  0.1959  ,  0.5155\n",
      "0.01127167114844307  ,  0.2577  ,  0.8019\n",
      "-0.061393848565444546  ,  0.2984  ,  0.7722\n",
      "1135\n",
      "1136\n",
      "0.7319866150904942  ,  0.144  ,  0.4951\n",
      "0.003404461593450654  ,  0.2013  ,  0.7198\n",
      "0.043658101202298974  ,  0.251  ,  0.6901\n",
      "1137\n",
      "1138\n",
      "0.6928832694648893  ,  0.4698  ,  0.973\n",
      "-0.09616184166136882  ,  0.2698  ,  0.7939\n",
      "-0.0570123418233076  ,  0.2629  ,  0.7929\n",
      "1139\n",
      "1140\n",
      "0.602335265992446  ,  0.2467  ,  0.6974\n",
      "0.14724132469808282  ,  0.3727  ,  0.7714\n",
      "-0.031431573872186785  ,  0.3635  ,  0.791\n",
      "1141\n",
      "1142\n",
      "0.6388142008989336  ,  0.2798  ,  0.7191\n",
      "-0.13815572266974008  ,  0.3968  ,  0.9326\n",
      "-0.048370484921398796  ,  0.5561  ,  0.8131\n",
      "1143\n",
      "1144\n",
      "0.5947316696482879  ,  0.1894  ,  0.6199\n",
      "0.12401419160764962  ,  0.4129  ,  0.6174\n",
      "0.06827996273856678  ,  0.3344  ,  0.6662\n",
      "1145\n",
      "1146\n",
      "0.27575875419606455  ,  0.3111  ,  0.7659\n",
      "0.07890275214910364  ,  0.4709  ,  0.6663\n",
      "-0.05432256529486286  ,  0.5954  ,  0.5807\n",
      "1147\n",
      "1148\n",
      "0.7637057758091778  ,  0.2984  ,  0.5758\n",
      "-0.0006454842427679082  ,  0.8208  ,  0.6454\n",
      "-0.024352232990974935  ,  0.5384  ,  0.796\n",
      "1149\n",
      "1150\n",
      "0.4100484806625541  ,  1.0639  ,  1.9743\n",
      "0.02464136748453782  ,  0.2107  ,  0.7143\n",
      "-0.03186099454819226  ,  0.211  ,  0.7144\n",
      "1151\n",
      "64\n",
      "0.6668418999241862  ,  0.5166  ,  1.5081\n",
      "0.71469600580988  ,  0.4772  ,  1.3317\n",
      "0.3343104973033049  ,  0.6764  ,  1.5287\n",
      "65\n",
      "0.9267509812097696  ,  0.2861  ,  0.8671\n",
      "0.2828675945516562  ,  1.0168  ,  2.111\n",
      "0.09034955699611864  ,  0.6064  ,  2.4022\n",
      "66\n",
      "0.8116807670047161  ,  1.049  ,  2.0974\n",
      "0.7501283420452036  ,  1.2071  ,  2.4277\n",
      "0.7267435724950115  ,  1.3121  ,  2.6503\n",
      "67\n",
      "0.8300249439026157  ,  1.8156  ,  2.2579\n",
      "0.48881054301373084  ,  2.3915  ,  2.9572\n",
      "0.48707276947381095  ,  2.9003  ,  3.6028\n",
      "68\n",
      "0.6108267543194267  ,  0.2784  ,  1.0505\n",
      "0.48036829513886725  ,  0.3252  ,  1.2006\n",
      "0.07193899373931192  ,  0.3359  ,  1.2555\n",
      "69\n",
      "0.6713369685925509  ,  0.5309  ,  1.0859\n",
      "0.04842652610306125  ,  0.7973  ,  1.5119\n",
      "-0.005086342437210033  ,  0.7751  ,  1.5005\n",
      "70\n",
      "0.8988494126324034  ,  0.2302  ,  0.6832\n",
      "0.5802104104708063  ,  1.0609  ,  1.2378\n",
      "nan  ,  0.3984  ,  1.546\n",
      "71\n",
      "0.6138091791089096  ,  0.6165  ,  1.5082\n",
      "0.3710355046349451  ,  0.7192  ,  1.6028\n",
      "-0.11073340916600591  ,  0.785  ,  1.7064\n",
      "72\n",
      "0.6300142688817982  ,  1.4047  ,  2.2167\n",
      "0.2004521761696112  ,  0.6553  ,  1.7084\n",
      "0.10934333270528616  ,  0.7066  ,  1.6937\n",
      "73\n",
      "0.6513414258131015  ,  0.5402  ,  1.2946\n",
      "0.24306421296878733  ,  0.8408  ,  1.5859\n",
      "0.043706873589238644  ,  0.7373  ,  1.6562\n",
      "74\n",
      "0.7481784746564264  ,  0.6519  ,  1.6091\n",
      "0.6425057461269696  ,  0.7046  ,  1.6967\n",
      "0.08569363048334008  ,  0.8249  ,  1.9008\n",
      "75\n",
      "0.9680584659501028  ,  0.296  ,  0.7302\n",
      "0.023113370467000818  ,  1.3918  ,  3.2273\n",
      "nan  ,  0.8849  ,  3.0265\n",
      "76\n",
      "0.8857019262386501  ,  0.473  ,  1.2668\n",
      "0.4151819378372825  ,  0.8131  ,  2.5137\n",
      "0.05962066200901216  ,  0.8349  ,  2.7412\n",
      "77\n",
      "0.31706798347401505  ,  1.1713  ,  2.1424\n",
      "0.1019332170949949  ,  2.5117  ,  2.0877\n",
      "-0.025731840855700093  ,  1.2301  ,  2.1392\n",
      "78\n",
      "0.7066105298031233  ,  0.841  ,  1.4476\n",
      "0.17645830809232985  ,  1.1066  ,  1.994\n",
      "-0.13090405157293675  ,  1.1131  ,  2.0119\n",
      "79\n",
      "0.631765594638378  ,  0.7416  ,  1.6241\n",
      "0.44584099596742177  ,  0.9924  ,  1.4444\n",
      "0.047382803549270755  ,  0.83  ,  1.8664\n",
      "80\n",
      "0.7626392702946139  ,  0.3462  ,  1.0584\n",
      "0.2102862614331879  ,  0.4753  ,  1.4448\n",
      "0.10903527646786944  ,  0.4798  ,  1.4698\n",
      "81\n",
      "0.5585768291909816  ,  0.5594  ,  1.3557\n",
      "0.5012715426489863  ,  0.5397  ,  1.3374\n",
      "0.17036563444260136  ,  0.6995  ,  1.374\n",
      "82\n",
      "0.6821107934474929  ,  0.1193  ,  0.6276\n",
      "0.3312751915869168  ,  0.3962  ,  0.8237\n",
      "-0.026375366704057452  ,  0.409  ,  0.573\n",
      "83\n",
      "0.7174029065443521  ,  0.5688  ,  1.4106\n",
      "0.5605373115715033  ,  0.6363  ,  1.5134\n",
      "0.289124054829241  ,  0.8226  ,  1.6447\n",
      "84\n",
      "0.8485379564977298  ,  0.962  ,  1.2772\n",
      "-0.18060683902892125  ,  2.2686  ,  1.6434\n",
      "-0.23766701066536947  ,  1.8886  ,  2.16\n",
      "85\n",
      "0.9022748069205754  ,  0.6967  ,  1.5497\n",
      "0.7294492852706016  ,  0.9815  ,  2.138\n",
      "0.02982723125091382  ,  1.2672  ,  2.7994\n",
      "86\n",
      "0.4400353268468772  ,  0.7273  ,  1.7918\n",
      "0.19890558982201384  ,  1.4253  ,  2.2504\n",
      "nan  ,  0.6588  ,  2.1379\n",
      "87\n",
      "0.4071403461090711  ,  0.4463  ,  1.3339\n",
      "0.07312083723967314  ,  0.4881  ,  1.3968\n",
      "0.02447675035367542  ,  0.484  ,  1.4024\n",
      "88\n",
      "0.8735318980209014  ,  0.7327  ,  1.5948\n",
      "0.8522398901878384  ,  0.7322  ,  1.539\n",
      "0.6931590874516506  ,  0.9589  ,  2.148\n",
      "89\n",
      "0.7425722050248486  ,  0.6921  ,  1.1623\n",
      "0.16524540165482085  ,  3.9301  ,  3.3423\n",
      "0.06936975552018261  ,  1.0545  ,  1.821\n",
      "90\n",
      "0.7590184724517092  ,  0.1616  ,  0.7224\n",
      "0.33164216615682035  ,  0.2962  ,  1.0139\n",
      "0.053866647722633734  ,  0.2235  ,  1.1115\n",
      "91\n",
      "0.7517676219052296  ,  0.4637  ,  1.2699\n",
      "0.06916337638516412  ,  0.583  ,  1.7184\n",
      "0.02403688046464493  ,  0.5863  ,  1.7163\n",
      "92\n",
      "0.7482609844814505  ,  0.2767  ,  0.6565\n",
      "0.08540527599113941  ,  0.4397  ,  1.0252\n",
      "nan  ,  0.3927  ,  1.0555\n",
      "93\n",
      "0.8208156589752205  ,  0.6725  ,  1.5367\n",
      "0.12751987051573696  ,  1.0421  ,  2.4539\n",
      "0.043489520613937356  ,  1.0255  ,  2.5354\n",
      "94\n",
      "0.6331267770247624  ,  0.9924  ,  2.1537\n",
      "0.1933957687207609  ,  1.1394  ,  2.3692\n",
      "nan  ,  1.1148  ,  2.4814\n",
      "95\n",
      "0.6847344301077825  ,  1.2542  ,  2.5714\n",
      "0.4119971589432007  ,  3.2593  ,  2.8668\n",
      "0.11686373437595415  ,  1.4183  ,  3.1179\n",
      "96\n",
      "0.5214063611484147  ,  0.5456  ,  1.2321\n",
      "0.21970923468464218  ,  1.5712  ,  1.2178\n",
      "-0.048230945532844724  ,  0.672  ,  1.4619\n",
      "97\n",
      "0.8182224352145884  ,  0.632  ,  1.5699\n",
      "0.5680990637074366  ,  1.2791  ,  1.5557\n",
      "0.32054783521372143  ,  0.8678  ,  2.2516\n",
      "98\n",
      "0.7126065128094057  ,  0.5884  ,  1.3336\n",
      "0.41574803034506624  ,  0.8139  ,  1.7217\n",
      "0.16935345543802027  ,  0.97  ,  1.7837\n",
      "99\n",
      "0.8695464769693658  ,  0.3781  ,  0.942\n",
      "0.6224212351389011  ,  0.7427  ,  1.4547\n",
      "0.04754950421176769  ,  0.6633  ,  2.0014\n",
      "100\n",
      "0.9153274408806356  ,  0.3237  ,  0.8349\n",
      "0.008091098685607225  ,  1.0261  ,  1.9575\n",
      "nan  ,  0.5917  ,  2.0212\n",
      "101\n",
      "0.5769427066136847  ,  0.6558  ,  1.7989\n",
      "0.5848102340490334  ,  0.6678  ,  1.6389\n",
      "0.08969590818413073  ,  0.7393  ,  2.0819\n",
      "102\n",
      "0.8581520567000878  ,  0.6071  ,  1.0019\n",
      "0.15488011220783132  ,  1.0899  ,  1.8066\n",
      "-0.05760754079356269  ,  1.1329  ,  1.6765\n",
      "103\n",
      "0.864980947347334  ,  1.1813  ,  1.8011\n",
      "0.7215689058963491  ,  1.1877  ,  1.7358\n",
      "0.3473166218752965  ,  1.5173  ,  2.5261\n",
      "104\n",
      "0.8179255441524044  ,  0.8003  ,  1.7913\n",
      "0.5797700240028251  ,  1.0618  ,  2.0357\n",
      "0.019511986562005288  ,  1.1483  ,  2.6889\n",
      "105\n",
      "0.6360092637696867  ,  0.2797  ,  0.7919\n",
      "0.31109942983479066  ,  0.3339  ,  1.0071\n",
      "0.09808641231680498  ,  0.6393  ,  0.9477\n",
      "106\n",
      "0.8145795574970002  ,  0.5414  ,  1.2781\n",
      "nan  ,  0.7328  ,  2.0006\n",
      "nan  ,  0.7328  ,  2.0006\n",
      "107\n",
      "0.5966359696377257  ,  1.0359  ,  2.4006\n",
      "0.677932390345678  ,  1.0186  ,  2.2813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014028377284953993  ,  1.1232  ,  2.6002\n",
      "108\n",
      "0.3615183058215877  ,  0.4219  ,  1.4415\n",
      "0.26583701459103154  ,  0.4263  ,  1.4688\n",
      "0.24676490796013348  ,  0.5883  ,  1.3287\n",
      "109\n",
      "0.6561559220477462  ,  0.6152  ,  1.5527\n",
      "0.6502534040767617  ,  0.6311  ,  1.5626\n",
      "0.13213933174057255  ,  0.7885  ,  1.6818\n",
      "110\n",
      "0.8719558297220917  ,  0.4033  ,  1.2937\n",
      "0.5675516394781986  ,  0.5209  ,  1.9156\n",
      "-0.004143357795694475  ,  0.5457  ,  2.0529\n",
      "111\n",
      "0.6785819374788753  ,  0.5602  ,  1.1612\n",
      "0.21484555675288722  ,  1.0975  ,  1.3745\n",
      "-0.02770009074925061  ,  0.8927  ,  1.5374\n",
      "112\n",
      "0.8618510091760568  ,  0.48  ,  1.4073\n",
      "0.691634525837201  ,  0.5934  ,  1.6192\n",
      "0.1663247791925139  ,  0.7027  ,  2.1601\n",
      "113\n",
      "0.6807416463037794  ,  0.5713  ,  1.8447\n",
      "0.7100525485683794  ,  0.556  ,  1.6461\n",
      "nan  ,  0.6344  ,  2.1141\n",
      "114\n",
      "0.6418591027831597  ,  0.6442  ,  1.8454\n",
      "0.66656777550415  ,  0.611  ,  1.6961\n",
      "0.10040403706635531  ,  0.7431  ,  2.0469\n",
      "115\n",
      "0.7301471105156127  ,  0.2508  ,  0.8647\n",
      "0.05349811869219761  ,  0.3373  ,  1.1296\n",
      "0.15476322384704475  ,  0.3464  ,  1.1068\n",
      "116\n",
      "0.9192261106935873  ,  0.4615  ,  1.1893\n",
      "0.023273985801279536  ,  0.9052  ,  2.521\n",
      "-0.08321216835699234  ,  0.9048  ,  2.537\n",
      "117\n",
      "0.775796047959947  ,  0.7525  ,  1.6259\n",
      "0.6426044717268364  ,  0.8089  ,  1.4343\n",
      "0.17026586278896796  ,  0.9631  ,  2.0638\n",
      "118\n",
      "0.8041554827893493  ,  0.3691  ,  1.0826\n",
      "0.049311372203812626  ,  0.9176  ,  1.6559\n",
      "0.010274068015291174  ,  0.567  ,  1.7444\n",
      "119\n",
      "0.6565483928002995  ,  0.3617  ,  1.0617\n",
      "0.15894515419418337  ,  1.0002  ,  0.9572\n",
      "0.04831427445768214  ,  0.5528  ,  1.2458\n",
      "120\n",
      "0.8111112406335879  ,  0.3621  ,  0.8843\n",
      "0.22276361539741646  ,  0.5518  ,  1.2794\n",
      "0.03292956884266129  ,  0.5317  ,  1.362\n",
      "121\n",
      "0.9759296874432214  ,  0.296  ,  1.3192\n",
      "0.9485069481919869  ,  0.4652  ,  2.1368\n",
      "0.305809307343004  ,  0.7066  ,  2.3322\n",
      "122\n",
      "0.7356813002549288  ,  0.5341  ,  1.0971\n",
      "0.22183492841137492  ,  1.5262  ,  1.5555\n",
      "0.07576798692762764  ,  0.8064  ,  1.4768\n",
      "123\n",
      "0.7240747054234372  ,  0.2396  ,  0.8767\n",
      "0.3243146004552664  ,  0.3181  ,  1.1214\n",
      "0.11416439572259651  ,  0.6724  ,  0.9463\n",
      "124\n",
      "0.7950867985845513  ,  0.4458  ,  1.2287\n",
      "0.689579184292317  ,  0.5199  ,  1.4925\n",
      "0.19623023223429828  ,  0.6142  ,  1.6588\n",
      "125\n",
      "0.16246860635539345  ,  0.6248  ,  1.6844\n",
      "0.5049710182508347  ,  0.5889  ,  1.4287\n",
      "0.10951129373291928  ,  0.6401  ,  1.683\n",
      "126\n",
      "0.861983587698591  ,  0.9852  ,  1.4268\n",
      "0.12662940692515584  ,  1.6976  ,  2.169\n",
      "-0.2529957085125183  ,  1.7076  ,  2.4204\n",
      "127\n",
      "0.8380422652556905  ,  0.1121  ,  0.4686\n",
      "0.4447403412227361  ,  0.2525  ,  0.7149\n",
      "-0.17062427599053992  ,  0.3584  ,  0.7125\n",
      "128\n",
      "0.8092248597161575  ,  0.1886  ,  0.5659\n",
      "0.5155440260736986  ,  0.2755  ,  0.9058\n",
      "0.03501422876671755  ,  0.3787  ,  0.9342\n",
      "129\n",
      "0.7827008427231661  ,  0.6045  ,  1.1723\n",
      "0.29590858097793804  ,  0.7504  ,  1.3112\n",
      "0.08204442406039522  ,  0.7016  ,  1.4367\n",
      "130\n",
      "0.8135991646846646  ,  0.4477  ,  1.2734\n",
      "0.4262572683741285  ,  0.6848  ,  1.8667\n",
      "-0.008367525847833127  ,  0.6981  ,  2.0509\n",
      "131\n",
      "0.46808657727108927  ,  1.3045  ,  2.467\n",
      "0.18429900459202803  ,  1.3715  ,  2.5789\n",
      "0.0262142847610252  ,  1.3869  ,  2.584\n",
      "132\n",
      "0.7166315419379566  ,  1.0625  ,  1.5754\n",
      "0.07660150564810696  ,  2.4273  ,  1.958\n",
      "0.20090938832800936  ,  1.5065  ,  2.1138\n",
      "133\n",
      "0.6333401862714645  ,  0.967  ,  1.9241\n",
      "-0.01428587115141857  ,  1.1786  ,  2.3625\n",
      "0.26150454844613674  ,  1.1435  ,  2.284\n",
      "134\n",
      "0.390080886743101  ,  0.4778  ,  1.3243\n",
      "0.1010859558066122  ,  0.5875  ,  1.3367\n",
      "-0.00017901285749916031  ,  0.594  ,  1.3509\n",
      "135\n",
      "0.871512560122938  ,  0.6174  ,  1.5064\n",
      "0.74526780815957  ,  0.7069  ,  1.5732\n",
      "nan  ,  0.8774  ,  2.2806\n",
      "136\n",
      "0.6894608073068926  ,  0.5881  ,  1.1578\n",
      "0.16808746301665467  ,  0.3823  ,  1.1366\n",
      "nan  ,  0.3371  ,  1.1911\n",
      "137\n",
      "0.8531776592086191  ,  0.2471  ,  0.6875\n",
      "0.304016084633072  ,  0.42  ,  1.2195\n",
      "0.1278230375407933  ,  0.394  ,  1.3207\n",
      "138\n",
      "0.5726559808088882  ,  1.154  ,  2.5357\n",
      "0.5557163120110603  ,  1.5416  ,  1.7196\n",
      "0.3871922332163968  ,  1.1682  ,  2.6031\n",
      "139\n",
      "0.7668936949914481  ,  0.3508  ,  1.0024\n",
      "0.3766824815529977  ,  1.4853  ,  1.5609\n",
      "0.10324427584141611  ,  0.692  ,  1.3926\n",
      "140\n",
      "0.8071394317563606  ,  0.4007  ,  1.0578\n",
      "0.30187346967197143  ,  0.9662  ,  1.5614\n",
      "0.4975623556881123  ,  0.6283  ,  1.4431\n",
      "141\n",
      "0.7271705422372308  ,  0.5092  ,  1.0052\n",
      "0.175420802821037  ,  1.4395  ,  1.537\n",
      "0.1250359667329118  ,  0.9434  ,  1.295\n",
      "142\n",
      "0.7413481005299078  ,  0.378  ,  0.9995\n",
      "0.20460543127235328  ,  0.6002  ,  1.1508\n",
      "0.05663610636517742  ,  0.5423  ,  1.2317\n",
      "143\n",
      "0.4925158134772439  ,  0.7389  ,  1.5529\n",
      "0.39148993953759054  ,  0.8565  ,  1.665\n",
      "0.24204612772511022  ,  0.9723  ,  1.4514\n",
      "144\n",
      "0.6893997461653878  ,  0.7751  ,  1.7736\n",
      "0.7751632954207269  ,  0.7796  ,  1.3984\n",
      "0.026979822141942666  ,  1.0112  ,  2.4279\n",
      "145\n",
      "0.5400230831971492  ,  0.463  ,  1.4054\n",
      "0.2940552846021488  ,  0.5006  ,  1.464\n",
      "0.06941940191581883  ,  0.5216  ,  1.528\n",
      "146\n",
      "0.7458574016299957  ,  0.51  ,  1.7353\n",
      "0.8067864970167341  ,  0.5273  ,  1.7845\n",
      "0.3181019839325068  ,  0.602  ,  2.0007\n",
      "147\n",
      "0.8771339476341432  ,  0.2325  ,  0.7308\n",
      "0.31720446691563214  ,  0.4463  ,  1.5251\n",
      "0.20755590869233365  ,  0.5938  ,  1.4527\n",
      "148\n",
      "0.7578943041233531  ,  0.5269  ,  1.2863\n",
      "0.3955315025177006  ,  1.1266  ,  1.6057\n",
      "nan  ,  0.7566  ,  2.0741\n",
      "149\n",
      "0.855231612643696  ,  0.6808  ,  1.8972\n",
      "0.0222996990834069  ,  0.965  ,  2.6217\n",
      "0.007336974241230413  ,  0.9103  ,  2.6677\n",
      "150\n",
      "0.6037361074155518  ,  0.3361  ,  1.0901\n",
      "0.5623964422494285  ,  0.4176  ,  1.0797\n",
      "0.16581994687681967  ,  0.6192  ,  1.2858\n",
      "151\n",
      "0.857147467697911  ,  0.441  ,  1.0617\n",
      "0.4346221948645371  ,  0.7279  ,  1.6511\n",
      "0.27440867680215525  ,  0.7336  ,  1.8691\n",
      "152\n",
      "0.598432237387247  ,  0.5926  ,  1.5756\n",
      "0.6255908694548228  ,  0.6798  ,  1.3059\n",
      "0.10642367031514446  ,  0.7332  ,  1.8183\n",
      "153\n",
      "0.5174800324262137  ,  0.7627  ,  1.9239\n",
      "0.5003449674921767  ,  0.7723  ,  1.778\n",
      "0.2526448067767685  ,  0.822  ,  1.9833\n",
      "154\n",
      "0.7713421621493758  ,  0.8554  ,  2.5126\n",
      "0.054061745819092316  ,  0.9643  ,  2.9672\n",
      "-0.002567990384263058  ,  1.0155  ,  2.9243\n",
      "155\n",
      "0.6205125811300203  ,  0.4587  ,  1.2414\n",
      "0.5004254924314403  ,  0.5312  ,  1.325\n",
      "0.1505391869858549  ,  0.6045  ,  1.5113\n",
      "156\n",
      "0.6195013327328877  ,  0.4476  ,  1.0427\n",
      "0.16788455111638187  ,  1.1592  ,  1.371\n",
      "0.14610847293998314  ,  0.5697  ,  1.3549\n",
      "157\n",
      "0.8106114467378979  ,  0.4027  ,  1.0691\n",
      "0.017288983132050253  ,  0.5469  ,  1.8715\n",
      "nan  ,  0.5469  ,  1.8715\n",
      "158\n",
      "0.8137505907538605  ,  0.3704  ,  1.162\n",
      "0.5953607204679319  ,  0.4849  ,  1.5695\n",
      "0.31013493899534117  ,  0.5794  ,  1.7074\n",
      "159\n",
      "0.428036520240724  ,  0.4782  ,  1.4586\n",
      "0.6328963416067462  ,  0.4591  ,  1.3288\n",
      "0.18916262760018906  ,  0.5519  ,  1.5791\n",
      "160\n",
      "0.8287042451127489  ,  0.388  ,  1.4033\n",
      "-0.007900320818400617  ,  0.5333  ,  1.972\n",
      "0.1159082810786452  ,  0.5074  ,  1.9804\n",
      "161\n",
      "0.7404003144949536  ,  0.6332  ,  1.6727\n",
      "0.42625708875659046  ,  1.034  ,  1.711\n",
      "nan  ,  0.7883  ,  2.2\n",
      "162\n",
      "0.8469946446962193  ,  0.4697  ,  1.4249\n",
      "0.7128498771071106  ,  0.5813  ,  1.5754\n",
      "0.1918990845878318  ,  0.6458  ,  2.0944\n",
      "163\n",
      "0.7279482113600942  ,  0.4365  ,  1.2038\n",
      "0.30095852306038884  ,  2.4432  ,  2.7677\n",
      "0.18635187388379387  ,  0.5857  ,  1.4914\n",
      "164\n",
      "0.8339183216567294  ,  0.6139  ,  1.4075\n",
      "0.03786280663623494  ,  0.8752  ,  2.1254\n",
      "-0.05148696391157538  ,  0.8895  ,  2.1045\n",
      "165\n",
      "0.7227943020665528  ,  0.5126  ,  1.2838\n",
      "0.18001205315878338  ,  1.3443  ,  1.5294\n",
      "0.13740661284451924  ,  0.8177  ,  1.8273\n",
      "166\n",
      "0.7800450112691674  ,  0.6368  ,  1.6347\n",
      "0.25831948562240914  ,  0.9796  ,  1.9812\n",
      "0.0009779390203780705  ,  0.8626  ,  2.2123\n",
      "167\n",
      "0.42068419869313745  ,  0.2868  ,  1.2203\n",
      "0.5764803499829295  ,  0.7173  ,  1.1938\n",
      "0.26877104463811036  ,  0.3095  ,  1.2944\n",
      "168\n",
      "0.47522938608617943  ,  3.1902  ,  3.5112\n",
      "0.11817668674492995  ,  0.4917  ,  1.8106\n",
      "-0.0036807647603828934  ,  0.5653  ,  1.7859\n",
      "169\n",
      "0.7903372590070731  ,  0.8834  ,  1.8128\n",
      "0.7495928237442112  ,  0.9497  ,  1.9511\n",
      "2.5948480057226206e-05  ,  1.1554  ,  2.4921\n",
      "170\n",
      "0.5632834916395794  ,  0.8051  ,  1.7558\n",
      "0.5386209445470376  ,  0.8311  ,  1.6577\n",
      "0.12036650881106262  ,  0.9458  ,  2.0479\n",
      "171\n",
      "0.5003327777765341  ,  1.2033  ,  1.9433\n",
      "0.4018635398311713  ,  1.4535  ,  1.7225\n",
      "0.31331775212337215  ,  1.4773  ,  2.1136\n",
      "172\n",
      "0.6672170408155206  ,  1.8269  ,  2.1759\n",
      "0.38990327754939014  ,  1.7305  ,  1.9344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3284511634356175  ,  1.0573  ,  1.7775\n",
      "173\n",
      "0.8152999020272436  ,  1.1597  ,  1.594\n",
      "0.053175028449309596  ,  1.1301  ,  2.0094\n",
      "0.07331570653638164  ,  1.1854  ,  1.8426\n",
      "174\n",
      "0.4821233808894235  ,  0.717  ,  1.8684\n",
      "0.38487135126088784  ,  0.785  ,  1.7823\n",
      "0.1745458311304901  ,  0.7666  ,  2.0309\n",
      "175\n",
      "0.7840975380578674  ,  0.6405  ,  1.391\n",
      "0.4167281812784952  ,  0.764  ,  2.144\n",
      "0.14060029109543964  ,  0.8161  ,  2.2085\n",
      "176\n",
      "0.800506540267208  ,  0.662  ,  1.5141\n",
      "0.05551448818264675  ,  0.9714  ,  2.3657\n",
      "nan  ,  0.9643  ,  2.3843\n",
      "177\n",
      "0.5589781356794536  ,  0.4444  ,  1.3324\n",
      "0.3563088593345429  ,  0.5315  ,  1.4412\n",
      "0.22253234956770368  ,  0.5876  ,  1.5055\n",
      "178\n",
      "0.655671552304553  ,  0.8711  ,  1.7258\n",
      "nan  ,  0.8999  ,  2.5554\n",
      "nan  ,  0.8999  ,  2.5554\n",
      "179\n",
      "0.6046202979381069  ,  0.3931  ,  1.0466\n",
      "0.511601979518415  ,  0.4096  ,  1.032\n",
      "-0.006898643886181624  ,  0.5141  ,  1.1666\n",
      "180\n",
      "0.9197033916919204  ,  0.4428  ,  0.9899\n",
      "0.3090062960575075  ,  0.7723  ,  2.6396\n",
      "0.08003973232551306  ,  0.8568  ,  2.6591\n",
      "181\n",
      "0.689836223578618  ,  0.8803  ,  1.7468\n",
      "0.10538693425834798  ,  1.1088  ,  2.2408\n",
      "0.4585865433615218  ,  1.0655  ,  2.143\n",
      "182\n",
      "0.8947653307526572  ,  0.2738  ,  1.0018\n",
      "0.01698614899002522  ,  0.4909  ,  1.9071\n",
      "nan  ,  0.4909  ,  1.9072\n",
      "183\n",
      "0.8967005370899721  ,  0.3818  ,  0.9861\n",
      "0.201907227355477  ,  0.7287  ,  2.2971\n",
      "-0.012128830819340393  ,  0.7485  ,  2.3638\n",
      "184\n",
      "0.6680548697878839  ,  0.6455  ,  1.7381\n",
      "0.4899858920620442  ,  0.8383  ,  1.9838\n",
      "0.0008905626110792578  ,  0.8439  ,  2.3581\n",
      "185\n",
      "0.8887672151015006  ,  0.1323  ,  0.3719\n",
      "-0.0846668334214207  ,  0.8371  ,  0.7204\n",
      "0.0877918819547153  ,  0.2436  ,  0.5487\n",
      "186\n",
      "0.6219845960631707  ,  1.2652  ,  1.7485\n",
      "0.14374217185830487  ,  1.7387  ,  2.2131\n",
      "0.17725643846856326  ,  1.7963  ,  2.166\n",
      "187\n",
      "0.5007358593350604  ,  0.317  ,  1.0685\n",
      "0.5225689105087127  ,  0.3604  ,  1.1378\n",
      "0.0697452839046945  ,  0.5516  ,  1.0608\n",
      "188\n",
      "0.8473323546461944  ,  0.6274  ,  1.6204\n",
      "0.7240832048569864  ,  0.7  ,  1.7412\n",
      "nan  ,  0.7999  ,  2.2089\n",
      "189\n",
      "0.6107497584135336  ,  1.0157  ,  1.6377\n",
      "0.04667224177458733  ,  2.1604  ,  1.6713\n",
      "0.17040101352944004  ,  1.2248  ,  1.7021\n",
      "190\n",
      "0.6241425611914533  ,  0.3726  ,  0.9356\n",
      "0.2995546761723288  ,  0.4606  ,  1.1735\n",
      "0.160131372285029  ,  0.4915  ,  1.2175\n",
      "191\n",
      "0.9254819357050458  ,  0.3994  ,  1.1629\n",
      "0.028681978278321994  ,  0.7222  ,  2.3837\n",
      "nan  ,  0.7222  ,  2.385\n",
      "192\n",
      "0.12705556821947694  ,  1.1037  ,  1.668\n",
      "0.09244042932372343  ,  1.0847  ,  1.5657\n",
      "0.16146553449740408  ,  1.1022  ,  1.4239\n",
      "193\n",
      "0.7876816490124151  ,  1.1253  ,  1.5596\n",
      "0.029474812572320173  ,  1.5153  ,  2.4645\n",
      "0.0684595783284469  ,  1.5397  ,  2.2031\n",
      "194\n",
      "0.22388879686181  ,  0.8222  ,  1.5473\n",
      "-0.006358942233122571  ,  1.4712  ,  1.1243\n",
      "0.06071329782978335  ,  0.8821  ,  1.4821\n",
      "195\n",
      "0.7664175959952237  ,  0.48  ,  1.555\n",
      "0.5502998630464874  ,  0.5436  ,  1.7492\n",
      "-0.0264152718615909  ,  0.591  ,  1.9381\n",
      "196\n",
      "0.8936981444340893  ,  0.4339  ,  1.9934\n",
      "0.870285814313583  ,  0.4195  ,  1.7999\n",
      "0.15820989280229586  ,  0.7094  ,  2.4194\n",
      "197\n",
      "0.8708900829274435  ,  0.5961  ,  2.2587\n",
      "0.6697956867162979  ,  0.8344  ,  2.1512\n",
      "0.46323601072970155  ,  0.907  ,  2.6565\n",
      "198\n",
      "0.8511646065885927  ,  0.6991  ,  0.8652\n",
      "-0.049748291577725354  ,  1.772  ,  2.076\n",
      "0.27637231869787315  ,  1.7526  ,  2.003\n",
      "199\n",
      "0.8520161039514129  ,  0.6601  ,  1.6084\n",
      "0.6772910453030907  ,  0.8064  ,  2.0244\n",
      "0.31023286612536083  ,  0.9045  ,  2.3172\n",
      "200\n",
      "0.6750248057874879  ,  0.8437  ,  1.9112\n",
      "0.08676382856967903  ,  1.0955  ,  2.2851\n",
      "nan  ,  1.0263  ,  2.4059\n",
      "201\n",
      "0.8992224368972905  ,  0.4531  ,  1.1417\n",
      "0.3377832071700452  ,  0.9865  ,  1.9742\n",
      "0.20068328974246474  ,  0.8746  ,  2.1951\n",
      "202\n",
      "0.5401884536605381  ,  0.974  ,  1.9483\n",
      "0.2617785406701938  ,  1.1193  ,  1.8417\n",
      "0.04225526216095407  ,  1.1309  ,  2.0182\n",
      "203\n",
      "0.44299740634384877  ,  0.7151  ,  1.5333\n",
      "0.32545341695976293  ,  0.812  ,  1.4432\n",
      "0.2603284250948942  ,  0.9243  ,  1.4199\n",
      "204\n",
      "0.49801758031701115  ,  4.0914  ,  4.3878\n",
      "0.16950058260616024  ,  3.7484  ,  2.9536\n",
      "-0.024202017455255444  ,  0.626  ,  1.7532\n",
      "205\n",
      "0.6186423187794702  ,  0.3287  ,  1.1919\n",
      "0.40052302011476526  ,  0.4075  ,  1.2359\n",
      "0.24337625447631747  ,  0.5843  ,  1.2852\n",
      "206\n",
      "0.44106780163235454  ,  0.591  ,  1.4436\n",
      "0.4000261451612428  ,  0.8742  ,  1.2858\n",
      "0.2710511853973241  ,  0.778  ,  1.4444\n",
      "207\n",
      "0.9567941391963786  ,  0.2709  ,  0.6556\n",
      "0.33520263011879675  ,  0.7892  ,  2.0916\n",
      "nan  ,  0.7919  ,  2.1901\n",
      "208\n",
      "0.7278536612464381  ,  0.3655  ,  1.1292\n",
      "0.4961545611034605  ,  0.6878  ,  1.2452\n",
      "0.256624204670828  ,  0.6799  ,  1.447\n",
      "209\n",
      "0.7369215086099057  ,  0.6552  ,  1.3856\n",
      "0.5429539261324062  ,  0.7853  ,  1.4392\n",
      "-0.01584095133186294  ,  0.8437  ,  1.8274\n",
      "210\n",
      "0.6823501446527601  ,  1.2985  ,  2.1975\n",
      "0.11053200540965577  ,  1.5354  ,  2.7217\n",
      "nan  ,  1.55  ,  2.7652\n",
      "211\n",
      "0.8911387477167863  ,  0.5084  ,  1.1675\n",
      "0.7173296321295747  ,  0.702  ,  1.7095\n",
      "0.12017075627653616  ,  0.856  ,  2.1859\n",
      "212\n",
      "0.37578400917966576  ,  0.4663  ,  1.1789\n",
      "-0.10219125095994722  ,  4.3184  ,  3.291\n",
      "0.12115774899645973  ,  0.5381  ,  1.2527\n",
      "213\n",
      "0.7342393776478343  ,  1.2863  ,  1.9399\n",
      "-0.08158226920383163  ,  2.1102  ,  2.5325\n",
      "-0.01502858324401591  ,  1.9544  ,  2.7602\n",
      "214\n",
      "0.6407280883628883  ,  0.7415  ,  1.5235\n",
      "0.2407326317858417  ,  0.871  ,  1.8101\n",
      "-0.06321982172892651  ,  0.8805  ,  1.8983\n",
      "215\n",
      "0.6631324850677597  ,  0.5313  ,  1.1978\n",
      "0.15359535025992752  ,  0.7414  ,  1.4909\n",
      "0.1529276213087592  ,  0.7621  ,  1.4819\n",
      "216\n",
      "0.9111293088185412  ,  0.311  ,  0.8517\n",
      "0.33864933465558517  ,  4.247  ,  3.8838\n",
      "0.05666983129988964  ,  0.5191  ,  2.1753\n",
      "217\n",
      "0.814778095818439  ,  0.3505  ,  1.1336\n",
      "0.5674959968231739  ,  0.5779  ,  1.3954\n",
      "0.11533117986693808  ,  0.6937  ,  1.6645\n",
      "218\n",
      "0.6045065604612759  ,  1.8375  ,  2.5886\n",
      "0.45278709016617624  ,  1.8675  ,  2.6156\n",
      "0.1808889668874605  ,  2.0125  ,  2.5198\n",
      "219\n",
      "0.8110295359637888  ,  0.5077  ,  1.1399\n",
      "0.5818317823014365  ,  0.5334  ,  1.6448\n",
      "0.05812217100858761  ,  0.5911  ,  1.9299\n",
      "220\n",
      "0.3359141881597951  ,  0.9153  ,  1.5294\n",
      "0.22225944371565323  ,  1.7973  ,  1.1242\n",
      "-0.06755024230068465  ,  0.9982  ,  1.51\n",
      "221\n",
      "0.7575469103596403  ,  0.3948  ,  1.2049\n",
      "0.1715814572286683  ,  0.517  ,  1.639\n",
      "nan  ,  0.5078  ,  1.6611\n",
      "222\n",
      "0.9072173005071911  ,  0.492  ,  1.2673\n",
      "0.20568624908372213  ,  1.1785  ,  2.5982\n",
      "nan  ,  0.8296  ,  2.723\n",
      "223\n",
      "0.9014130760914616  ,  0.5063  ,  1.1384\n",
      "0.14126304696491615  ,  0.8165  ,  2.7755\n",
      "-0.002233854683053991  ,  0.8818  ,  2.777\n",
      "224\n",
      "0.809704117209988  ,  0.2369  ,  0.7726\n",
      "0.1272167033827878  ,  1.6912  ,  1.6811\n",
      "0.07798912677389881  ,  0.595  ,  0.9426\n",
      "225\n",
      "0.7965513665471251  ,  1.189  ,  1.8175\n",
      "-0.006615910958768793  ,  1.8465  ,  2.9557\n",
      "0.09379734349427057  ,  1.8396  ,  2.9655\n",
      "226\n",
      "0.7313761097702195  ,  0.4272  ,  1.0497\n",
      "0.4428299311124228  ,  0.8344  ,  1.3113\n",
      "0.006327629362159257  ,  0.6596  ,  1.3142\n",
      "227\n",
      "0.5837451016345022  ,  0.5432  ,  1.6265\n",
      "0.39220997012662423  ,  0.7596  ,  1.5972\n",
      "0.28249107236238724  ,  0.6717  ,  1.7817\n",
      "228\n",
      "0.720900313544659  ,  0.3199  ,  0.8981\n",
      "0.20823000223381335  ,  1.3098  ,  0.9454\n",
      "0.014774705626170666  ,  0.5416  ,  1.0843\n",
      "229\n",
      "0.6714487354313448  ,  0.5335  ,  0.8286\n",
      "0.29915927511003876  ,  0.3868  ,  0.8871\n",
      "0.16745537406155228  ,  0.47  ,  0.8521\n",
      "230\n",
      "0.7144947060314389  ,  0.5679  ,  1.0586\n",
      "0.1479292788338  ,  0.9709  ,  1.0951\n",
      "0.15487481096138522  ,  0.7461  ,  1.2716\n",
      "231\n",
      "0.7332574635262507  ,  0.4821  ,  1.3198\n",
      "0.5413914248770038  ,  0.9776  ,  1.6459\n",
      "0.026471082213432133  ,  0.6343  ,  1.9894\n",
      "232\n",
      "0.4767532791092391  ,  0.4679  ,  1.5187\n",
      "0.6016334256194419  ,  0.4642  ,  1.3026\n",
      "0.34686763595326353  ,  0.6331  ,  1.4412\n",
      "233\n",
      "0.9192260685688105  ,  0.3094  ,  0.6678\n",
      "0.46953906948481494  ,  0.6721  ,  1.5137\n",
      "0.218693774279462  ,  0.754  ,  1.6823\n",
      "234\n",
      "0.8885164985534947  ,  0.3974  ,  0.8923\n",
      "0.5868881615139124  ,  0.7087  ,  1.5276\n",
      "0.12487719165022512  ,  0.7728  ,  1.9863\n",
      "235\n",
      "0.6556170426275663  ,  1.3621  ,  1.7969\n",
      "0.04943103157254705  ,  2.6533  ,  1.9409\n",
      "0.40224524839872633  ,  2.0573  ,  2.1388\n",
      "236\n",
      "0.5798596923729832  ,  0.83  ,  1.3875\n",
      "0.43126492550912476  ,  1.1343  ,  1.5101\n",
      "0.13442737433643107  ,  1.0408  ,  1.7348\n",
      "237\n",
      "0.6291139347250055  ,  0.3343  ,  0.827\n",
      "0.05213909202848445  ,  1.1914  ,  0.568\n",
      "0.0006960718946223074  ,  0.4732  ,  0.8028\n",
      "238\n",
      "0.8050966282841089  ,  0.2362  ,  0.8745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044318984041843985  ,  0.3944  ,  1.4473\n",
      "nan  ,  0.3944  ,  1.4473\n",
      "239\n",
      "0.2089558523756762  ,  0.4555  ,  1.3355\n",
      "0.207696552095161  ,  0.6072  ,  1.2693\n",
      "0.04330550967500592  ,  0.5408  ,  1.274\n",
      "240\n",
      "0.1940505064749671  ,  0.5596  ,  1.9271\n",
      "0.21003689843215229  ,  0.5578  ,  1.9576\n",
      "-0.01652993027594321  ,  0.5882  ,  1.9672\n",
      "241\n",
      "0.6831449311248056  ,  0.4824  ,  1.1925\n",
      "0.6008884305975047  ,  0.5002  ,  1.3467\n",
      "0.38609874139041034  ,  0.5811  ,  1.6768\n",
      "242\n",
      "0.8086779286523819  ,  0.357  ,  0.8414\n",
      "0.0725202392133954  ,  0.5789  ,  1.4964\n",
      "nan  ,  0.5249  ,  1.5302\n",
      "243\n",
      "0.7973119346521824  ,  0.18  ,  0.948\n",
      "0.49850325293100933  ,  0.2231  ,  1.068\n",
      "nan  ,  0.2065  ,  1.1515\n",
      "244\n",
      "0.9563492842548509  ,  0.3433  ,  0.73\n",
      "0.021212750723272333  ,  0.93  ,  2.7127\n",
      "nan  ,  0.9269  ,  2.7168\n",
      "245\n",
      "0.5026446890179019  ,  1.2298  ,  2.0431\n",
      "0.4216360487036347  ,  1.2391  ,  2.0838\n",
      "-0.01750144484702911  ,  1.3011  ,  2.2047\n",
      "246\n",
      "0.8830686517328848  ,  0.5856  ,  1.3419\n",
      "0.6039710037454754  ,  0.8149  ,  1.7498\n",
      "0.10451785249803676  ,  0.9317  ,  2.2028\n",
      "247\n",
      "0.6859673496835866  ,  0.6238  ,  1.3143\n",
      "0.01578545325024937  ,  0.8239  ,  1.7544\n",
      "-0.007958545175308258  ,  0.8023  ,  1.6949\n",
      "248\n",
      "0.6538987488203297  ,  0.8213  ,  2.0478\n",
      "0.3365732245461507  ,  1.046  ,  2.0618\n",
      "0.014104625014074869  ,  0.9154  ,  2.3921\n",
      "249\n",
      "0.8697015593359884  ,  0.4141  ,  1.4454\n",
      "0.7220005558754402  ,  0.4863  ,  1.5977\n",
      "0.022435940165377533  ,  0.793  ,  1.8319\n",
      "250\n",
      "0.4864578133595515  ,  0.8547  ,  1.7951\n",
      "0.2223507002784081  ,  1.328  ,  1.6037\n",
      "-0.06068985684471111  ,  1.0579  ,  1.8525\n",
      "251\n",
      "0.7347284351993811  ,  0.4562  ,  1.1522\n",
      "0.43153255784644645  ,  0.5201  ,  1.3547\n",
      "0.35401334346704266  ,  0.5901  ,  1.3727\n",
      "252\n",
      "0.8658315709658692  ,  0.4014  ,  1.0455\n",
      "0.429657920818648  ,  0.6926  ,  1.5271\n",
      "0.1589395897385587  ,  0.7752  ,  1.6918\n",
      "253\n",
      "0.8326912379975018  ,  0.4888  ,  1.1888\n",
      "0.3782925058207973  ,  0.7486  ,  1.9152\n",
      "0.23692199364598343  ,  0.8332  ,  1.9\n",
      "254\n",
      "0.5526717832402551  ,  0.3447  ,  1.0036\n",
      "0.3075046936450276  ,  0.4261  ,  1.1611\n",
      "0.015816887305908356  ,  0.4049  ,  1.2406\n",
      "255\n",
      "0.5208106606320958  ,  0.1552  ,  0.6164\n",
      "0.1459785274133117  ,  0.3219  ,  0.6954\n",
      "-0.03545580156693893  ,  0.2294  ,  0.6386\n",
      "256\n",
      "0.40334081980684566  ,  0.7959  ,  1.5604\n",
      "0.24879720753298282  ,  0.8333  ,  1.631\n",
      "-0.15392930076295264  ,  0.8546  ,  1.6686\n",
      "257\n",
      "0.824643443931  ,  0.5627  ,  1.2275\n",
      "0.25278969855052513  ,  1.1263  ,  2.0431\n",
      "0.19788906572736142  ,  1.0386  ,  2.2868\n",
      "258\n",
      "0.7677094659316182  ,  0.5667  ,  1.162\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "259\n",
      "0.25083818549047643  ,  0.4512  ,  0.9834\n",
      "0.21113434645301637  ,  0.4571  ,  1.0023\n",
      "0.18088306115039837  ,  0.5083  ,  0.937\n",
      "260\n",
      "0.6057135448685911  ,  0.6424  ,  1.0583\n",
      "0.11868139543499352  ,  0.7536  ,  1.5069\n",
      "nan  ,  0.7539  ,  1.5164\n",
      "261\n",
      "0.3164365523980569  ,  0.813  ,  1.9511\n",
      "0.22319639757363896  ,  0.865  ,  1.9455\n",
      "nan  ,  0.8415  ,  2.0292\n",
      "262\n",
      "0.6842950858626051  ,  0.8813  ,  1.8438\n",
      "0.3109522257445332  ,  0.9909  ,  2.1404\n",
      "-0.25760181378057523  ,  1.0406  ,  2.1359\n",
      "263\n",
      "0.024327709016049047  ,  0.5554  ,  1.6252\n",
      "0.03259907025303715  ,  0.6315  ,  1.5676\n",
      "nan  ,  0.5552  ,  1.6264\n",
      "264\n",
      "0.4267022124952429  ,  0.4195  ,  1.2042\n",
      "0.1496555648291918  ,  1.2789  ,  1.1178\n",
      "0.0669866752931842  ,  0.4515  ,  1.3245\n",
      "265\n",
      "0.6636707676978246  ,  0.7425  ,  1.4774\n",
      "0.08218785568845872  ,  0.9804  ,  1.7706\n",
      "nan  ,  0.8632  ,  1.9664\n",
      "266\n",
      "0.300504447232263  ,  0.6824  ,  1.2518\n",
      "0.15862542279596614  ,  0.9454  ,  1.0413\n",
      "nan  ,  0.7208  ,  1.3886\n",
      "267\n",
      "0.4036235224506408  ,  0.7267  ,  1.6408\n",
      "0.3477954774036713  ,  1.3685  ,  1.1902\n",
      "-0.0066001754707452585  ,  0.7932  ,  1.7017\n",
      "268\n",
      "0.7208655384437042  ,  0.9276  ,  1.1703\n",
      "0.27258785056346563  ,  1.2421  ,  2.0918\n",
      "nan  ,  1.2628  ,  2.1513\n",
      "269\n",
      "0.7388690380384877  ,  0.6705  ,  1.0926\n",
      "0.13205013178652275  ,  1.0122  ,  1.6635\n",
      "0.0834178583077493  ,  0.9779  ,  1.8102\n",
      "270\n",
      "0.7585136986184421  ,  2.303  ,  1.8267\n",
      "0.409685981263599  ,  1.8471  ,  2.4023\n",
      "nan  ,  1.9837  ,  2.7294\n",
      "271\n",
      "0.5118638284647985  ,  0.524  ,  1.2574\n",
      "0.001119040041040951  ,  0.9671  ,  1.3665\n",
      "nan  ,  0.5583  ,  1.556\n",
      "272\n",
      "0.44685484382597795  ,  0.5257  ,  1.4024\n",
      "-0.01792029187730497  ,  0.5567  ,  1.6132\n",
      "nan  ,  0.5416  ,  1.6211\n",
      "273\n",
      "0.6199907829723784  ,  0.8883  ,  1.4765\n",
      "0.04076515710436597  ,  0.8537  ,  2.0698\n",
      "nan  ,  0.8526  ,  2.0736\n",
      "274\n",
      "0.42142846920556143  ,  0.9338  ,  1.8061\n",
      "0.1459184321971543  ,  0.8829  ,  1.9392\n",
      "nan  ,  0.8095  ,  2.077\n",
      "275\n",
      "0.37790130536767863  ,  0.5819  ,  1.0942\n",
      "0.2519795154440734  ,  0.6072  ,  1.0833\n",
      "nan  ,  0.6126  ,  1.1486\n",
      "276\n",
      "0.7428917557713546  ,  0.6938  ,  1.2673\n",
      "0.28115662661387464  ,  1.0517  ,  2.086\n",
      "nan  ,  1.0597  ,  2.107\n",
      "277\n",
      "0.8072153121844454  ,  0.6134  ,  1.0956\n",
      "0.5756423580348491  ,  0.8984  ,  1.754\n",
      "-0.05664264841934626  ,  1.0437  ,  1.9144\n",
      "278\n",
      "0.23784682312405622  ,  0.6226  ,  1.6927\n",
      "0.10792245967958737  ,  0.6483  ,  1.7223\n",
      "nan  ,  0.6337  ,  1.7583\n",
      "279\n",
      "0.6313430197532269  ,  0.5054  ,  1.0989\n",
      "0.08390446121794236  ,  1.4318  ,  1.0679\n",
      "0.011556411210956664  ,  0.6502  ,  1.437\n",
      "280\n",
      "0.7847835962235625  ,  0.5602  ,  1.0313\n",
      "0.06324938799898266  ,  0.7542  ,  1.5099\n",
      "nan  ,  0.7536  ,  1.5149\n",
      "281\n",
      "0.35632391649348594  ,  0.9801  ,  2.2121\n",
      "0.21703482058391393  ,  1.4592  ,  1.7177\n",
      "0.06600409052391369  ,  1.0592  ,  2.2316\n",
      "282\n",
      "0.49516567538186673  ,  0.6133  ,  1.295\n",
      "0.01299276395775166  ,  0.8548  ,  1.152\n",
      "0.062253675878219464  ,  0.7544  ,  1.2492\n",
      "283\n",
      "0.5430860853231984  ,  0.4748  ,  1.4767\n",
      "0.16763871891507026  ,  0.5213  ,  1.691\n",
      "nan  ,  0.5204  ,  1.7121\n",
      "284\n",
      "0.3802590525239327  ,  0.5462  ,  1.1078\n",
      "0.0908353727202405  ,  0.564  ,  1.1465\n",
      "0.08417727312236817  ,  0.5908  ,  1.1017\n",
      "285\n",
      "0.7059418696174806  ,  0.6681  ,  0.9567\n",
      "0.10281657407472225  ,  0.9674  ,  1.4326\n",
      "-0.07961353380443167  ,  0.9913  ,  1.3828\n",
      "286\n",
      "0.2656458134314739  ,  1.2516  ,  1.8346\n",
      "0.3422398579220493  ,  1.2244  ,  1.703\n",
      "0.2019904449776637  ,  1.2788  ,  1.839\n",
      "287\n",
      "0.31932139543575805  ,  0.8803  ,  2.0039\n",
      "-0.08569275522462916  ,  1.4566  ,  1.6429\n",
      "nan  ,  0.8943  ,  2.0395\n",
      "288\n",
      "0.7930469975377377  ,  1.0169  ,  1.1503\n",
      "0.3694236585376747  ,  1.5004  ,  2.2314\n",
      "-0.19895715982536227  ,  1.5613  ,  2.3419\n",
      "289\n",
      "0.7685280677385324  ,  0.5824  ,  1.1601\n",
      "0.04961255195951392  ,  1.1255  ,  1.7207\n",
      "-0.08046159310125943  ,  0.7876  ,  2.0052\n",
      "290\n",
      "0.6847525449009577  ,  0.9483  ,  1.3705\n",
      "0.007788678354455673  ,  1.1807  ,  2.2351\n",
      "-0.04692136771188054  ,  1.1824  ,  2.2266\n",
      "291\n",
      "0.8094650251870739  ,  0.5669  ,  1.108\n",
      "-0.04680406061473856  ,  0.9311  ,  2.0439\n",
      "nan  ,  0.8753  ,  2.0967\n",
      "292\n",
      "0.5366234625107791  ,  1.0426  ,  1.3814\n",
      "0.2592295923207988  ,  1.2673  ,  1.5976\n",
      "0.020028924357569214  ,  1.3169  ,  1.6657\n",
      "293\n",
      "0.6518662311748444  ,  0.9149  ,  1.7461\n",
      "0.24203137724569407  ,  1.0809  ,  1.9641\n",
      "-0.005497385568038145  ,  1.0616  ,  2.0692\n",
      "294\n",
      "0.8727218771210012  ,  0.537  ,  1.168\n",
      "0.1857673105572449  ,  0.7174  ,  2.6134\n",
      "nan  ,  0.7176  ,  2.6151\n",
      "295\n",
      "0.6523106021256952  ,  0.7286  ,  1.4274\n",
      "0.23339644018493697  ,  0.9293  ,  1.9294\n",
      "-0.06595146962509961  ,  0.9401  ,  1.9282\n",
      "296\n",
      "0.6646852715783308  ,  0.5535  ,  1.0087\n",
      "0.2861890319384655  ,  0.691  ,  1.3971\n",
      "0.049119965755519836  ,  0.6884  ,  1.5039\n",
      "297\n",
      "0.07415046408374057  ,  1.1563  ,  1.9542\n",
      "0.10858872839426628  ,  1.1718  ,  1.834\n",
      "0.0125476220176281  ,  1.1878  ,  1.8413\n",
      "298\n",
      "0.442624118319836  ,  1.3788  ,  2.71\n",
      "0.08168612082239382  ,  1.5281  ,  2.5899\n",
      "0.036107334150314474  ,  1.4393  ,  2.8023\n",
      "299\n",
      "0.3604553177942896  ,  0.5356  ,  1.0099\n",
      "0.1968432767478469  ,  0.4476  ,  1.086\n",
      "-0.02703542429526162  ,  0.4773  ,  1.0821\n",
      "300\n",
      "0.23998417934067376  ,  0.7622  ,  2.1937\n",
      "-0.04181184480266198  ,  0.8575  ,  2.1654\n",
      "nan  ,  0.7732  ,  2.2247\n",
      "301\n",
      "0.26878887247994243  ,  1.2209  ,  1.8595\n",
      "0.18242115338071715  ,  1.2251  ,  1.8025\n",
      "-0.3988090474257503  ,  1.24  ,  1.8626\n",
      "302\n",
      "0.1426107018610969  ,  0.4845  ,  1.2705\n",
      "nan  ,  0.486  ,  1.2905\n",
      "-0.06634447165075748  ,  0.5177  ,  1.2578\n",
      "303\n",
      "0.28276062750884984  ,  1.0146  ,  1.6554\n",
      "-0.050911923176703955  ,  1.075  ,  1.5844\n",
      "0.012267151470097439  ,  1.0622  ,  1.5859\n",
      "304\n",
      "0.09451130840870571  ,  1.5935  ,  2.1728\n",
      "0.00024319601459189648  ,  1.593  ,  2.1186\n",
      "-0.07686311198276775  ,  1.5934  ,  2.146\n",
      "305\n",
      "0.024404988884458932  ,  0.7604  ,  1.9066\n",
      "0.07369782010485766  ,  0.7608  ,  1.8992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  ,  0.761  ,  1.907\n",
      "306\n",
      "0.9330555939862859  ,  0.2832  ,  0.8053\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "307\n",
      "0.5879892167763598  ,  0.4936  ,  0.9836\n",
      "nan  ,  0.563  ,  1.1967\n",
      "nan  ,  0.563  ,  1.1967\n",
      "308\n",
      "0.6424689642675097  ,  0.4175  ,  1.3585\n",
      "0.08177010159061375  ,  0.5131  ,  1.6993\n",
      "nan  ,  0.4949  ,  1.7215\n",
      "309\n",
      "0.6382404994540232  ,  1.1136  ,  1.2179\n",
      "0.2115909263091092  ,  1.1699  ,  1.5658\n",
      "0.12401332930253123  ,  1.1772  ,  1.7819\n",
      "310\n",
      "0.7446101432305727  ,  0.5957  ,  1.2202\n",
      "0.009674793707244916  ,  0.8173  ,  1.9265\n",
      "nan  ,  0.8173  ,  1.9267\n",
      "311\n",
      "0.4499058183698967  ,  0.7005  ,  1.564\n",
      "0.06072568752558723  ,  0.8045  ,  1.644\n",
      "nan  ,  0.763  ,  1.7097\n",
      "312\n",
      "0.9430358310064025  ,  0.264  ,  0.8111\n",
      "0.10579418362136886  ,  0.5086  ,  2.3381\n",
      "nan  ,  0.5086  ,  2.3385\n",
      "313\n",
      "0.5608374704481217  ,  0.4589  ,  1.12\n",
      "0.0797325513580623  ,  0.5107  ,  1.3116\n",
      "nan  ,  0.5113  ,  1.3129\n",
      "314\n",
      "0.5315408641762787  ,  0.6206  ,  1.6918\n",
      "0.16921774984732899  ,  1.554  ,  1.6364\n",
      "nan  ,  0.7027  ,  1.9405\n",
      "315\n",
      "0.008725994002793253  ,  0.4111  ,  1.0868\n",
      "0.01878341540473575  ,  0.6227  ,  0.9137\n",
      "0.14128282361320468  ,  0.4278  ,  1.0695\n",
      "316\n",
      "0.007603887280257825  ,  0.6577  ,  1.6994\n",
      "0.18269489363929053  ,  0.7717  ,  1.5293\n",
      "0.0030946268059610874  ,  0.6947  ,  1.6556\n",
      "317\n",
      "0.602569527948867  ,  0.9796  ,  1.8895\n",
      "0.15990982108452165  ,  1.1723  ,  2.3218\n",
      "nan  ,  1.1661  ,  2.4048\n",
      "318\n",
      "0.07957143477466802  ,  0.3015  ,  0.8413\n",
      "0.06974188272404525  ,  0.4409  ,  0.7562\n",
      "0.016978738186066235  ,  0.3584  ,  0.7888\n",
      "319\n",
      "0.8595789174435754  ,  0.9219  ,  1.3886\n",
      "0.12205009257295608  ,  1.4515  ,  2.7315\n",
      "0.009423797144923791  ,  1.4827  ,  2.6516\n",
      "320\n",
      "0.7844100317035715  ,  0.8187  ,  1.2383\n",
      "0.233467821681888  ,  1.2105  ,  1.9871\n",
      "0.22167946957150386  ,  1.2295  ,  1.9172\n",
      "321\n",
      "0.05089376259679588  ,  0.2649  ,  1.2031\n",
      "-0.003736596154359825  ,  0.2651  ,  1.2055\n",
      "nan  ,  0.2651  ,  1.2055\n",
      "322\n",
      "0.6806782669057175  ,  0.9311  ,  1.1023\n",
      "0.38234041599763474  ,  1.3445  ,  1.7419\n",
      "nan  ,  1.4461  ,  1.935\n",
      "323\n",
      "0.5841747379365119  ,  0.6823  ,  1.3523\n",
      "0.006364735220332409  ,  0.7682  ,  1.8117\n",
      "0.06863921292312346  ,  0.7681  ,  1.812\n",
      "324\n",
      "0.7905899616059526  ,  0.7611  ,  1.471\n",
      "0.002326677506964821  ,  1.1209  ,  2.388\n",
      "0.08069059096656343  ,  1.1265  ,  2.3766\n",
      "325\n",
      "0.2683930833208291  ,  0.6837  ,  1.4123\n",
      "0.1278409733679746  ,  0.736  ,  1.4431\n",
      "nan  ,  0.6899  ,  1.5352\n",
      "326\n",
      "0.49365709828643556  ,  0.6324  ,  1.5625\n",
      "0.08376957015479444  ,  0.6538  ,  1.8887\n",
      "nan  ,  0.6536  ,  1.8912\n",
      "327\n",
      "0.34698317992214833  ,  0.7247  ,  1.2277\n",
      "0.42554752007504615  ,  0.7166  ,  1.3733\n",
      "nan  ,  0.7293  ,  1.4415\n",
      "328\n",
      "0.08329041658619397  ,  0.5158  ,  1.2646\n",
      "0.060367898015179236  ,  0.5179  ,  1.2596\n",
      "0.007348893733786013  ,  0.7112  ,  1.0622\n",
      "329\n",
      "0.7769811305257259  ,  0.4647  ,  0.9946\n",
      "0.04998665383930803  ,  0.6743  ,  1.5372\n",
      "nan  ,  0.6631  ,  1.5563\n",
      "330\n",
      "0.7214683059309269  ,  0.6435  ,  1.4884\n",
      "-0.03875076390914906  ,  0.8114  ,  2.0176\n",
      "nan  ,  0.8079  ,  2.0201\n",
      "331\n",
      "0.7890366734267118  ,  0.9963  ,  1.7337\n",
      "0.019439275951311896  ,  1.3133  ,  2.332\n",
      "-0.11110799446491548  ,  1.3153  ,  2.3215\n",
      "332\n",
      "0.6185457092860028  ,  0.8021  ,  1.2812\n",
      "0.06338764270843933  ,  0.9049  ,  1.4097\n",
      "-0.2912175520816264  ,  0.9548  ,  1.2946\n",
      "333\n",
      "0.596161819253646  ,  0.6451  ,  1.1297\n",
      "0.07761284619611368  ,  0.8578  ,  1.3185\n",
      "0.10302325072755274  ,  0.8133  ,  1.4376\n",
      "334\n",
      "0.3926715541437337  ,  0.7902  ,  1.4926\n",
      "0.23265602583369066  ,  0.8381  ,  1.5869\n",
      "0.05057739371213986  ,  0.8841  ,  1.5414\n",
      "335\n",
      "0.507751423933591  ,  0.467  ,  0.8025\n",
      "0.15475994162099665  ,  0.5356  ,  0.9942\n",
      "-0.02100907208954371  ,  0.5586  ,  0.9695\n",
      "336\n",
      "0.2268602820798993  ,  0.8644  ,  1.635\n",
      "0.05924098988722892  ,  0.8989  ,  1.6299\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "337\n",
      "0.6525012906353265  ,  0.5632  ,  0.7695\n",
      "0.3024172944722084  ,  0.5897  ,  1.1339\n",
      "-0.027057608526873687  ,  0.6233  ,  1.1584\n",
      "338\n",
      "0.5699153715067422  ,  1.0097  ,  1.2111\n",
      "0.24414195863396226  ,  1.1071  ,  1.7984\n",
      "nan  ,  1.1207  ,  1.8448\n",
      "339\n",
      "0.5108576274243355  ,  0.259  ,  0.8503\n",
      "0.0025226752894362027  ,  0.9486  ,  0.7539\n",
      "nan  ,  0.2825  ,  0.9596\n",
      "340\n",
      "0.551549310392968  ,  0.8287  ,  1.4116\n",
      "0.09511775805318179  ,  1.0003  ,  1.3689\n",
      "0.06699683902720147  ,  0.9588  ,  1.553\n",
      "341\n",
      "0.48447068201506027  ,  0.3545  ,  0.9322\n",
      "0.012966401794766798  ,  1.0982  ,  0.8451\n",
      "-0.06139144989273522  ,  0.5782  ,  0.9023\n",
      "342\n",
      "0.5110496487089478  ,  1.0796  ,  1.5461\n",
      "-0.04558724196214366  ,  1.2369  ,  2.1096\n",
      "0.05807215565162894  ,  1.2478  ,  1.997\n",
      "343\n",
      "0.9401214256313135  ,  0.5877  ,  1.4065\n",
      "0.8756008805686497  ,  1.0863  ,  2.6713\n",
      "0.13983835360263347  ,  1.3712  ,  2.7866\n",
      "344\n",
      "0.6412974916645755  ,  0.367  ,  1.0628\n",
      "0.06241917971676664  ,  0.3718  ,  1.4523\n",
      "nan  ,  0.358  ,  1.4638\n",
      "345\n",
      "0.5476578101495633  ,  0.5917  ,  1.0361\n",
      "0.20276314152124583  ,  0.7296  ,  1.2399\n",
      "0.07626607509525737  ,  0.7037  ,  1.3096\n",
      "346\n",
      "0.6731251381608739  ,  0.5722  ,  1.0326\n",
      "0.2989146477053237  ,  0.8421  ,  1.1946\n",
      "nan  ,  0.7692  ,  1.4957\n",
      "347\n",
      "0.5962172364658005  ,  0.7735  ,  1.3911\n",
      "0.09018618437492101  ,  1.0785  ,  1.5909\n",
      "-0.015119343962308861  ,  0.9691  ,  1.7655\n",
      "348\n",
      "0.4427253691922111  ,  1.6453  ,  1.5687\n",
      "0.14932173446403524  ,  1.1822  ,  2.0733\n",
      "nan  ,  1.1876  ,  2.0974\n",
      "349\n",
      "0.21684209427282825  ,  0.8678  ,  1.5642\n",
      "0.08482993810176456  ,  0.8815  ,  1.592\n",
      "nan  ,  0.8818  ,  1.5942\n",
      "350\n",
      "0.7457289007154051  ,  0.6948  ,  1.5105\n",
      "0.17533592330914197  ,  0.8827  ,  1.969\n",
      "-0.04645968715804271  ,  0.8928  ,  1.9592\n",
      "351\n",
      "0.5986626113996409  ,  1.1465  ,  1.919\n",
      "0.029001778316697955  ,  1.2285  ,  2.1301\n",
      "nan  ,  1.2285  ,  2.1302\n",
      "352\n",
      "0.4892657941062276  ,  0.8372  ,  1.3361\n",
      "0.2882875040646853  ,  0.8896  ,  1.6263\n",
      "nan  ,  0.888  ,  1.7709\n",
      "353\n",
      "0.6637130712132746  ,  0.3606  ,  1.2433\n",
      "nan  ,  0.4044  ,  1.446\n",
      "nan  ,  0.4044  ,  1.446\n",
      "354\n",
      "0.310377425849088  ,  0.9072  ,  1.5026\n",
      "0.1357701914165451  ,  0.9816  ,  1.5281\n",
      "0.04859669296523341  ,  1.0026  ,  1.5095\n",
      "355\n",
      "0.4123507062858683  ,  0.7314  ,  1.3702\n",
      "0.25866149389814785  ,  0.7684  ,  1.4586\n",
      "0.07261693795697684  ,  0.7799  ,  1.4625\n",
      "356\n",
      "0.6085773470865381  ,  0.6022  ,  1.5973\n",
      "0.22563656429338108  ,  0.6584  ,  1.8159\n",
      "nan  ,  0.6586  ,  1.8511\n",
      "357\n",
      "0.7094918083948689  ,  0.2939  ,  0.9847\n",
      "0.2230109665123542  ,  0.8026  ,  1.1803\n",
      "0.09486064086866147  ,  0.4728  ,  1.323\n",
      "358\n",
      "0.14778046963422606  ,  0.5812  ,  1.1573\n",
      "0.04147186909559614  ,  0.7163  ,  0.9917\n",
      "-0.0665572120864546  ,  0.6489  ,  1.0585\n",
      "359\n",
      "0.6124947994665365  ,  0.8156  ,  0.9611\n",
      "0.11994097436526187  ,  1.1299  ,  1.377\n",
      "-0.05212451662762406  ,  1.1501  ,  1.3428\n",
      "360\n",
      "0.729196305259697  ,  1.1107  ,  1.325\n",
      "0.5225717727679097  ,  1.1871  ,  2.1752\n",
      "nan  ,  1.26  ,  2.4055\n",
      "361\n",
      "0.6820573194216442  ,  0.7343  ,  1.2921\n",
      "-0.00648633886496019  ,  1.0018  ,  1.8843\n",
      "nan  ,  1.0051  ,  1.8886\n",
      "362\n",
      "0.2531301690695052  ,  0.579  ,  1.2426\n",
      "0.06508498864865327  ,  0.615  ,  1.2557\n",
      "0.020387194315656356  ,  0.6354  ,  1.2256\n",
      "363\n",
      "0.7622007881314617  ,  0.7875  ,  1.4115\n",
      "0.48890640814948827  ,  1.0376  ,  2.0649\n",
      "nan  ,  1.0609  ,  2.1441\n",
      "364\n",
      "0.6295007447266256  ,  0.8381  ,  1.1468\n",
      "0.03230674832886907  ,  0.4109  ,  1.3089\n",
      "nan  ,  0.4108  ,  1.3093\n",
      "365\n",
      "0.40181184037157375  ,  0.2787  ,  0.9365\n",
      "0.042820476792807344  ,  0.6483  ,  0.9531\n",
      "0.019524212246525882  ,  0.2973  ,  1.0293\n",
      "366\n",
      "0.6251852069248057  ,  0.5354  ,  1.4504\n",
      "0.08482400297998316  ,  0.6379  ,  1.8015\n",
      "nan  ,  0.6372  ,  1.8039\n",
      "367\n",
      "0.46842215471888343  ,  0.529  ,  1.0047\n",
      "0.1505541190510088  ,  0.6077  ,  1.1887\n",
      "0.03116046436230483  ,  0.6336  ,  1.1776\n",
      "368\n",
      "0.16239172159555326  ,  0.7966  ,  1.6099\n",
      "0.04296236511335336  ,  0.805  ,  1.6273\n",
      "nan  ,  0.8054  ,  1.6351\n",
      "369\n",
      "0.6769400007601276  ,  0.8477  ,  1.7754\n",
      "0.3213730256051692  ,  1.0329  ,  1.7913\n",
      "nan  ,  0.982  ,  2.0937\n",
      "370\n",
      "0.4082424249746092  ,  0.7691  ,  1.6034\n",
      "-0.02268967454263381  ,  0.8237  ,  1.8107\n",
      "nan  ,  0.8211  ,  1.8119\n",
      "371\n",
      "0.7742354877173542  ,  0.7013  ,  1.5569\n",
      "0.2670357565367113  ,  1.093  ,  2.1923\n",
      "-0.07032102937375395  ,  1.0184  ,  2.4026\n",
      "372\n",
      "0.5460845189933168  ,  0.5237  ,  1.5642\n",
      "0.17360057315683702  ,  0.566  ,  1.7184\n",
      "nan  ,  0.564  ,  1.7359\n",
      "373\n",
      "0.0648637848865669  ,  0.7299  ,  1.3579\n",
      "0.09411972818345803  ,  0.8066  ,  1.1933\n",
      "-0.04116356168220735  ,  0.7702  ,  1.2722\n",
      "374\n",
      "0.43855600908441217  ,  1.4647  ,  2.0654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32725603803470593  ,  1.5763  ,  2.2821\n",
      "nan  ,  1.624  ,  2.7311\n",
      "375\n",
      "0.7239263018682576  ,  0.7538  ,  1.3285\n",
      "0.32935941770372146  ,  1.2047  ,  1.7096\n",
      "nan  ,  0.9041  ,  2.2136\n",
      "376\n",
      "0.278178453192643  ,  0.9019  ,  1.8911\n",
      "0.04806428349264554  ,  0.9522  ,  1.9331\n",
      "nan  ,  0.9349  ,  1.9727\n",
      "377\n",
      "0.28731686060139683  ,  0.7268  ,  1.4005\n",
      "-0.018306073425127155  ,  0.8249  ,  1.4251\n",
      "0.02854158832781939  ,  0.8169  ,  1.3891\n",
      "378\n",
      "0.5515588237176083  ,  0.9234  ,  1.2063\n",
      "0.48287604890232205  ,  1.178  ,  1.5001\n",
      "-0.34558285453750553  ,  1.2694  ,  1.2731\n",
      "379\n",
      "0.4062329626559287  ,  0.7967  ,  1.4375\n",
      "0.14493303842491334  ,  0.8571  ,  1.5167\n",
      "nan  ,  0.856  ,  1.5604\n",
      "380\n",
      "0.6295976313679778  ,  1.1329  ,  1.7283\n",
      "0.07008149183429142  ,  1.3213  ,  2.4205\n",
      "nan  ,  1.2932  ,  2.507\n",
      "381\n",
      "0.16817817643940886  ,  0.4833  ,  1.2399\n",
      "0.015822346157732113  ,  0.4878  ,  1.2576\n",
      "-0.03570596242599758  ,  0.5341  ,  1.2061\n",
      "382\n",
      "0.6867411708591336  ,  1.185  ,  2.1398\n",
      "0.46552378333994393  ,  1.5002  ,  1.8593\n",
      "nan  ,  1.3618  ,  2.6171\n",
      "383\n",
      "0.24215795549074443  ,  2.2838  ,  2.2566\n",
      "0.03420726174325993  ,  0.7043  ,  1.4034\n",
      "nan  ,  0.6506  ,  1.4881\n",
      "384\n",
      "0.6346744848845055  ,  1.0476  ,  1.389\n",
      "0.05776014977905032  ,  0.6391  ,  1.4637\n",
      "0.12564665459120689  ,  0.6681  ,  1.4308\n",
      "385\n",
      "0.6350776622704282  ,  0.9468  ,  1.1201\n",
      "-0.0368645911900119  ,  0.9839  ,  1.7536\n",
      "0.01969940228007637  ,  0.9789  ,  1.7544\n",
      "386\n",
      "0.7149018394777424  ,  0.3982  ,  0.9241\n",
      "0.07381993451740326  ,  1.2026  ,  0.8166\n",
      "0.28320664165843346  ,  0.8036  ,  1.0492\n",
      "387\n",
      "0.045178323423480334  ,  1.0162  ,  1.9411\n",
      "0.11371629118895984  ,  1.2734  ,  1.516\n",
      "0.06684225141378763  ,  1.1018  ,  1.777\n",
      "388\n",
      "0.6347490529284975  ,  0.6733  ,  1.0723\n",
      "0.15055708823982045  ,  1.0354  ,  1.138\n",
      "0.10248252824165222  ,  0.9674  ,  1.4401\n",
      "389\n",
      "0.3029603623976825  ,  1.2152  ,  1.6515\n",
      "0.015678806911318465  ,  1.483  ,  1.3837\n",
      "0.029165604383708466  ,  1.3427  ,  1.7462\n",
      "390\n",
      "0.16550969792626924  ,  0.735  ,  1.6454\n",
      "0.04386538040265409  ,  0.7493  ,  1.661\n",
      "nan  ,  0.7476  ,  1.6644\n",
      "391\n",
      "0.11978328258187568  ,  0.6232  ,  1.5663\n",
      "0.20005334136536793  ,  0.6284  ,  1.5425\n",
      "0.0697032369666058  ,  0.6301  ,  1.5625\n",
      "392\n",
      "0.8432081996903691  ,  0.5465  ,  0.8989\n",
      "0.13408165740952904  ,  0.914  ,  1.9124\n",
      "nan  ,  0.9138  ,  1.9164\n",
      "393\n",
      "0.8165497176593376  ,  0.2937  ,  1.3597\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "394\n",
      "0.6425179209037013  ,  0.8375  ,  1.3624\n",
      "0.38333851498923655  ,  0.8644  ,  1.9301\n",
      "nan  ,  0.8851  ,  2.083\n",
      "395\n",
      "0.5576395459513661  ,  0.878  ,  1.8517\n",
      "0.05942339121897411  ,  0.995  ,  2.0539\n",
      "nan  ,  0.962  ,  2.1165\n",
      "396\n",
      "0.012817325646936936  ,  0.9585  ,  1.8108\n",
      "0.07726354848831045  ,  0.9565  ,  1.8048\n",
      "0.07645586263122903  ,  0.9696  ,  1.781\n",
      "397\n",
      "0.6475378936890832  ,  0.7679  ,  1.3615\n",
      "-0.07479055008660253  ,  0.9875  ,  1.5583\n",
      "nan  ,  0.8937  ,  1.6115\n",
      "398\n",
      "0.728451722333013  ,  0.609  ,  1.339\n",
      "0.04184492452310115  ,  0.7716  ,  1.8166\n",
      "nan  ,  0.7659  ,  1.8275\n",
      "399\n",
      "0.5562090668197754  ,  3.6265  ,  3.3886\n",
      "0.0269757789402315  ,  0.6707  ,  2.2132\n",
      "nan  ,  0.6587  ,  2.2224\n",
      "400\n",
      "0.8529763704033684  ,  0.5764  ,  1.0196\n",
      "0.17828107720907388  ,  0.9302  ,  2.1528\n",
      "nan  ,  0.9001  ,  2.2427\n",
      "401\n",
      "0.7775743863441785  ,  0.469  ,  1.0645\n",
      "0.19357151789195853  ,  0.5968  ,  1.4534\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "402\n",
      "0.27364606598107766  ,  1.5044  ,  2.0525\n",
      "0.3253728036518073  ,  1.4993  ,  2.0366\n",
      "0.2026792435353827  ,  1.5315  ,  2.0774\n",
      "403\n",
      "0.8993759254128859  ,  0.7399  ,  1.8943\n",
      "0.7813663179691669  ,  1.2123  ,  2.3137\n",
      "-0.032138679427176645  ,  1.4142  ,  2.7787\n",
      "404\n",
      "0.6414947889308227  ,  0.7591  ,  1.1231\n",
      "0.2722800872912319  ,  0.9547  ,  1.5768\n",
      "nan  ,  0.9597  ,  1.7002\n",
      "405\n",
      "0.6465986821877634  ,  0.8452  ,  1.6866\n",
      "0.11709785208381078  ,  0.9611  ,  1.9928\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "406\n",
      "0.6402460816148371  ,  0.7881  ,  1.5957\n",
      "0.012195102863673896  ,  0.9541  ,  2.2486\n",
      "0.16185966892848697  ,  0.9621  ,  2.2363\n",
      "407\n",
      "0.5455840279772557  ,  1.209  ,  2.5073\n",
      "0.4568720974681043  ,  1.2542  ,  2.5001\n",
      "nan  ,  1.2703  ,  2.6999\n",
      "408\n",
      "0.3727498202585802  ,  0.7759  ,  1.6227\n",
      "nan  ,  0.8393  ,  1.7605\n",
      "nan  ,  0.8393  ,  1.7605\n",
      "409\n",
      "0.06507779692673019  ,  1.2995  ,  2.0339\n",
      "0.1883209145940414  ,  1.2986  ,  2.0209\n",
      "0.1996297620354603  ,  1.3064  ,  2.0379\n",
      "410\n",
      "0.3272570901590827  ,  0.3432  ,  1.2677\n",
      "0.20413948230101037  ,  1.4975  ,  1.6362\n",
      "nan  ,  0.3307  ,  1.3698\n",
      "411\n",
      "0.6720239257585189  ,  0.6362  ,  1.0801\n",
      "0.26312925596349673  ,  0.8421  ,  1.5925\n",
      "0.0635166148785381  ,  0.8589  ,  1.5773\n",
      "412\n",
      "0.5712560333785581  ,  0.6452  ,  1.2351\n",
      "0.2013928292927546  ,  0.7363  ,  1.4338\n",
      "-0.1697347713850756  ,  0.7875  ,  1.4285\n",
      "413\n",
      "0.36171492247559733  ,  0.6973  ,  1.5392\n",
      "0.1324946533118186  ,  0.73  ,  1.5783\n",
      "nan  ,  0.7292  ,  1.6047\n",
      "414\n",
      "0.16716683452214828  ,  0.4391  ,  1.1223\n",
      "0.16973768447372656  ,  0.4943  ,  1.0591\n",
      "-0.0762523499927624  ,  0.5101  ,  1.0714\n",
      "415\n",
      "0.5316036498840544  ,  1.0412  ,  1.1694\n",
      "0.14756329532170545  ,  0.983  ,  1.6464\n",
      "-0.12276044726940194  ,  0.9914  ,  1.6579\n",
      "416\n",
      "0.5421445703974437  ,  0.8137  ,  1.279\n",
      "0.309162208214683  ,  1.0243  ,  1.3639\n",
      "-0.04650731878431857  ,  0.902  ,  1.7573\n",
      "417\n",
      "0.5447719139858406  ,  0.5085  ,  1.2162\n",
      "0.21269330593658786  ,  1.0692  ,  0.9559\n",
      "nan  ,  0.5942  ,  1.4205\n",
      "418\n",
      "0.3066249712826406  ,  0.6958  ,  2.1631\n",
      "0.14443072566148232  ,  2.048  ,  1.7372\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "419\n",
      "0.6537803114480363  ,  0.7919  ,  1.3758\n",
      "0.2636376056749804  ,  0.9489  ,  1.7299\n",
      "nan  ,  0.9621  ,  1.7865\n",
      "420\n",
      "0.31461809704641863  ,  0.45  ,  1.2109\n",
      "0.020194354314173407  ,  0.4566  ,  1.2362\n",
      "0.04940624019215317  ,  0.4727  ,  1.2194\n",
      "421\n",
      "0.44226685055139636  ,  0.6025  ,  1.1008\n",
      "0.10920459455527054  ,  0.439  ,  1.1417\n",
      "0.038385113842177444  ,  0.4591  ,  1.1261\n",
      "422\n",
      "0.3915366101509742  ,  0.8549  ,  1.1703\n",
      "0.12736686176853831  ,  0.9315  ,  1.2544\n",
      "0.013198043413265154  ,  0.9405  ,  1.2268\n",
      "423\n",
      "0.6533091505429798  ,  0.9907  ,  1.2632\n",
      "-0.028761349901307312  ,  0.7722  ,  1.6714\n",
      "0.044068504328932494  ,  0.8013  ,  1.6114\n",
      "424\n",
      "0.7546045974813088  ,  0.5719  ,  0.9631\n",
      "-0.04280283826070591  ,  0.6247  ,  1.5296\n",
      "0.07692961597175386  ,  0.6392  ,  1.5105\n",
      "425\n",
      "0.3612740851299017  ,  1.2271  ,  1.6821\n",
      "0.24165547987705943  ,  1.3747  ,  1.8662\n",
      "0.2699695010833587  ,  1.3837  ,  1.8628\n",
      "426\n",
      "0.4264621185439271  ,  0.3682  ,  1.0614\n",
      "-0.19915389020809912  ,  1.9499  ,  0.7965\n",
      "-0.09575292752799788  ,  0.6166  ,  0.9108\n",
      "427\n",
      "0.09891366235745393  ,  0.3441  ,  1.0089\n",
      "0.06669946567736919  ,  0.3869  ,  0.9825\n",
      "-0.017261197992084688  ,  0.3568  ,  0.999\n",
      "428\n",
      "0.7629461443441379  ,  0.434  ,  0.9233\n",
      "0.05154888040394624  ,  0.7136  ,  1.2124\n",
      "nan  ,  0.6046  ,  1.3573\n",
      "429\n",
      "0.17546989557100307  ,  0.4556  ,  1.7189\n",
      "0.34642618233185635  ,  0.5645  ,  1.5489\n",
      "nan  ,  0.4602  ,  1.7395\n",
      "430\n",
      "0.4486071608188557  ,  1.0368  ,  1.3542\n",
      "-0.030503756697378426  ,  1.1351  ,  1.8367\n",
      "-0.07574178259172756  ,  1.1563  ,  1.74\n",
      "431\n",
      "0.5033521884308683  ,  0.302  ,  0.7372\n",
      "0.07262125367969674  ,  0.5922  ,  0.7281\n",
      "0.029833244580326067  ,  0.2952  ,  0.8731\n",
      "432\n",
      "0.11759069404495817  ,  1.1666  ,  1.7432\n",
      "-0.010205850349985621  ,  1.1687  ,  1.7474\n",
      "-0.035510730498008854  ,  1.17  ,  1.654\n",
      "433\n",
      "0.5719349981574149  ,  0.6503  ,  1.8329\n",
      "0.28461197745441275  ,  0.7148  ,  2.0319\n",
      "nan  ,  0.7174  ,  2.0959\n",
      "434\n",
      "0.5048442764951184  ,  0.2247  ,  0.6273\n",
      "0.10710511840871353  ,  0.6754  ,  0.6221\n",
      "-0.11275302251913616  ,  0.3886  ,  0.6324\n",
      "435\n",
      "0.5697904712059059  ,  0.4982  ,  0.8995\n",
      "-0.07196570065960664  ,  0.7407  ,  0.9181\n",
      "nan  ,  0.5723  ,  1.0996\n",
      "436\n",
      "0.7060466794574791  ,  0.7868  ,  1.0963\n",
      "0.026460273876264123  ,  0.9725  ,  1.8969\n",
      "-0.1103039181720888  ,  0.9767  ,  1.8904\n",
      "437\n",
      "0.460981771957469  ,  0.4944  ,  1.0763\n",
      "0.07454476536585707  ,  0.5736  ,  1.209\n",
      "nan  ,  0.5194  ,  1.2783\n",
      "438\n",
      "0.5098921830878034  ,  0.4797  ,  1.1377\n",
      "0.00289633666596998  ,  0.5483  ,  1.2829\n",
      "-0.04705710505294332  ,  0.5784  ,  1.2424\n",
      "439\n",
      "0.7708956002701437  ,  0.6828  ,  1.0232\n",
      "0.3255365992544355  ,  0.926  ,  1.7621\n",
      "nan  ,  0.9366  ,  1.8831\n",
      "440\n",
      "0.188132347745389  ,  0.3846  ,  1.174\n",
      "-0.002047905633047277  ,  0.3621  ,  1.2084\n",
      "nan  ,  0.3609  ,  1.2092\n",
      "441\n",
      "0.3706356121482433  ,  0.6945  ,  1.3276\n",
      "-0.02687341677337648  ,  0.7188  ,  1.3806\n",
      "0.142350699796566  ,  0.7752  ,  1.2599\n",
      "442\n",
      "0.2748229543979872  ,  0.6709  ,  2.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1861735909408541  ,  0.7056  ,  2.0758\n",
      "nan  ,  0.6747  ,  2.143\n",
      "443\n",
      "0.526131806338556  ,  0.9334  ,  1.6108\n",
      "0.25407014619011437  ,  1.0323  ,  1.9643\n",
      "nan  ,  1.0097  ,  2.1361\n",
      "444\n",
      "0.6891603246723035  ,  1.2786  ,  1.558\n",
      "0.0798278148174287  ,  0.7696  ,  1.6857\n",
      "nan  ,  0.7703  ,  1.6875\n",
      "445\n",
      "0.49440303045914447  ,  0.3233  ,  1.0974\n",
      "0.18718197715628213  ,  0.3184  ,  1.2494\n",
      "nan  ,  0.2958  ,  1.2878\n",
      "446\n",
      "0.5314667465348475  ,  0.5917  ,  1.8871\n",
      "0.2667774587998508  ,  0.9409  ,  1.918\n",
      "nan  ,  0.6548  ,  2.2088\n",
      "447\n",
      "0.4753178752202224  ,  1.1021  ,  2.3512\n",
      "-0.03800889102333172  ,  1.153  ,  2.4833\n",
      "-0.14609260308575056  ,  1.1646  ,  2.4585\n",
      "448\n",
      "0.18464322692238444  ,  0.3318  ,  1.022\n",
      "0.19041345643187269  ,  0.4854  ,  0.926\n",
      "-0.08874769466111558  ,  0.415  ,  0.9699\n",
      "449\n",
      "0.6022707519635471  ,  0.5106  ,  1.1162\n",
      "nan  ,  0.5997  ,  1.5091\n",
      "nan  ,  0.5997  ,  1.5091\n",
      "450\n",
      "0.02327719069326532  ,  0.8616  ,  2.409\n",
      "-0.004813275835191132  ,  0.8619  ,  2.4096\n",
      "nan  ,  0.8619  ,  2.4096\n",
      "451\n",
      "0.2123615011576205  ,  0.9598  ,  2.0611\n",
      "0.27658360393744597  ,  0.7595  ,  2.0336\n",
      "nan  ,  0.753  ,  2.0771\n",
      "452\n",
      "0.4012440328108543  ,  1.0783  ,  1.5194\n",
      "0.3248602276308919  ,  1.1178  ,  1.5279\n",
      "nan  ,  1.1735  ,  1.6495\n",
      "453\n",
      "0.6482470169872709  ,  0.6579  ,  1.3159\n",
      "0.08985202321617022  ,  0.7862  ,  1.8126\n",
      "-0.007775806095626276  ,  0.819  ,  1.7894\n",
      "454\n",
      "0.6793712460795551  ,  0.5621  ,  1.3309\n",
      "0.017915309750238452  ,  0.6298  ,  1.8928\n",
      "nan  ,  0.5747  ,  1.9301\n",
      "455\n",
      "0.479067415566959  ,  0.7356  ,  1.0862\n",
      "0.09799074123031842  ,  0.8721  ,  1.3701\n",
      "-0.0017201717688671812  ,  0.891  ,  1.3562\n",
      "456\n",
      "0.5315820082797391  ,  1.0085  ,  1.0048\n",
      "-0.03355211194502351  ,  1.0265  ,  1.4579\n",
      "0.09341568773891717  ,  1.0172  ,  1.379\n",
      "457\n",
      "0.4740409998699497  ,  1.0601  ,  1.2689\n",
      "0.2682299830449647  ,  0.8819  ,  0.875\n",
      "0.03771685921571304  ,  0.6129  ,  1.1369\n",
      "458\n",
      "0.6950542354275566  ,  0.6072  ,  1.023\n",
      "0.027751141327012244  ,  0.8042  ,  1.6074\n",
      "-0.10870066722416029  ,  0.8049  ,  1.6038\n",
      "459\n",
      "0.5846361343452531  ,  0.8305  ,  1.4955\n",
      "0.3119531958583801  ,  0.8776  ,  1.5223\n",
      "nan  ,  0.9004  ,  1.6364\n",
      "460\n",
      "0.36361523200345913  ,  0.5288  ,  1.2655\n",
      "0.11753873180494886  ,  0.5615  ,  1.3534\n",
      "-0.03247469426733533  ,  0.6971  ,  1.2168\n",
      "461\n",
      "0.5839119684595425  ,  0.4104  ,  0.9519\n",
      "0.08217550001017074  ,  0.4833  ,  1.1622\n",
      "0.057027443225713285  ,  0.5295  ,  1.1144\n",
      "462\n",
      "0.35148140259645383  ,  0.5827  ,  1.3492\n",
      "-0.0025991360013133853  ,  0.7199  ,  1.2803\n",
      "-0.1016538711069458  ,  0.6134  ,  1.3945\n",
      "463\n",
      "0.5819213415314796  ,  0.5881  ,  0.922\n",
      "0.13804599917577604  ,  0.8155  ,  1.0149\n",
      "0.015779795520586684  ,  0.6539  ,  1.1649\n",
      "464\n",
      "0.09152344782629486  ,  0.9887  ,  1.7034\n",
      "0.008985319161744285  ,  0.9999  ,  1.7117\n",
      "-0.02902553092536658  ,  1.0932  ,  1.4631\n",
      "465\n",
      "0.2961666597287733  ,  0.9589  ,  1.5329\n",
      "-0.18100757649051472  ,  1.1924  ,  1.2131\n",
      "-0.24539056508871188  ,  1.0483  ,  1.3798\n",
      "466\n",
      "0.3408461990396233  ,  0.7018  ,  1.5139\n",
      "0.08187822732999403  ,  0.8175  ,  1.4465\n",
      "nan  ,  0.5033  ,  1.4638\n",
      "467\n",
      "0.61224424829355  ,  0.9546  ,  1.3576\n",
      "0.1487049017481315  ,  1.2489  ,  1.8308\n",
      "nan  ,  1.2576  ,  1.8461\n",
      "468\n",
      "0.3713734217328778  ,  0.7872  ,  1.6205\n",
      "0.04900636455003035  ,  0.7108  ,  1.8471\n",
      "-0.01853562227562038  ,  0.7282  ,  1.8275\n",
      "469\n",
      "0.6316251065784759  ,  0.6797  ,  1.5784\n",
      "0.046603223892058517  ,  0.8004  ,  2.0792\n",
      "nan  ,  0.7947  ,  2.0891\n",
      "470\n",
      "0.4349811340528408  ,  0.7867  ,  1.3417\n",
      "0.050520563829072856  ,  1.1307  ,  1.2565\n",
      "0.17133744603759643  ,  0.9692  ,  1.4314\n",
      "471\n",
      "0.8382968522129847  ,  0.6084  ,  1.1296\n",
      "0.025480759867903897  ,  0.9521  ,  2.1235\n",
      "nan  ,  0.9403  ,  2.1437\n",
      "472\n",
      "0.3927006187335619  ,  0.5571  ,  1.2251\n",
      "0.041776661092539524  ,  0.5444  ,  1.3783\n",
      "0.06009712153431028  ,  0.5525  ,  1.3702\n",
      "473\n",
      "0.6608702291931272  ,  0.6699  ,  1.3021\n",
      "0.33599048744192583  ,  0.8894  ,  1.4252\n",
      "nan  ,  0.8222  ,  1.7002\n",
      "474\n",
      "0.6415598736464424  ,  1.2176  ,  1.5614\n",
      "0.18452372195380579  ,  1.4543  ,  2.2507\n",
      "nan  ,  1.4654  ,  2.4262\n",
      "475\n",
      "0.7389132984645769  ,  0.8351  ,  1.0232\n",
      "0.40026141380533653  ,  1.2329  ,  1.3445\n",
      "-0.09839320157549936  ,  1.1558  ,  1.9032\n",
      "476\n",
      "0.759064879497556  ,  0.9955  ,  1.3701\n",
      "0.2836278361257917  ,  1.0807  ,  2.0242\n",
      "nan  ,  1.0756  ,  2.1925\n",
      "477\n",
      "0.30112026427638294  ,  0.5195  ,  1.3655\n",
      "0.145085000399227  ,  0.6648  ,  1.252\n",
      "nan  ,  0.5335  ,  1.4008\n",
      "478\n",
      "0.33200682816732574  ,  1.1778  ,  1.7663\n",
      "0.4513445689580258  ,  1.145  ,  1.7271\n",
      "-0.04894687772147885  ,  1.2308  ,  2.0851\n",
      "479\n",
      "0.6868154280946916  ,  0.7245  ,  1.0991\n",
      "-0.0006541111619360399  ,  0.7887  ,  1.8062\n",
      "nan  ,  0.7886  ,  1.8062\n",
      "480\n",
      "0.7924607557849652  ,  1.094  ,  1.0523\n",
      "-0.04331339040246031  ,  2.08  ,  2.3941\n",
      "0.2191134132255967  ,  2.0485  ,  2.362\n",
      "481\n",
      "0.10248780220871453  ,  1.0611  ,  1.9117\n",
      "0.03516754347268501  ,  1.1962  ,  1.7244\n",
      "nan  ,  1.0687  ,  1.9416\n",
      "482\n",
      "0.2720902569302009  ,  0.6279  ,  1.275\n",
      "0.035454748602381424  ,  0.6453  ,  1.2645\n",
      "-0.04985532870097212  ,  0.6593  ,  1.2425\n",
      "483\n",
      "0.46786922542752196  ,  0.6327  ,  1.8744\n",
      "0.05341235108969268  ,  0.6977  ,  2.0862\n",
      "nan  ,  0.6811  ,  2.1043\n",
      "484\n",
      "0.17173862508509397  ,  0.695  ,  1.7987\n",
      "0.1043515127301967  ,  0.7543  ,  1.7288\n",
      "0.013542348653513336  ,  0.7155  ,  1.7901\n",
      "485\n",
      "0.6151214857876991  ,  0.8737  ,  1.1803\n",
      "0.10849125330738964  ,  1.1172  ,  1.6756\n",
      "0.0838383562197273  ,  1.1221  ,  1.6538\n",
      "486\n",
      "0.5629345324091408  ,  0.7556  ,  1.495\n",
      "0.02456215520116  ,  0.8152  ,  1.6772\n",
      "nan  ,  0.815  ,  1.6781\n",
      "487\n",
      "0.3338424660915159  ,  0.4489  ,  1.7344\n",
      "0.08571744755960378  ,  0.4557  ,  1.7758\n",
      "nan  ,  0.4539  ,  1.7793\n",
      "488\n",
      "0.20318393666654963  ,  0.7599  ,  1.6558\n",
      "0.014834637841806855  ,  1.1511  ,  1.3891\n",
      "0.17594996101291  ,  0.8967  ,  1.5032\n",
      "489\n",
      "0.15047578854266694  ,  1.7473  ,  2.4702\n",
      "0.06531314354624453  ,  1.9082  ,  2.184\n",
      "nan  ,  1.7928  ,  2.5835\n",
      "490\n",
      "0.4360136070931876  ,  0.9253  ,  1.1672\n",
      "0.022800641820892385  ,  0.7035  ,  1.4748\n",
      "-0.08699030521746803  ,  0.6998  ,  1.4809\n",
      "491\n",
      "0.5918802530812572  ,  1.3001  ,  1.3416\n",
      "0.010460877833668489  ,  1.447  ,  2.039\n",
      "0.20020631365371774  ,  1.4416  ,  2.0191\n",
      "492\n",
      "0.6735331669035203  ,  0.4423  ,  1.182\n",
      "0.08514922855070069  ,  0.5837  ,  1.4787\n",
      "nan  ,  0.5235  ,  1.5411\n",
      "493\n",
      "0.48161047698212367  ,  0.7568  ,  1.2601\n",
      "0.11903739307632971  ,  0.7801  ,  1.3112\n",
      "0.07688774748887914  ,  0.8022  ,  1.2774\n",
      "494\n",
      "0.2578337859198486  ,  0.4728  ,  1.3804\n",
      "0.06263693894598765  ,  0.6576  ,  1.282\n",
      "0.04074066939582714  ,  0.4849  ,  1.3809\n",
      "495\n",
      "0.5368767770861835  ,  1.216  ,  1.9422\n",
      "0.09070736613263836  ,  0.4827  ,  1.4302\n",
      "nan  ,  0.4024  ,  1.4817\n",
      "496\n",
      "0.6402281550065163  ,  1.0047  ,  1.7613\n",
      "0.012722291075345619  ,  1.2449  ,  2.2574\n",
      "0.048412245564220864  ,  1.2591  ,  2.2128\n",
      "497\n",
      "0.639982438836385  ,  1.0852  ,  1.4165\n",
      "-0.016604029696992696  ,  0.7198  ,  1.3684\n",
      "-0.048810319110667154  ,  0.7345  ,  1.3338\n",
      "498\n",
      "0.25983834769403324  ,  0.6789  ,  1.9633\n",
      "0.23277750155978988  ,  1.1195  ,  1.6486\n",
      "nan  ,  0.6864  ,  1.9911\n",
      "499\n",
      "0.6388580492717375  ,  0.8596  ,  2.2996\n",
      "0.1771544578389686  ,  1.0117  ,  2.807\n",
      "nan  ,  1.0159  ,  2.8372\n",
      "500\n",
      "0.6072293260992736  ,  0.769  ,  1.5974\n",
      "0.17510718301203615  ,  0.7483  ,  2.1478\n",
      "nan  ,  0.7438  ,  2.1814\n",
      "501\n",
      "0.10550445292386752  ,  0.3281  ,  1.0917\n",
      "0.040418152665022855  ,  0.3869  ,  1.0517\n",
      "-0.04033863559904694  ,  0.4059  ,  1.0382\n",
      "502\n",
      "0.5490622567428967  ,  0.9595  ,  1.0702\n",
      "-0.015934882701985648  ,  1.1054  ,  1.6243\n",
      "0.03264343660567366  ,  1.1037  ,  1.6125\n",
      "503\n",
      "0.24397745267196333  ,  0.2935  ,  1.0581\n",
      "0.04527485401556022  ,  0.2974  ,  1.0679\n",
      "-0.18519411163770944  ,  0.3072  ,  1.0635\n",
      "504\n",
      "0.08361758074772424  ,  0.525  ,  1.3823\n",
      "0.17399214710961  ,  0.5483  ,  1.3231\n",
      "-0.032545576704750924  ,  0.6578  ,  1.252\n",
      "505\n",
      "0.7000522563227821  ,  0.6166  ,  1.2683\n",
      "0.5392757746921167  ,  0.7564  ,  1.4177\n",
      "0.13541192379963568  ,  0.8459  ,  1.4697\n",
      "506\n",
      "0.5112920185934392  ,  1.291  ,  2.0678\n",
      "0.22910175691450307  ,  1.3922  ,  2.0995\n",
      "-0.22467896778268867  ,  1.4254  ,  2.242\n",
      "507\n",
      "0.4473728808992427  ,  0.7383  ,  1.3769\n",
      "0.3112676359517842  ,  0.8928  ,  1.2348\n",
      "0.09793523041905322  ,  0.839  ,  1.4601\n",
      "508\n",
      "0.02886762200929669  ,  0.9852  ,  2.0216\n",
      "0.2649419174403914  ,  1.0049  ,  1.8146\n",
      "0.1457405424697572  ,  1.0157  ,  1.9614\n",
      "509\n",
      "0.7118145206456332  ,  0.5627  ,  1.1245\n",
      "0.06658339800627625  ,  0.6635  ,  1.779\n",
      "nan  ,  0.6606  ,  1.7862\n",
      "510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7589041489329418  ,  0.5888  ,  1.2972\n",
      "0.007652404806955826  ,  0.8526  ,  1.73\n",
      "0.016596172520264754  ,  0.7955  ,  1.8053\n",
      "511\n",
      "0.29041263066419826  ,  0.8291  ,  1.734\n",
      "0.025057811586777088  ,  2.3673  ,  1.6655\n",
      "nan  ,  0.1237  ,  0.7853\n",
      "512\n",
      "0.5414609912850725  ,  0.4175  ,  1.0652\n",
      "0.12851301798747364  ,  0.6938  ,  1.0697\n",
      "0.12041152224858893  ,  0.6094  ,  1.1478\n",
      "513\n",
      "0.08329732730337235  ,  0.8747  ,  1.5586\n",
      "-0.016031030321444706  ,  0.8909  ,  1.5363\n",
      "nan  ,  0.8779  ,  1.5636\n",
      "514\n",
      "0.592705506277813  ,  0.5146  ,  1.0802\n",
      "0.0548949142656988  ,  0.7161  ,  1.3446\n",
      "-0.03487157808010346  ,  0.614  ,  1.4339\n",
      "515\n",
      "0.4300085120050199  ,  1.401  ,  2.0776\n",
      "0.31854478349717685  ,  1.4336  ,  1.9776\n",
      "-0.007592642322518207  ,  1.5039  ,  2.2546\n",
      "516\n",
      "0.723024804928222  ,  0.7965  ,  1.2814\n",
      "0.3231204407931152  ,  0.9644  ,  2.0549\n",
      "nan  ,  0.9795  ,  2.1574\n",
      "517\n",
      "0.750039484911501  ,  1.0295  ,  1.7167\n",
      "0.2264251134057052  ,  1.4029  ,  2.3574\n",
      "nan  ,  1.3938  ,  2.5139\n",
      "518\n",
      "0.48091975500921275  ,  0.6686  ,  1.4682\n",
      "0.14848168966084724  ,  0.7301  ,  1.6111\n",
      "0.07201591539939911  ,  0.7753  ,  1.5761\n",
      "519\n",
      "0.321122681732008  ,  0.3889  ,  1.0825\n",
      "0.11657377665800726  ,  0.724  ,  0.9693\n",
      "-0.026662909149998203  ,  0.4405  ,  1.1065\n",
      "520\n",
      "0.6399183489122119  ,  0.5381  ,  1.0632\n",
      "0.2223911448256335  ,  0.646  ,  1.4228\n",
      "nan  ,  0.6501  ,  1.4329\n",
      "521\n",
      "0.4246062883467203  ,  0.618  ,  1.2981\n",
      "0.10251866428240344  ,  0.6721  ,  1.4194\n",
      "-0.02287615639868085  ,  0.7401  ,  1.3261\n",
      "522\n",
      "0.6935882589145753  ,  0.4539  ,  1.2754\n",
      "0.09965074269170533  ,  0.5493  ,  1.6236\n",
      "nan  ,  0.5151  ,  1.664\n",
      "523\n",
      "0.6917188099382894  ,  0.5187  ,  1.4068\n",
      "0.27259340072286153  ,  0.6517  ,  1.8248\n",
      "-0.03456538031582551  ,  0.6571  ,  1.8885\n",
      "524\n",
      "0.7522063748416787  ,  0.5313  ,  1.3037\n",
      "-0.0002750866978340105  ,  0.7339  ,  1.927\n",
      "-0.07585677833443369  ,  0.7423  ,  1.9168\n",
      "525\n",
      "0.13419628246661813  ,  0.5558  ,  1.5134\n",
      "-0.0028899023940253893  ,  0.5821  ,  1.5051\n",
      "nan  ,  0.56  ,  1.5225\n",
      "526\n",
      "0.5536880898639264  ,  0.8091  ,  1.5182\n",
      "0.22137283794144547  ,  0.8795  ,  1.6499\n",
      "-0.0775233914865272  ,  0.8992  ,  1.6516\n",
      "527\n",
      "0.6251606519427215  ,  0.7976  ,  1.6444\n",
      "0.18331138483474593  ,  1.0065  ,  2.1113\n",
      "0.11142521568786429  ,  1.0093  ,  2.1475\n",
      "528\n",
      "0.5164392526134723  ,  0.4068  ,  0.7714\n",
      "0.05046452832419587  ,  0.4897  ,  0.9493\n",
      "nan  ,  0.4804  ,  0.9696\n",
      "529\n",
      "0.16809813696999074  ,  1.2309  ,  1.705\n",
      "0.05984364407790776  ,  1.2334  ,  1.4311\n",
      "-0.03819706931109924  ,  1.2298  ,  1.6043\n",
      "530\n",
      "0.6650306067648375  ,  0.5582  ,  1.0776\n",
      "-0.08147587780510784  ,  0.7577  ,  1.5878\n",
      "-0.08100523732665395  ,  0.8171  ,  1.4753\n",
      "531\n",
      "0.4149765145890972  ,  1.4449  ,  2.1793\n",
      "0.20396017645606002  ,  1.519  ,  2.2802\n",
      "nan  ,  1.5254  ,  2.2955\n",
      "532\n",
      "0.29124546507861687  ,  2.5375  ,  2.5084\n",
      "0.043569073938850775  ,  0.7547  ,  1.5025\n",
      "0.011750886282427646  ,  0.8319  ,  1.3643\n",
      "533\n",
      "0.5199619869340241  ,  1.1887  ,  1.8863\n",
      "0.13956714173563356  ,  0.6391  ,  1.9188\n",
      "nan  ,  0.6403  ,  1.9255\n",
      "534\n",
      "0.8490416823878907  ,  0.6962  ,  1.3536\n",
      "0.3404168047696905  ,  1.1077  ,  2.3523\n",
      "nan  ,  1.1142  ,  2.3723\n",
      "535\n",
      "0.6956782988299871  ,  0.9444  ,  1.9135\n",
      "0.048815948679281254  ,  1.2229  ,  2.8461\n",
      "nan  ,  1.2035  ,  2.8847\n",
      "536\n",
      "0.4808727383899979  ,  1.007  ,  1.5121\n",
      "0.16141940461659998  ,  0.6927  ,  1.6145\n",
      "nan  ,  0.6937  ,  1.6342\n",
      "537\n",
      "0.1194762981566605  ,  0.8945  ,  1.7755\n",
      "0.08596798712554288  ,  0.8924  ,  1.7579\n",
      "-0.11253594363987654  ,  0.9162  ,  1.7377\n",
      "538\n",
      "0.52882551006741  ,  0.2935  ,  0.8687\n",
      "0.12364809780912081  ,  0.5414  ,  0.8471\n",
      "-0.06032568896282969  ,  0.4456  ,  0.8881\n",
      "539\n",
      "0.07336796848160551  ,  0.492  ,  1.4848\n",
      "0.3284858749342955  ,  0.5129  ,  1.3776\n",
      "0.04053952791014552  ,  0.4963  ,  1.4834\n",
      "540\n",
      "0.7488305026326447  ,  0.6013  ,  1.2163\n",
      "0.06938185673382839  ,  0.8207  ,  1.6421\n",
      "0.1404481465497247  ,  0.8596  ,  1.5751\n",
      "541\n",
      "0.7172068200181536  ,  0.5622  ,  1.0699\n",
      "0.04530900887359509  ,  0.6233  ,  1.6502\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "542\n",
      "0.5590875102132862  ,  0.9773  ,  1.0525\n",
      "-0.009836484629974608  ,  1.3015  ,  1.6855\n",
      "-0.10764628476599383  ,  1.2922  ,  1.6423\n",
      "543\n",
      "0.08085662938884211  ,  0.7712  ,  1.5897\n",
      "0.01976194606071178  ,  0.952  ,  1.3243\n",
      "-0.08849639490064445  ,  0.8461  ,  1.465\n",
      "544\n",
      "0.5080627575701439  ,  0.5568  ,  0.9997\n",
      "0.09533704218335916  ,  0.6097  ,  1.2494\n",
      "-0.07099519273440492  ,  0.7559  ,  1.0625\n",
      "545\n",
      "0.6216434604053781  ,  0.7765  ,  1.1191\n",
      "0.21067158117174606  ,  0.9804  ,  1.4986\n",
      "-0.02073860176138967  ,  0.97  ,  1.6376\n",
      "546\n",
      "0.2949901290036776  ,  0.5171  ,  1.3708\n",
      "0.09062338849213539  ,  1.0457  ,  1.306\n",
      "nan  ,  0.4942  ,  1.4661\n",
      "547\n",
      "0.6409838557589107  ,  0.5798  ,  1.153\n",
      "0.109536970455518  ,  0.6653  ,  1.633\n",
      "nan  ,  0.6447  ,  1.6726\n",
      "548\n",
      "0.6879765479844892  ,  0.8279  ,  1.2228\n",
      "0.44393721895286464  ,  1.1414  ,  1.866\n",
      "nan  ,  1.187  ,  1.9868\n",
      "549\n",
      "0.629503366149982  ,  1.2471  ,  1.311\n",
      "0.1894185960552165  ,  1.0221  ,  1.7359\n",
      "-0.026378221967919162  ,  1.0244  ,  1.8322\n",
      "550\n",
      "0.6681116417693528  ,  0.8647  ,  1.9918\n",
      "0.06937224056700918  ,  0.9692  ,  2.252\n",
      "nan  ,  0.9584  ,  2.2766\n",
      "551\n",
      "0.7128764368211908  ,  0.7963  ,  1.5546\n",
      "0.5749978481608242  ,  0.9315  ,  1.7492\n",
      "-0.3573220436325957  ,  1.0686  ,  1.7069\n",
      "552\n",
      "0.7124089645928219  ,  0.6851  ,  0.9114\n",
      "nan  ,  0.5836  ,  1.509\n",
      "nan  ,  0.5836  ,  1.509\n",
      "553\n",
      "0.5785013883546056  ,  0.6809  ,  1.2322\n",
      "0.1300019000028887  ,  1.1958  ,  1.249\n",
      "nan  ,  0.778  ,  1.6827\n",
      "554\n",
      "0.4644043279586803  ,  0.506  ,  0.9656\n",
      "0.2592809231908366  ,  0.5525  ,  1.1152\n",
      "-0.22992081749628865  ,  0.6489  ,  1.0409\n",
      "555\n",
      "0.26135916385461205  ,  0.3158  ,  1.04\n",
      "-0.03783800167714782  ,  1.2052  ,  0.9545\n",
      "-0.13214740075229345  ,  0.4208  ,  0.9996\n",
      "556\n",
      "0.5494920958722664  ,  0.8706  ,  1.7976\n",
      "0.4118125570790555  ,  0.9475  ,  1.8749\n",
      "nan  ,  0.9815  ,  2.095\n",
      "557\n",
      "0.00421297430893641  ,  0.3653  ,  1.4451\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "558\n",
      "0.7152068802087936  ,  0.9362  ,  1.2859\n",
      "0.06688315114466323  ,  1.1169  ,  2.2206\n",
      "nan  ,  1.0988  ,  2.2739\n",
      "559\n",
      "0.38465022246956204  ,  0.8216  ,  1.8745\n",
      "0.060226491075912145  ,  0.8634  ,  2.0308\n",
      "nan  ,  0.8602  ,  2.0446\n",
      "560\n",
      "0.5025865476871761  ,  0.5206  ,  1.5591\n",
      "-0.023518362110368066  ,  1.1277  ,  1.587\n",
      "nan  ,  0.5586  ,  1.7751\n",
      "561\n",
      "0.08429871367974687  ,  0.737  ,  2.3016\n",
      "0.056349174688230835  ,  0.7776  ,  2.2646\n",
      "nan  ,  0.7374  ,  2.3059\n",
      "562\n",
      "0.31318357339476666  ,  0.3971  ,  1.1509\n",
      "0.22174236220871674  ,  0.4827  ,  1.132\n",
      "0.004878340817418822  ,  0.3933  ,  1.2387\n",
      "563\n",
      "0.5994695112410675  ,  0.9755  ,  1.6906\n",
      "0.19383277492014675  ,  1.2257  ,  2.1324\n",
      "nan  ,  1.2265  ,  2.1348\n",
      "564\n",
      "0.08966240097796221  ,  0.4413  ,  1.0853\n",
      "-0.12060394595623851  ,  0.7602  ,  0.8523\n",
      "0.041894825664560445  ,  0.5224  ,  0.9995\n",
      "565\n",
      "0.5251540911813154  ,  0.7306  ,  1.1263\n",
      "0.13684854121064546  ,  0.9955  ,  1.2203\n",
      "-0.03491558115174024  ,  0.7905  ,  1.4655\n",
      "566\n",
      "0.3414887026723122  ,  0.6989  ,  1.5439\n",
      "0.18263521041900635  ,  0.7046  ,  1.5435\n",
      "-0.039842676219050514  ,  0.7867  ,  1.4756\n",
      "567\n",
      "0.42182666339603025  ,  0.4966  ,  1.253\n",
      "0.021619807773503776  ,  0.5278  ,  1.4071\n",
      "nan  ,  0.5278  ,  1.4074\n",
      "568\n",
      "0.735565907227623  ,  0.5698  ,  1.1298\n",
      "0.3303379563433485  ,  0.797  ,  1.5196\n",
      "0.08415279915402574  ,  0.7641  ,  1.6487\n",
      "569\n",
      "0.8846502584152347  ,  0.5566  ,  1.1561\n",
      "0.5579604224365382  ,  0.897  ,  2.2024\n",
      "nan  ,  0.9157  ,  2.3808\n",
      "570\n",
      "0.6869862341488338  ,  0.7618  ,  1.0608\n",
      "0.16341979642471732  ,  1.1518  ,  1.4989\n",
      "-0.00015017711252858848  ,  1.1565  ,  1.6694\n",
      "571\n",
      "0.3948011725876641  ,  1.2872  ,  1.3688\n",
      "0.031682410541162886  ,  0.7234  ,  1.4667\n",
      "nan  ,  0.7106  ,  1.4938\n",
      "572\n",
      "0.8042649249126478  ,  0.6014  ,  1.4925\n",
      "0.24868961831780118  ,  0.8031  ,  2.0849\n",
      "nan  ,  0.8035  ,  2.0864\n",
      "573\n",
      "0.8313315914563948  ,  0.5073  ,  0.9438\n",
      "0.015930545098499158  ,  0.8026  ,  1.6646\n",
      "0.016730988472367137  ,  0.8106  ,  1.6516\n",
      "574\n",
      "0.4388807456068605  ,  1.206  ,  1.5037\n",
      "0.140956508805665  ,  1.3574  ,  1.1855\n",
      "0.03157575121000082  ,  0.748  ,  1.4813\n",
      "575\n",
      "0.5508847966325605  ,  0.8871  ,  1.816\n",
      "0.6288293490808544  ,  0.8635  ,  1.7495\n",
      "nan  ,  0.9529  ,  1.9767\n",
      "576\n",
      "0.11116271037268753  ,  0.6568  ,  1.5834\n",
      "0.026532623512207157  ,  0.6596  ,  1.5944\n",
      "0.033229590425116404  ,  0.7055  ,  1.5343\n",
      "577\n",
      "0.6014110822501606  ,  0.5988  ,  1.1813\n",
      "0.27130843249523096  ,  0.9087  ,  1.2727\n",
      "nan  ,  0.6627  ,  1.6222\n",
      "578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4896486318804688  ,  1.3915  ,  0.9675\n",
      "-0.029246827477903675  ,  1.4156  ,  1.2804\n",
      "-0.21502647439326555  ,  1.3981  ,  1.4996\n",
      "579\n",
      "0.7038952957240543  ,  0.469  ,  1.3349\n",
      "0.16751135704328451  ,  0.675  ,  1.7524\n",
      "nan  ,  0.6545  ,  1.8015\n",
      "580\n",
      "0.8555422015947143  ,  0.6211  ,  1.1774\n",
      "0.07478343625983173  ,  1.0963  ,  2.354\n",
      "nan  ,  1.0957  ,  2.3638\n",
      "581\n",
      "0.4736401837638312  ,  0.5873  ,  1.0408\n",
      "0.01564567566105809  ,  0.7617  ,  1.0463\n",
      "0.02244200927730807  ,  0.6806  ,  1.2065\n",
      "582\n",
      "0.7521883298198657  ,  0.4538  ,  1.3508\n",
      "0.17136644457760913  ,  1.9876  ,  1.6276\n",
      "nan  ,  0.556  ,  1.9375\n",
      "583\n",
      "0.4814651217127651  ,  1.0091  ,  1.9539\n",
      "0.45373619342364035  ,  1.0023  ,  1.916\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "584\n",
      "0.42029859711026796  ,  0.4948  ,  1.0444\n",
      "0.15049933030055307  ,  0.4318  ,  0.8502\n",
      "-0.08690840819149878  ,  0.519  ,  0.7938\n",
      "585\n",
      "0.3666580691890427  ,  2.1467  ,  2.0392\n",
      "0.007790738722070404  ,  0.4697  ,  1.1966\n",
      "-0.047835073923379434  ,  0.5119  ,  1.149\n",
      "586\n",
      "0.5628158922148403  ,  1.4997  ,  1.3352\n",
      "0.3560210098629176  ,  1.3169  ,  1.9163\n",
      "0.0020149533925408387  ,  1.3709  ,  2.0222\n",
      "587\n",
      "0.3513760300922508  ,  0.2178  ,  0.7501\n",
      "0.055275175228015595  ,  0.195  ,  0.8191\n",
      "0.06536752303912649  ,  0.2322  ,  0.8008\n",
      "588\n",
      "0.6345021759756915  ,  0.7537  ,  1.2263\n",
      "0.24891781632003887  ,  0.9853  ,  1.5797\n",
      "0.08605913618312477  ,  0.9986  ,  1.5966\n",
      "589\n",
      "0.6789816350304241  ,  0.6849  ,  1.6344\n",
      "0.19990898671359386  ,  0.8533  ,  2.1621\n",
      "0.13854535389211073  ,  0.8705  ,  2.1615\n",
      "590\n",
      "0.4733272626856264  ,  0.5503  ,  1.5515\n",
      "0.01658262695276037  ,  1.2269  ,  1.2562\n",
      "0.04887092596833961  ,  0.6654  ,  1.5466\n",
      "591\n",
      "0.4128474440439883  ,  0.4513  ,  1.1245\n",
      "0.016658367265656653  ,  0.5027  ,  1.2192\n",
      "-0.038450601823269676  ,  0.5344  ,  1.1852\n",
      "592\n",
      "0.01058298273903446  ,  0.654  ,  1.2922\n",
      "0.2773107241271228  ,  0.9132  ,  0.8561\n",
      "nan  ,  0.654  ,  1.2922\n",
      "593\n",
      "0.6421171800419361  ,  0.7409  ,  1.4703\n",
      "0.22321197491417274  ,  0.9022  ,  1.7823\n",
      "nan  ,  0.9043  ,  1.7954\n",
      "594\n",
      "0.06655653793579236  ,  0.6528  ,  1.4347\n",
      "-0.035751780774962966  ,  1.1201  ,  0.989\n",
      "0.16281012085195024  ,  0.8203  ,  1.2228\n",
      "595\n",
      "0.8513845810126776  ,  0.5239  ,  1.1943\n",
      "0.45879953261003437  ,  0.8554  ,  1.9572\n",
      "-0.011030561567428812  ,  0.8523  ,  2.1192\n",
      "596\n",
      "0.5498875815364601  ,  0.9457  ,  1.5103\n",
      "0.164005917200781  ,  1.1444  ,  1.6051\n",
      "-0.0384318740679703  ,  1.1461  ,  1.7309\n",
      "597\n",
      "0.6526601456524683  ,  1.4306  ,  1.7243\n",
      "0.11215546654928821  ,  0.6152  ,  1.6721\n",
      "nan  ,  0.5984  ,  1.6989\n",
      "598\n",
      "0.6229205449129314  ,  0.9018  ,  1.5141\n",
      "0.10546026229091575  ,  1.2227  ,  1.9642\n",
      "-0.0028677904465991  ,  1.1153  ,  2.1834\n",
      "599\n",
      "0.5668003492040843  ,  1.2541  ,  1.9513\n",
      "0.17958425432227354  ,  1.5143  ,  2.5063\n",
      "nan  ,  1.52  ,  2.5242\n",
      "600\n",
      "0.669962474987778  ,  0.8468  ,  1.104\n",
      "0.22000597636633545  ,  1.0165  ,  1.2408\n",
      "nan  ,  1.0466  ,  1.3783\n",
      "601\n",
      "0.37313427144983946  ,  0.7511  ,  1.6299\n",
      "0.004899797835753124  ,  1.1699  ,  1.4551\n",
      "-0.05257711273851261  ,  0.8285  ,  1.8137\n",
      "602\n",
      "-0.003742907078546076  ,  0.9665  ,  1.6903\n",
      "-0.0038625706946879405  ,  0.9661  ,  1.6895\n",
      "-0.0816130216862822  ,  0.9681  ,  1.6808\n",
      "603\n",
      "0.4333540606260814  ,  0.6116  ,  0.8941\n",
      "-0.1287068560563432  ,  0.7123  ,  1.1043\n",
      "0.055272553152105414  ,  0.7137  ,  1.0558\n",
      "604\n",
      "0.48879654200291245  ,  1.06  ,  1.4304\n",
      "0.32291134123571436  ,  1.1103  ,  1.4801\n",
      "0.17063539073415326  ,  1.2049  ,  1.6308\n",
      "605\n",
      "0.6762665778445436  ,  1.0665  ,  1.5047\n",
      "0.3870016073303547  ,  0.9058  ,  1.6341\n",
      "-0.0207833696386415  ,  0.7875  ,  1.9798\n",
      "606\n",
      "0.6836496696425316  ,  0.7475  ,  1.5686\n",
      "0.2529652598661842  ,  0.9171  ,  2.0642\n",
      "nan  ,  0.9249  ,  2.1226\n",
      "607\n",
      "0.6351244756976793  ,  0.4752  ,  1.0096\n",
      "0.3459831228832392  ,  0.5417  ,  1.2251\n",
      "-0.01491423554571889  ,  0.572  ,  1.2173\n",
      "608\n",
      "0.5710696630204423  ,  0.6976  ,  1.0334\n",
      "0.027876352597083237  ,  0.8381  ,  1.4806\n",
      "nan  ,  0.8378  ,  1.4816\n",
      "609\n",
      "0.6045786306826679  ,  0.5548  ,  1.0512\n",
      "-0.07699301490279886  ,  0.6627  ,  1.3579\n",
      "-0.09090464969748513  ,  0.6783  ,  1.3208\n",
      "610\n",
      "0.673708957827953  ,  0.4467  ,  0.9547\n",
      "0.04376796523085563  ,  0.748  ,  1.0871\n",
      "-0.03128149829191076  ,  0.4407  ,  1.2684\n",
      "611\n",
      "0.14794737792045498  ,  1.1113  ,  1.815\n",
      "-0.06657970569566306  ,  1.1277  ,  1.829\n",
      "0.09549231689283046  ,  1.1286  ,  1.7929\n",
      "612\n",
      "0.31187938685360905  ,  1.4228  ,  1.8815\n",
      "-0.020789564477418872  ,  1.5086  ,  1.9818\n",
      "-0.012789599702576858  ,  1.5014  ,  1.9597\n",
      "613\n",
      "0.5896468684802985  ,  0.6926  ,  1.6543\n",
      "0.2533371633857594  ,  0.8535  ,  1.8579\n",
      "0.04401452419307424  ,  0.8217  ,  1.9743\n",
      "614\n",
      "0.7130179714911322  ,  0.4874  ,  1.0168\n",
      "-0.03459065240396224  ,  0.5647  ,  1.5476\n",
      "nan  ,  0.5544  ,  1.5537\n",
      "615\n",
      "0.0362495284858155  ,  0.0831  ,  0.477\n",
      "0.21817391622833085  ,  0.0827  ,  0.4752\n",
      "-0.05090190962545192  ,  0.1952  ,  0.4373\n",
      "616\n",
      "0.08087573994150946  ,  1.0045  ,  1.5766\n",
      "0.03063942899723634  ,  1.0108  ,  1.5307\n",
      "-0.03468221527602034  ,  1.0305  ,  1.4619\n",
      "617\n",
      "0.20275284267975466  ,  1.0186  ,  2.1727\n",
      "0.028085327533125475  ,  1.0441  ,  2.1745\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "618\n",
      "0.7171124691418741  ,  0.8451  ,  1.6341\n",
      "0.5302860043837181  ,  1.0564  ,  2.0497\n",
      "-0.028992998589149426  ,  1.1108  ,  2.2085\n",
      "619\n",
      "0.6325405261667623  ,  0.8818  ,  1.4815\n",
      "0.33480698681050314  ,  0.997  ,  1.6539\n",
      "-0.13279839834603535  ,  1.0208  ,  1.7174\n",
      "620\n",
      "0.5729786488123916  ,  0.7094  ,  1.5179\n",
      "0.13752539831931296  ,  0.8232  ,  1.7582\n",
      "nan  ,  0.8192  ,  1.7778\n",
      "621\n",
      "0.6932307622681417  ,  0.7563  ,  1.1767\n",
      "0.05668310829924257  ,  0.8935  ,  1.8192\n",
      "nan  ,  0.8865  ,  1.8439\n",
      "622\n",
      "0.7813403297562964  ,  0.6194  ,  1.3203\n",
      "0.39282605703452617  ,  0.882  ,  1.831\n",
      "nan  ,  0.8699  ,  2.0202\n",
      "623\n",
      "0.25906771170243814  ,  0.6869  ,  1.5069\n",
      "0.2260572603881883  ,  0.7812  ,  1.3615\n",
      "nan  ,  0.705  ,  1.5479\n",
      "624\n",
      "0.46848675502001985  ,  0.7464  ,  1.3619\n",
      "0.14256187889569166  ,  0.8559  ,  1.5121\n",
      "-0.05268882971958881  ,  0.8772  ,  1.5168\n",
      "625\n",
      "0.8467966730901548  ,  0.3414  ,  0.9266\n",
      "0.06170409342740361  ,  0.5758  ,  1.6783\n",
      "nan  ,  0.5148  ,  1.7248\n",
      "626\n",
      "0.4571406791494862  ,  0.4332  ,  1.1462\n",
      "0.01640650114840486  ,  0.4768  ,  1.3265\n",
      "nan  ,  0.4256  ,  1.3574\n",
      "627\n",
      "0.6587193301943932  ,  0.7442  ,  1.2251\n",
      "0.37526933012053887  ,  0.8649  ,  1.7425\n",
      "-0.001427023646972404  ,  0.8753  ,  1.8901\n",
      "628\n",
      "0.5908637271117907  ,  0.5682  ,  1.0188\n",
      "0.23870973174250876  ,  0.7051  ,  1.3085\n",
      "0.1489498673665047  ,  0.7404  ,  1.2534\n",
      "629\n",
      "0.5017989415177344  ,  1.1808  ,  1.3221\n",
      "0.2851258906962353  ,  0.8626  ,  1.3367\n",
      "0.15787250546807147  ,  0.8837  ,  1.4561\n",
      "630\n",
      "0.7928469726805799  ,  0.8944  ,  1.5757\n",
      "0.2012368695054358  ,  1.3327  ,  2.2721\n",
      "nan  ,  1.3036  ,  2.4833\n",
      "631\n",
      "0.8849318367333237  ,  0.6821  ,  1.6988\n",
      "0.7896360951610837  ,  0.9879  ,  2.3713\n",
      "-0.02776344222153706  ,  1.3663  ,  2.387\n",
      "632\n",
      "0.5550046487373099  ,  0.4764  ,  1.4149\n",
      "-0.03213267656407971  ,  0.614  ,  1.5059\n",
      "nan  ,  0.5064  ,  1.5653\n",
      "633\n",
      "0.5291551578509401  ,  0.8465  ,  1.5421\n",
      "0.3963157579946023  ,  0.9658  ,  1.3404\n",
      "0.12462075879711368  ,  0.959  ,  1.6945\n",
      "634\n",
      "0.0789898310133325  ,  0.7274  ,  1.4741\n",
      "0.12819812053175086  ,  0.729  ,  1.4565\n",
      "-0.06217342036720678  ,  0.7555  ,  1.4343\n",
      "635\n",
      "0.6009636333904191  ,  0.6906  ,  1.2219\n",
      "0.08567770274882061  ,  0.8915  ,  1.5443\n",
      "0.07366230423884264  ,  0.7595  ,  1.6854\n",
      "636\n",
      "0.9381569791919908  ,  0.7363  ,  1.8816\n",
      "0.014914124264909  ,  1.5385  ,  3.8255\n",
      "0.23427995736934623  ,  1.5468  ,  3.8162\n",
      "637\n",
      "0.7440916323829447  ,  0.8174  ,  1.2108\n",
      "0.43767934781203965  ,  1.1962  ,  1.6873\n",
      "nan  ,  1.2821  ,  2.1346\n",
      "638\n",
      "0.4934700311568301  ,  0.7317  ,  1.0781\n",
      "0.2740091479860423  ,  0.8257  ,  1.3041\n",
      "0.09361650900769039  ,  0.8504  ,  1.3938\n",
      "639\n",
      "0.2917184550434329  ,  2.0171  ,  2.6166\n",
      "0.42184345382906285  ,  1.6131  ,  2.0484\n",
      "nan  ,  1.8033  ,  2.3966\n",
      "640\n",
      "0.14224670509029816  ,  1.0665  ,  1.6707\n",
      "0.019036874244970546  ,  1.0843  ,  1.7185\n",
      "nan  ,  1.085  ,  1.7216\n",
      "641\n",
      "0.5605105574622303  ,  0.8341  ,  1.0173\n",
      "0.17144076009345527  ,  0.8228  ,  1.4524\n",
      "-0.02515115391162759  ,  0.8232  ,  1.4893\n",
      "642\n",
      "0.38900797842086965  ,  0.9092  ,  1.1756\n",
      "0.32617214572898967  ,  1.0369  ,  1.413\n",
      "-0.1652504701144334  ,  1.0582  ,  1.2978\n",
      "643\n",
      "0.07169368775053503  ,  1.1688  ,  1.4292\n",
      "-0.00540750037327014  ,  1.1639  ,  1.398\n",
      "0.09571444073047627  ,  1.1537  ,  1.3629\n",
      "644\n",
      "0.3814332898439443  ,  0.7207  ,  1.3042\n",
      "-0.1866794072021522  ,  0.7916  ,  1.4595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0768950609112748  ,  0.8383  ,  1.324\n",
      "645\n",
      "0.6452026588805174  ,  0.6536  ,  0.9991\n",
      "0.03876992885067837  ,  0.8373  ,  1.4695\n",
      "-0.09040195558882522  ,  0.8534  ,  1.4035\n",
      "646\n",
      "0.41048996284365025  ,  0.9005  ,  1.1637\n",
      "0.051935766499373634  ,  1.0059  ,  1.4684\n",
      "-0.24880765329485816  ,  1.0165  ,  1.4488\n",
      "647\n",
      "0.18415430950654785  ,  0.5513  ,  1.2563\n",
      "0.007095073441961799  ,  0.5577  ,  1.2736\n",
      "nan  ,  0.556  ,  1.2765\n",
      "648\n",
      "0.35649025541983  ,  0.9077  ,  1.1667\n",
      "0.07030584413945332  ,  1.0208  ,  1.013\n",
      "0.2515398035494798  ,  1.0232  ,  1.071\n",
      "649\n",
      "0.34780623080980855  ,  0.8687  ,  0.9145\n",
      "0.0022262587495821343  ,  0.7434  ,  1.0339\n",
      "0.170868724580373  ,  0.7445  ,  1.0157\n",
      "650\n",
      "0.20811715439325293  ,  0.4497  ,  1.3157\n",
      "0.16222029259489032  ,  0.4611  ,  1.3257\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "651\n",
      "0.4732134555156793  ,  0.9307  ,  1.2814\n",
      "0.012691488351458969  ,  1.0137  ,  1.7047\n",
      "nan  ,  1.0137  ,  1.7047\n",
      "652\n",
      "0.37568886258140266  ,  1.1898  ,  1.3633\n",
      "0.19559529398033632  ,  0.7021  ,  1.3986\n",
      "0.242553546033988  ,  0.7933  ,  1.2742\n",
      "653\n",
      "0.058369788045252696  ,  0.7378  ,  1.5691\n",
      "0.1111646415879932  ,  0.819  ,  1.4188\n",
      "0.06782271605355217  ,  0.8112  ,  1.4527\n",
      "654\n",
      "0.4176876800014634  ,  0.6618  ,  1.4896\n",
      "-0.1129493354505341  ,  0.7606  ,  1.4802\n",
      "-0.007457200518640827  ,  0.7764  ,  1.4392\n",
      "655\n",
      "0.3221712547326787  ,  0.4564  ,  1.287\n",
      "-0.07455479200357475  ,  0.4768  ,  1.3955\n",
      "-0.011782925436918324  ,  0.5856  ,  1.3006\n",
      "656\n",
      "0.5164197972581783  ,  0.4717  ,  1.0192\n",
      "0.09357678074064067  ,  0.5249  ,  1.1876\n",
      "-0.06527339541800979  ,  0.5311  ,  1.1881\n",
      "657\n",
      "0.37054380127767694  ,  0.3211  ,  1.2398\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "658\n",
      "0.12987293799747332  ,  0.5545  ,  1.1527\n",
      "0.07751405307578392  ,  0.5726  ,  1.1364\n",
      "-0.1546373495824135  ,  0.7955  ,  0.8782\n",
      "659\n",
      "0.35267898472209946  ,  0.5291  ,  1.4109\n",
      "-0.06463900121722621  ,  0.5801  ,  1.4406\n",
      "0.028701992651890197  ,  0.5801  ,  1.4338\n",
      "660\n",
      "0.2666428949415314  ,  0.3133  ,  1.0367\n",
      "0.07515542848723725  ,  0.3446  ,  1.0425\n",
      "-0.046004001757186976  ,  0.3769  ,  1.0247\n",
      "661\n",
      "0.3425171949431916  ,  1.4075  ,  1.2886\n",
      "-0.057190492963132215  ,  0.9357  ,  1.4886\n",
      "0.008462041057601847  ,  0.9423  ,  1.4337\n",
      "662\n",
      "0.08413619836293132  ,  0.3318  ,  0.965\n",
      "-0.04195744536261831  ,  0.4819  ,  0.8835\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "663\n",
      "0.18768242860314233  ,  0.3857  ,  0.8284\n",
      "0.04569863483716087  ,  0.3379  ,  0.7404\n",
      "0.06905559745121284  ,  0.3298  ,  0.7363\n",
      "664\n",
      "0.24391490879986497  ,  0.8862  ,  1.1005\n",
      "0.07649793129922307  ,  0.5341  ,  1.1298\n",
      "-0.0165292094595569  ,  0.6083  ,  1.0224\n",
      "665\n",
      "0.5210520800593853  ,  1.2446  ,  1.1669\n",
      "0.30162136362070024  ,  0.9518  ,  1.3191\n",
      "0.10181758144078107  ,  0.976  ,  1.4453\n",
      "666\n",
      "0.35430689636705465  ,  0.2454  ,  0.7821\n",
      "0.018998449774603694  ,  0.2034  ,  0.8527\n",
      "nan  ,  0.2033  ,  0.8528\n",
      "667\n",
      "0.17707797208802276  ,  1.0429  ,  1.715\n",
      "0.07011075088903596  ,  1.0714  ,  1.7572\n",
      "nan  ,  1.072  ,  1.7601\n",
      "668\n",
      "0.2501000078015454  ,  1.0185  ,  1.2653\n",
      "0.04203833244577874  ,  0.791  ,  1.4505\n",
      "0.02089241625202501  ,  0.7992  ,  1.4335\n",
      "669\n",
      "0.3380564946353996  ,  0.9921  ,  1.4452\n",
      "0.034133573160612225  ,  1.0723  ,  1.4625\n",
      "-0.04740327026167486  ,  1.0919  ,  1.3996\n",
      "670\n",
      "0.4261398641082517  ,  0.8839  ,  1.041\n",
      "0.0039073021188568875  ,  0.6749  ,  1.3197\n",
      "-0.048129940377833955  ,  0.6826  ,  1.3\n",
      "671\n",
      "0.24764107574883826  ,  0.4779  ,  1.2518\n",
      "0.001537387969013779  ,  0.485  ,  1.2856\n",
      "nan  ,  0.485  ,  1.2857\n",
      "672\n",
      "0.3955341200124287  ,  0.4769  ,  1.0626\n",
      "-0.004678812083470865  ,  0.4958  ,  1.1528\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "673\n",
      "0.2924145276646805  ,  1.5713  ,  1.4435\n",
      "0.07123384024268938  ,  1.295  ,  1.6725\n",
      "0.1861525286912651  ,  1.3102  ,  1.8143\n",
      "674\n",
      "0.23954517719178953  ,  0.5296  ,  1.1279\n",
      "-0.00014747526288661503  ,  0.5448  ,  1.1581\n",
      "nan  ,  0.5411  ,  1.1629\n",
      "675\n",
      "0.42911797390392104  ,  0.9394  ,  1.1165\n",
      "0.03901966816783474  ,  1.095  ,  1.3458\n",
      "-0.25869829207519585  ,  1.1032  ,  1.4646\n",
      "676\n",
      "0.3373979638564542  ,  0.5689  ,  1.3367\n",
      "0.1691113356822871  ,  0.5867  ,  1.3747\n",
      "nan  ,  0.5835  ,  1.397\n",
      "677\n",
      "0.19781799947014267  ,  1.1748  ,  1.4639\n",
      "0.0645291830081772  ,  1.1633  ,  1.345\n",
      "0.05241701376987579  ,  1.2027  ,  1.4727\n",
      "678\n",
      "0.22354129089717806  ,  0.9488  ,  1.3366\n",
      "-0.020285847438389938  ,  0.969  ,  1.2599\n",
      "0.07024881987175995  ,  0.9681  ,  1.2435\n",
      "679\n",
      "0.5348963865065398  ,  0.885  ,  1.0174\n",
      "0.10631720160734881  ,  1.08  ,  1.4749\n",
      "nan  ,  1.0945  ,  1.5329\n",
      "680\n",
      "0.37693589090092294  ,  0.6381  ,  1.0174\n",
      "-0.130999336917515  ,  0.9519  ,  0.8815\n",
      "-0.2594585887550393  ,  0.7468  ,  1.0485\n",
      "681\n",
      "0.3188983237841121  ,  1.319  ,  1.6253\n",
      "0.1013986720436925  ,  1.3211  ,  1.5489\n",
      "-0.48181583137229084  ,  1.3183  ,  1.5181\n",
      "682\n",
      "0.4846416057156063  ,  0.7891  ,  1.386\n",
      "0.33869869262646257  ,  0.8941  ,  1.6274\n",
      "0.09443211188183975  ,  0.9665  ,  1.5335\n",
      "683\n",
      "0.5321029011501731  ,  0.9566  ,  1.0133\n",
      "0.04154228406638277  ,  1.089  ,  1.4018\n",
      "-0.15659415679580746  ,  1.1218  ,  1.298\n",
      "684\n",
      "0.23227092398932503  ,  0.7423  ,  0.8334\n",
      "0.1345019692235481  ,  0.4444  ,  0.9494\n",
      "0.19871281225966414  ,  0.4421  ,  0.9644\n",
      "685\n",
      "0.34273725141401223  ,  0.4395  ,  1.0521\n",
      "0.09083496930764233  ,  0.4487  ,  1.0849\n",
      "-0.06614263849194249  ,  0.4786  ,  1.0536\n",
      "686\n",
      "0.3810869377077952  ,  0.8047  ,  1.0189\n",
      "0.07615621792319374  ,  0.8035  ,  1.154\n",
      "0.12476346691217377  ,  0.8601  ,  1.0568\n",
      "687\n",
      "0.39715355850353246  ,  1.2886  ,  1.435\n",
      "0.13520051341987507  ,  1.4872  ,  1.5272\n",
      "0.5281466741886447  ,  1.505  ,  1.5572\n",
      "688\n",
      "0.2424365326294548  ,  1.1223  ,  1.113\n",
      "0.026718539024348613  ,  1.0001  ,  0.9745\n",
      "-0.41033798513577274  ,  0.9806  ,  1.0188\n",
      "689\n",
      "0.3052438670709243  ,  0.6195  ,  0.9685\n",
      "0.07435153977604528  ,  0.5407  ,  1.1207\n",
      "nan  ,  0.526  ,  1.1493\n",
      "690\n",
      "0.4054605603172921  ,  0.4599  ,  1.1271\n",
      "-0.004653564776827041  ,  0.494  ,  1.2378\n",
      "nan  ,  0.4915  ,  1.2401\n",
      "691\n",
      "0.33809269843618006  ,  0.473  ,  1.0987\n",
      "0.042511286137765454  ,  0.6384  ,  1.0472\n",
      "-0.027250412124848508  ,  0.6091  ,  1.0757\n",
      "692\n",
      "0.43209105497831535  ,  0.6651  ,  1.1016\n",
      "-0.0024509646374379175  ,  0.8101  ,  1.1973\n",
      "0.27339748010524395  ,  0.7698  ,  1.2857\n",
      "693\n",
      "0.1481792786083711  ,  0.3161  ,  0.9497\n",
      "0.029100447299812666  ,  0.3174  ,  0.9614\n",
      "nan  ,  0.3157  ,  0.9632\n",
      "694\n",
      "0.2657989505268144  ,  0.8805  ,  1.0108\n",
      "0.07717323249043967  ,  0.9482  ,  1.308\n",
      "0.12704457314560835  ,  0.9407  ,  1.2061\n",
      "695\n",
      "0.418771059260687  ,  0.6092  ,  1.0973\n",
      "0.07166946993009347  ,  0.7188  ,  1.0874\n",
      "0.02745765884420141  ,  0.727  ,  1.0771\n",
      "696\n",
      "0.01362077200376232  ,  0.8223  ,  1.3112\n",
      "0.005850231980232903  ,  0.8263  ,  1.2025\n",
      "-0.04257837558867147  ,  0.8177  ,  1.2195\n",
      "697\n",
      "0.18197808508048502  ,  1.1204  ,  1.6177\n",
      "0.003156730939604144  ,  0.3362  ,  1.1518\n",
      "nan  ,  0.3362  ,  1.1518\n",
      "698\n",
      "0.1463899866853873  ,  0.5177  ,  1.2426\n",
      "0.009821137546442479  ,  0.522  ,  1.2622\n",
      "nan  ,  0.522  ,  1.2622\n",
      "699\n",
      "0.03724920052043193  ,  0.5292  ,  1.2378\n",
      "0.22281813055650768  ,  0.5642  ,  1.1562\n",
      "0.027067417235268197  ,  0.6534  ,  1.0868\n",
      "700\n",
      "0.0482343134197652  ,  0.3561  ,  1.0618\n",
      "0.12494101593842007  ,  0.4418  ,  0.9784\n",
      "0.05261738388908971  ,  0.5086  ,  0.9402\n",
      "701\n",
      "0.18332226411961622  ,  0.9519  ,  1.3012\n",
      "-0.014942905718919205  ,  0.9762  ,  1.3321\n",
      "0.008442081328849792  ,  0.9596  ,  1.1497\n",
      "702\n",
      "0.013785577393513387  ,  0.2055  ,  0.9769\n",
      "0.04669799187908287  ,  0.3657  ,  0.9224\n",
      "-0.021921277558932327  ,  0.2439  ,  0.9592\n",
      "703\n",
      "0.2053796844320525  ,  0.6402  ,  1.2307\n",
      "0.027019192966265114  ,  0.6047  ,  1.3284\n",
      "nan  ,  0.6046  ,  1.3289\n",
      "704\n",
      "0.4691048386372215  ,  1.0096  ,  1.0902\n",
      "nan  ,  1.191  ,  1.4689\n",
      "nan  ,  1.191  ,  1.4689\n",
      "705\n",
      "0.6549387851062549  ,  0.5622  ,  1.0105\n",
      "nan  ,  0.6675  ,  1.2446\n",
      "nan  ,  0.6675  ,  1.2446\n",
      "706\n",
      "0.5269696372249997  ,  1.0873  ,  1.6245\n",
      "-0.013634776065347961  ,  1.2498  ,  1.9637\n",
      "nan  ,  1.2497  ,  1.9638\n",
      "707\n",
      "0.49777939052421305  ,  0.7695  ,  1.5377\n",
      "0.2191404020779744  ,  0.8285  ,  1.6178\n",
      "nan  ,  0.822  ,  1.673\n",
      "708\n",
      "0.10469318455890025  ,  0.6239  ,  1.3255\n",
      "0.06861652095671052  ,  0.6219  ,  1.3484\n",
      "nan  ,  0.6219  ,  1.3491\n",
      "709\n",
      "0.13455451615096883  ,  0.547  ,  0.868\n",
      "0.09070375932789304  ,  0.5654  ,  0.8252\n",
      "-0.17302952454946466  ,  0.5732  ,  0.8184\n",
      "710\n",
      "0.13665216849872902  ,  0.4266  ,  1.1247\n",
      "-0.02655213223128953  ,  0.6125  ,  0.9832\n",
      "0.19711012362933145  ,  0.5534  ,  1.018\n",
      "711\n",
      "0.37499886969369944  ,  0.8679  ,  1.4582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020302267185464667  ,  0.9033  ,  1.5336\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "712\n",
      "0.39734400761598576  ,  1.0191  ,  0.9184\n",
      "0.11235412812658194  ,  1.2838  ,  1.4462\n",
      "nan  ,  1.2859  ,  1.4483\n",
      "713\n",
      "0.5116350049698817  ,  0.8664  ,  0.9992\n",
      "-0.047107325970967215  ,  1.1122  ,  1.0564\n",
      "-0.40758766277447467  ,  1.115  ,  1.0356\n",
      "714\n",
      "0.29498097253574346  ,  1.0409  ,  1.5635\n",
      "0.08031760149012704  ,  1.1036  ,  1.6773\n",
      "nan  ,  1.1045  ,  1.679\n",
      "715\n",
      "0.09222466162029425  ,  0.8988  ,  1.587\n",
      "0.31238366216605423  ,  0.9286  ,  1.3779\n",
      "0.05175361336560537  ,  1.0453  ,  1.2748\n",
      "716\n",
      "0.5652567682885472  ,  0.7243  ,  1.1333\n",
      "0.0805375635194431  ,  0.8357  ,  1.5687\n",
      "-0.12959360209374998  ,  0.895  ,  1.4419\n",
      "717\n",
      "0.132896187731511  ,  0.6106  ,  1.0476\n",
      "0.0722047958752643  ,  0.5877  ,  1.0686\n",
      "-0.010719817235162101  ,  0.6311  ,  0.9963\n",
      "718\n",
      "0.2647574362077057  ,  0.5313  ,  1.0886\n",
      "-0.063901203626879  ,  0.5506  ,  1.1248\n",
      "0.015821406648435753  ,  0.5778  ,  1.0896\n",
      "719\n",
      "-0.08814169440805411  ,  1.2067  ,  1.4259\n",
      "nan  ,  1.1323  ,  1.4711\n",
      "nan  ,  1.1323  ,  1.4711\n",
      "720\n",
      "0.29240962009204485  ,  0.9368  ,  1.4111\n",
      "0.03304504863315992  ,  1.0288  ,  1.2861\n",
      "0.0837159763459354  ,  1.0073  ,  1.3915\n",
      "721\n",
      "0.1541691167823241  ,  1.0976  ,  1.5118\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "722\n",
      "0.6964689095189496  ,  0.3906  ,  1.2183\n",
      "0.03830302707724657  ,  0.4516  ,  1.5059\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "723\n",
      "0.46948070868222946  ,  0.673  ,  1.1715\n",
      "-0.029034351889648386  ,  0.766  ,  1.3471\n",
      "0.04200427472813665  ,  0.7774  ,  1.3058\n",
      "724\n",
      "0.2973867592423242  ,  0.7431  ,  1.1758\n",
      "0.06701755704860374  ,  0.7996  ,  1.2053\n",
      "0.14830170863703473  ,  0.827  ,  1.149\n",
      "725\n",
      "0.23329170173442304  ,  0.9699  ,  1.2007\n",
      "0.11250038530711035  ,  0.6343  ,  1.1714\n",
      "-0.07599485616293979  ,  0.6998  ,  1.0876\n",
      "726\n",
      "0.7818041353722995  ,  0.3395  ,  1.0038\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "727\n",
      "0.39667552603596995  ,  0.5118  ,  1.2063\n",
      "0.01570995233596885  ,  0.5337  ,  1.2768\n",
      "nan  ,  0.5337  ,  1.277\n",
      "728\n",
      "0.1637935979143752  ,  0.7292  ,  1.3773\n",
      "0.21536316367180777  ,  0.846  ,  1.1556\n",
      "-0.0038045168947820167  ,  0.8184  ,  1.2491\n",
      "729\n",
      "0.046733217777165124  ,  0.6403  ,  1.0587\n",
      "0.015808045946258474  ,  0.6408  ,  1.0591\n",
      "nan  ,  0.6408  ,  1.0592\n",
      "730\n",
      "0.25371842429420843  ,  0.4869  ,  1.302\n",
      "-0.08609952206919566  ,  0.5491  ,  1.3188\n",
      "-0.02389178812935539  ,  0.516  ,  1.3387\n",
      "731\n",
      "0.3869862063046742  ,  0.7497  ,  1.323\n",
      "0.13810939686027823  ,  0.8266  ,  1.3307\n",
      "-0.07059548930109066  ,  0.8783  ,  1.2515\n",
      "732\n",
      "0.42262272178988036  ,  0.7017  ,  1.2402\n",
      "0.08473683322725573  ,  0.7804  ,  1.3776\n",
      "-0.05073400341898279  ,  0.7778  ,  1.3991\n",
      "733\n",
      "0.05651878864508822  ,  0.3513  ,  1.1164\n",
      "-0.030837094950832665  ,  0.3834  ,  1.0993\n",
      "0.020856679266225784  ,  0.4508  ,  1.0416\n",
      "734\n",
      "0.3421782300719144  ,  1.4235  ,  1.1381\n",
      "0.17623337192840716  ,  1.1869  ,  1.4323\n",
      "0.2288075553543742  ,  1.1711  ,  1.3767\n",
      "735\n",
      "0.20882762402201915  ,  0.377  ,  0.9568\n",
      "-0.03863114362849732  ,  0.1632  ,  0.6921\n",
      "0.05882452915833271  ,  0.1516  ,  0.6867\n",
      "736\n",
      "0.12004347888551702  ,  1.7895  ,  1.8994\n",
      "-0.024634894575461627  ,  0.7632  ,  1.2493\n",
      "nan  ,  0.7432  ,  1.2892\n",
      "737\n",
      "0.5822122352626998  ,  0.6681  ,  1.3604\n",
      "0.08642505447205198  ,  0.7649  ,  1.6852\n",
      "nan  ,  0.765  ,  1.6857\n",
      "738\n",
      "0.56060485746558  ,  0.809  ,  1.0087\n",
      "-0.02066782936176309  ,  1.0542  ,  1.3828\n",
      "nan  ,  1.0551  ,  1.3859\n",
      "739\n",
      "0.12801260469920278  ,  0.5707  ,  1.3363\n",
      "-0.08695151242265278  ,  0.6057  ,  1.3258\n",
      "0.0756509823730579  ,  0.6492  ,  1.2567\n",
      "740\n",
      "0.2807182115774118  ,  0.84  ,  1.5099\n",
      "0.12318728496873144  ,  0.9653  ,  1.3378\n",
      "-0.11054754761086535  ,  0.8757  ,  1.5778\n",
      "741\n",
      "0.017017313235391435  ,  0.7287  ,  1.479\n",
      "0.16880822753977903  ,  0.7249  ,  1.4477\n",
      "nan  ,  0.7287  ,  1.4792\n",
      "742\n",
      "0.2693128052448771  ,  0.6303  ,  1.3107\n",
      "0.2152258053743124  ,  0.6479  ,  1.3391\n",
      "nan  ,  0.6517  ,  1.3606\n",
      "743\n",
      "0.27025188591444776  ,  0.9152  ,  1.3563\n",
      "0.02309349433331348  ,  0.951  ,  1.4136\n",
      "0.12299097490308725  ,  0.9499  ,  1.3961\n",
      "744\n",
      "0.3674650798050829  ,  0.9038  ,  1.2035\n",
      "0.004832583877687813  ,  0.9841  ,  0.9776\n",
      "-0.21010035218052225  ,  0.9655  ,  1.1425\n",
      "745\n",
      "0.4556674969128596  ,  0.5906  ,  0.9846\n",
      "-0.026501383988941477  ,  0.4823  ,  1.2487\n",
      "-0.07758333135652146  ,  0.5665  ,  1.1572\n",
      "746\n",
      "0.30025980145746256  ,  0.8721  ,  1.2577\n",
      "0.04879102684433606  ,  0.9309  ,  1.3282\n",
      "nan  ,  0.9238  ,  1.3964\n",
      "747\n",
      "0.14636984978342948  ,  0.4525  ,  1.0564\n",
      "-0.017852654227503314  ,  0.4361  ,  1.0872\n",
      "0.028672147270744262  ,  0.4847  ,  1.0335\n",
      "748\n",
      "0.14699751579045184  ,  1.2538  ,  1.1399\n",
      "0.03485970149969845  ,  0.6977  ,  0.9488\n",
      "0.029039477756406976  ,  0.6348  ,  1.0698\n",
      "749\n",
      "0.38387737740769323  ,  0.8802  ,  0.9922\n",
      "0.008561174278901665  ,  0.9062  ,  1.3313\n",
      "-0.15827762768752743  ,  0.9166  ,  1.2602\n",
      "750\n",
      "0.5987649104564199  ,  1.0187  ,  0.9702\n",
      "0.2954586135777122  ,  1.2526  ,  1.7181\n",
      "nan  ,  1.2599  ,  1.7359\n",
      "751\n",
      "0.3986717261378449  ,  0.5388  ,  0.9494\n",
      "0.029854855922313617  ,  0.4201  ,  0.8438\n",
      "0.052957818180532856  ,  0.4422  ,  0.8207\n",
      "752\n",
      "0.16324553256289503  ,  0.276  ,  0.9571\n",
      "0.017922349823654923  ,  0.2794  ,  0.9715\n",
      "nan  ,  0.2766  ,  0.9737\n",
      "753\n",
      "0.1303361143583824  ,  1.1954  ,  1.0109\n",
      "0.13663750258155632  ,  0.9321  ,  1.1991\n",
      "-0.15472643493224042  ,  0.9423  ,  1.193\n",
      "754\n",
      "0.11988466941823274  ,  0.7959  ,  1.1788\n",
      "-0.016787085710993133  ,  0.805  ,  1.248\n",
      "nan  ,  0.8034  ,  1.2534\n",
      "755\n",
      "0.06434737348105338  ,  0.6397  ,  1.2405\n",
      "0.09160382679677287  ,  0.6434  ,  1.2261\n",
      "nan  ,  0.6401  ,  1.2414\n",
      "756\n",
      "0.4398797660530659  ,  0.678  ,  1.1597\n",
      "0.09972753202702726  ,  0.6146  ,  1.4266\n",
      "nan  ,  0.6142  ,  1.4292\n",
      "757\n",
      "0.15174009073322525  ,  1.1152  ,  1.6181\n",
      "0.059019411146567995  ,  1.1364  ,  1.6445\n",
      "nan  ,  1.1373  ,  1.6481\n",
      "758\n",
      "0.30192956692675366  ,  0.9147  ,  0.8718\n",
      "-0.06817104117859255  ,  0.9006  ,  0.9315\n",
      "-0.03786061234651338  ,  0.9116  ,  0.8811\n",
      "759\n",
      "0.5227002348837894  ,  0.9167  ,  1.1728\n",
      "-0.13585007439626196  ,  1.1523  ,  1.5723\n",
      "0.2750786713106153  ,  1.1433  ,  1.6336\n",
      "760\n",
      "0.637339751024614  ,  0.4259  ,  1.0547\n",
      "-0.12081320515854721  ,  0.5241  ,  1.3213\n",
      "0.021618040727278645  ,  0.5374  ,  1.2976\n",
      "761\n",
      "0.4322115804408223  ,  0.7051  ,  1.0506\n",
      "-0.06117740801064059  ,  0.7805  ,  1.2616\n",
      "0.01657397240181978  ,  0.7751  ,  1.2508\n",
      "762\n",
      "0.5797469807948243  ,  0.8091  ,  0.6969\n",
      "0.30768384127480214  ,  0.8599  ,  0.9149\n",
      "-0.12863008510874754  ,  0.9387  ,  1.1327\n",
      "763\n",
      "0.37926050205559564  ,  1.0013  ,  1.3037\n",
      "0.060209463494862926  ,  1.1017  ,  1.4506\n",
      "-0.08687775258909967  ,  1.0954  ,  1.4299\n",
      "764\n",
      "0.40495752365589077  ,  1.3966  ,  1.2611\n",
      "0.11621535492822352  ,  0.9855  ,  1.4226\n",
      "0.031176245533156427  ,  0.9946  ,  1.4326\n",
      "765\n",
      "0.3191308920048085  ,  0.5032  ,  0.9361\n",
      "-0.0506017233937862  ,  0.4728  ,  1.0311\n",
      "nan  ,  0.3926  ,  1.0833\n",
      "766\n",
      "0.13107637056177918  ,  0.439  ,  1.1084\n",
      "0.13088302536424667  ,  0.5986  ,  0.9655\n",
      "0.027365266655639132  ,  0.5695  ,  1.0015\n",
      "767\n",
      "0.09124838793162476  ,  0.1819  ,  0.7765\n",
      "-0.037132058604039814  ,  0.1941  ,  0.7783\n",
      "0.02792841614911622  ,  0.4006  ,  0.6773\n",
      "768\n",
      "0.06664766547859607  ,  0.8401  ,  1.7428\n",
      "nan  ,  0.83  ,  1.7606\n",
      "nan  ,  0.83  ,  1.7606\n",
      "769\n",
      "0.3101877306533637  ,  1.1774  ,  1.4991\n",
      "0.01768785631121378  ,  1.1902  ,  1.4947\n",
      "0.033208047510944166  ,  1.19  ,  1.4958\n",
      "770\n",
      "0.24084093380753668  ,  0.6521  ,  1.234\n",
      "nan  ,  0.6643  ,  1.3178\n",
      "nan  ,  0.6643  ,  1.3178\n",
      "771\n",
      "0.14826136638671947  ,  0.8173  ,  1.4022\n",
      "-0.04787710862121481  ,  0.8444  ,  1.3921\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "772\n",
      "0.5542914310095082  ,  0.8741  ,  1.5036\n",
      "0.0538519563487211  ,  1.1838  ,  1.7359\n",
      "0.09661529845842694  ,  1.113  ,  1.8343\n",
      "773\n",
      "0.48677529341182096  ,  0.893  ,  1.4511\n",
      "-0.07441423633001841  ,  0.9939  ,  1.7725\n",
      "0.025266041765776865  ,  0.9918  ,  1.7655\n",
      "774\n",
      "0.3416664342293749  ,  0.6109  ,  1.1835\n",
      "-0.01636836054395761  ,  0.704  ,  1.2285\n",
      "0.06904786634074132  ,  0.721  ,  1.1924\n",
      "775\n",
      "0.10771894134720875  ,  1.0464  ,  1.6342\n",
      "0.08553364236931738  ,  1.0368  ,  1.6476\n",
      "-0.0848396143039755  ,  1.0395  ,  1.6585\n",
      "776\n",
      "0.31212078330384924  ,  1.2541  ,  1.6639\n",
      "0.1116078096950041  ,  1.3339  ,  1.8111\n",
      "0.13537378139961642  ,  1.3223  ,  1.762\n",
      "777\n",
      "778\n",
      "0.3530253705688923  ,  1.3146  ,  1.0436\n",
      "0.0498084799691245  ,  0.7636  ,  1.0793\n",
      "-0.22225250848550251  ,  0.7566  ,  1.089\n",
      "779\n",
      "780\n",
      "0.5715556259586163  ,  1.4778  ,  1.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19701135850077006  ,  0.7045  ,  1.326\n",
      "nan  ,  0.7059  ,  1.3333\n",
      "781\n",
      "782\n",
      "0.5699627939566679  ,  1.1293  ,  1.1863\n",
      "-0.0840812315533807  ,  0.885  ,  1.5775\n",
      "-0.04981235261493247  ,  0.8869  ,  1.5668\n",
      "783\n",
      "784\n",
      "0.21903953275181473  ,  1.1676  ,  1.2357\n",
      "0.16199504265403264  ,  0.9452  ,  1.4319\n",
      "-0.3732685992394567  ,  1.0424  ,  1.1642\n",
      "785\n",
      "786\n",
      "0.4215197146420424  ,  0.7065  ,  1.1803\n",
      "-0.050425484257852246  ,  0.9207  ,  0.9541\n",
      "-0.21922033639159721  ,  0.8203  ,  1.0985\n",
      "787\n",
      "788\n",
      "0.10585611453384382  ,  0.6068  ,  1.4315\n",
      "-0.12889543784395813  ,  0.643  ,  1.4131\n",
      "0.03182290734952746  ,  0.6753  ,  1.3564\n",
      "789\n",
      "790\n",
      "0.02413649083897746  ,  8.3139  ,  5.6892\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "791\n",
      "792\n",
      "0.4591182486647226  ,  0.5676  ,  1.0556\n",
      "0.20388094347322838  ,  0.6802  ,  1.1743\n",
      "-0.029688672919887655  ,  0.684  ,  1.2125\n",
      "793\n",
      "794\n",
      "0.20841461393290406  ,  0.8938  ,  1.3943\n",
      "-0.03597028663416074  ,  0.6474  ,  1.0331\n",
      "-0.10175284368618935  ,  0.5752  ,  1.0788\n",
      "795\n",
      "796\n",
      "0.4660639893705205  ,  0.7783  ,  1.082\n",
      "0.06259421336349057  ,  0.8281  ,  1.4712\n",
      "nan  ,  0.828  ,  1.4744\n",
      "797\n",
      "798\n",
      "0.533458205556064  ,  0.878  ,  1.3375\n",
      "0.03720042607171795  ,  1.0149  ,  1.4526\n",
      "-0.07916039745006453  ,  1.0052  ,  1.5047\n",
      "799\n",
      "800\n",
      "0.3882428297045691  ,  0.7195  ,  1.2021\n",
      "0.09692056165004892  ,  0.8882  ,  0.9541\n",
      "-0.08053087267765931  ,  0.8535  ,  1.0314\n",
      "801\n",
      "802\n",
      "0.24020763191676014  ,  0.3335  ,  0.9392\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "803\n",
      "804\n",
      "0.2961016009635517  ,  0.7545  ,  1.2978\n",
      "0.2507384392908382  ,  0.7746  ,  1.2984\n",
      "0.14085654482400992  ,  0.7971  ,  1.2683\n",
      "805\n",
      "806\n",
      "0.07562185697893542  ,  0.5309  ,  1.2718\n",
      "0.0502735684271456  ,  0.5638  ,  1.2305\n",
      "-0.04150868680983451  ,  0.6675  ,  1.1139\n",
      "807\n",
      "808\n",
      "0.3948271325361385  ,  0.7723  ,  1.3957\n",
      "0.011696456868560707  ,  0.8568  ,  1.5028\n",
      "nan  ,  0.8413  ,  1.5434\n",
      "809\n",
      "810\n",
      "0.33972010578252787  ,  0.5993  ,  0.9367\n",
      "0.008318378001726929  ,  0.5923  ,  1.0972\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "811\n",
      "812\n",
      "0.12099924709411708  ,  0.5214  ,  0.9895\n",
      "0.09951710225894363  ,  0.5402  ,  0.9511\n",
      "-0.042058715703713466  ,  0.5935  ,  0.8845\n",
      "813\n",
      "814\n",
      "0.10865885630232175  ,  0.9509  ,  1.5684\n",
      "0.18245730519528647  ,  0.9283  ,  1.6051\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "815\n",
      "816\n",
      "0.25731558746297367  ,  0.8285  ,  1.3459\n",
      "0.0514616982674245  ,  0.6075  ,  1.4429\n",
      "-0.03828921026864166  ,  0.6165  ,  1.4347\n",
      "817\n",
      "818\n",
      "0.30874343821732664  ,  1.5657  ,  1.3139\n",
      "0.13473305058382984  ,  0.6134  ,  0.7629\n",
      "-0.0909503164397389  ,  0.5169  ,  0.8615\n",
      "819\n",
      "820\n",
      "0.1595706281930064  ,  0.4414  ,  1.1244\n",
      "0.35985485079179236  ,  0.487  ,  1.0189\n",
      "0.06780527725998794  ,  0.5955  ,  0.981\n",
      "821\n",
      "822\n",
      "0.09917120751936011  ,  0.7638  ,  1.487\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "823\n",
      "824\n",
      "0.1316424136409801  ,  0.8006  ,  1.4193\n",
      "0.09942662558731732  ,  0.86  ,  1.2428\n",
      "0.055138759120465675  ,  0.8176  ,  1.3877\n",
      "825\n",
      "826\n",
      "0.52003311341199  ,  0.556  ,  1.3304\n",
      "0.14891058617082412  ,  0.6051  ,  1.5079\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "827\n",
      "828\n",
      "0.5924899825965835  ,  0.658  ,  1.2797\n",
      "0.023744182651511857  ,  0.7174  ,  1.6609\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "829\n",
      "830\n",
      "0.46621992338759094  ,  1.4564  ,  1.0157\n",
      "-0.05062001281457548  ,  1.0201  ,  1.3975\n",
      "nan  ,  1.0213  ,  1.4041\n",
      "831\n",
      "832\n",
      "0.15956408126668672  ,  1.8802  ,  2.5134\n",
      "0.06532322973127698  ,  0.375  ,  0.8305\n",
      "0.14325661384466665  ,  0.3878  ,  0.8252\n",
      "833\n",
      "834\n",
      "0.23542528839311438  ,  0.5961  ,  1.1444\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "835\n",
      "836\n",
      "0.42251723818434195  ,  0.7421  ,  1.1907\n",
      "0.14445270341265698  ,  0.8639  ,  1.3927\n",
      "-0.03810696281553862  ,  0.8804  ,  1.3694\n",
      "837\n",
      "838\n",
      "0.14347891098104348  ,  0.4816  ,  1.1629\n",
      "0.002814725172832438  ,  0.5385  ,  1.1339\n",
      "-0.0845618411713758  ,  0.505  ,  1.1576\n",
      "839\n",
      "840\n",
      "0.19732613966855  ,  0.5289  ,  1.1244\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "841\n",
      "842\n",
      "0.4887834445268828  ,  0.4559  ,  1.0682\n",
      "0.296462908884544  ,  0.6328  ,  0.9379\n",
      "-0.0015979358971051263  ,  0.5611  ,  1.0857\n",
      "843\n",
      "844\n",
      "0.3569971895713923  ,  0.9517  ,  1.2548\n",
      "-0.03999521820729579  ,  0.9036  ,  1.4925\n",
      "nan  ,  0.8372  ,  1.5933\n",
      "845\n",
      "846\n",
      "0.36112839526283314  ,  0.5806  ,  0.9953\n",
      "0.023239750411029235  ,  0.6671  ,  1.0475\n",
      "-0.02148658424451376  ,  0.6373  ,  1.0919\n",
      "847\n",
      "848\n",
      "0.5703365833303876  ,  0.4673  ,  0.9754\n",
      "-0.003080196519910662  ,  0.3713  ,  1.3116\n",
      "nan  ,  0.3713  ,  1.3116\n",
      "849\n",
      "850\n",
      "0.16786301587644012  ,  0.5773  ,  1.0642\n",
      "-0.02677730682030184  ,  0.5806  ,  1.0894\n",
      "0.029594830605198713  ,  0.5896  ,  1.0621\n",
      "851\n",
      "852\n",
      "0.13884633273128816  ,  0.8103  ,  1.1684\n",
      "0.025765848022326863  ,  0.5385  ,  1.1598\n",
      "-0.0024808340408509974  ,  0.6642  ,  1.0606\n",
      "853\n",
      "854\n",
      "0.7703295730700808  ,  0.4731  ,  1.1708\n",
      "-0.034696676292036495  ,  0.6662  ,  1.7608\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "855\n",
      "856\n",
      "0.2610540238405634  ,  0.8033  ,  1.1727\n",
      "0.05397940173994522  ,  0.8095  ,  1.189\n",
      "0.22334105358750564  ,  0.8063  ,  1.1619\n",
      "857\n",
      "858\n",
      "0.4479887823297217  ,  0.7131  ,  1.3541\n",
      "0.12485596388978934  ,  0.8117  ,  1.3487\n",
      "0.09927508295611157  ,  0.7738  ,  1.4496\n",
      "859\n",
      "860\n",
      "0.7501247829720251  ,  0.4666  ,  1.0205\n",
      "0.01858939920706625  ,  0.6075  ,  1.5703\n",
      "0.07535982732182392  ,  0.6193  ,  1.5578\n",
      "861\n",
      "862\n",
      "0.20358985006750405  ,  2.6376  ,  2.2175\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "863\n",
      "864\n",
      "0.5197732105885887  ,  0.7484  ,  1.3115\n",
      "0.08183532376073913  ,  0.9338  ,  1.3457\n",
      "-0.01992604592026785  ,  0.8936  ,  1.4444\n",
      "865\n",
      "866\n",
      "0.1335028951211626  ,  0.4285  ,  1.0096\n",
      "0.03606760651827051  ,  0.4337  ,  1.0166\n",
      "0.190674409393159  ,  0.444  ,  1.0042\n",
      "867\n",
      "868\n",
      "0.34162322368269527  ,  1.577  ,  1.2871\n",
      "0.03190385579835363  ,  1.1637  ,  1.2879\n",
      "0.6213769727072294  ,  1.1302  ,  1.3411\n",
      "869\n",
      "870\n",
      "0.24322761532768458  ,  1.0124  ,  1.4469\n",
      "0.08279720746647372  ,  1.0445  ,  1.3056\n",
      "0.4144495198312046  ,  1.0588  ,  1.2687\n",
      "871\n",
      "872\n",
      "0.27976752006834904  ,  1.0386  ,  1.3515\n",
      "0.21313512262278106  ,  1.0455  ,  1.6405\n",
      "0.3533841110685002  ,  1.0605  ,  1.6451\n",
      "873\n",
      "874\n",
      "0.6040380939144614  ,  0.5118  ,  0.9222\n",
      "0.1162730610895751  ,  0.6133  ,  1.1563\n",
      "nan  ,  0.586  ,  1.2262\n",
      "875\n",
      "876\n",
      "0.33422596555847633  ,  0.4684  ,  1.1372\n",
      "0.15984216747217034  ,  0.7504  ,  0.9626\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "877\n",
      "878\n",
      "0.39297195679951513  ,  1.2111  ,  1.3973\n",
      "0.13459080758163683  ,  0.9936  ,  1.2345\n",
      "0.04883684121843432  ,  0.9709  ,  1.3077\n",
      "879\n",
      "880\n",
      "0.3825170500486443  ,  4.526  ,  2.8763\n",
      "0.10947484841603383  ,  0.8317  ,  1.4484\n",
      "0.053723426789492795  ,  0.8262  ,  1.4936\n",
      "881\n",
      "882\n",
      "0.5391338204391768  ,  0.8784  ,  0.9967\n",
      "-0.0022765121816805253  ,  1.0354  ,  1.4452\n",
      "0.03970406913994646  ,  1.0366  ,  1.3936\n",
      "883\n",
      "884\n",
      "0.3267245115989592  ,  0.7667  ,  1.1672\n",
      "0.07722046244497333  ,  0.7957  ,  1.1935\n",
      "-0.15844985795568817  ,  0.815  ,  1.0994\n",
      "885\n",
      "886\n",
      "0.41275060410587777  ,  0.8915  ,  1.194\n",
      "0.28477798160432294  ,  1.0035  ,  1.3409\n",
      "0.09092248422051408  ,  1.0319  ,  1.4319\n",
      "887\n",
      "888\n",
      "0.1823327612094656  ,  0.7338  ,  1.3524\n",
      "-0.12291635501873924  ,  0.9069  ,  1.1026\n",
      "-0.13414016408737126  ,  0.7762  ,  1.2823\n",
      "889\n",
      "890\n",
      "0.0708863836180517  ,  0.9233  ,  1.8304\n",
      "0.07313683751189738  ,  0.922  ,  1.8482\n",
      "0.036458116024606045  ,  0.948  ,  1.8001\n",
      "891\n",
      "892\n",
      "0.3208770962413365  ,  0.653  ,  1.3244\n",
      "0.0354584262846727  ,  0.7197  ,  1.3864\n",
      "0.02603973818025246  ,  0.7905  ,  1.2836\n",
      "893\n",
      "894\n",
      "0.17445124067813034  ,  1.0823  ,  1.3331\n",
      "0.057230391574053165  ,  1.1129  ,  1.3161\n",
      "-0.08408785804045546  ,  1.1072  ,  1.2829\n",
      "895\n",
      "896\n",
      "0.6971654429174848  ,  0.2428  ,  0.6863\n",
      "0.13340043377010405  ,  0.3505  ,  0.8504\n",
      "-0.051721710721287326  ,  0.2361  ,  0.9106\n",
      "897\n",
      "898\n",
      "0.03326765396652614  ,  0.2378  ,  0.6814\n",
      "-0.013611596212629317  ,  0.415  ,  0.5492\n",
      "-0.06245370711150415  ,  0.3514  ,  0.5886\n",
      "899\n",
      "900\n",
      "0.5628499611820679  ,  0.8424  ,  0.7712\n",
      "-0.07172846129116504  ,  0.3961  ,  0.9316\n",
      "0.019861846790293215  ,  0.4399  ,  0.8884\n",
      "901\n",
      "902\n",
      "-0.005049100729911195  ,  0.1899  ,  0.7117\n",
      "-0.030137768039300662  ,  0.2059  ,  0.7038\n",
      "0.04409112221731498  ,  0.247  ,  0.6772\n",
      "903\n",
      "904\n",
      "0.36304785332627093  ,  0.2292  ,  0.6506\n",
      "-0.17318479011493254  ,  0.2935  ,  0.6695\n",
      "-0.02466361014049528  ,  0.2957  ,  0.6625\n",
      "905\n",
      "906\n",
      "0.25077999224220543  ,  0.3422  ,  0.7528\n",
      "-0.0015906818673343723  ,  0.2223  ,  0.6905\n",
      "-0.08370199960711108  ,  0.2471  ,  0.6706\n",
      "907\n",
      "908\n",
      "0.43132565378220233  ,  0.7237  ,  0.7918\n",
      "-0.058360849871701016  ,  0.3782  ,  0.442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006743850139800772  ,  0.319  ,  0.4671\n",
      "909\n",
      "910\n",
      "0.08794834769844784  ,  0.1808  ,  0.5833\n",
      "0.013719099095109403  ,  0.1529  ,  0.5381\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "911\n",
      "912\n",
      "-0.03984754341537079  ,  0.3852  ,  0.8914\n",
      "0.03315952102100653  ,  0.9117  ,  0.5208\n",
      "-0.049892817337663986  ,  0.7093  ,  0.6015\n",
      "913\n",
      "914\n",
      "nan  ,  0.2208  ,  0.779\n",
      "nan  ,  0.2208  ,  0.779\n",
      "nan  ,  0.2208  ,  0.779\n",
      "915\n",
      "916\n",
      "0.12662788121268523  ,  0.3087  ,  0.7274\n",
      "0.05796635961046702  ,  0.2469  ,  0.7064\n",
      "-0.04229483819209338  ,  0.3055  ,  0.6652\n",
      "917\n",
      "918\n",
      "0.07368020444406993  ,  0.2532  ,  0.4955\n",
      "0.030368814085380502  ,  0.8946  ,  0.2747\n",
      "-0.026424189898289183  ,  0.9102  ,  0.2781\n",
      "919\n",
      "920\n",
      "0.06795460035027011  ,  0.6775  ,  0.9181\n",
      "-0.057635349969489824  ,  0.6306  ,  0.7784\n",
      "0.02050900767997188  ,  0.6547  ,  0.7484\n",
      "921\n",
      "922\n",
      "0.18783332087493687  ,  0.3053  ,  0.8831\n",
      "0.03576403220973163  ,  0.5597  ,  0.7041\n",
      "0.054969373701424906  ,  0.3424  ,  0.8624\n",
      "923\n",
      "924\n",
      "0.36682278841335736  ,  0.4135  ,  0.8275\n",
      "0.008210846184787372  ,  0.2467  ,  0.6428\n",
      "-0.014036603793890403  ,  0.2719  ,  0.6292\n",
      "925\n",
      "926\n",
      "0.0220369654446614  ,  0.366  ,  0.8902\n",
      "0.002885332093588891  ,  0.3238  ,  0.7176\n",
      "-0.09303636067973386  ,  0.2446  ,  0.7584\n",
      "927\n",
      "928\n",
      "0.20079577779583813  ,  0.2984  ,  0.8388\n",
      "0.04013363153405974  ,  0.3263  ,  0.8195\n",
      "0.006471575599379684  ,  0.3046  ,  0.8412\n",
      "929\n",
      "930\n",
      "0.13031826833052623  ,  0.5043  ,  0.9296\n",
      "0.08901045797532764  ,  0.3232  ,  0.8643\n",
      "0.07104145691362149  ,  0.3585  ,  0.8457\n",
      "931\n",
      "932\n",
      "0.32023078636052393  ,  0.3896  ,  0.8004\n",
      "0.040345590393205406  ,  0.3738  ,  0.8752\n",
      "-0.035701079549711766  ,  0.3951  ,  0.8513\n",
      "933\n",
      "934\n",
      "0.4340833229228503  ,  0.4269  ,  0.8257\n",
      "0.1276912966178444  ,  0.5763  ,  0.6059\n",
      "-0.025757814586073652  ,  0.4312  ,  0.7001\n",
      "935\n",
      "936\n",
      "0.07906512811886202  ,  0.3382  ,  0.7763\n",
      "-0.028225286292310685  ,  0.344  ,  0.7713\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "937\n",
      "938\n",
      "0.3564564434162343  ,  0.428  ,  1.0611\n",
      "0.11072886527015921  ,  0.4429  ,  1.0806\n",
      "-0.08713827964944462  ,  0.5045  ,  1.0147\n",
      "939\n",
      "940\n",
      "0.024636921341820286  ,  0.9596  ,  0.9623\n",
      "-0.015059781518449639  ,  0.445  ,  0.825\n",
      "-0.026307773217411276  ,  0.497  ,  0.7862\n",
      "941\n",
      "942\n",
      "0.39858123786255584  ,  0.3083  ,  0.9335\n",
      "0.0035434185608931718  ,  0.3283  ,  1.0094\n",
      "nan  ,  0.3254  ,  1.012\n",
      "943\n",
      "944\n",
      "0.1968748461207829  ,  0.9303  ,  0.8254\n",
      "-0.07303472271214788  ,  0.3465  ,  0.7776\n",
      "-0.17620438562921797  ,  0.369  ,  0.7477\n",
      "945\n",
      "946\n",
      "0.38473158115537137  ,  0.3397  ,  0.8527\n",
      "-0.051356726629061475  ,  0.3726  ,  0.9341\n",
      "0.04864483236586134  ,  0.4795  ,  0.8266\n",
      "947\n",
      "948\n",
      "0.19673558881046815  ,  1.5856  ,  1.2064\n",
      "0.0072205517605585644  ,  0.5562  ,  0.6836\n",
      "0.1260545898360284  ,  0.5575  ,  0.6817\n",
      "949\n",
      "950\n",
      "0.13704675890019283  ,  0.295  ,  0.4727\n",
      "-0.008229388470662935  ,  0.6441  ,  0.2534\n",
      "0.055499490664570716  ,  0.5547  ,  0.263\n",
      "951\n",
      "952\n",
      "0.5369392476933053  ,  2.7023  ,  1.7476\n",
      "-0.07345561755348015  ,  0.4679  ,  1.0633\n",
      "-0.060379297910014125  ,  0.5493  ,  0.9665\n",
      "953\n",
      "954\n",
      "0.038221309179374344  ,  0.5649  ,  1.1685\n",
      "0.19903883415138263  ,  0.7205  ,  0.9353\n",
      "0.029684269268543846  ,  0.6823  ,  0.9925\n",
      "955\n",
      "956\n",
      "0.04742210012219133  ,  2.4126  ,  1.5649\n",
      "-0.0838503305453031  ,  0.419  ,  0.4584\n",
      "0.011202998169126593  ,  0.3012  ,  0.5256\n",
      "957\n",
      "958\n",
      "0.27974619111582055  ,  0.2802  ,  0.7003\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "959\n",
      "960\n",
      "0.09451068711884797  ,  0.2381  ,  0.8626\n",
      "0.017865440235937342  ,  0.5696  ,  0.695\n",
      "-0.022827399276565293  ,  0.285  ,  0.8355\n",
      "961\n",
      "962\n",
      "-0.0038725283569986777  ,  0.2259  ,  0.9737\n",
      "0.16601883926713096  ,  0.4592  ,  0.8485\n",
      "nan  ,  0.224  ,  0.9738\n",
      "963\n",
      "964\n",
      "0.4548526089541075  ,  3.0965  ,  2.2059\n",
      "-0.07604491081127786  ,  0.5092  ,  0.8656\n",
      "-0.01594862310287908  ,  0.5127  ,  0.8527\n",
      "965\n",
      "966\n",
      "0.19816932047264826  ,  0.1203  ,  0.6662\n",
      "-0.01891086162891018  ,  0.1215  ,  0.6711\n",
      "nan  ,  0.121  ,  0.6713\n",
      "967\n",
      "968\n",
      "0.3848104749454606  ,  3.0258  ,  2.7571\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "969\n",
      "970\n",
      "0.45186420904080443  ,  0.291  ,  0.6761\n",
      "0.016519250270307866  ,  0.4551  ,  0.5622\n",
      "0.04961771174466599  ,  0.5037  ,  0.5332\n",
      "971\n",
      "972\n",
      "0.786850356620201  ,  0.2145  ,  0.7614\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "973\n",
      "974\n",
      "0.2847821423821287  ,  0.2934  ,  0.8284\n",
      "-0.14611517401723356  ,  0.3341  ,  0.8347\n",
      "0.04928642714927704  ,  0.3601  ,  0.8042\n",
      "975\n",
      "976\n",
      "0.17715999733333873  ,  1.6412  ,  1.1987\n",
      "0.02962466987981443  ,  0.2412  ,  0.7455\n",
      "nan  ,  0.2412  ,  0.7456\n",
      "977\n",
      "978\n",
      "0.2555716202615978  ,  0.2068  ,  0.6004\n",
      "-0.022006947736603024  ,  0.2119  ,  0.6235\n",
      "nan  ,  0.2112  ,  0.6239\n",
      "979\n",
      "980\n",
      "0.15232208358145694  ,  0.2056  ,  0.4587\n",
      "0.030272421611856906  ,  0.2705  ,  0.3037\n",
      "-0.01726800484903919  ,  0.1659  ,  0.3513\n",
      "981\n",
      "982\n",
      "0.1389545674610566  ,  0.2901  ,  0.7607\n",
      "-0.027929520496862377  ,  0.5002  ,  0.6042\n",
      "-0.03550112651134263  ,  0.5587  ,  0.5611\n",
      "983\n",
      "984\n",
      "0.08286000613213168  ,  0.3069  ,  0.8813\n",
      "0.11973603027146076  ,  0.3327  ,  0.8572\n",
      "nan  ,  0.288  ,  0.8972\n",
      "985\n",
      "986\n",
      "0.34529293735757827  ,  0.2474  ,  0.6669\n",
      "0.04410278806547773  ,  0.2162  ,  0.7231\n",
      "0.01708341144585589  ,  0.2114  ,  0.7275\n",
      "987\n",
      "988\n",
      "0.22400662646918176  ,  0.3434  ,  0.9906\n",
      "0.043311192424731186  ,  0.3467  ,  1.0111\n",
      "-0.058443248986416674  ,  0.3529  ,  1.0065\n",
      "989\n",
      "990\n",
      "0.2661545849051752  ,  0.2434  ,  0.7123\n",
      "-0.0674181726481651  ,  0.3382  ,  0.6815\n",
      "-0.055521454285473185  ,  0.2578  ,  0.7388\n",
      "991\n",
      "992\n",
      "0.05980209659514715  ,  0.3571  ,  0.8785\n",
      "-0.0019048362710989315  ,  0.3988  ,  0.8352\n",
      "-0.08656248770822465  ,  0.446  ,  0.7818\n",
      "993\n",
      "994\n",
      "0.09975473711134143  ,  0.2208  ,  0.7939\n",
      "-0.12146406397564499  ,  0.231  ,  0.7923\n",
      "0.03523541307021313  ,  0.2223  ,  0.7947\n",
      "995\n",
      "996\n",
      "0.3458585077414206  ,  0.4487  ,  0.7813\n",
      "0.13610173495666072  ,  0.5631  ,  0.6581\n",
      "-0.0023037996221001488  ,  0.5229  ,  0.6902\n",
      "997\n",
      "998\n",
      "0.139589116328953  ,  0.1829  ,  0.6988\n",
      "0.0049084593757198975  ,  0.1738  ,  0.7108\n",
      "nan  ,  0.1738  ,  0.7109\n",
      "999\n",
      "1000\n",
      "0.2284384051232321  ,  0.453  ,  0.7634\n",
      "-0.021156148632204653  ,  0.197  ,  0.6725\n",
      "-0.027333727783733705  ,  0.1996  ,  0.6705\n",
      "1001\n",
      "1002\n",
      "0.4346539996037421  ,  0.246  ,  0.4563\n",
      "-0.1565266761655409  ,  0.8331  ,  0.2692\n",
      "-0.18524337175668082  ,  0.7042  ,  0.2697\n",
      "1003\n",
      "1004\n",
      "0.4908750511556685  ,  0.2575  ,  0.731\n",
      "-0.008651565112729291  ,  0.4278  ,  0.7022\n",
      "-0.03518957027476114  ,  0.3568  ,  0.7539\n",
      "1005\n",
      "1006\n",
      "0.05742743045831597  ,  0.3261  ,  0.8581\n",
      "nan  ,  0.322  ,  0.8655\n",
      "nan  ,  0.322  ,  0.8655\n",
      "1007\n",
      "1008\n",
      "-0.012084499504362033  ,  0.2394  ,  0.7447\n",
      "0.04626965775781048  ,  0.2501  ,  0.729\n",
      "-0.03764520097908505  ,  0.3147  ,  0.6837\n",
      "1009\n",
      "1010\n",
      "0.34180473675592127  ,  2.1965  ,  1.383\n",
      "-0.012307598259252404  ,  0.4481  ,  0.8026\n",
      "0.0643862661660704  ,  0.4315  ,  0.8186\n",
      "1011\n",
      "1012\n",
      "0.1775190285927787  ,  0.3599  ,  0.8579\n",
      "-0.008383441128866478  ,  0.3192  ,  0.8976\n",
      "0.012733099204965279  ,  0.3352  ,  0.8822\n",
      "1013\n",
      "1014\n",
      "0.3789961152793422  ,  2.5349  ,  2.0156\n",
      "-0.1085594575931273  ,  0.3782  ,  1.2441\n",
      "0.031159038039130275  ,  0.4224  ,  1.2122\n",
      "1015\n",
      "1016\n",
      "0.27123962973836213  ,  0.3108  ,  0.8532\n",
      "-0.1345182815568748  ,  0.4079  ,  0.8089\n",
      "0.07646441459600481  ,  0.402  ,  0.8099\n",
      "1017\n",
      "1018\n",
      "0.13295479975545837  ,  0.4207  ,  0.8805\n",
      "0.08742828704496111  ,  0.5632  ,  0.6858\n",
      "-0.03467957528551493  ,  0.6253  ,  0.6307\n",
      "1019\n",
      "1020\n",
      "0.3141060304556716  ,  0.3147  ,  0.7892\n",
      "-0.03466092907147672  ,  0.2883  ,  0.8441\n",
      "-0.03409265667829493  ,  0.2929  ,  0.8393\n",
      "1021\n",
      "1022\n",
      "0.295851393066961  ,  1.0895  ,  0.8143\n",
      "-0.009574261515676454  ,  0.5274  ,  0.5246\n",
      "-0.11578374398393562  ,  0.5711  ,  0.4912\n",
      "1023\n",
      "1024\n",
      "-0.012422074640915264  ,  0.2537  ,  0.9123\n",
      "-0.02290231088273591  ,  0.2149  ,  0.9009\n",
      "-0.0027078858019686193  ,  0.2879  ,  0.8626\n",
      "1025\n",
      "1026\n",
      "0.17464487315954022  ,  0.4134  ,  0.9002\n",
      "0.004425635662492111  ,  0.3932  ,  0.6061\n",
      "0.034430659005246146  ,  0.1872  ,  0.6937\n",
      "1027\n",
      "1028\n",
      "0.14223713233460258  ,  2.7642  ,  1.8091\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "1029\n",
      "1030\n",
      "0.42249412926434105  ,  0.3613  ,  0.6778\n",
      "0.11428490356133846  ,  0.4466  ,  0.7099\n",
      "-0.06769799786224036  ,  0.5823  ,  0.6083\n",
      "1031\n",
      "1032\n",
      "0.5066795133914925  ,  0.3553  ,  0.8218\n",
      "-0.06425975756532291  ,  0.3325  ,  1.0084\n",
      "0.057239229407515385  ,  0.3549  ,  0.9878\n",
      "1033\n",
      "1034\n",
      "0.2864802039427692  ,  0.2172  ,  0.5339\n",
      "0.15962925926838564  ,  0.3078  ,  0.4892\n",
      "-0.1026678627238394  ,  0.2802  ,  0.5168\n",
      "1035\n",
      "1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04499683918982305  ,  0.3356  ,  0.8969\n",
      "-0.0010420088788802347  ,  0.4357  ,  0.7912\n",
      "0.11274480764984757  ,  0.4715  ,  0.7619\n",
      "1037\n",
      "1038\n",
      "0.6223661652565461  ,  0.3914  ,  0.9055\n",
      "-0.01738061195246566  ,  0.3108  ,  1.0872\n",
      "-0.05168714770101275  ,  0.3132  ,  1.0854\n",
      "1039\n",
      "1040\n",
      "0.27519685411969663  ,  0.9487  ,  0.8943\n",
      "-0.10838965247051116  ,  0.4336  ,  0.6998\n",
      "0.087831418429368  ,  0.4347  ,  0.6914\n",
      "1041\n",
      "1042\n",
      "0.11744271283773189  ,  0.7552  ,  0.7609\n",
      "0.09916897588746812  ,  0.4937  ,  0.4512\n",
      "0.009744313044029614  ,  0.4773  ,  0.4634\n",
      "1043\n",
      "1044\n",
      "-0.0032980538302610166  ,  0.2858  ,  0.8224\n",
      "0.1491961726113758  ,  0.2969  ,  0.705\n",
      "0.010389098994365527  ,  0.3556  ,  0.6664\n",
      "1045\n",
      "1046\n",
      "0.1829054429329624  ,  0.6602  ,  0.9414\n",
      "0.00563721567979863  ,  0.4722  ,  0.7016\n",
      "0.01026876272814559  ,  0.338  ,  0.78\n",
      "1047\n",
      "1048\n",
      "0.2152744251188815  ,  0.3475  ,  0.7638\n",
      "0.022839219217804147  ,  0.6677  ,  0.5396\n",
      "-0.1357755977044257  ,  0.695  ,  0.525\n",
      "1049\n",
      "1050\n",
      "0.3009713210392916  ,  0.37  ,  0.8845\n",
      "-0.011854700188730919  ,  0.6357  ,  0.733\n",
      "0.023905946016081533  ,  0.6863  ,  0.701\n",
      "1051\n",
      "1052\n",
      "0.15843825355148844  ,  0.4832  ,  0.6837\n",
      "0.09699657221719825  ,  0.5142  ,  0.5477\n",
      "0.03548142916559309  ,  0.499  ,  0.5643\n",
      "1053\n",
      "1054\n",
      "0.1868140859299433  ,  0.3366  ,  0.7457\n",
      "0.2608452773338992  ,  0.6091  ,  0.4743\n",
      "-0.02394873709179239  ,  0.6909  ,  0.4407\n",
      "1055\n",
      "1056\n",
      "0.49113635081957063  ,  0.6368  ,  0.8442\n",
      "0.12749190935914068  ,  0.201  ,  0.7075\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "1057\n",
      "1058\n",
      "0.006569137866550666  ,  0.3051  ,  0.8072\n",
      "-0.0077645855307264125  ,  0.3029  ,  0.8089\n",
      "0.07827999569727317  ,  0.3283  ,  0.7821\n",
      "1059\n",
      "1060\n",
      "0.3903444579061329  ,  0.4755  ,  0.6355\n",
      "0.20311775601701834  ,  0.6463  ,  0.558\n",
      "0.020913284435908334  ,  0.6928  ,  0.5379\n",
      "1061\n",
      "1062\n",
      "0.31844916035886467  ,  0.463  ,  0.9684\n",
      "0.20067568774548972  ,  0.4599  ,  0.9922\n",
      "0.03406257946614429  ,  0.4648  ,  0.9934\n",
      "1063\n",
      "1064\n",
      "0.32481123509347953  ,  0.7749  ,  0.8011\n",
      "-0.10296130726535144  ,  0.617  ,  0.5469\n",
      "0.0007354505948729525  ,  0.5574  ,  0.585\n",
      "1065\n",
      "1066\n",
      "0.12227565057823157  ,  0.1941  ,  0.6676\n",
      "0.0509840581877754  ,  0.319  ,  0.5554\n",
      "-0.06152905912303062  ,  0.2442  ,  0.5902\n",
      "1067\n",
      "1068\n",
      "0.10301691565172376  ,  0.389  ,  0.7277\n",
      "-0.013486514885119528  ,  0.6672  ,  0.4445\n",
      "-0.06319467045219214  ,  0.6728  ,  0.4391\n",
      "1069\n",
      "1070\n",
      "0.12619607666644342  ,  0.2592  ,  0.7825\n",
      "0.10938224373069269  ,  0.3515  ,  0.6938\n",
      "0.07282760886292311  ,  0.3134  ,  0.7191\n",
      "1071\n",
      "1072\n",
      "0.02431603876387759  ,  0.8203  ,  1.4777\n",
      "nan  ,  0.1737  ,  0.7998\n",
      "nan  ,  0.1737  ,  0.7998\n",
      "1073\n",
      "1074\n",
      "0.419579290805947  ,  0.223  ,  0.5876\n",
      "0.06535708105728157  ,  0.3779  ,  0.5573\n",
      "-0.001973325743403302  ,  0.2575  ,  0.6413\n",
      "1075\n",
      "1076\n",
      "0.1619157457099772  ,  1.8663  ,  1.7192\n",
      "-0.061039951981126425  ,  0.342  ,  0.5875\n",
      "-0.07380573692102871  ,  0.2082  ,  0.6659\n",
      "1077\n",
      "1078\n",
      "0.291375267159188  ,  0.4134  ,  0.7093\n",
      "0.024404626805805095  ,  0.5659  ,  0.5744\n",
      "0.05198723070186313  ,  0.4814  ,  0.6321\n",
      "1079\n",
      "1080\n",
      "0.26563142903427217  ,  0.6408  ,  1.1995\n",
      "-0.005175893419994098  ,  0.1266  ,  0.5706\n",
      "-0.008626222876992476  ,  0.1876  ,  0.5448\n",
      "1081\n",
      "1082\n",
      "0.4290703072151729  ,  0.4094  ,  0.7843\n",
      "-0.006937438281481449  ,  0.3323  ,  0.7348\n",
      "-0.06521981883133744  ,  0.3395  ,  0.7276\n",
      "1083\n",
      "1084\n",
      "0.24755386164638524  ,  0.3783  ,  0.7334\n",
      "-0.06572034798049142  ,  0.268  ,  0.6786\n",
      "-0.037077034711158564  ,  0.3167  ,  0.6418\n",
      "1085\n",
      "1086\n",
      "0.6225305264025396  ,  0.1773  ,  0.6096\n",
      "-0.018070419557894502  ,  0.2099  ,  0.7877\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "1087\n",
      "1088\n",
      "0.2865140959704617  ,  0.3021  ,  0.6761\n",
      "-0.059819658235122995  ,  0.2974  ,  0.6315\n",
      "-0.023771306299418617  ,  0.2693  ,  0.631\n",
      "1089\n",
      "1090\n",
      "0.33840411610173277  ,  0.5568  ,  0.807\n",
      "-0.0724185137596757  ,  0.3752  ,  0.8702\n",
      "0.024683337655987188  ,  0.3673  ,  0.8636\n",
      "1091\n",
      "1092\n",
      "0.08375236142473386  ,  0.2824  ,  0.9915\n",
      "0.1292034069078492  ,  0.2873  ,  0.9517\n",
      "0.00892495680426572  ,  0.2637  ,  0.9705\n",
      "1093\n",
      "1094\n",
      "0.1481298152187841  ,  0.4247  ,  0.927\n",
      "-0.04388392756263796  ,  0.5412  ,  0.8051\n",
      "-0.01816294053204989  ,  0.5969  ,  0.7484\n",
      "1095\n",
      "1096\n",
      "0.31192585157936736  ,  1.0899  ,  0.9607\n",
      "0.02033776278147642  ,  0.6845  ,  0.6068\n",
      "0.0690319862320506  ,  0.5398  ,  0.7133\n",
      "1097\n",
      "1098\n",
      "0.45562606071430223  ,  0.345  ,  0.8185\n",
      "0.19964118476559137  ,  0.3937  ,  0.8324\n",
      "0.05074662330129242  ,  0.4533  ,  0.8026\n",
      "1099\n",
      "1100\n",
      "0.2940092763260652  ,  0.9504  ,  0.9004\n",
      "-0.05453261795508779  ,  0.4621  ,  0.9705\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "1101\n",
      "1102\n",
      "0.2585513763017297  ,  1.5925  ,  1.4559\n",
      "-0.044528151292779934  ,  0.3244  ,  0.8544\n",
      "-0.010028109787131503  ,  0.3892  ,  0.7882\n",
      "1103\n",
      "1104\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "0.09900872902971795  ,  0.4265  ,  1.0845\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "1105\n",
      "1106\n",
      "0.1952173049844492  ,  0.3363  ,  0.6265\n",
      "-0.03682121838157198  ,  0.6498  ,  0.3992\n",
      "-0.04638518931801057  ,  0.5501  ,  0.4356\n",
      "1107\n",
      "1108\n",
      "0.13589557495232552  ,  0.2788  ,  0.6485\n",
      "-0.03794073146982739  ,  0.6222  ,  0.4101\n",
      "0.0716957037555378  ,  0.5475  ,  0.4454\n",
      "1109\n",
      "1110\n",
      "0.3275539415189668  ,  0.5051  ,  0.8329\n",
      "0.04513241974565062  ,  0.6343  ,  0.7549\n",
      "0.021933082239049433  ,  0.6624  ,  0.7325\n",
      "1111\n",
      "1112\n",
      "0.1592994218117894  ,  0.321  ,  0.8317\n",
      "0.1083076260481923  ,  0.323  ,  0.8377\n",
      "-0.03403801461437419  ,  0.4265  ,  0.7366\n",
      "1113\n",
      "1114\n",
      "0.3311617041384488  ,  0.4337  ,  0.6\n",
      "0.034835545557891125  ,  0.5656  ,  0.4455\n",
      "0.01795842789136471  ,  0.5804  ,  0.4392\n",
      "1115\n",
      "1116\n",
      "0.46638266678347595  ,  0.3688  ,  0.9166\n",
      "-0.026762882603267195  ,  0.3871  ,  1.0012\n",
      "0.02709730171636952  ,  0.3858  ,  1.0016\n",
      "1117\n",
      "1118\n",
      "0.031950756849422744  ,  0.2217  ,  0.7276\n",
      "0.09192578383935221  ,  0.3133  ,  0.6598\n",
      "0.019428809853899227  ,  0.2597  ,  0.7005\n",
      "1119\n",
      "1120\n",
      "0.1260560389035017  ,  1.7262  ,  1.9079\n",
      "0.02158974135853256  ,  0.4606  ,  0.8231\n",
      "0.04072995297120325  ,  0.4435  ,  0.8338\n",
      "1121\n",
      "1122\n",
      "0.05495114499799183  ,  0.4573  ,  0.7625\n",
      "-0.021352209511469634  ,  0.7028  ,  0.4545\n",
      "0.09010994272394221  ,  0.6351  ,  0.4912\n",
      "1123\n",
      "1124\n",
      "-0.017525495157084466  ,  0.2902  ,  0.8041\n",
      "0.04225310052159919  ,  0.7359  ,  0.5323\n",
      "0.032943224005109656  ,  0.6259  ,  0.5721\n",
      "1125\n",
      "1126\n",
      "0.1316218128277537  ,  0.3365  ,  0.7344\n",
      "-0.10466549518186798  ,  0.6706  ,  0.4393\n",
      "-0.04536648251784518  ,  0.6392  ,  0.4518\n",
      "1127\n",
      "1128\n",
      "-0.000193019807123925  ,  0.2668  ,  0.8582\n",
      "0.09856279160927164  ,  0.4148  ,  0.7477\n",
      "-0.0027535376375658763  ,  0.3242  ,  0.8139\n",
      "1129\n",
      "1130\n",
      "0.5192741459097324  ,  0.3378  ,  0.7798\n",
      "0.0875714548799356  ,  0.6165  ,  0.6685\n",
      "0.024936072968221673  ,  0.6308  ,  0.6614\n",
      "1131\n",
      "1132\n",
      "0.4854084250088191  ,  0.2304  ,  0.6749\n",
      "0.016166430643931456  ,  0.3265  ,  0.7063\n",
      "-0.028441847767873132  ,  0.3753  ,  0.6744\n",
      "1133\n",
      "1134\n",
      "0.6242058263276535  ,  0.2252  ,  0.6854\n",
      "0.08067550533686652  ,  0.4189  ,  0.6919\n",
      "-0.06729357459066873  ,  0.2983  ,  0.7723\n",
      "1135\n",
      "1136\n",
      "0.31292632691651534  ,  0.1934  ,  0.6788\n",
      "-0.015401207992889793  ,  0.1937  ,  0.7244\n",
      "0.01596693309395808  ,  0.251  ,  0.6901\n",
      "1137\n",
      "1138\n",
      "0.5302748481157646  ,  0.2495  ,  0.6684\n",
      "0.0007774388346783656  ,  0.2414  ,  0.8085\n",
      "-0.05377413949034599  ,  0.2629  ,  0.7929\n",
      "1139\n",
      "1140\n",
      "0.36939437778502016  ,  0.2808  ,  0.8333\n",
      "-0.014400231441460371  ,  0.2942  ,  0.848\n",
      "-0.03549220380598638  ,  0.3635  ,  0.791\n",
      "1141\n",
      "1142\n",
      "0.17231776703945395  ,  0.3582  ,  0.9323\n",
      "0.1452645650692869  ,  0.609  ,  0.7772\n",
      "-0.05248672790719845  ,  0.5562  ,  0.8131\n",
      "1143\n",
      "1144\n",
      "0.38345405210296135  ,  0.3457  ,  0.728\n",
      "-0.005910247620816545  ,  0.5305  ,  0.5706\n",
      "0.05598575304415398  ,  0.3343  ,  0.6662\n",
      "1145\n",
      "1146\n",
      "-0.017980396193573  ,  0.3361  ,  0.8146\n",
      "-0.03413280603742612  ,  0.5821  ,  0.5899\n",
      "-0.09627544108246071  ,  0.5954  ,  0.5807\n",
      "1147\n",
      "1148\n",
      "0.5376534177355564  ,  0.91  ,  0.6978\n",
      "0.12584429454632426  ,  0.5348  ,  0.7974\n",
      "-0.058367276384707456  ,  0.5384  ,  0.796\n",
      "1149\n",
      "1150\n",
      "0.2578600581362819  ,  2.1659  ,  2.6425\n",
      "-0.08563166230572028  ,  0.2143  ,  0.714\n",
      "-0.008812833249871923  ,  0.211  ,  0.7144\n",
      "1151\n",
      "64\n",
      "0.4566501342560597  ,  0.5597  ,  1.6731\n",
      "0.3472730084779321  ,  0.7108  ,  1.4893\n",
      "0.00443017466565245  ,  0.5826  ,  1.746\n",
      "65\n",
      "0.856738920371181  ,  0.4233  ,  1.4285\n",
      "0.2660292186130898  ,  0.9779  ,  2.1234\n",
      "0.02500745060330742  ,  0.604  ,  2.41\n",
      "66\n",
      "0.7041039974538442  ,  1.1831  ,  2.3691\n",
      "0.6788029889726752  ,  1.139  ,  1.9037\n",
      "0.20118237235602782  ,  1.3994  ,  2.8386\n",
      "67\n",
      "0.7155289709275783  ,  2.0452  ,  2.5359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016717508631028166  ,  3.0062  ,  3.7468\n",
      "0.4950364177836577  ,  2.9447  ,  3.663\n",
      "68\n",
      "0.4679021727629486  ,  0.3075  ,  1.1623\n",
      "0.0065624200042458  ,  0.3359  ,  1.2555\n",
      "nan  ,  0.3359  ,  1.2555\n",
      "69\n",
      "0.5510922360467183  ,  0.9484  ,  1.2111\n",
      "0.17251952808898616  ,  1.6657  ,  0.9973\n",
      "-0.04951531868538387  ,  0.7668  ,  1.506\n",
      "70\n",
      "0.1968284051401003  ,  0.3967  ,  1.5345\n",
      "0.1080614480302832  ,  0.3985  ,  1.544\n",
      "nan  ,  0.3984  ,  1.546\n",
      "71\n",
      "0.10892956022426319  ,  0.7346  ,  1.7631\n",
      "-0.19332418765873624  ,  1.7026  ,  1.6987\n",
      "-0.11317808139083085  ,  0.785  ,  1.7064\n",
      "72\n",
      "0.6733978587469069  ,  0.525  ,  1.2411\n",
      "0.4309602695165521  ,  0.7746  ,  1.4077\n",
      "0.05385455001103072  ,  0.6788  ,  1.7465\n",
      "73\n",
      "0.174724859755753  ,  0.7934  ,  1.7315\n",
      "0.04978328589835275  ,  0.6978  ,  1.6932\n",
      "0.10441689277134089  ,  0.6783  ,  1.7081\n",
      "74\n",
      "0.6994416461556832  ,  0.665  ,  1.6664\n",
      "0.2469246436293694  ,  0.8819  ,  1.7666\n",
      "0.08606784968929344  ,  0.821  ,  1.9115\n",
      "75\n",
      "0.9559819023335752  ,  0.3564  ,  0.9698\n",
      "0.13492086044219104  ,  0.8855  ,  3.0173\n",
      "nan  ,  0.8849  ,  3.0265\n",
      "76\n",
      "0.7494924093451005  ,  0.703  ,  2.1108\n",
      "0.5185158509230821  ,  0.8615  ,  2.2253\n",
      "0.16260084863369448  ,  0.832  ,  2.7439\n",
      "77\n",
      "0.4582166543112014  ,  1.6577  ,  2.3721\n",
      "0.004914965316013934  ,  1.2711  ,  2.162\n",
      "-0.014162570820167128  ,  1.2301  ,  2.1392\n",
      "78\n",
      "0.24965656099901956  ,  1.0876  ,  1.9317\n",
      "0.16079637898858298  ,  1.11  ,  2.006\n",
      "-0.2728212303001037  ,  1.1131  ,  2.0119\n",
      "79\n",
      "0.6793118904186486  ,  0.6985  ,  1.4872\n",
      "0.163894445798267  ,  1.1356  ,  1.5516\n",
      "0.012655351257888988  ,  0.8298  ,  1.8766\n",
      "80\n",
      "0.5989096942032299  ,  0.3952  ,  1.2232\n",
      "0.35230124236592836  ,  0.4695  ,  1.3936\n",
      "0.08718389623990025  ,  0.4798  ,  1.4699\n",
      "81\n",
      "0.48467264429311113  ,  0.5876  ,  1.4253\n",
      "0.4402427381087292  ,  0.6742  ,  1.1882\n",
      "0.10676758073740755  ,  0.7026  ,  1.3857\n",
      "82\n",
      "0.7282627667400063  ,  0.1094  ,  0.5888\n",
      "0.48291181816624196  ,  0.1868  ,  0.5657\n",
      "-0.03406100698446353  ,  0.409  ,  0.573\n",
      "83\n",
      "0.7228811572436014  ,  0.6305  ,  1.5103\n",
      "0.30750780276729445  ,  0.7257  ,  1.84\n",
      "0.1628354003204464  ,  0.7676  ,  1.8202\n",
      "84\n",
      "0.7622821623691347  ,  1.1141  ,  1.5936\n",
      "0.28586690584564584  ,  1.4638  ,  2.0335\n",
      "-0.1660700053426704  ,  1.8886  ,  2.1601\n",
      "85\n",
      "0.8325137087968757  ,  0.8956  ,  2.0134\n",
      "0.43056340193246134  ,  1.2027  ,  2.6489\n",
      "nan  ,  1.2393  ,  2.8407\n",
      "86\n",
      "-0.0034806299112722632  ,  0.6893  ,  2.1284\n",
      "0.13781396555122846  ,  0.7145  ,  2.0627\n",
      "nan  ,  0.6588  ,  2.1379\n",
      "87\n",
      "0.2109406661964179  ,  0.4702  ,  1.3763\n",
      "0.18747189093980765  ,  0.5738  ,  1.3409\n",
      "0.03577508198032008  ,  0.4793  ,  1.4067\n",
      "88\n",
      "0.7306724629004171  ,  0.9436  ,  2.0717\n",
      "0.6223806863487484  ,  0.8892  ,  1.9146\n",
      "0.4527792401871654  ,  1.0308  ,  2.3333\n",
      "89\n",
      "0.6600202579919446  ,  0.837  ,  1.4246\n",
      "0.02789595187338831  ,  1.0327  ,  1.8641\n",
      "0.028825632402838856  ,  1.0485  ,  1.8646\n",
      "90\n",
      "0.6491282206881768  ,  0.1949  ,  0.8358\n",
      "0.15448964502475362  ,  0.4668  ,  1.1189\n",
      "0.06693087233495436  ,  0.2241  ,  1.1113\n",
      "91\n",
      "0.7360072365447967  ,  0.4525  ,  1.1636\n",
      "0.3275515043271748  ,  0.8039  ,  1.4201\n",
      "0.05640884653374773  ,  0.5848  ,  1.7183\n",
      "92\n",
      "0.47837198793745594  ,  0.3554  ,  0.8902\n",
      "0.12629393736419087  ,  0.4335  ,  1.0033\n",
      "nan  ,  0.3927  ,  1.0555\n",
      "93\n",
      "0.6645609627315032  ,  0.9152  ,  2.1838\n",
      "0.04686434182036349  ,  1.0239  ,  2.5364\n",
      "nan  ,  1.0234  ,  2.539\n",
      "94\n",
      "0.617826948900295  ,  0.9913  ,  2.1874\n",
      "0.020670545304544735  ,  1.1148  ,  2.4813\n",
      "nan  ,  1.1148  ,  2.4814\n",
      "95\n",
      "0.3211079106169914  ,  1.3994  ,  3.0542\n",
      "0.28318721921346723  ,  3.0914  ,  2.6275\n",
      "nan  ,  1.4183  ,  3.1236\n",
      "96\n",
      "0.12828228691515742  ,  0.665  ,  1.4588\n",
      "0.13831986826965495  ,  0.7045  ,  1.3849\n",
      "-0.07568167809557698  ,  0.6722  ,  1.4617\n",
      "97\n",
      "0.6980208466269124  ,  0.707  ,  1.7641\n",
      "0.23655277255381724  ,  0.8791  ,  2.2188\n",
      "0.12699335408339832  ,  0.8753  ,  2.2827\n",
      "98\n",
      "0.4435629453487393  ,  0.7678  ,  1.8036\n",
      "0.11719737318361716  ,  0.8391  ,  1.9619\n",
      "0.04391724870996608  ,  0.8873  ,  1.9064\n",
      "99\n",
      "0.7140845567998255  ,  0.4967  ,  1.3938\n",
      "0.37884767933875657  ,  3.8431  ,  3.6761\n",
      "0.047620662383103154  ,  0.6309  ,  2.0309\n",
      "100\n",
      "0.7909841899762196  ,  0.4661  ,  1.2206\n",
      "nan  ,  0.5917  ,  2.0212\n",
      "nan  ,  0.5917  ,  2.0212\n",
      "101\n",
      "0.3341561909961289  ,  0.7178  ,  1.9951\n",
      "0.3757327333052002  ,  0.8914  ,  1.7315\n",
      "0.0019117919403389976  ,  0.7393  ,  2.0834\n",
      "102\n",
      "0.4034212382571948  ,  1.0723  ,  1.7624\n",
      "0.009525415427530201  ,  1.5743  ,  1.3245\n",
      "-0.03258862027351853  ,  1.1328  ,  1.6768\n",
      "103\n",
      "0.7299938029224882  ,  1.3655  ,  2.1972\n",
      "0.7132867376678336  ,  1.4015  ,  2.3087\n",
      "0.07068298768923369  ,  1.5312  ,  2.5707\n",
      "104\n",
      "0.7901870886516156  ,  0.933  ,  2.1028\n",
      "0.5325699745834043  ,  1.0848  ,  2.4474\n",
      "-0.06590304112188482  ,  1.1483  ,  2.689\n",
      "105\n",
      "0.39246138747577913  ,  0.3296  ,  0.9802\n",
      "0.1065902187558655  ,  0.5689  ,  0.9845\n",
      "0.10785126570552045  ,  0.4205  ,  1.0157\n",
      "106\n",
      "0.8251380719759487  ,  0.5354  ,  1.2385\n",
      "0.281322305883571  ,  0.7188  ,  1.9505\n",
      "nan  ,  0.7328  ,  2.0006\n",
      "107\n",
      "0.6399944108122804  ,  1.019  ,  2.3644\n",
      "0.004104805270630639  ,  1.1905  ,  2.5165\n",
      "-0.009963141244445063  ,  1.1232  ,  2.6001\n",
      "108\n",
      "0.2639933771203116  ,  0.4276  ,  1.4663\n",
      "0.4249673645688581  ,  0.4757  ,  1.2796\n",
      "0.13342369378887894  ,  0.4508  ,  1.4613\n",
      "109\n",
      "0.23126981070842245  ,  0.6717  ,  1.7641\n",
      "0.3677181208295084  ,  1.0841  ,  1.4747\n",
      "0.09342384148186404  ,  0.7383  ,  1.7438\n",
      "110\n",
      "0.73110846999204  ,  0.4929  ,  1.728\n",
      "0.13513944003564643  ,  0.8111  ,  1.8806\n",
      "nan  ,  0.5453  ,  2.0531\n",
      "111\n",
      "0.5204435787655414  ,  0.6812  ,  1.4501\n",
      "0.007594253336725388  ,  1.0385  ,  1.6475\n",
      "0.006936745675246724  ,  0.8158  ,  1.6286\n",
      "112\n",
      "0.7387763665698553  ,  0.608  ,  1.8304\n",
      "0.6626374957001276  ,  0.6393  ,  1.6938\n",
      "nan  ,  0.6962  ,  2.1789\n",
      "113\n",
      "0.6135259751869275  ,  0.5686  ,  1.8031\n",
      "0.22771485751959342  ,  0.7154  ,  1.9751\n",
      "nan  ,  0.6344  ,  2.1141\n",
      "114\n",
      "0.6368242581102332  ,  0.6537  ,  1.8312\n",
      "0.49513819823956917  ,  0.695  ,  2.0097\n",
      "nan  ,  0.7157  ,  2.0862\n",
      "115\n",
      "0.6616240825971973  ,  0.2604  ,  0.8728\n",
      "-0.03769148945621936  ,  0.4062  ,  1.1181\n",
      "0.21357469387746983  ,  0.356  ,  1.1062\n",
      "116\n",
      "0.844954779045246  ,  0.6594  ,  1.78\n",
      "-0.08125168789648682  ,  0.9491  ,  2.5208\n",
      "-0.085998131310549  ,  0.8955  ,  2.5372\n",
      "117\n",
      "0.6291996886503252  ,  0.8392  ,  1.8354\n",
      "0.08506509916908586  ,  1.0599  ,  1.9231\n",
      "0.03520717948023401  ,  0.9629  ,  2.0643\n",
      "118\n",
      "0.3336438609707434  ,  0.6695  ,  1.577\n",
      "0.14766512855076244  ,  0.5744  ,  1.7139\n",
      "-0.0126830151627205  ,  0.5667  ,  1.7447\n",
      "119\n",
      "0.015606930035354929  ,  0.466  ,  1.3235\n",
      "0.1198737670066257  ,  0.5775  ,  1.2187\n",
      "0.06092663422357068  ,  0.5527  ,  1.2458\n",
      "120\n",
      "0.24954585812436347  ,  0.5145  ,  1.3431\n",
      "0.07659560052577036  ,  0.5239  ,  1.3674\n",
      "0.025902620680387206  ,  0.5284  ,  1.3659\n",
      "121\n",
      "0.9165573914725691  ,  0.4074  ,  1.8977\n",
      "0.6348796522806195  ,  0.5165  ,  2.3582\n",
      "0.03587671372316254  ,  0.7167  ,  2.3454\n",
      "122\n",
      "0.5450955743688195  ,  0.8513  ,  1.4176\n",
      "0.2305725489830087  ,  1.5442  ,  1.7215\n",
      "0.14801145270419108  ,  0.797  ,  1.4643\n",
      "123\n",
      "0.768746832049498  ,  0.2368  ,  0.7959\n",
      "0.1308664755269141  ,  0.5521  ,  1.0207\n",
      "-0.17032708927389228  ,  0.6697  ,  0.9486\n",
      "124\n",
      "0.2723624911575946  ,  0.5697  ,  1.7074\n",
      "0.38377426288271504  ,  0.5692  ,  1.6539\n",
      "nan  ,  0.5802  ,  1.7346\n",
      "125\n",
      "0.09192171246112135  ,  0.6306  ,  1.6953\n",
      "0.08175272220428483  ,  1.5132  ,  1.4163\n",
      "nan  ,  0.6332  ,  1.6993\n",
      "126\n",
      "0.7667898485753047  ,  1.15  ,  1.6342\n",
      "0.2338511010930306  ,  1.6747  ,  2.0191\n",
      "-0.259449253672127  ,  1.7073  ,  2.4188\n",
      "127\n",
      "0.7566496085230141  ,  0.1328  ,  0.5088\n",
      "0.4989826184565348  ,  0.2021  ,  0.7342\n",
      "-0.03688676209790181  ,  0.3584  ,  0.7125\n",
      "128\n",
      "0.6678003057708682  ,  0.2461  ,  0.7833\n",
      "-0.10684715708483472  ,  0.7627  ,  0.8144\n",
      "0.17199163726005037  ,  0.3771  ,  0.9357\n",
      "129\n",
      "0.5582735686961424  ,  0.5805  ,  1.1718\n",
      "0.22160344718162225  ,  1.8336  ,  2.1276\n",
      "0.12704958727548965  ,  0.6915  ,  1.4541\n",
      "130\n",
      "0.7764978229080278  ,  0.4768  ,  1.3017\n",
      "0.5780916217298824  ,  0.9075  ,  1.6513\n",
      "nan  ,  0.6876  ,  2.0588\n",
      "131\n",
      "0.08434953463753557  ,  1.3625  ,  2.5878\n",
      "0.5229726217896831  ,  1.4161  ,  1.8345\n",
      "-0.0029017054941411725  ,  1.3814  ,  2.5973\n",
      "132\n",
      "0.37791384622376034  ,  1.4258  ,  2.1486\n",
      "0.0979251647824975  ,  1.4909  ,  2.1479\n",
      "0.1102034267906576  ,  1.5184  ,  2.1251\n",
      "133\n",
      "0.569336846437175  ,  0.9635  ,  1.8331\n",
      "0.008854692220300529  ,  1.1571  ,  2.3797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.190835780181111  ,  1.1521  ,  2.3501\n",
      "134\n",
      "0.3459026002619362  ,  0.4896  ,  1.3167\n",
      "0.4252671083377344  ,  0.7099  ,  1.1667\n",
      "0.03945115957799961  ,  0.573  ,  1.3529\n",
      "135\n",
      "0.709453029005764  ,  0.7658  ,  1.9456\n",
      "0.28111288765128967  ,  0.8608  ,  2.2287\n",
      "nan  ,  0.8774  ,  2.2806\n",
      "136\n",
      "0.5205734861170361  ,  1.1605  ,  1.4923\n",
      "0.018428766787445816  ,  0.3512  ,  1.184\n",
      "nan  ,  0.3371  ,  1.1911\n",
      "137\n",
      "0.5745165158755767  ,  0.548  ,  1.0421\n",
      "-0.016053761643717475  ,  0.7045  ,  1.1881\n",
      "nan  ,  0.3905  ,  1.3252\n",
      "138\n",
      "0.013379475525329332  ,  1.2004  ,  2.7136\n",
      "0.4402961045609602  ,  1.1914  ,  2.4051\n",
      "0.08517845893220484  ,  1.2003  ,  2.7134\n",
      "139\n",
      "0.6563237841248024  ,  0.4144  ,  1.2034\n",
      "0.2930915215337746  ,  0.5689  ,  1.3845\n",
      "0.17016966771951217  ,  0.5275  ,  1.4954\n",
      "140\n",
      "0.5311240450312547  ,  0.5351  ,  1.5254\n",
      "0.06992009556235426  ,  0.6167  ,  1.7623\n",
      "0.2414183388011363  ,  0.6123  ,  1.7089\n",
      "141\n",
      "0.22861888153901158  ,  0.73  ,  1.5425\n",
      "0.18498137099987252  ,  0.7375  ,  1.5612\n",
      "-0.007866388522683948  ,  0.8105  ,  1.4636\n",
      "142\n",
      "0.03937217789135471  ,  0.463  ,  1.3088\n",
      "-0.008454505766611189  ,  1.4729  ,  1.1849\n",
      "-0.21304000308950577  ,  0.5565  ,  1.2233\n",
      "143\n",
      "0.33278466668814083  ,  0.7959  ,  1.6406\n",
      "0.24224556135320474  ,  0.8706  ,  1.7049\n",
      "0.12050435336896259  ,  0.9696  ,  1.5343\n",
      "144\n",
      "0.21349252797648685  ,  0.9872  ,  2.3189\n",
      "0.6071477988530165  ,  0.8923  ,  1.9897\n",
      "-0.011173533540027444  ,  1.0035  ,  2.4412\n",
      "145\n",
      "0.49693070214220364  ,  0.461  ,  1.3942\n",
      "0.3271389776734742  ,  1.977  ,  1.6454\n",
      "0.07109769591720044  ,  0.5082  ,  1.5428\n",
      "146\n",
      "0.3224305504849546  ,  0.5821  ,  2.0403\n",
      "0.24312906827015063  ,  1.015  ,  1.74\n",
      "nan  ,  0.5862  ,  2.0592\n",
      "147\n",
      "0.6879164214210391  ,  0.3854  ,  1.208\n",
      "0.49595867537224547  ,  0.4431  ,  1.4834\n",
      "0.19772099119857467  ,  0.5453  ,  1.4924\n",
      "148\n",
      "0.5331007886850566  ,  0.6919  ,  1.871\n",
      "0.2797264034897914  ,  1.2278  ,  1.6429\n",
      "nan  ,  0.7566  ,  2.0741\n",
      "149\n",
      "0.9171366536491197  ,  0.4952  ,  1.3228\n",
      "0.026938916679945364  ,  1.0039  ,  2.5917\n",
      "-0.052965848788696715  ,  0.9103  ,  2.6678\n",
      "150\n",
      "0.5270530611963165  ,  0.37  ,  1.1932\n",
      "0.2236589319416068  ,  0.9703  ,  1.118\n",
      "0.08020803220918844  ,  0.4337  ,  1.3837\n",
      "151\n",
      "0.6950752303805108  ,  0.639  ,  1.6457\n",
      "0.13404832386218538  ,  0.9396  ,  1.7622\n",
      "0.011763604561147457  ,  0.7207  ,  1.9539\n",
      "152\n",
      "0.3025468726704621  ,  0.6716  ,  1.8242\n",
      "0.4679704241905692  ,  0.8265  ,  1.4494\n",
      "0.07563932263594457  ,  0.6856  ,  1.8836\n",
      "153\n",
      "0.18821085823959552  ,  0.7967  ,  2.0267\n",
      "0.30011607802402374  ,  0.8054  ,  1.9735\n",
      "0.14797402412989746  ,  0.8266  ,  1.9968\n",
      "154\n",
      "0.8110669071882579  ,  0.7902  ,  2.3335\n",
      "-0.06570749595625708  ,  1.0395  ,  2.9088\n",
      "-0.00919043621193804  ,  1.0155  ,  2.9243\n",
      "155\n",
      "0.5621933895441336  ,  0.4815  ,  1.2729\n",
      "0.048656685816998425  ,  0.5325  ,  1.5952\n",
      "0.0141107343876277  ,  0.6402  ,  1.5398\n",
      "156\n",
      "0.5709726959879222  ,  0.5226  ,  1.0538\n",
      "-0.03519627609578656  ,  2.297  ,  1.9788\n",
      "nan  ,  0.5538  ,  1.3935\n",
      "157\n",
      "0.35442409779749307  ,  0.542  ,  1.8491\n",
      "0.7546160203775425  ,  0.5405  ,  1.1094\n",
      "nan  ,  0.5469  ,  1.8715\n",
      "158\n",
      "0.7477812344200718  ,  0.4335  ,  1.3825\n",
      "0.3961887840319744  ,  0.5678  ,  1.6402\n",
      "-0.006933193440610167  ,  0.526  ,  1.8461\n",
      "159\n",
      "0.6561627763856913  ,  0.432  ,  1.3184\n",
      "0.20342885095892316  ,  0.7849  ,  1.5208\n",
      "0.08852268679216982  ,  0.5264  ,  1.6312\n",
      "160\n",
      "0.3818113964110145  ,  0.5033  ,  1.9551\n",
      "0.5912016999165547  ,  0.5016  ,  1.8211\n",
      "nan  ,  0.5071  ,  1.9811\n",
      "161\n",
      "0.3157900517287175  ,  0.7807  ,  2.1624\n",
      "0.0547178139785512  ,  0.7875  ,  2.1991\n",
      "nan  ,  0.7883  ,  2.2\n",
      "162\n",
      "0.6694301163705719  ,  0.5889  ,  1.8723\n",
      "0.23128700249856615  ,  0.6587  ,  2.0642\n",
      "nan  ,  0.6417  ,  2.111\n",
      "163\n",
      "0.6759930541690619  ,  0.4553  ,  1.2413\n",
      "0.05104493529816623  ,  0.5501  ,  1.5577\n",
      "0.10644066630443394  ,  0.5653  ,  1.5415\n",
      "164\n",
      "0.7095988798857478  ,  0.6837  ,  1.5144\n",
      "0.26880944485201624  ,  0.8704  ,  2.07\n",
      "-0.1451716491169033  ,  0.8876  ,  2.1064\n",
      "165\n",
      "0.4638352845786796  ,  0.7201  ,  1.7047\n",
      "0.07147559171531195  ,  0.7932  ,  1.8774\n",
      "0.09338124502355931  ,  0.7934  ,  1.8904\n",
      "166\n",
      "0.43129445343715644  ,  0.7836  ,  2.1103\n",
      "0.4637277950444087  ,  0.83  ,  2.0018\n",
      "0.019841520934590982  ,  0.8464  ,  2.2257\n",
      "167\n",
      "0.5002842133595726  ,  0.2794  ,  1.1656\n",
      "0.33879535899683416  ,  0.3059  ,  1.2903\n",
      "nan  ,  0.3077  ,  1.3019\n",
      "168\n",
      "0.23782628973949818  ,  7.7291  ,  6.2149\n",
      "0.028382860902649985  ,  0.5405  ,  1.7914\n",
      "-0.00949336116929395  ,  0.4932  ,  1.8224\n",
      "169\n",
      "0.4072351190262314  ,  1.1072  ,  2.31\n",
      "0.298895788774851  ,  1.207  ,  2.18\n",
      "nan  ,  1.1553  ,  2.4921\n",
      "170\n",
      "0.36116580471277226  ,  0.8779  ,  1.9258\n",
      "0.20419278932187143  ,  0.9518  ,  1.9514\n",
      "0.08751498250334341  ,  0.9399  ,  2.0698\n",
      "171\n",
      "0.21024193671208127  ,  1.4581  ,  2.316\n",
      "0.23060733706502717  ,  1.6326  ,  1.9488\n",
      "0.12952976138873679  ,  1.5198  ,  2.2289\n",
      "172\n",
      "0.4658322807521319  ,  0.9408  ,  1.6075\n",
      "0.10277739264310759  ,  1.233  ,  1.7701\n",
      "0.2631121753191028  ,  1.0748  ,  1.9115\n",
      "173\n",
      "0.7042595269828159  ,  0.8538  ,  1.5098\n",
      "0.04301870790554735  ,  1.1648  ,  1.9371\n",
      "0.040607363615994645  ,  1.1461  ,  1.9665\n",
      "174\n",
      "0.3945500405703799  ,  0.7127  ,  1.8787\n",
      "nan  ,  0.7701  ,  2.0416\n",
      "nan  ,  0.7701  ,  2.0416\n",
      "175\n",
      "0.7205537616691763  ,  0.6101  ,  1.5112\n",
      "0.19147215147301178  ,  0.8318  ,  2.1434\n",
      "0.3350543604722703  ,  0.7912  ,  2.2027\n",
      "176\n",
      "0.7241297580223969  ,  0.7172  ,  1.5062\n",
      "0.6240955489789463  ,  1.021  ,  1.6631\n",
      "nan  ,  0.9643  ,  2.3843\n",
      "177\n",
      "0.3015598654569703  ,  0.5076  ,  1.5125\n",
      "0.1928188278162854  ,  0.7794  ,  1.5327\n",
      "0.16162287451342636  ,  0.531  ,  1.5906\n",
      "178\n",
      "0.34096684762799984  ,  1.3514  ,  2.442\n",
      "0.07275031279395679  ,  0.9003  ,  2.553\n",
      "nan  ,  0.8999  ,  2.5554\n",
      "179\n",
      "0.38177455020064954  ,  0.431  ,  1.2142\n",
      "0.17212851016501013  ,  0.5312  ,  1.1236\n",
      "-0.18493841165804542  ,  0.4905  ,  1.1839\n",
      "180\n",
      "0.8054395277268355  ,  0.6175  ,  1.5559\n",
      "0.47299288133113526  ,  0.7723  ,  2.5822\n",
      "0.07441433113005087  ,  0.7786  ,  2.7302\n",
      "181\n",
      "0.30926730653585593  ,  1.071  ,  2.1559\n",
      "0.6546497707430763  ,  0.9432  ,  1.6625\n",
      "0.2584749970641111  ,  1.1046  ,  2.2559\n",
      "182\n",
      "0.588005517792968  ,  0.4438  ,  1.6834\n",
      "-0.004117446355129363  ,  0.4909  ,  1.9072\n",
      "nan  ,  0.4909  ,  1.9072\n",
      "183\n",
      "0.7287929705425165  ,  0.5614  ,  1.7806\n",
      "0.0816282265544585  ,  0.7407  ,  2.3415\n",
      "0.02293792231557092  ,  0.6973  ,  2.3855\n",
      "184\n",
      "0.5460045980435326  ,  0.7305  ,  2.0083\n",
      "0.1484495911502465  ,  0.8528  ,  2.3176\n",
      "nan  ,  0.8439  ,  2.3581\n",
      "185\n",
      "0.7951749377331736  ,  0.2735  ,  0.5926\n",
      "-0.06675977201089785  ,  0.5735  ,  0.5791\n",
      "0.059778265185193094  ,  0.2436  ,  0.5487\n",
      "186\n",
      "0.3793748391693322  ,  1.7275  ,  2.2421\n",
      "0.25745689668637534  ,  1.683  ,  1.7097\n",
      "-0.10039331161290559  ,  1.7964  ,  2.1665\n",
      "187\n",
      "0.09767142974397486  ,  0.3704  ,  1.1885\n",
      "0.1600408375498072  ,  0.4297  ,  1.125\n",
      "0.1460366379665797  ,  0.5516  ,  1.0608\n",
      "188\n",
      "0.6559124384132544  ,  0.7357  ,  1.9617\n",
      "0.5605498122433907  ,  0.7547  ,  2.0176\n",
      "nan  ,  0.7999  ,  2.2089\n",
      "189\n",
      "0.17496028951802967  ,  1.1513  ,  1.9078\n",
      "0.35148256462830585  ,  1.1379  ,  1.6701\n",
      "0.1815310963596503  ,  1.2243  ,  1.7069\n",
      "190\n",
      "0.4332252154931768  ,  0.6599  ,  1.2459\n",
      "-0.006056568243402234  ,  1.1152  ,  0.9933\n",
      "0.11250923928031878  ,  0.4916  ,  1.2174\n",
      "191\n",
      "0.6173732683694216  ,  0.6592  ,  2.1544\n",
      "0.012938037498193352  ,  0.7222  ,  2.385\n",
      "nan  ,  0.7222  ,  2.385\n",
      "192\n",
      "0.29720235969038317  ,  1.0975  ,  1.6493\n",
      "0.23337743260143737  ,  1.06  ,  1.541\n",
      "-0.002746202784289501  ,  1.1078  ,  1.5385\n",
      "193\n",
      "0.29936901103141006  ,  1.5131  ,  2.42\n",
      "0.003316843293919472  ,  1.8896  ,  1.7575\n",
      "0.0940808653183959  ,  1.5384  ,  2.2088\n",
      "194\n",
      "0.07063556079085581  ,  0.8392  ,  1.5756\n",
      "0.13157726025943545  ,  1.0882  ,  1.1265\n",
      "0.1121718303951334  ,  0.8821  ,  1.4822\n",
      "195\n",
      "0.6744928090012918  ,  0.5262  ,  1.698\n",
      "0.6299754163524939  ,  0.5298  ,  1.6998\n",
      "nan  ,  0.5842  ,  1.9416\n",
      "196\n",
      "0.9330488658957543  ,  0.4303  ,  1.9523\n",
      "0.27732093133697727  ,  0.7243  ,  2.373\n",
      "-0.10653334740813483  ,  0.7105  ,  2.4207\n",
      "197\n",
      "0.8580152473017857  ,  0.6104  ,  2.3004\n",
      "0.6393592813112529  ,  0.7351  ,  2.6443\n",
      "0.2548998392098485  ,  0.9379  ,  2.7488\n",
      "198\n",
      "0.41681418271275533  ,  1.5891  ,  1.9062\n",
      "0.07841211527710401  ,  1.7426  ,  1.9835\n",
      "0.21537662801714927  ,  1.7527  ,  2.0031\n",
      "199\n",
      "0.7984640985561255  ,  0.7547  ,  1.8674\n",
      "0.39989129696921405  ,  0.9159  ,  2.1659\n",
      "nan  ,  0.9051  ,  2.363\n",
      "200\n",
      "0.5642898201730705  ,  0.8845  ,  1.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  ,  1.0263  ,  2.4059\n",
      "nan  ,  1.0263  ,  2.4059\n",
      "201\n",
      "0.6685500057925232  ,  0.6802  ,  1.8555\n",
      "0.6140094664211729  ,  0.7523  ,  1.9351\n",
      "0.11199361879688421  ,  0.807  ,  2.314\n",
      "202\n",
      "0.07660835817225568  ,  1.0464  ,  2.1732\n",
      "0.11403844163089576  ,  1.9263  ,  1.7886\n",
      "0.01554065291762156  ,  1.0849  ,  2.0936\n",
      "203\n",
      "0.3614776392138799  ,  0.7605  ,  1.5987\n",
      "0.4658510967662355  ,  0.7367  ,  1.4666\n",
      "0.22082149131417186  ,  0.9242  ,  1.4203\n",
      "204\n",
      "0.3154659676990577  ,  8.1581  ,  6.2106\n",
      "-0.02048999469295954  ,  0.6129  ,  1.7694\n",
      "nan  ,  0.5855  ,  1.7826\n",
      "205\n",
      "0.3199579470457084  ,  0.3637  ,  1.3659\n",
      "0.17944112979403543  ,  0.4951  ,  1.3157\n",
      "0.11544398036074192  ,  0.4492  ,  1.3502\n",
      "206\n",
      "0.3777728060188875  ,  0.6247  ,  1.5067\n",
      "0.7200675406857371  ,  0.5837  ,  1.3327\n",
      "0.0994082881472216  ,  0.8202  ,  1.4592\n",
      "207\n",
      "0.883455015736534  ,  0.447  ,  0.985\n",
      "0.4046025050196415  ,  0.8068  ,  2.0495\n",
      "nan  ,  0.7919  ,  2.1901\n",
      "208\n",
      "0.5756610165917566  ,  0.4762  ,  1.253\n",
      "0.33260999503262406  ,  0.5901  ,  1.4841\n",
      "0.2961807469345661  ,  0.6983  ,  1.4876\n",
      "209\n",
      "0.33180420886563117  ,  0.8194  ,  1.6697\n",
      "0.06661282696071431  ,  1.4759  ,  1.4213\n",
      "0.13436540093127247  ,  0.8436  ,  1.8275\n",
      "210\n",
      "0.7239418139160445  ,  1.1459  ,  1.8943\n",
      "0.18442466928304724  ,  1.5039  ,  2.6228\n",
      "nan  ,  1.55  ,  2.7652\n",
      "211\n",
      "0.8115123435355157  ,  0.6926  ,  1.6728\n",
      "0.5746925897442126  ,  0.7977  ,  1.9517\n",
      "nan  ,  0.8562  ,  2.1869\n",
      "212\n",
      "0.16676810146298296  ,  0.51  ,  1.2665\n",
      "0.1825270391384391  ,  0.5136  ,  1.2715\n",
      "0.09631407144097291  ,  0.5404  ,  1.2571\n",
      "213\n",
      "0.5400010547417274  ,  1.6909  ,  2.4607\n",
      "0.2441087769710152  ,  1.951  ,  2.7721\n",
      "-0.01992646986363853  ,  1.9541  ,  2.7615\n",
      "214\n",
      "0.6708918685209447  ,  0.7393  ,  1.5096\n",
      "0.12398632690330737  ,  1.6362  ,  2.2\n",
      "-0.06706901954441652  ,  0.8806  ,  1.898\n",
      "215\n",
      "0.3835384072494452  ,  0.6681  ,  1.516\n",
      "0.22956300447984843  ,  0.8223  ,  1.363\n",
      "0.03617294585302704  ,  0.7604  ,  1.5\n",
      "216\n",
      "0.7179141914031514  ,  0.4903  ,  1.8427\n",
      "0.022901805930024777  ,  0.5181  ,  2.1768\n",
      "nan  ,  0.5182  ,  2.1769\n",
      "217\n",
      "0.732733543554331  ,  0.416  ,  1.2154\n",
      "0.40915529270382905  ,  0.5255  ,  1.601\n",
      "0.01305721185734113  ,  0.5272  ,  1.7838\n",
      "218\n",
      "0.2096685902907252  ,  1.9443  ,  2.7924\n",
      "0.16627841639900806  ,  2.0353  ,  2.3999\n",
      "0.11096902244230447  ,  2.0216  ,  2.5758\n",
      "219\n",
      "0.6343994451624937  ,  0.8476  ,  1.5699\n",
      "0.35582030962266664  ,  0.5909  ,  1.7965\n",
      "0.035221712485523145  ,  0.5885  ,  1.9335\n",
      "220\n",
      "0.02543995037103412  ,  0.9851  ,  1.5943\n",
      "0.17751784061517256  ,  1.2614  ,  0.97\n",
      "-0.029267109151863653  ,  0.9982  ,  1.51\n",
      "221\n",
      "0.33106568724500635  ,  0.4867  ,  1.5825\n",
      "0.4646083777710889  ,  0.6809  ,  1.3243\n",
      "nan  ,  0.5078  ,  1.6611\n",
      "222\n",
      "0.48919349631909  ,  0.8945  ,  2.2534\n",
      "0.07605435839800471  ,  0.9311  ,  2.6196\n",
      "nan  ,  0.8296  ,  2.723\n",
      "223\n",
      "0.8170570693234214  ,  0.792  ,  1.4753\n",
      "0.0880330551866581  ,  0.834  ,  2.7798\n",
      "0.12660681195593199  ,  0.8218  ,  2.7988\n",
      "224\n",
      "0.8234588564558246  ,  0.2154  ,  0.6652\n",
      "-0.12427267031937612  ,  1.2239  ,  0.9496\n",
      "0.10223116088989698  ,  0.5782  ,  0.9523\n",
      "225\n",
      "0.6398657120124811  ,  1.4347  ,  2.1909\n",
      "0.14304051910817428  ,  2.0186  ,  2.3073\n",
      "0.016411084636580496  ,  1.8411  ,  2.9738\n",
      "226\n",
      "0.3958306571045454  ,  0.5399  ,  1.3586\n",
      "0.2803163169830067  ,  0.5572  ,  1.3594\n",
      "-0.032175698471752286  ,  0.6393  ,  1.3299\n",
      "227\n",
      "0.6236605997243317  ,  0.5586  ,  1.6934\n",
      "0.34294904426124395  ,  0.672  ,  1.7133\n",
      "0.14259263508692474  ,  0.6282  ,  1.8929\n",
      "228\n",
      "0.3665726619222847  ,  0.3952  ,  1.117\n",
      "0.26240572636789505  ,  0.4301  ,  1.148\n",
      "0.03049001960959349  ,  0.5427  ,  1.0834\n",
      "229\n",
      "0.6340817120881362  ,  0.4094  ,  0.6878\n",
      "0.19074835039338683  ,  0.3695  ,  0.9114\n",
      "0.18632864564680107  ,  0.4702  ,  0.8519\n",
      "230\n",
      "0.5397945006488818  ,  0.6123  ,  1.1541\n",
      "-0.1349707040426403  ,  1.6866  ,  1.1745\n",
      "0.2160288534635207  ,  0.7349  ,  1.2999\n",
      "231\n",
      "0.6778796533015954  ,  0.5485  ,  1.3743\n",
      "0.38582277578772756  ,  0.6695  ,  1.7513\n",
      "nan  ,  0.6343  ,  1.9895\n",
      "232\n",
      "0.3235570093164045  ,  0.489  ,  1.6097\n",
      "0.3120127200792889  ,  0.6204  ,  1.4752\n",
      "0.2674010134658465  ,  0.602  ,  1.5119\n",
      "233\n",
      "0.873327542239227  ,  0.3969  ,  0.8065\n",
      "0.34993643226045856  ,  0.7444  ,  1.5859\n",
      "-0.08662821001228498  ,  0.7372  ,  1.803\n",
      "234\n",
      "0.6541292506049783  ,  0.7447  ,  1.3202\n",
      "0.6197610852821896  ,  0.6952  ,  1.6553\n",
      "nan  ,  0.7728  ,  1.988\n",
      "235\n",
      "0.44742382027125055  ,  1.5623  ,  1.8955\n",
      "0.3323282950502974  ,  1.943  ,  1.888\n",
      "0.3972312481001557  ,  2.1092  ,  2.2207\n",
      "236\n",
      "0.47515443813027236  ,  0.937  ,  1.4106\n",
      "-0.01519077544757005  ,  1.0211  ,  1.8469\n",
      "0.07902409235377826  ,  1.0471  ,  1.7544\n",
      "237\n",
      "0.6170194755275682  ,  0.3263  ,  0.7598\n",
      "0.29927748287304157  ,  0.4455  ,  0.8159\n",
      "0.050055694096841116  ,  0.4732  ,  0.8028\n",
      "238\n",
      "0.7563833151300533  ,  0.3254  ,  0.9149\n",
      "0.11347673429601458  ,  0.684  ,  1.301\n",
      "nan  ,  0.3944  ,  1.4473\n",
      "239\n",
      "0.15192157800325753  ,  0.4578  ,  1.343\n",
      "0.05990418032220197  ,  0.8585  ,  1.3361\n",
      "0.020151753524917333  ,  0.5445  ,  1.2715\n",
      "240\n",
      "0.041173863236603415  ,  0.5626  ,  1.9854\n",
      "-0.025636932028699044  ,  1.2493  ,  2.144\n",
      "-0.021312831282208212  ,  0.5878  ,  1.9675\n",
      "241\n",
      "0.3790705428897662  ,  0.7092  ,  1.5051\n",
      "0.37071998377644017  ,  0.5693  ,  1.7163\n",
      "0.23972019866645095  ,  0.5804  ,  1.7369\n",
      "242\n",
      "0.7093219041997755  ,  0.4209  ,  1.1169\n",
      "0.06009296454930352  ,  0.5249  ,  1.53\n",
      "nan  ,  0.5249  ,  1.5302\n",
      "243\n",
      "0.8038703281615543  ,  0.1782  ,  0.9432\n",
      "0.11971142377437718  ,  0.2814  ,  1.1147\n",
      "nan  ,  0.2065  ,  1.1515\n",
      "244\n",
      "0.9533980934624052  ,  0.3372  ,  0.7717\n",
      "0.1187998861377829  ,  0.9472  ,  2.6553\n",
      "nan  ,  0.9269  ,  2.7168\n",
      "245\n",
      "0.39299037921035135  ,  1.2852  ,  2.145\n",
      "0.4574892178663175  ,  1.2006  ,  2.0474\n",
      "nan  ,  1.2999  ,  2.2069\n",
      "246\n",
      "0.676552459679917  ,  0.8137  ,  1.9184\n",
      "0.19492081723009583  ,  0.9792  ,  2.0855\n",
      "-0.036140476773604616  ,  0.9323  ,  2.2388\n",
      "247\n",
      "0.11797265001588125  ,  0.753  ,  1.751\n",
      "0.24740081353486845  ,  1.0303  ,  1.4124\n",
      "0.16258765294873356  ,  0.8019  ,  1.6954\n",
      "248\n",
      "0.7234794975304542  ,  0.7634  ,  1.8308\n",
      "0.3307727212726038  ,  0.8959  ,  2.2499\n",
      "0.013893514002354312  ,  0.9154  ,  2.3921\n",
      "249\n",
      "0.35192799875930364  ,  0.5741  ,  1.9587\n",
      "0.28497635431092105  ,  1.0215  ,  1.6072\n",
      "-0.011117239693353749  ,  0.7622  ,  1.8521\n",
      "250\n",
      "0.2688119689130885  ,  0.9159  ,  1.9199\n",
      "0.09489709525912858  ,  1.4459  ,  1.5\n",
      "-0.17993626060452733  ,  1.0609  ,  1.8875\n",
      "251\n",
      "0.31745205960035305  ,  0.5375  ,  1.4132\n",
      "0.22174219424295957  ,  0.5571  ,  1.4009\n",
      "0.07528703769987714  ,  0.6131  ,  1.3878\n",
      "252\n",
      "0.6209211344752281  ,  0.5486  ,  1.5061\n",
      "0.4369724842938123  ,  0.6434  ,  1.6641\n",
      "0.09421286085007308  ,  0.6769  ,  1.8036\n",
      "253\n",
      "0.5429593368144561  ,  0.7086  ,  1.8587\n",
      "0.20879940949158404  ,  1.064  ,  1.7584\n",
      "0.06799179643575673  ,  0.8126  ,  1.9984\n",
      "254\n",
      "0.4916615954313761  ,  0.3668  ,  1.0513\n",
      "0.2284189104154431  ,  0.3919  ,  1.2332\n",
      "-0.1306959001171742  ,  0.4004  ,  1.2443\n",
      "255\n",
      "0.3738185942752593  ,  0.1577  ,  0.6403\n",
      "0.15492914724325255  ,  0.1682  ,  0.6623\n",
      "0.009467581172088589  ,  0.2233  ,  0.641\n",
      "256\n",
      "0.16404044159079983  ,  0.842  ,  1.6691\n",
      "0.22819224366309826  ,  0.8608  ,  1.6123\n",
      "-0.03665891670620233  ,  0.8546  ,  1.6686\n",
      "257\n",
      "0.7576405051820947  ,  0.6859  ,  1.5283\n",
      "0.25560403099055273  ,  0.9876  ,  2.3412\n",
      "0.34188139444559396  ,  1.0386  ,  2.2867\n",
      "258\n",
      "0.25208888225312176  ,  0.8507  ,  1.7109\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "259\n",
      "0.1720040630522886  ,  0.4521  ,  0.9894\n",
      "0.20312149376068053  ,  0.508  ,  0.9372\n",
      "0.22247110340792575  ,  0.5083  ,  0.9369\n",
      "260\n",
      "0.35897559788427286  ,  1.5138  ,  1.2418\n",
      "0.060857481315432005  ,  0.763  ,  1.4905\n",
      "nan  ,  0.7539  ,  1.5164\n",
      "261\n",
      "0.058111168980375605  ,  0.8407  ,  2.0281\n",
      "-0.004601608801747684  ,  0.8556  ,  2.0089\n",
      "nan  ,  0.8415  ,  2.0292\n",
      "262\n",
      "0.16709699088767183  ,  0.9861  ,  2.1288\n",
      "0.24401471709597083  ,  1.0092  ,  2.148\n",
      "-0.3322940458033106  ,  1.0406  ,  2.1359\n",
      "263\n",
      "0.1049080359160395  ,  0.5554  ,  1.6216\n",
      "0.04612974411681821  ,  0.5728  ,  1.6082\n",
      "nan  ,  0.5552  ,  1.6264\n",
      "264\n",
      "0.2586147926755332  ,  1.2338  ,  1.2671\n",
      "0.049575699476235795  ,  0.4383  ,  1.3341\n",
      "0.09141972261182432  ,  0.4518  ,  1.3242\n",
      "265\n",
      "0.35117368480711475  ,  0.8449  ,  1.8768\n",
      "-0.009180279610923697  ,  0.876  ,  1.9438\n",
      "nan  ,  0.8632  ,  1.9664\n",
      "266\n",
      "0.347413522406515  ,  1.0041  ,  0.9616\n",
      "0.02636684464276389  ,  0.7522  ,  1.3279\n",
      "nan  ,  0.7208  ,  1.3886\n",
      "267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09518457660427115  ,  0.7622  ,  1.7442\n",
      "0.11221529801737293  ,  0.8488  ,  1.5991\n",
      "0.0500871723925533  ,  0.7932  ,  1.7017\n",
      "268\n",
      "0.6932121471547055  ,  0.9674  ,  1.4945\n",
      "-0.0005593820762474309  ,  1.2651  ,  2.1455\n",
      "nan  ,  1.2628  ,  2.1513\n",
      "269\n",
      "0.5672885874684102  ,  0.8494  ,  1.5342\n",
      "-0.06320282950133009  ,  0.9859  ,  1.8085\n",
      "0.09521125938536404  ,  0.9779  ,  1.8102\n",
      "270\n",
      "0.6596514482745477  ,  1.4563  ,  1.4992\n",
      "0.11396418014660552  ,  1.9569  ,  2.666\n",
      "nan  ,  1.9837  ,  2.7294\n",
      "271\n",
      "0.3142122725725659  ,  0.5607  ,  1.441\n",
      "-0.0014054492855510928  ,  0.5597  ,  1.5547\n",
      "nan  ,  0.5583  ,  1.556\n",
      "272\n",
      "0.294966389871971  ,  0.7219  ,  1.4353\n",
      "0.011178712785038021  ,  0.5528  ,  1.6118\n",
      "nan  ,  0.5416  ,  1.6211\n",
      "273\n",
      "0.32727074358123776  ,  0.875  ,  1.8107\n",
      "0.054513425917259564  ,  0.8568  ,  2.0643\n",
      "nan  ,  0.8526  ,  2.0736\n",
      "274\n",
      "0.22454437981916667  ,  0.7989  ,  1.9911\n",
      "0.06063132541894302  ,  0.9739  ,  1.8966\n",
      "nan  ,  0.8095  ,  2.077\n",
      "275\n",
      "0.17456405372502265  ,  0.6052  ,  1.134\n",
      "0.1418938691595678  ,  0.6121  ,  1.1444\n",
      "nan  ,  0.6126  ,  1.1486\n",
      "276\n",
      "0.520587709241961  ,  0.9582  ,  1.9345\n",
      "0.0873758751274487  ,  1.0695  ,  2.0813\n",
      "nan  ,  1.0597  ,  2.107\n",
      "277\n",
      "0.7257847955639497  ,  0.7727  ,  1.4205\n",
      "-0.156808020823145  ,  1.1097  ,  1.8683\n",
      "-0.1225729687362577  ,  1.0437  ,  1.9144\n",
      "278\n",
      "0.030096279557895303  ,  0.6367  ,  1.7544\n",
      "0.0870738375279985  ,  0.6711  ,  1.7109\n",
      "nan  ,  0.6337  ,  1.7583\n",
      "279\n",
      "0.47380565527624596  ,  0.7531  ,  1.1207\n",
      "0.02475924726972652  ,  0.7046  ,  1.3639\n",
      "-0.014786133964781314  ,  0.6501  ,  1.4371\n",
      "280\n",
      "0.55928418901443  ,  0.7162  ,  1.4009\n",
      "-0.02250217438281666  ,  0.7538  ,  1.5147\n",
      "nan  ,  0.7536  ,  1.5149\n",
      "281\n",
      "-0.004737371891916665  ,  1.0052  ,  2.3085\n",
      "0.21784830319972087  ,  1.006  ,  2.296\n",
      "-0.03024296397631772  ,  1.0592  ,  2.2316\n",
      "282\n",
      "0.1247467257153846  ,  0.6487  ,  1.3988\n",
      "-0.16896687540731628  ,  0.8968  ,  1.1299\n",
      "0.01778677790133603  ,  0.7544  ,  1.2492\n",
      "283\n",
      "0.2586111783928251  ,  0.5128  ,  1.6563\n",
      "0.033939974688414365  ,  0.5511  ,  1.687\n",
      "nan  ,  0.5204  ,  1.7121\n",
      "284\n",
      "0.014012716652341977  ,  0.5652  ,  1.1485\n",
      "0.01450848656722162  ,  0.5866  ,  1.1092\n",
      "-0.0003637690133688207  ,  0.5908  ,  1.1017\n",
      "285\n",
      "0.3119170960064012  ,  0.9444  ,  1.4585\n",
      "-0.00018180927328753302  ,  0.9745  ,  1.4775\n",
      "0.1515104495361265  ,  0.9913  ,  1.3828\n",
      "286\n",
      "0.02003516803601451  ,  1.2808  ,  1.8752\n",
      "0.21308373007045214  ,  1.2686  ,  1.847\n",
      "0.12105772197879164  ,  1.2788  ,  1.839\n",
      "287\n",
      "0.2885649545048987  ,  0.8878  ,  2.0264\n",
      "0.15577288296454628  ,  0.8946  ,  2.0362\n",
      "nan  ,  0.8943  ,  2.0395\n",
      "288\n",
      "0.5528782028738948  ,  1.3126  ,  1.4934\n",
      "-0.08665598448045261  ,  1.5636  ,  2.3434\n",
      "0.15681523562382102  ,  1.5613  ,  2.3419\n",
      "289\n",
      "0.5062066453587724  ,  0.7344  ,  1.8039\n",
      "-0.05727323852648361  ,  0.8158  ,  1.977\n",
      "-0.04790887190872968  ,  0.7876  ,  2.0052\n",
      "290\n",
      "0.30980400304358113  ,  1.1691  ,  2.1994\n",
      "0.04589889020722006  ,  1.1807  ,  2.2347\n",
      "0.09122615455811972  ,  1.1824  ,  2.2266\n",
      "291\n",
      "0.6555518974621934  ,  0.7298  ,  1.5501\n",
      "0.11672717040383979  ,  0.9526  ,  1.9712\n",
      "nan  ,  0.8753  ,  2.0967\n",
      "292\n",
      "0.2682173457389371  ,  1.1919  ,  1.5431\n",
      "0.008219367574596313  ,  1.3212  ,  1.6493\n",
      "0.20683272441793907  ,  1.3168  ,  1.6656\n",
      "293\n",
      "0.5997966195890625  ,  0.8961  ,  1.6738\n",
      "0.011103701098268267  ,  1.0624  ,  2.0671\n",
      "0.043263861201203804  ,  1.0616  ,  2.0692\n",
      "294\n",
      "0.6282547927163045  ,  0.6623  ,  2.2758\n",
      "nan  ,  0.7176  ,  2.6151\n",
      "nan  ,  0.7176  ,  2.6151\n",
      "295\n",
      "0.4789610710300512  ,  0.927  ,  1.4629\n",
      "0.1620964053927358  ,  0.9849  ,  1.8085\n",
      "-0.03088227638323676  ,  0.9401  ,  1.9282\n",
      "296\n",
      "0.16602473875568835  ,  0.679  ,  1.4986\n",
      "0.10777027929841138  ,  0.6819  ,  1.5121\n",
      "0.1012279190684344  ,  0.6884  ,  1.5039\n",
      "297\n",
      "-0.016521088388297044  ,  1.1618  ,  1.9642\n",
      "-0.009599080775371251  ,  1.1591  ,  1.9573\n",
      "-0.07963461508239816  ,  1.1878  ,  1.8412\n",
      "298\n",
      "0.1186651511363966  ,  1.4223  ,  2.8331\n",
      "0.318119632431961  ,  1.3917  ,  2.6712\n",
      "-0.13851021980510544  ,  1.4393  ,  2.8023\n",
      "299\n",
      "0.14800018680949364  ,  0.4843  ,  1.0704\n",
      "-0.05590096494308833  ,  0.4782  ,  1.0998\n",
      "0.05962124426065756  ,  0.4773  ,  1.082\n",
      "300\n",
      "0.2023261091070632  ,  0.7727  ,  2.2222\n",
      "0.006552569113380936  ,  0.7733  ,  2.2247\n",
      "nan  ,  0.7732  ,  2.2247\n",
      "301\n",
      "0.2130158800337144  ,  1.2309  ,  1.8781\n",
      "0.046460888961287444  ,  1.2498  ,  1.7918\n",
      "0.09559454528714316  ,  1.24  ,  1.8626\n",
      "302\n",
      "-0.004816217513041807  ,  0.486  ,  1.2905\n",
      "0.016216371061447226  ,  0.4897  ,  1.2856\n",
      "-0.043068236078401025  ,  0.5177  ,  1.2579\n",
      "303\n",
      "0.1510850195189128  ,  1.019  ,  1.6432\n",
      "0.16563762165507337  ,  1.0638  ,  1.5222\n",
      "0.024030456747792375  ,  1.0622  ,  1.5859\n",
      "304\n",
      "0.023363365210740086  ,  1.5961  ,  2.1756\n",
      "0.3377978116671727  ,  1.5781  ,  2.0796\n",
      "-0.04794787119284957  ,  1.5934  ,  2.146\n",
      "305\n",
      "nan  ,  0.761  ,  1.907\n",
      "0.12219794417507382  ,  0.7702  ,  1.8835\n",
      "nan  ,  0.761  ,  1.907\n",
      "306\n",
      "0.8760358908207662  ,  0.4718  ,  1.0804\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "307\n",
      "0.5019398728080166  ,  0.5224  ,  1.0489\n",
      "nan  ,  0.563  ,  1.1967\n",
      "nan  ,  0.563  ,  1.1967\n",
      "308\n",
      "0.007425873720988411  ,  0.4955  ,  1.7207\n",
      "0.25018871348735044  ,  0.6396  ,  1.5686\n",
      "nan  ,  0.4949  ,  1.7215\n",
      "309\n",
      "0.4822617335799138  ,  1.0345  ,  1.5665\n",
      "0.15186928375976827  ,  1.1763  ,  1.7709\n",
      "-0.012041286231109654  ,  1.1772  ,  1.7819\n",
      "310\n",
      "0.540425832954028  ,  0.7848  ,  1.8114\n",
      "0.0879236392825723  ,  0.8241  ,  1.9069\n",
      "nan  ,  0.8173  ,  1.9267\n",
      "311\n",
      "0.16828220122356505  ,  0.755  ,  1.6843\n",
      "0.014924734106472564  ,  0.763  ,  1.7097\n",
      "nan  ,  0.763  ,  1.7097\n",
      "312\n",
      "0.9010667864076447  ,  0.3691  ,  0.9565\n",
      "0.06303063533935624  ,  0.5094  ,  2.3372\n",
      "nan  ,  0.5086  ,  2.3385\n",
      "313\n",
      "0.4058109050895237  ,  0.4877  ,  1.1846\n",
      "0.029010153093417368  ,  0.5703  ,  1.2542\n",
      "nan  ,  0.5113  ,  1.3129\n",
      "314\n",
      "0.47106103599100657  ,  0.7008  ,  1.5934\n",
      "0.245314902065875  ,  0.7351  ,  1.8488\n",
      "nan  ,  0.7027  ,  1.9405\n",
      "315\n",
      "nan  ,  0.4111  ,  1.0868\n",
      "0.01292979987484884  ,  0.5538  ,  0.9672\n",
      "0.09454991092622866  ,  0.4278  ,  1.0695\n",
      "316\n",
      "0.266622264122346  ,  0.6457  ,  1.667\n",
      "0.15684016104566229  ,  0.7367  ,  1.5917\n",
      "-0.017092648807079367  ,  0.6947  ,  1.6556\n",
      "317\n",
      "0.2685408055314408  ,  1.1471  ,  2.3511\n",
      "0.24118257569514057  ,  1.2382  ,  2.1484\n",
      "nan  ,  1.1661  ,  2.4048\n",
      "318\n",
      "0.017501784740038714  ,  0.3017  ,  0.8418\n",
      "0.10812860560413051  ,  0.3502  ,  0.7939\n",
      "0.021236470717945585  ,  0.3584  ,  0.7888\n",
      "319\n",
      "0.7329726158772695  ,  1.2648  ,  1.9556\n",
      "-0.002591306461231825  ,  1.4657  ,  2.7398\n",
      "0.2111735256134673  ,  1.4827  ,  2.6516\n",
      "320\n",
      "0.6409373217043915  ,  0.9981  ,  1.4978\n",
      "0.1554660968574934  ,  1.2058  ,  1.984\n",
      "0.1703459434000364  ,  1.2295  ,  1.9172\n",
      "321\n",
      "0.08182797828529781  ,  0.4006  ,  1.2414\n",
      "nan  ,  0.2651  ,  1.2055\n",
      "nan  ,  0.2651  ,  1.2055\n",
      "322\n",
      "0.31703023836668376  ,  1.3761  ,  1.8287\n",
      "-0.0031231375181600706  ,  1.4417  ,  1.9206\n",
      "nan  ,  1.4461  ,  1.935\n",
      "323\n",
      "0.513784890501216  ,  0.7434  ,  1.3904\n",
      "0.041500932941028426  ,  0.7781  ,  1.7932\n",
      "-0.037071130833817446  ,  0.7681  ,  1.8119\n",
      "324\n",
      "0.656325982424324  ,  1.0576  ,  1.4952\n",
      "-0.07835164557811318  ,  1.1222  ,  2.3867\n",
      "-0.0010960043970518448  ,  1.1265  ,  2.3766\n",
      "325\n",
      "0.033633688632886474  ,  0.6898  ,  1.5349\n",
      "0.21368670457434016  ,  0.7554  ,  1.3886\n",
      "nan  ,  0.6899  ,  1.5352\n",
      "326\n",
      "0.3401836889351833  ,  0.6385  ,  1.751\n",
      "0.012247324505899205  ,  0.6566  ,  1.8877\n",
      "nan  ,  0.6536  ,  1.8912\n",
      "327\n",
      "0.2790467178657202  ,  0.727  ,  1.4324\n",
      "-0.12972329219001028  ,  0.7616  ,  1.4057\n",
      "nan  ,  0.7293  ,  1.4415\n",
      "328\n",
      "0.007930246465725585  ,  0.517  ,  1.2674\n",
      "0.03601922639726602  ,  0.7474  ,  1.047\n",
      "-0.0600176825553214  ,  0.7112  ,  1.0622\n",
      "329\n",
      "0.592495456195399  ,  0.6056  ,  1.3839\n",
      "nan  ,  0.6631  ,  1.5563\n",
      "nan  ,  0.6631  ,  1.5563\n",
      "330\n",
      "0.656770421544101  ,  0.7197  ,  1.6274\n",
      "0.05055034710690428  ,  0.808  ,  2.0174\n",
      "nan  ,  0.8079  ,  2.0201\n",
      "331\n",
      "0.5694987911262102  ,  1.2089  ,  2.1044\n",
      "0.10580379312408858  ,  1.3252  ,  2.2755\n",
      "-0.195088418208954  ,  1.3153  ,  2.3215\n",
      "332\n",
      "0.5776428754789924  ,  0.7937  ,  1.2355\n",
      "0.1363895453189703  ,  0.9924  ,  1.1751\n",
      "-0.3181805151465342  ,  0.9548  ,  1.2946\n",
      "333\n",
      "0.4374593431907853  ,  0.7613  ,  1.4181\n",
      "0.032807447756365404  ,  0.8118  ,  1.4557\n",
      "0.0914943344206777  ,  0.8133  ,  1.4376\n",
      "334\n",
      "0.12975964631930983  ,  0.8415  ,  1.6213\n",
      "0.08485102685289901  ,  0.8999  ,  1.5038\n",
      "0.06132837482038118  ,  0.8841  ,  1.5414\n",
      "335\n",
      "0.39358239530507905  ,  0.6994  ,  0.7784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1323540344188291  ,  0.5517  ,  0.9609\n",
      "-0.0671166048854394  ,  0.5586  ,  0.9695\n",
      "336\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "0.03401406495323046  ,  0.8809  ,  1.6672\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "337\n",
      "0.4172949634393246  ,  0.7321  ,  0.8569\n",
      "0.053043001054481606  ,  0.5966  ,  1.2009\n",
      "-0.081662452093939  ,  0.6233  ,  1.1584\n",
      "338\n",
      "0.4045583168303065  ,  1.134  ,  1.3235\n",
      "-0.005707431593495996  ,  1.1222  ,  1.8404\n",
      "nan  ,  1.1207  ,  1.8448\n",
      "339\n",
      "0.3579995261697103  ,  0.2877  ,  0.871\n",
      "-0.014996473905824422  ,  0.2979  ,  0.9529\n",
      "nan  ,  0.2825  ,  0.9596\n",
      "340\n",
      "0.1970607441811965  ,  0.9226  ,  1.5805\n",
      "0.11615232282569324  ,  0.947  ,  1.6125\n",
      "0.10427846624404453  ,  0.9588  ,  1.5529\n",
      "341\n",
      "0.09191464802533991  ,  0.3951  ,  1.0647\n",
      "0.11985248588704805  ,  0.5058  ,  0.9507\n",
      "0.058321534494216495  ,  0.5782  ,  0.9023\n",
      "342\n",
      "0.32545643558803344  ,  1.6137  ,  1.3965\n",
      "-0.07825623515802613  ,  1.2604  ,  2.0234\n",
      "-0.025209714217436924  ,  1.2478  ,  1.9973\n",
      "343\n",
      "0.9331318052824504  ,  0.8503  ,  2.0622\n",
      "0.5699658129217566  ,  1.2009  ,  2.7743\n",
      "0.04323778074508971  ,  1.3712  ,  2.7866\n",
      "344\n",
      "0.4332681227044944  ,  0.6241  ,  1.2286\n",
      "0.17176630314137828  ,  0.402  ,  1.4124\n",
      "nan  ,  0.358  ,  1.4638\n",
      "345\n",
      "0.2940018641034383  ,  1.296  ,  1.3647\n",
      "0.24158308715185325  ,  0.6947  ,  1.2955\n",
      "0.07648681725470721  ,  0.7037  ,  1.3096\n",
      "346\n",
      "0.3472946248025505  ,  0.7514  ,  1.4493\n",
      "0.13525249246671003  ,  0.7949  ,  1.4084\n",
      "nan  ,  0.7692  ,  1.4957\n",
      "347\n",
      "0.2847496561512238  ,  0.8943  ,  1.7494\n",
      "-0.11880997219924946  ,  0.9391  ,  1.8397\n",
      "-0.0012844233378546078  ,  0.9691  ,  1.7655\n",
      "348\n",
      "0.2683968838760805  ,  1.4801  ,  1.4742\n",
      "0.22039417083074378  ,  1.1843  ,  2.0292\n",
      "nan  ,  1.1876  ,  2.0974\n",
      "349\n",
      "nan  ,  0.8818  ,  1.5942\n",
      "0.2053623190639072  ,  0.8938  ,  1.5076\n",
      "nan  ,  0.8818  ,  1.5942\n",
      "350\n",
      "0.5947513774050354  ,  0.8076  ,  1.5134\n",
      "0.46294353503313995  ,  0.8693  ,  1.8998\n",
      "-0.015646734626357316  ,  0.8928  ,  1.9592\n",
      "351\n",
      "0.5715383280933561  ,  1.0468  ,  1.5099\n",
      "0.053258807864389496  ,  1.2282  ,  2.1296\n",
      "nan  ,  1.2285  ,  2.1302\n",
      "352\n",
      "0.3340638938942886  ,  0.8577  ,  1.6494\n",
      "0.008409259153247684  ,  0.9022  ,  1.7438\n",
      "nan  ,  0.888  ,  1.7709\n",
      "353\n",
      "0.62340044385804  ,  0.3699  ,  1.2179\n",
      "nan  ,  0.4044  ,  1.446\n",
      "nan  ,  0.4044  ,  1.446\n",
      "354\n",
      "0.17415106192087704  ,  0.9572  ,  1.5439\n",
      "0.23395507209203686  ,  0.9987  ,  1.4724\n",
      "0.13882856365580312  ,  1.0026  ,  1.5096\n",
      "355\n",
      "0.40879844835846235  ,  0.7396  ,  1.3848\n",
      "0.10979016170766814  ,  0.8135  ,  1.3705\n",
      "-0.06177123192894558  ,  0.7799  ,  1.4625\n",
      "356\n",
      "0.4987923695654181  ,  0.637  ,  1.748\n",
      "0.13650925662168845  ,  0.6656  ,  1.8357\n",
      "nan  ,  0.6586  ,  1.8511\n",
      "357\n",
      "0.41362607168604515  ,  0.3734  ,  1.3564\n",
      "-0.0230947643787136  ,  0.409  ,  1.3694\n",
      "-0.013862301919610085  ,  0.4728  ,  1.323\n",
      "358\n",
      "0.06348585597858677  ,  0.5856  ,  1.1701\n",
      "0.047407870378373546  ,  0.5857  ,  1.1639\n",
      "-0.09547939732028318  ,  0.6489  ,  1.0585\n",
      "359\n",
      "0.37040717069459034  ,  1.0363  ,  1.3514\n",
      "0.28204037242497604  ,  1.1212  ,  1.307\n",
      "0.008292846858830503  ,  1.1501  ,  1.3428\n",
      "360\n",
      "0.3303712930171011  ,  1.2247  ,  2.292\n",
      "0.5375914099219808  ,  1.2033  ,  2.1065\n",
      "nan  ,  1.26  ,  2.4055\n",
      "361\n",
      "0.27395679756580893  ,  1.0009  ,  1.6443\n",
      "0.05511028043644261  ,  1.0135  ,  1.8601\n",
      "nan  ,  1.0051  ,  1.8886\n",
      "362\n",
      "0.022852869680327768  ,  0.5977  ,  1.2909\n",
      "-0.09517029293349047  ,  0.6761  ,  1.1767\n",
      "0.015613819525210173  ,  0.6354  ,  1.2256\n",
      "363\n",
      "0.5190825313068317  ,  1.0302  ,  1.5909\n",
      "-0.0690360270981022  ,  1.0877  ,  2.108\n",
      "nan  ,  1.0609  ,  2.1441\n",
      "364\n",
      "0.1912690268388099  ,  0.4292  ,  1.2612\n",
      "0.13963952363070503  ,  0.4152  ,  1.2984\n",
      "nan  ,  0.4108  ,  1.3093\n",
      "365\n",
      "0.15634480591082323  ,  0.4027  ,  0.9925\n",
      "0.05503916148198526  ,  0.3673  ,  0.9832\n",
      "0.04079538254951503  ,  0.2974  ,  1.0292\n",
      "366\n",
      "0.3379983130371557  ,  0.6278  ,  1.7565\n",
      "0.07315430959890246  ,  0.6372  ,  1.8029\n",
      "nan  ,  0.6372  ,  1.8039\n",
      "367\n",
      "0.026222620151103854  ,  0.6104  ,  1.2281\n",
      "0.13325617714689084  ,  0.6571  ,  1.115\n",
      "0.06456210372121218  ,  0.6336  ,  1.1776\n",
      "368\n",
      "0.11323447527724868  ,  0.8392  ,  1.5955\n",
      "-0.02317346037766997  ,  0.8606  ,  1.5609\n",
      "nan  ,  0.8054  ,  1.6351\n",
      "369\n",
      "0.36461947841629067  ,  0.9407  ,  1.9851\n",
      "0.024242056815469117  ,  0.982  ,  2.0937\n",
      "nan  ,  0.982  ,  2.0937\n",
      "370\n",
      "0.09062251545146291  ,  0.8282  ,  1.7781\n",
      "0.20061085999116013  ,  0.9503  ,  1.5539\n",
      "nan  ,  0.8211  ,  1.8119\n",
      "371\n",
      "0.34104577815696524  ,  0.9771  ,  2.3592\n",
      "0.3172679300835623  ,  1.0111  ,  2.3752\n",
      "-0.05432444657580447  ,  1.0184  ,  2.4025\n",
      "372\n",
      "0.33686067089155247  ,  0.5578  ,  1.7068\n",
      "0.04903693254443138  ,  0.5674  ,  1.731\n",
      "nan  ,  0.564  ,  1.7359\n",
      "373\n",
      "0.02841414592660393  ,  0.7347  ,  1.3611\n",
      "0.06072958793830241  ,  0.7724  ,  1.2604\n",
      "-0.06363276330974527  ,  0.7702  ,  1.2722\n",
      "374\n",
      "0.2686367682586167  ,  1.603  ,  2.6858\n",
      "0.08935949083220661  ,  1.6224  ,  2.7282\n",
      "nan  ,  1.624  ,  2.7311\n",
      "375\n",
      "0.39807248389869704  ,  0.8753  ,  2.085\n",
      "-0.012963785651721712  ,  0.9044  ,  2.2133\n",
      "nan  ,  0.9041  ,  2.2136\n",
      "376\n",
      "0.0071238458235353165  ,  0.9349  ,  1.9726\n",
      "0.13139992584183513  ,  0.9368  ,  1.9544\n",
      "nan  ,  0.9349  ,  1.9727\n",
      "377\n",
      "0.353945201103426  ,  0.7739  ,  1.244\n",
      "-0.021463742460568647  ,  0.827  ,  1.3748\n",
      "0.1447179679909463  ,  0.8169  ,  1.3891\n",
      "378\n",
      "0.4055070534086399  ,  1.1232  ,  1.4719\n",
      "0.3145404550781516  ,  1.2019  ,  1.4396\n",
      "-0.13890234604607116  ,  1.2694  ,  1.2732\n",
      "379\n",
      "0.13859908771024737  ,  0.851  ,  1.5373\n",
      "nan  ,  0.856  ,  1.5604\n",
      "nan  ,  0.856  ,  1.5604\n",
      "380\n",
      "0.49093383008742864  ,  1.3192  ,  1.8111\n",
      "-0.0067007657180864315  ,  1.343  ,  2.4051\n",
      "nan  ,  1.2932  ,  2.507\n",
      "381\n",
      "-0.005875373906942327  ,  0.487  ,  1.2589\n",
      "0.007061440125174447  ,  0.4875  ,  1.2579\n",
      "-0.07780634706053435  ,  0.5342  ,  1.206\n",
      "382\n",
      "0.6059486681854029  ,  1.2124  ,  2.213\n",
      "0.003682963475634798  ,  1.3618  ,  2.6171\n",
      "nan  ,  1.3618  ,  2.6171\n",
      "383\n",
      "0.05492790244422563  ,  3.6685  ,  2.8994\n",
      "0.0822410853639698  ,  0.6508  ,  1.4858\n",
      "nan  ,  0.6506  ,  1.4881\n",
      "384\n",
      "0.44876585112362355  ,  0.9227  ,  1.1577\n",
      "0.19162949297779192  ,  0.695  ,  1.3564\n",
      "0.004441747509032841  ,  0.6681  ,  1.4308\n",
      "385\n",
      "0.48804344640321196  ,  1.0391  ,  1.1615\n",
      "0.1190575883377112  ,  0.9872  ,  1.6721\n",
      "-0.0075333259860350735  ,  0.9789  ,  1.7543\n",
      "386\n",
      "0.14078263628117205  ,  0.5113  ,  1.3163\n",
      "0.16215893059631684  ,  0.6912  ,  1.1222\n",
      "0.037234033547649176  ,  0.8036  ,  1.0492\n",
      "387\n",
      "-0.007638782470279071  ,  1.0184  ,  1.946\n",
      "0.03534844988160422  ,  1.0566  ,  1.8514\n",
      "-0.02338985384518086  ,  1.1018  ,  1.7771\n",
      "388\n",
      "0.32985547664217046  ,  0.9148  ,  1.4416\n",
      "0.08135969135500762  ,  0.9665  ,  1.4251\n",
      "0.27448892281698783  ,  0.9674  ,  1.4401\n",
      "389\n",
      "0.15729193805210753  ,  1.3028  ,  1.6508\n",
      "-0.010578888877510207  ,  1.3477  ,  1.8748\n",
      "-0.12309202268775023  ,  1.3427  ,  1.7464\n",
      "390\n",
      "0.016412267444827773  ,  0.7476  ,  1.6643\n",
      "0.13214327646442126  ,  0.7596  ,  1.6366\n",
      "nan  ,  0.7476  ,  1.6644\n",
      "391\n",
      "0.03659265088654816  ,  0.6243  ,  1.5689\n",
      "-0.04168964933936436  ,  0.7124  ,  1.4833\n",
      "-0.08215152487949325  ,  0.6301  ,  1.5625\n",
      "392\n",
      "0.6917154948462426  ,  0.7375  ,  1.1815\n",
      "0.18592171852690154  ,  0.9285  ,  1.8029\n",
      "nan  ,  0.9138  ,  1.9164\n",
      "393\n",
      "0.7799764273893743  ,  0.3247  ,  1.4505\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "394\n",
      "0.4472674612246843  ,  0.8565  ,  1.9713\n",
      "0.037759178087361  ,  0.9374  ,  2.0013\n",
      "nan  ,  0.8851  ,  2.083\n",
      "395\n",
      "0.28025176921340716  ,  0.9573  ,  2.0985\n",
      "-0.056025592817300095  ,  0.9799  ,  2.0988\n",
      "nan  ,  0.962  ,  2.1165\n",
      "396\n",
      "0.030193412705021624  ,  0.9584  ,  1.8105\n",
      "0.002247630222355558  ,  0.99  ,  1.7362\n",
      "0.07572204239595834  ,  0.9696  ,  1.7809\n",
      "397\n",
      "0.4276156315732422  ,  0.8366  ,  1.4698\n",
      "0.07143261678547173  ,  1.0253  ,  1.3181\n",
      "nan  ,  0.8937  ,  1.6115\n",
      "398\n",
      "0.4393309710574894  ,  0.7418  ,  1.7417\n",
      "-0.053516722804429484  ,  0.7998  ,  1.8056\n",
      "nan  ,  0.7659  ,  1.8275\n",
      "399\n",
      "0.35587606282511464  ,  4.3681  ,  3.3855\n",
      "0.13827690096206027  ,  0.6951  ,  2.1679\n",
      "nan  ,  0.6587  ,  2.2224\n",
      "400\n",
      "0.7321822074528855  ,  0.703  ,  1.4716\n",
      "-0.017742105962678858  ,  0.9087  ,  2.2324\n",
      "nan  ,  0.9001  ,  2.2427\n",
      "401\n",
      "0.21328824229912643  ,  0.5925  ,  1.4554\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "402\n",
      "0.08321206625292824  ,  1.5352  ,  2.0977\n",
      "0.1687821606163539  ,  1.4951  ,  1.9119\n",
      "-0.0234853096555979  ,  1.5315  ,  2.0774\n",
      "403\n",
      "0.8000079899916656  ,  1.0802  ,  2.6799\n",
      "0.4749695277644596  ,  1.4719  ,  2.5793\n",
      "-0.41896042250350707  ,  1.4112  ,  2.7814\n",
      "404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3111691877616097  ,  0.9201  ,  1.5509\n",
      "nan  ,  0.9597  ,  1.7002\n",
      "nan  ,  0.9597  ,  1.7002\n",
      "405\n",
      "0.2515808077564439  ,  0.9399  ,  1.9666\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "406\n",
      "0.3813890237891748  ,  0.912  ,  2.0416\n",
      "0.18696874381484313  ,  0.9649  ,  2.1981\n",
      "0.11108214072812517  ,  0.962  ,  2.2364\n",
      "407\n",
      "0.4961296236456927  ,  1.2241  ,  2.5544\n",
      "0.026942542745643453  ,  1.2705  ,  2.6992\n",
      "nan  ,  1.2703  ,  2.6999\n",
      "408\n",
      "0.2761949753641139  ,  0.8138  ,  1.7024\n",
      "0.057312601718929476  ,  0.8391  ,  1.7597\n",
      "nan  ,  0.8393  ,  1.7605\n",
      "409\n",
      "nan  ,  1.3061  ,  2.0397\n",
      "0.08730092427747818  ,  1.3113  ,  1.997\n",
      "0.08443978066015403  ,  1.3064  ,  2.0378\n",
      "410\n",
      "0.005798487522498847  ,  0.3323  ,  1.3692\n",
      "0.07304172048515832  ,  0.3755  ,  1.347\n",
      "nan  ,  0.3307  ,  1.3698\n",
      "411\n",
      "0.5656301971254616  ,  0.7192  ,  1.3183\n",
      "-0.08311578220954347  ,  0.9205  ,  1.492\n",
      "0.0662314665464852  ,  0.8589  ,  1.5774\n",
      "412\n",
      "0.08873397312235934  ,  0.7538  ,  1.4869\n",
      "0.1387979860638104  ,  0.7528  ,  1.4839\n",
      "-0.15618471742382078  ,  0.7874  ,  1.4285\n",
      "413\n",
      "0.02356236727784967  ,  0.7289  ,  1.6044\n",
      "0.1396185093339832  ,  0.7568  ,  1.5364\n",
      "nan  ,  0.7292  ,  1.6047\n",
      "414\n",
      "0.03310102764012324  ,  0.4499  ,  1.14\n",
      "0.07856024017277706  ,  0.5284  ,  1.0482\n",
      "-0.07378305519660713  ,  0.5101  ,  1.0714\n",
      "415\n",
      "0.13154993438575566  ,  0.987  ,  1.6068\n",
      "-0.013875627839372889  ,  0.987  ,  1.6801\n",
      "-0.10203996484072618  ,  0.9914  ,  1.6578\n",
      "416\n",
      "0.05380500855795829  ,  0.8929  ,  1.7645\n",
      "0.1426265001519093  ,  0.8931  ,  1.7591\n",
      "-0.008452566747476572  ,  0.902  ,  1.7573\n",
      "417\n",
      "0.04472108188216354  ,  0.5927  ,  1.4189\n",
      "0.018133887448592408  ,  0.6161  ,  1.394\n",
      "nan  ,  0.5942  ,  1.4205\n",
      "418\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "0.11525785048992648  ,  0.716  ,  2.1836\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "419\n",
      "0.3604939196183653  ,  0.936  ,  1.7211\n",
      "0.03365657838871758  ,  0.9619  ,  1.7856\n",
      "nan  ,  0.9621  ,  1.7865\n",
      "420\n",
      "0.2915694281870864  ,  0.4468  ,  1.1997\n",
      "0.03811748249471203  ,  0.5165  ,  1.176\n",
      "0.062035634031393797  ,  0.4727  ,  1.2194\n",
      "421\n",
      "0.02890517983903466  ,  0.4649  ,  1.1409\n",
      "0.04972246993362049  ,  0.4402  ,  1.1432\n",
      "-0.01682097293551426  ,  0.4591  ,  1.1261\n",
      "422\n",
      "0.2719674206636872  ,  0.8963  ,  1.2148\n",
      "-0.06453910121972034  ,  0.9428  ,  1.2713\n",
      "0.15611131064607747  ,  0.9405  ,  1.2268\n",
      "423\n",
      "0.45630230139057265  ,  0.7022  ,  1.5206\n",
      "-0.10364282566553511  ,  0.7677  ,  1.6668\n",
      "-0.04762549398393879  ,  0.8013  ,  1.6114\n",
      "424\n",
      "0.5828864872123467  ,  1.531  ,  1.2662\n",
      "-0.009132148953339043  ,  0.6232  ,  1.5303\n",
      "-0.0721757257391252  ,  0.6392  ,  1.5105\n",
      "425\n",
      "0.3587528720004226  ,  1.3459  ,  1.8261\n",
      "0.05485014845830637  ,  1.3817  ,  1.8677\n",
      "0.2585089610929446  ,  1.3838  ,  1.8627\n",
      "426\n",
      "0.25300987671209363  ,  0.3779  ,  1.0909\n",
      "0.3082862546557089  ,  0.5048  ,  0.9371\n",
      "-0.0472879412639635  ,  0.6166  ,  0.9108\n",
      "427\n",
      "0.17644802612964472  ,  0.343  ,  1.005\n",
      "-0.14433081998380995  ,  1.2086  ,  0.8437\n",
      "-0.0006984897580608433  ,  0.3568  ,  0.999\n",
      "428\n",
      "0.6593338715756591  ,  0.4839  ,  1.0153\n",
      "nan  ,  0.6046  ,  1.3573\n",
      "nan  ,  0.6046  ,  1.3573\n",
      "429\n",
      "0.18527532810307387  ,  0.4573  ,  1.7291\n",
      "0.07897990755712332  ,  0.5732  ,  1.6627\n",
      "nan  ,  0.4602  ,  1.7395\n",
      "430\n",
      "0.25917701890424155  ,  1.0957  ,  1.8065\n",
      "0.1506087324295844  ,  1.1608  ,  1.7034\n",
      "0.00044708845014554497  ,  1.1563  ,  1.74\n",
      "431\n",
      "0.20810584355476944  ,  0.2694  ,  0.8623\n",
      "0.18810513580649119  ,  0.3733  ,  0.8015\n",
      "0.02110879429318137  ,  0.2952  ,  0.8731\n",
      "432\n",
      "0.17322701258969198  ,  1.1573  ,  1.7072\n",
      "0.007410974551952966  ,  1.1681  ,  1.7078\n",
      "0.08297243898699601  ,  1.17  ,  1.654\n",
      "433\n",
      "0.14125720442365014  ,  0.7165  ,  2.0918\n",
      "0.09609210654144923  ,  0.7263  ,  2.0746\n",
      "nan  ,  0.7174  ,  2.0959\n",
      "434\n",
      "0.18122314915035587  ,  0.2108  ,  0.7343\n",
      "0.23631356155980945  ,  0.2892  ,  0.6733\n",
      "-0.10704077548029592  ,  0.3885  ,  0.6325\n",
      "435\n",
      "0.1728991768912071  ,  0.5578  ,  1.0754\n",
      "0.059110411352854844  ,  0.5809  ,  1.0804\n",
      "nan  ,  0.5723  ,  1.0996\n",
      "436\n",
      "0.5098153945012032  ,  1.0087  ,  1.3241\n",
      "0.014310851917856702  ,  1.1164  ,  1.6333\n",
      "-0.13546492926566334  ,  0.9767  ,  1.8904\n",
      "437\n",
      "0.2506112350672158  ,  0.5131  ,  1.2241\n",
      "nan  ,  0.5194  ,  1.2783\n",
      "nan  ,  0.5194  ,  1.2783\n",
      "438\n",
      "0.36988848889922693  ,  0.8537  ,  1.0913\n",
      "0.0738236839429013  ,  0.5426  ,  1.2784\n",
      "-0.1152991909458535  ,  0.5784  ,  1.2423\n",
      "439\n",
      "0.5473161700152525  ,  0.8309  ,  1.4906\n",
      "0.06932834191895211  ,  0.9497  ,  1.8283\n",
      "nan  ,  0.9366  ,  1.8831\n",
      "440\n",
      "-0.014720300254793643  ,  0.3611  ,  1.2091\n",
      "0.09353005943344919  ,  0.3986  ,  1.1744\n",
      "nan  ,  0.3609  ,  1.2092\n",
      "441\n",
      "-0.017145490755646246  ,  0.7199  ,  1.381\n",
      "0.16721417174598138  ,  0.7566  ,  1.2463\n",
      "-0.0278074040924145  ,  0.7752  ,  1.2599\n",
      "442\n",
      "0.14652620122193655  ,  0.6741  ,  2.1341\n",
      "0.11390614852692729  ,  0.6766  ,  2.1365\n",
      "nan  ,  0.6747  ,  2.143\n",
      "443\n",
      "0.3380314434680415  ,  1.2118  ,  1.642\n",
      "0.002515641890862617  ,  1.0138  ,  2.1241\n",
      "nan  ,  1.0097  ,  2.1361\n",
      "444\n",
      "0.6541430671446462  ,  0.903  ,  1.1295\n",
      "nan  ,  0.7703  ,  1.6875\n",
      "nan  ,  0.7703  ,  1.6875\n",
      "445\n",
      "0.08064849616944647  ,  0.2963  ,  1.2828\n",
      "0.07173957773563294  ,  0.395  ,  1.2355\n",
      "nan  ,  0.2958  ,  1.2878\n",
      "446\n",
      "0.19771799810498691  ,  0.6513  ,  2.1536\n",
      "-0.030488302708843142  ,  0.6579  ,  2.2074\n",
      "nan  ,  0.6548  ,  2.2088\n",
      "447\n",
      "0.5290503741856415  ,  1.1208  ,  2.3911\n",
      "0.029806450673102072  ,  1.3261  ,  2.2813\n",
      "-0.06389244271451952  ,  1.1645  ,  2.4586\n",
      "448\n",
      "nan  ,  0.335  ,  1.0313\n",
      "0.11769840254004019  ,  0.4048  ,  0.9671\n",
      "-0.07559137216863379  ,  0.415  ,  0.9699\n",
      "449\n",
      "0.24242947892990466  ,  0.6036  ,  1.427\n",
      "0.0578601605678228  ,  0.6036  ,  1.4998\n",
      "nan  ,  0.5997  ,  1.5091\n",
      "450\n",
      "-0.007407736954721292  ,  0.8619  ,  2.4096\n",
      "0.1016072577291912  ,  0.8958  ,  2.3699\n",
      "nan  ,  0.8619  ,  2.4096\n",
      "451\n",
      "0.13883372504661737  ,  0.9493  ,  2.0548\n",
      "0.17043716299651743  ,  0.7657  ,  2.0465\n",
      "nan  ,  0.753  ,  2.0771\n",
      "452\n",
      "0.037258559381450215  ,  1.1712  ,  1.648\n",
      "0.08606482072382984  ,  1.1723  ,  1.647\n",
      "nan  ,  1.1735  ,  1.6495\n",
      "453\n",
      "0.6440699355001752  ,  0.6749  ,  1.4021\n",
      "0.08318745916799034  ,  0.9612  ,  1.6077\n",
      "-0.02470498557872378  ,  0.819  ,  1.7894\n",
      "454\n",
      "0.6300981881030944  ,  0.5258  ,  1.5149\n",
      "0.0103311044296896  ,  0.5747  ,  1.9301\n",
      "nan  ,  0.5747  ,  1.9301\n",
      "455\n",
      "0.04562393418793312  ,  0.8721  ,  1.428\n",
      "0.1696682547660061  ,  0.8697  ,  1.3365\n",
      "-0.12529902906499543  ,  0.8911  ,  1.3562\n",
      "456\n",
      "0.3813614851178626  ,  0.9537  ,  1.3743\n",
      "-0.019149356545557942  ,  1.0194  ,  1.4587\n",
      "-0.002275500930336424  ,  1.0172  ,  1.3791\n",
      "457\n",
      "0.2826652100485194  ,  0.697  ,  1.0106\n",
      "-0.0014277828011988313  ,  0.603  ,  1.1742\n",
      "0.10954877018495396  ,  0.6129  ,  1.1369\n",
      "458\n",
      "0.5769365045007789  ,  0.8141  ,  1.0805\n",
      "0.03507418568038747  ,  0.8099  ,  1.5934\n",
      "-0.04613744801548874  ,  0.805  ,  1.6037\n",
      "459\n",
      "0.2010725781767303  ,  0.895  ,  1.6244\n",
      "0.07678929298967187  ,  0.9296  ,  1.554\n",
      "nan  ,  0.9004  ,  1.6364\n",
      "460\n",
      "0.22462744644748733  ,  0.561  ,  1.3537\n",
      "0.12700556911013575  ,  0.5649  ,  1.3536\n",
      "-0.14758911258470636  ,  0.6971  ,  1.2168\n",
      "461\n",
      "0.18709736191622614  ,  0.4677  ,  1.1812\n",
      "0.14469763283436288  ,  0.6203  ,  1.0075\n",
      "0.07337301662444658  ,  0.5295  ,  1.1144\n",
      "462\n",
      "0.09588893642979361  ,  0.6046  ,  1.3983\n",
      "0.13182337015571888  ,  0.606  ,  1.4027\n",
      "-0.11930135732586027  ,  0.6133  ,  1.3946\n",
      "463\n",
      "0.43388465276899846  ,  0.5576  ,  1.0532\n",
      "-0.06609888711958727  ,  0.8052  ,  1.0924\n",
      "0.08112511855731028  ,  0.6539  ,  1.1649\n",
      "464\n",
      "0.023594527403002254  ,  0.9962  ,  1.7043\n",
      "0.10563450591036681  ,  1.0067  ,  1.6207\n",
      "-0.059654047302703066  ,  1.0932  ,  1.4632\n",
      "465\n",
      "0.03884274116624444  ,  0.9907  ,  1.5845\n",
      "-0.12296483583051396  ,  1.0836  ,  1.3348\n",
      "-0.05326644741232198  ,  1.0483  ,  1.3798\n",
      "466\n",
      "0.23444148553366084  ,  0.6578  ,  1.3716\n",
      "0.0016377168498636287  ,  0.5344  ,  1.4396\n",
      "nan  ,  0.5033  ,  1.4638\n",
      "467\n",
      "0.3862268026363966  ,  1.1085  ,  1.4051\n",
      "0.12329723583798494  ,  1.2536  ,  1.8358\n",
      "nan  ,  1.2576  ,  1.8461\n",
      "468\n",
      "0.011699770098411609  ,  0.7062  ,  1.8543\n",
      "0.033022870941327206  ,  0.7063  ,  1.855\n",
      "-0.025025692915236587  ,  0.7282  ,  1.8275\n",
      "469\n",
      "0.5095829179960867  ,  0.7709  ,  1.6655\n",
      "-0.04272484576700425  ,  0.7993  ,  2.0872\n",
      "nan  ,  0.7947  ,  2.0891\n",
      "470\n",
      "0.36375643493086435  ,  0.9251  ,  1.2359\n",
      "0.19899437331579217  ,  0.9127  ,  1.4546\n",
      "0.15560889125123703  ,  0.9693  ,  1.4313\n",
      "471\n",
      "0.662217616355256  ,  0.8672  ,  1.9235\n",
      "0.023692191816314784  ,  0.9411  ,  2.1412\n",
      "nan  ,  0.9403  ,  2.1437\n",
      "472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.482592163724619  ,  0.5356  ,  1.1504\n",
      "-0.02038186976759626  ,  0.5462  ,  1.3788\n",
      "0.10321750147032488  ,  0.5525  ,  1.3702\n",
      "473\n",
      "0.3669942349919112  ,  0.7999  ,  1.6388\n",
      "0.0012961535160816114  ,  0.8223  ,  1.6997\n",
      "nan  ,  0.8222  ,  1.7002\n",
      "474\n",
      "0.34041403386208646  ,  1.5602  ,  1.8039\n",
      "0.040545826942400935  ,  1.466  ,  2.4186\n",
      "nan  ,  1.4654  ,  2.4262\n",
      "475\n",
      "0.4644596772519759  ,  1.1283  ,  1.3399\n",
      "0.12720509509948946  ,  1.1583  ,  1.8622\n",
      "0.001257785089617546  ,  1.1558  ,  1.9032\n",
      "476\n",
      "0.5809784938617393  ,  0.95  ,  1.8315\n",
      "-0.040390549829209955  ,  1.0785  ,  2.1894\n",
      "nan  ,  1.0756  ,  2.1925\n",
      "477\n",
      "0.05179909077155863  ,  0.5333  ,  1.4004\n",
      "0.08567911653842829  ,  0.5337  ,  1.3991\n",
      "nan  ,  0.5335  ,  1.4008\n",
      "478\n",
      "0.11539276592173264  ,  1.5803  ,  1.5657\n",
      "0.3112295200024459  ,  1.2087  ,  2.0148\n",
      "-0.10143017260759617  ,  1.2308  ,  2.085\n",
      "479\n",
      "0.42008185723132196  ,  0.753  ,  1.6699\n",
      "nan  ,  0.7886  ,  1.8062\n",
      "nan  ,  0.7886  ,  1.8062\n",
      "480\n",
      "0.747375184505766  ,  1.2337  ,  1.2284\n",
      "0.31076890184161426  ,  2.0395  ,  2.3528\n",
      "-0.13778400546471425  ,  2.0485  ,  2.362\n",
      "481\n",
      "0.15056703838360352  ,  2.7096  ,  2.5643\n",
      "0.01366431129580691  ,  1.0732  ,  1.9216\n",
      "nan  ,  1.0687  ,  1.9416\n",
      "482\n",
      "0.19273029003543216  ,  0.6269  ,  1.2752\n",
      "0.0319858303174173  ,  0.66  ,  1.2385\n",
      "0.07202911338369083  ,  0.6593  ,  1.2425\n",
      "483\n",
      "0.26641633133700315  ,  0.7103  ,  1.968\n",
      "0.1036906394633485  ,  0.6936  ,  2.0882\n",
      "nan  ,  0.6811  ,  2.1043\n",
      "484\n",
      "0.07982125493898247  ,  0.6985  ,  1.8092\n",
      "0.25023380256555816  ,  0.7894  ,  1.6483\n",
      "-0.039995374298024605  ,  0.7155  ,  1.7901\n",
      "485\n",
      "0.31186741891776715  ,  1.0759  ,  1.6187\n",
      "0.1241884647884454  ,  1.1316  ,  1.5034\n",
      "0.18961958154018133  ,  1.1221  ,  1.6537\n",
      "486\n",
      "0.5528288411030854  ,  0.7316  ,  1.3525\n",
      "0.26728372828271013  ,  0.8184  ,  1.5954\n",
      "nan  ,  0.815  ,  1.6781\n",
      "487\n",
      "0.29664944548442146  ,  0.4503  ,  1.7505\n",
      "0.0944777451886987  ,  0.481  ,  1.7555\n",
      "nan  ,  0.4539  ,  1.7793\n",
      "488\n",
      "0.21204487988479537  ,  0.7557  ,  1.6389\n",
      "0.09370991672972326  ,  0.8781  ,  1.5079\n",
      "0.03898505098957826  ,  0.8968  ,  1.5031\n",
      "489\n",
      "0.0662717545753155  ,  1.8132  ,  2.5296\n",
      "0.020214525552479056  ,  1.7909  ,  2.5002\n",
      "nan  ,  1.7928  ,  2.5835\n",
      "490\n",
      "0.2088264907560603  ,  1.3699  ,  1.0701\n",
      "-0.029715458194769465  ,  0.7847  ,  1.3763\n",
      "-0.049848769498449075  ,  0.6998  ,  1.4809\n",
      "491\n",
      "0.4739681055657114  ,  1.3442  ,  1.2291\n",
      "0.031309828773082804  ,  1.4487  ,  2.0477\n",
      "-0.09314145109532845  ,  1.4417  ,  2.0194\n",
      "492\n",
      "0.5580797774011561  ,  0.5011  ,  1.387\n",
      "0.2210957350038753  ,  0.5789  ,  1.4626\n",
      "nan  ,  0.5235  ,  1.5411\n",
      "493\n",
      "0.44936987594870104  ,  0.7303  ,  1.1896\n",
      "0.16607401067491673  ,  0.7966  ,  1.2623\n",
      "0.10369376523148434  ,  0.8022  ,  1.2774\n",
      "494\n",
      "0.29202218704675414  ,  0.4652  ,  1.3482\n",
      "0.11371650272096515  ,  0.5159  ,  1.3413\n",
      "0.059803444118208905  ,  0.4849  ,  1.3809\n",
      "495\n",
      "0.4032901714834558  ,  0.8002  ,  1.4673\n",
      "0.11012193361672801  ,  0.6148  ,  1.356\n",
      "nan  ,  0.4024  ,  1.4817\n",
      "496\n",
      "0.33258015707091626  ,  1.4198  ,  1.6293\n",
      "0.07999269817876879  ,  1.2465  ,  2.2286\n",
      "0.02376971494867949  ,  1.2591  ,  2.2134\n",
      "497\n",
      "0.5022214059530858  ,  1.3722  ,  1.4188\n",
      "0.033726571723197506  ,  1.3304  ,  1.1434\n",
      "-0.06795127950728831  ,  0.7345  ,  1.3338\n",
      "498\n",
      "0.002280073540651964  ,  0.6864  ,  1.991\n",
      "-0.004478823265320429  ,  0.6864  ,  1.991\n",
      "nan  ,  0.6864  ,  1.9911\n",
      "499\n",
      "0.4422604817162349  ,  0.9868  ,  2.6895\n",
      "0.02869938067503564  ,  1.0159  ,  2.837\n",
      "nan  ,  1.0159  ,  2.8372\n",
      "500\n",
      "0.3652832377498716  ,  2.1616  ,  2.1682\n",
      "0.011086530692943998  ,  0.7459  ,  2.1786\n",
      "nan  ,  0.7438  ,  2.1814\n",
      "501\n",
      "0.09472083088863245  ,  0.3281  ,  1.0921\n",
      "0.2515357721867859  ,  0.3453  ,  1.0692\n",
      "-0.018016586438404508  ,  0.4058  ,  1.0383\n",
      "502\n",
      "0.21677355283201985  ,  1.0531  ,  1.5034\n",
      "0.09496072005341227  ,  1.1064  ,  1.3901\n",
      "0.05158821320537747  ,  1.1037  ,  1.6125\n",
      "503\n",
      "0.1975020016790528  ,  0.2939  ,  1.0613\n",
      "-0.022873727408094208  ,  0.5475  ,  0.9468\n",
      "-0.15071484283420147  ,  0.3071  ,  1.0635\n",
      "504\n",
      "0.08812356532756453  ,  0.5247  ,  1.3821\n",
      "0.10214895752086868  ,  0.7485  ,  1.1645\n",
      "0.011131437377116686  ,  0.6578  ,  1.2519\n",
      "505\n",
      "0.5853256978903892  ,  0.6991  ,  1.4113\n",
      "0.22171896693139062  ,  0.9038  ,  1.324\n",
      "-0.13847075814011414  ,  0.8459  ,  1.4697\n",
      "506\n",
      "0.4074332096872621  ,  1.3866  ,  2.2411\n",
      "0.28648237027135554  ,  1.4043  ,  2.2253\n",
      "0.13158335280762562  ,  1.4254  ,  2.242\n",
      "507\n",
      "0.30595604477431504  ,  0.793  ,  1.4872\n",
      "0.011587493905535578  ,  0.8261  ,  1.4845\n",
      "-0.03395355878718612  ,  0.839  ,  1.4601\n",
      "508\n",
      "0.05321792305420667  ,  0.9837  ,  2.0203\n",
      "0.13024358167135544  ,  1.1024  ,  1.7867\n",
      "0.13861342502173923  ,  1.0157  ,  1.9614\n",
      "509\n",
      "0.5776672273712967  ,  1.1106  ,  1.1937\n",
      "-0.05137939692471077  ,  0.6895  ,  1.7609\n",
      "nan  ,  0.6606  ,  1.7862\n",
      "510\n",
      "0.6933432418275993  ,  0.7051  ,  1.5788\n",
      "0.27542522102560363  ,  0.814  ,  1.7089\n",
      "0.03896645974451607  ,  0.7956  ,  1.8053\n",
      "511\n",
      "0.21952506204885402  ,  0.1786  ,  0.7694\n",
      "0.02716763696888726  ,  0.4851  ,  0.8003\n",
      "nan  ,  0.1237  ,  0.7853\n",
      "512\n",
      "0.4585170708219952  ,  0.4637  ,  1.1059\n",
      "0.0821350133360282  ,  0.5142  ,  1.2242\n",
      "0.11326451723299212  ,  0.6094  ,  1.1478\n",
      "513\n",
      "0.01842390508880267  ,  0.8777  ,  1.5634\n",
      "0.2123864351756284  ,  0.9049  ,  1.394\n",
      "nan  ,  0.8779  ,  1.5636\n",
      "514\n",
      "0.4034245812657987  ,  0.7394  ,  1.2083\n",
      "-0.009297392567849911  ,  0.602  ,  1.451\n",
      "0.032117099351131995  ,  0.614  ,  1.434\n",
      "515\n",
      "0.03355449080536495  ,  1.5109  ,  2.3045\n",
      "-0.1087638440856073  ,  1.514  ,  2.2932\n",
      "-0.06360115055470254  ,  1.5038  ,  2.2545\n",
      "516\n",
      "0.3821023626458468  ,  0.9657  ,  2.1121\n",
      "0.24083198125792066  ,  0.9978  ,  2.0609\n",
      "nan  ,  0.9795  ,  2.1574\n",
      "517\n",
      "0.6501443801880928  ,  1.1917  ,  2.0335\n",
      "0.22330612976370426  ,  1.3853  ,  2.4708\n",
      "nan  ,  1.3938  ,  2.5139\n",
      "518\n",
      "0.09773850972524845  ,  0.7264  ,  1.6411\n",
      "-0.08923885034556589  ,  0.7488  ,  1.6215\n",
      "-0.010959509801793776  ,  0.7752  ,  1.5761\n",
      "519\n",
      "0.01848656023518566  ,  0.398  ,  1.1441\n",
      "0.0024770152110633603  ,  0.5952  ,  1.0083\n",
      "0.031175226523967762  ,  0.4405  ,  1.1066\n",
      "520\n",
      "0.40821663011091686  ,  1.2266  ,  1.1086\n",
      "nan  ,  0.6501  ,  1.4329\n",
      "nan  ,  0.6501  ,  1.4329\n",
      "521\n",
      "0.33312615489260944  ,  0.6664  ,  1.392\n",
      "-0.18223697568196232  ,  1.0901  ,  1.0977\n",
      "0.0007642295220656181  ,  0.7401  ,  1.3261\n",
      "522\n",
      "0.03215565457298087  ,  0.5168  ,  1.6619\n",
      "nan  ,  0.5151  ,  1.664\n",
      "nan  ,  0.5151  ,  1.664\n",
      "523\n",
      "0.4351555588383791  ,  0.6084  ,  1.7643\n",
      "0.18602521631367924  ,  0.7126  ,  1.7962\n",
      "-0.016783555828720292  ,  0.6566  ,  1.8889\n",
      "524\n",
      "0.4733849374990669  ,  0.7029  ,  1.809\n",
      "0.16526751569585507  ,  0.7654  ,  1.8704\n",
      "-0.004606232344327268  ,  0.7423  ,  1.9168\n",
      "525\n",
      "nan  ,  0.56  ,  1.5225\n",
      "nan  ,  0.56  ,  1.5225\n",
      "nan  ,  0.56  ,  1.5225\n",
      "526\n",
      "0.06883431260879146  ,  0.8759  ,  1.7051\n",
      "0.08850435730342264  ,  0.8982  ,  1.6445\n",
      "0.019875444131255957  ,  0.8992  ,  1.6516\n",
      "527\n",
      "0.6073451161586676  ,  0.8944  ,  1.857\n",
      "-0.02331859476621355  ,  1.0044  ,  2.1577\n",
      "0.03908929310642105  ,  1.0093  ,  2.1476\n",
      "528\n",
      "0.2634466087820123  ,  0.4682  ,  0.899\n",
      "nan  ,  0.4804  ,  0.9696\n",
      "nan  ,  0.4804  ,  0.9696\n",
      "529\n",
      "0.338896068206456  ,  1.1301  ,  1.5252\n",
      "0.028593474805903688  ,  1.223  ,  1.5249\n",
      "-0.0864318774620644  ,  1.2298  ,  1.6043\n",
      "530\n",
      "0.46283172892626634  ,  0.7325  ,  1.2512\n",
      "-0.03740676650085635  ,  0.7231  ,  1.6044\n",
      "0.04318429479391374  ,  0.8171  ,  1.4752\n",
      "531\n",
      "0.25745297435063186  ,  1.4955  ,  2.2553\n",
      "-0.03019559325806534  ,  1.5256  ,  2.295\n",
      "nan  ,  1.5254  ,  2.2955\n",
      "532\n",
      "0.2507055902319765  ,  0.8609  ,  1.2507\n",
      "0.08727809374082164  ,  0.8124  ,  1.3842\n",
      "0.15873142131131593  ,  0.8319  ,  1.3642\n",
      "533\n",
      "0.3758818617950744  ,  0.6613  ,  1.7191\n",
      "-0.006452018208642942  ,  0.6435  ,  1.9231\n",
      "nan  ,  0.6403  ,  1.9255\n",
      "534\n",
      "0.656767341220255  ,  1.0185  ,  2.0808\n",
      "0.06531287251042071  ,  1.1245  ,  2.3317\n",
      "nan  ,  1.1142  ,  2.3723\n",
      "535\n",
      "0.5899607426956126  ,  1.1901  ,  2.0396\n",
      "0.09147008121197817  ,  1.2036  ,  2.8825\n",
      "nan  ,  1.2035  ,  2.8847\n",
      "536\n",
      "0.012654050397769357  ,  0.6925  ,  1.6319\n",
      "-4.387431841612133e-05  ,  0.694  ,  1.6334\n",
      "nan  ,  0.6937  ,  1.6342\n",
      "537\n",
      "nan  ,  0.8965  ,  1.7824\n",
      "-0.06978567295092394  ,  0.9055  ,  1.7699\n",
      "-0.06787726502636324  ,  0.9163  ,  1.7374\n",
      "538\n",
      "0.1537637941990475  ,  0.3172  ,  0.9787\n",
      "0.030417567797922245  ,  0.4994  ,  0.8646\n",
      "-0.09597773231841625  ,  0.4456  ,  0.8881\n",
      "539\n",
      "0.053347962521889725  ,  0.4924  ,  1.4859\n",
      "0.20653081165014006  ,  0.4943  ,  1.4645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.019945777145374974  ,  0.4963  ,  1.4834\n",
      "540\n",
      "0.4818522494686222  ,  0.7719  ,  1.5365\n",
      "0.35059360840509013  ,  0.8183  ,  1.6311\n",
      "-0.03674290902061122  ,  0.8596  ,  1.5751\n",
      "541\n",
      "0.6803448140326063  ,  0.4783  ,  1.2433\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "542\n",
      "0.47029411297750673  ,  1.0538  ,  1.2521\n",
      "0.13889065873808548  ,  1.2965  ,  1.6804\n",
      "0.01573876292821853  ,  1.2922  ,  1.6423\n",
      "543\n",
      "nan  ,  0.7713  ,  1.5901\n",
      "0.09394137820693134  ,  0.7808  ,  1.5546\n",
      "0.02549764235111733  ,  0.8461  ,  1.465\n",
      "544\n",
      "0.2091027389415009  ,  1.3298  ,  1.2324\n",
      "0.08027570888654825  ,  0.7301  ,  1.0837\n",
      "-0.18442547974475068  ,  0.7558  ,  1.0625\n",
      "545\n",
      "0.37174728573779414  ,  0.9146  ,  1.4342\n",
      "-0.052629477199693575  ,  0.9837  ,  1.6187\n",
      "-0.11855760947238206  ,  0.97  ,  1.6376\n",
      "546\n",
      "0.1458731927133454  ,  0.6485  ,  1.4268\n",
      "0.03518352319000934  ,  0.5261  ,  1.441\n",
      "nan  ,  0.4942  ,  1.4661\n",
      "547\n",
      "0.46638427033305385  ,  0.7838  ,  1.2644\n",
      "0.28106974650234534  ,  0.6417  ,  1.6582\n",
      "nan  ,  0.6447  ,  1.6726\n",
      "548\n",
      "0.4560217033747281  ,  1.053  ,  1.6056\n",
      "0.3018323183022087  ,  1.172  ,  1.8411\n",
      "nan  ,  1.187  ,  1.9868\n",
      "549\n",
      "0.5146887722122208  ,  1.1832  ,  1.2611\n",
      "0.2729592153161591  ,  1.0686  ,  1.6341\n",
      "-0.03550689907786778  ,  1.0244  ,  1.8322\n",
      "550\n",
      "0.3665017215058225  ,  0.9383  ,  2.1873\n",
      "0.019131277527316908  ,  0.9626  ,  2.2707\n",
      "nan  ,  0.9584  ,  2.2766\n",
      "551\n",
      "0.2429789111569172  ,  0.9592  ,  1.875\n",
      "-0.12902780329385957  ,  1.0703  ,  1.7076\n",
      "-0.1631707315225258  ,  1.0685  ,  1.7069\n",
      "552\n",
      "0.6707611533730328  ,  0.8311  ,  0.9595\n",
      "nan  ,  0.5836  ,  1.509\n",
      "nan  ,  0.5836  ,  1.509\n",
      "553\n",
      "0.3784843370827425  ,  1.1155  ,  1.3381\n",
      "-0.01085615529874404  ,  0.7902  ,  1.6685\n",
      "nan  ,  0.778  ,  1.6827\n",
      "554\n",
      "0.4011028959989745  ,  0.5253  ,  1.0407\n",
      "0.2244210603228615  ,  0.5461  ,  1.1542\n",
      "-0.33325356657365596  ,  0.6488  ,  1.041\n",
      "555\n",
      "0.12071245226504643  ,  0.3198  ,  1.0666\n",
      "0.037596321427166124  ,  0.3277  ,  1.0629\n",
      "-0.07893873613174081  ,  0.4207  ,  0.9997\n",
      "556\n",
      "0.4397508330574255  ,  0.9308  ,  1.9405\n",
      "0.27102622468704785  ,  0.9794  ,  2.0781\n",
      "nan  ,  0.9815  ,  2.095\n",
      "557\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "558\n",
      "0.643260246123101  ,  1.3553  ,  1.2284\n",
      "0.30619264250000355  ,  1.0856  ,  2.2192\n",
      "nan  ,  1.0988  ,  2.2739\n",
      "559\n",
      "-0.004577389352429542  ,  0.8602  ,  2.0446\n",
      "0.0236752437536699  ,  0.8601  ,  2.0444\n",
      "nan  ,  0.8602  ,  2.0446\n",
      "560\n",
      "0.3858911933299841  ,  0.5501  ,  1.7174\n",
      "0.038014174098214656  ,  0.5601  ,  1.773\n",
      "nan  ,  0.5586  ,  1.7751\n",
      "561\n",
      "0.20187806167513483  ,  0.7361  ,  2.2975\n",
      "0.006065077151425874  ,  0.745  ,  2.2988\n",
      "nan  ,  0.7374  ,  2.3059\n",
      "562\n",
      "0.3083095990993886  ,  0.3895  ,  1.1552\n",
      "0.00242243169683146  ,  0.3953  ,  1.2369\n",
      "-0.03132684935906299  ,  0.3933  ,  1.2387\n",
      "563\n",
      "0.09963805446883761  ,  1.2258  ,  2.1328\n",
      "0.1051436708583491  ,  1.2264  ,  2.1342\n",
      "nan  ,  1.2265  ,  2.1348\n",
      "564\n",
      "0.03871094531134333  ,  0.4446  ,  1.0883\n",
      "0.12407228174451373  ,  0.5234  ,  0.9832\n",
      "0.0574822924544003  ,  0.5224  ,  0.9995\n",
      "565\n",
      "0.4446079773773206  ,  0.9037  ,  1.0873\n",
      "0.31155741008291943  ,  0.7254  ,  1.5144\n",
      "0.19379604777307344  ,  0.7904  ,  1.4656\n",
      "566\n",
      "0.07806459782363175  ,  0.711  ,  1.5801\n",
      "0.030421186720051244  ,  0.716  ,  1.5779\n",
      "0.02709710789235155  ,  0.7867  ,  1.4755\n",
      "567\n",
      "0.4902412999094231  ,  0.6435  ,  1.1393\n",
      "nan  ,  0.5278  ,  1.4074\n",
      "nan  ,  0.5278  ,  1.4074\n",
      "568\n",
      "0.5546124952788225  ,  0.6953  ,  1.2786\n",
      "0.1755662152385968  ,  0.7779  ,  1.6088\n",
      "-0.049219559959346404  ,  0.7641  ,  1.6487\n",
      "569\n",
      "0.7110097390071195  ,  0.7757  ,  1.7211\n",
      "nan  ,  0.9157  ,  2.3808\n",
      "nan  ,  0.9157  ,  2.3808\n",
      "570\n",
      "0.12037329521225493  ,  1.1388  ,  1.7409\n",
      "0.23577819875888553  ,  1.1435  ,  1.5627\n",
      "0.15498198323398782  ,  1.1565  ,  1.6693\n",
      "571\n",
      "0.3894650679508276  ,  0.7204  ,  1.2186\n",
      "0.05288204949894497  ,  0.7208  ,  1.4688\n",
      "nan  ,  0.7106  ,  1.4938\n",
      "572\n",
      "0.6349945042869218  ,  0.7407  ,  1.8801\n",
      "0.11624824855970316  ,  0.804  ,  2.0845\n",
      "nan  ,  0.8035  ,  2.0864\n",
      "573\n",
      "0.6995527279102044  ,  0.6443  ,  1.0649\n",
      "-0.06516518357266166  ,  0.8566  ,  1.5822\n",
      "0.02619802780619907  ,  0.8106  ,  1.6516\n",
      "574\n",
      "0.23989134839990922  ,  0.9005  ,  1.3285\n",
      "0.02075984806595693  ,  0.7532  ,  1.4725\n",
      "0.01593882959989135  ,  0.7479  ,  1.4813\n",
      "575\n",
      "0.42151934628586485  ,  0.9347  ,  1.9173\n",
      "0.08179932658628743  ,  0.9907  ,  1.8873\n",
      "nan  ,  0.9529  ,  1.9767\n",
      "576\n",
      "0.1314100231734604  ,  0.657  ,  1.5794\n",
      "0.010246299018646841  ,  0.6598  ,  1.5941\n",
      "-0.0030739127213035705  ,  0.7057  ,  1.5341\n",
      "577\n",
      "0.2591405525861542  ,  1.5056  ,  1.4173\n",
      "0.07778158632978188  ,  0.7351  ,  1.5287\n",
      "nan  ,  0.6627  ,  1.6222\n",
      "578\n",
      "0.02266691873629274  ,  1.6376  ,  1.1441\n",
      "0.31237814698403166  ,  1.3902  ,  1.5739\n",
      "-0.3305453209640016  ,  1.3981  ,  1.4997\n",
      "579\n",
      "0.6472574320571065  ,  0.5503  ,  1.3\n",
      "-0.010743867725347512  ,  0.6546  ,  1.8015\n",
      "nan  ,  0.6545  ,  1.8015\n",
      "580\n",
      "0.6322277190690494  ,  0.9719  ,  1.5803\n",
      "-0.05398680916229219  ,  1.0982  ,  2.3618\n",
      "nan  ,  1.0957  ,  2.3638\n",
      "581\n",
      "0.20151132315466658  ,  0.6662  ,  1.2218\n",
      "0.024347700937452886  ,  0.7024  ,  1.1645\n",
      "-0.0379900472359958  ,  0.6806  ,  1.2065\n",
      "582\n",
      "0.005646567434550596  ,  0.5584  ,  1.9357\n",
      "nan  ,  0.556  ,  1.9375\n",
      "nan  ,  0.556  ,  1.9375\n",
      "583\n",
      "0.1659956013232203  ,  1.0498  ,  2.0768\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "584\n",
      "0.27722115723135143  ,  1.065  ,  1.1981\n",
      "0.0965200852645337  ,  0.4431  ,  0.8391\n",
      "-0.08339040004103773  ,  0.519  ,  0.7938\n",
      "585\n",
      "0.2504310388287002  ,  1.527  ,  1.2541\n",
      "0.0925548066874552  ,  0.5644  ,  1.0949\n",
      "-0.11537796876297592  ,  0.5119  ,  1.149\n",
      "586\n",
      "0.2970737438405716  ,  1.5515  ,  1.3795\n",
      "0.0031228785793455324  ,  1.3721  ,  1.9903\n",
      "0.03196079667967282  ,  1.3709  ,  2.0222\n",
      "587\n",
      "0.25048282170786806  ,  0.3489  ,  0.8263\n",
      "0.0731973643259093  ,  0.4438  ,  0.756\n",
      "0.019778996571363606  ,  0.2322  ,  0.8008\n",
      "588\n",
      "0.43903514896579043  ,  0.947  ,  1.5485\n",
      "0.26510705696565356  ,  0.9888  ,  1.5711\n",
      "-0.04536769782323579  ,  0.9986  ,  1.5966\n",
      "589\n",
      "0.41642980178088995  ,  0.8191  ,  1.952\n",
      "0.2256986689018585  ,  0.9207  ,  2.0432\n",
      "0.3294540960970514  ,  0.8706  ,  2.1614\n",
      "590\n",
      "0.27268874999968834  ,  0.5674  ,  1.6259\n",
      "0.03839260572168611  ,  0.714  ,  1.5136\n",
      "-0.04555152715948938  ,  0.6653  ,  1.5467\n",
      "591\n",
      "0.2596780141254078  ,  0.4801  ,  1.1928\n",
      "0.07101245175004338  ,  0.4954  ,  1.2217\n",
      "0.05864395497428469  ,  0.5344  ,  1.1852\n",
      "592\n",
      "nan  ,  0.654  ,  1.2922\n",
      "-0.013198661463244813  ,  0.654  ,  1.2922\n",
      "nan  ,  0.654  ,  1.2922\n",
      "593\n",
      "0.2652689425832425  ,  0.8941  ,  1.7713\n",
      "0.18661281941640018  ,  0.9036  ,  1.7784\n",
      "nan  ,  0.9043  ,  1.7954\n",
      "594\n",
      "0.11126208376147248  ,  0.6513  ,  1.4329\n",
      "-0.010759850709750088  ,  0.8668  ,  1.1779\n",
      "0.214536493345853  ,  0.8203  ,  1.2228\n",
      "595\n",
      "0.7512181614078821  ,  0.6571  ,  1.5088\n",
      "0.39397982509896035  ,  0.844  ,  2.0741\n",
      "-0.09480090978770336  ,  0.8523  ,  2.1191\n",
      "596\n",
      "0.05943836274509863  ,  1.1324  ,  1.7867\n",
      "-0.08885249154689227  ,  1.1538  ,  1.7395\n",
      "-0.06262979136910525  ,  1.1461  ,  1.7307\n",
      "597\n",
      "0.5378035744270404  ,  1.1986  ,  1.5198\n",
      "nan  ,  0.5984  ,  1.6989\n",
      "nan  ,  0.5984  ,  1.6989\n",
      "598\n",
      "0.45958298692983734  ,  1.0773  ,  1.6874\n",
      "0.22273073729246934  ,  1.2786  ,  1.7874\n",
      "-0.1056045823609991  ,  1.1153  ,  2.1833\n",
      "599\n",
      "0.36418815707204844  ,  1.402  ,  2.1194\n",
      "-0.011534700305311441  ,  1.52  ,  2.5228\n",
      "nan  ,  1.52  ,  2.5242\n",
      "600\n",
      "0.42007862177673466  ,  1.0154  ,  1.3245\n",
      "0.07492514893264926  ,  1.0425  ,  1.343\n",
      "nan  ,  1.0466  ,  1.3783\n",
      "601\n",
      "0.30603475695345567  ,  0.7928  ,  1.7545\n",
      "0.07525032449514693  ,  0.8716  ,  1.7393\n",
      "-0.013196724261206324  ,  0.8285  ,  1.8137\n",
      "602\n",
      "-0.015500610063212671  ,  0.966  ,  1.691\n",
      "nan  ,  0.9659  ,  1.6911\n",
      "-0.10409401573081771  ,  0.9681  ,  1.6808\n",
      "603\n",
      "0.3324005335813891  ,  0.8312  ,  0.8626\n",
      "0.00335363433559307  ,  0.7334  ,  0.983\n",
      "-0.10141401040060073  ,  0.7137  ,  1.0558\n",
      "604\n",
      "0.3160869413461108  ,  1.1289  ,  1.5266\n",
      "0.061204276564809826  ,  1.2183  ,  1.6875\n",
      "0.06899908255567802  ,  1.2049  ,  1.6308\n",
      "605\n",
      "0.6642204657054979  ,  0.6549  ,  1.4824\n",
      "-0.19396152942770511  ,  1.4141  ,  2.0398\n",
      "-0.03003468949938105  ,  0.7873  ,  1.98\n",
      "606\n",
      "0.43938347482956414  ,  0.8941  ,  1.9861\n",
      "0.2332881119870367  ,  0.9245  ,  2.0936\n",
      "nan  ,  0.9249  ,  2.1226\n",
      "607\n",
      "0.34866489601790057  ,  0.5217  ,  1.1746\n",
      "0.12248099788634659  ,  0.5781  ,  1.2062\n",
      "0.09285922019297108  ,  0.572  ,  1.2173\n",
      "608\n",
      "0.021340832417133852  ,  0.856  ,  1.4532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07499577025690572  ,  0.8478  ,  1.4266\n",
      "nan  ,  0.8378  ,  1.4816\n",
      "609\n",
      "0.04243371228445918  ,  0.6486  ,  1.3592\n",
      "0.06936370411159584  ,  0.6823  ,  1.312\n",
      "0.02677274291002219  ,  0.6784  ,  1.3206\n",
      "610\n",
      "0.4451260133933527  ,  1.019  ,  1.0822\n",
      "-0.035485199147711  ,  0.4153  ,  1.29\n",
      "-0.013103114999034942  ,  0.4407  ,  1.2684\n",
      "611\n",
      "0.06628849689533242  ,  1.1205  ,  1.8288\n",
      "-0.028988353162159024  ,  1.1255  ,  1.8271\n",
      "-0.019337958118448476  ,  1.1286  ,  1.7929\n",
      "612\n",
      "0.016907019731987712  ,  1.5083  ,  1.9817\n",
      "-0.10660607975370301  ,  1.4891  ,  1.8744\n",
      "0.011619399894322048  ,  1.5014  ,  1.9597\n",
      "613\n",
      "0.3651507302826773  ,  0.7697  ,  1.8738\n",
      "0.043116050511758416  ,  0.8087  ,  1.9877\n",
      "0.0056596141626456846  ,  0.8217  ,  1.9744\n",
      "614\n",
      "0.7299234477015146  ,  0.5773  ,  1.1115\n",
      "-0.03117872012044834  ,  0.5558  ,  1.5529\n",
      "nan  ,  0.5544  ,  1.5537\n",
      "615\n",
      "0.14670219550513627  ,  0.083  ,  0.4767\n",
      "0.27165782374037095  ,  0.0865  ,  0.4697\n",
      "-0.00286051257657661  ,  0.1952  ,  0.4373\n",
      "616\n",
      "-0.01269098756549828  ,  1.0091  ,  1.584\n",
      "-0.02967975112352018  ,  1.0302  ,  1.4646\n",
      "-0.06734984551193764  ,  1.0305  ,  1.4619\n",
      "617\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "618\n",
      "0.41547534968818406  ,  1.061  ,  2.1359\n",
      "0.2012775300570084  ,  1.1039  ,  2.1737\n",
      "0.006626991306921629  ,  1.1108  ,  2.2086\n",
      "619\n",
      "0.39483297027798314  ,  0.9617  ,  1.6302\n",
      "0.23328196830414402  ,  1.0148  ,  1.6834\n",
      "-0.1472111344828216  ,  1.0208  ,  1.7173\n",
      "620\n",
      "0.02392639017721622  ,  0.8191  ,  1.7769\n",
      "nan  ,  0.8192  ,  1.7778\n",
      "nan  ,  0.8192  ,  1.7778\n",
      "621\n",
      "0.2445657905796685  ,  0.8805  ,  1.8232\n",
      "0.10919280301013966  ,  0.8911  ,  1.8276\n",
      "nan  ,  0.8865  ,  1.8439\n",
      "622\n",
      "0.5934010864618564  ,  0.7483  ,  1.6839\n",
      "0.27642750305327096  ,  0.8662  ,  2.0068\n",
      "nan  ,  0.8699  ,  2.0202\n",
      "623\n",
      "0.20525205499649965  ,  0.7022  ,  1.5411\n",
      "-0.2489942684984804  ,  0.8892  ,  1.395\n",
      "nan  ,  0.705  ,  1.5479\n",
      "624\n",
      "0.36109021199411295  ,  0.8049  ,  1.4469\n",
      "0.09716436679477868  ,  0.8609  ,  1.5406\n",
      "-0.06914142831119074  ,  0.8772  ,  1.5169\n",
      "625\n",
      "0.6833989681053539  ,  0.5343  ,  1.2866\n",
      "0.007713916431044901  ,  0.5148  ,  1.7248\n",
      "nan  ,  0.5148  ,  1.7248\n",
      "626\n",
      "0.15756593873438085  ,  0.4484  ,  1.3117\n",
      "0.04838309947848012  ,  0.4343  ,  1.3488\n",
      "nan  ,  0.4256  ,  1.3574\n",
      "627\n",
      "0.35952824947139267  ,  1.2467  ,  1.4082\n",
      "0.12793309253802698  ,  0.8822  ,  1.8641\n",
      "-0.020776667181894515  ,  0.8753  ,  1.8901\n",
      "628\n",
      "0.3936834931454277  ,  0.9737  ,  1.1148\n",
      "0.1739482031981563  ,  0.7366  ,  1.245\n",
      "0.09072437031233965  ,  0.7404  ,  1.2535\n",
      "629\n",
      "0.3529138544135766  ,  0.8656  ,  1.2078\n",
      "0.14399169383778998  ,  0.9278  ,  1.3103\n",
      "0.09121792836126558  ,  0.8837  ,  1.456\n",
      "630\n",
      "0.5981878418802048  ,  1.1293  ,  2.004\n",
      "0.07450713076148459  ,  1.3036  ,  2.4832\n",
      "nan  ,  1.3036  ,  2.4833\n",
      "631\n",
      "0.8086971354776906  ,  0.9388  ,  2.3128\n",
      "0.6271960167384721  ,  1.1206  ,  2.4076\n",
      "0.08809427947244945  ,  1.3662  ,  2.387\n",
      "632\n",
      "0.3054542719133281  ,  0.499  ,  1.512\n",
      "0.10524573825396381  ,  0.5257  ,  1.5427\n",
      "nan  ,  0.5064  ,  1.5653\n",
      "633\n",
      "0.1790112270759274  ,  0.9401  ,  1.7175\n",
      "0.27117646711357957  ,  0.9499  ,  1.6148\n",
      "0.005269380193896063  ,  0.959  ,  1.6946\n",
      "634\n",
      "0.023733429696446925  ,  0.7328  ,  1.4778\n",
      "-0.0037353895402461815  ,  1.7114  ,  1.1164\n",
      "-0.0035848644295841375  ,  0.7555  ,  1.4343\n",
      "635\n",
      "0.5168619654554351  ,  0.8917  ,  1.2367\n",
      "0.17602225204883623  ,  0.8764  ,  1.5067\n",
      "0.01585346864906717  ,  0.7594  ,  1.6855\n",
      "636\n",
      "0.8705895908654229  ,  0.9739  ,  2.5902\n",
      "0.10012628058375  ,  1.6814  ,  3.6523\n",
      "0.04093124178000734  ,  1.5469  ,  3.8162\n",
      "637\n",
      "0.5966137437158673  ,  1.2623  ,  1.3492\n",
      "0.02684888191220678  ,  1.282  ,  2.1336\n",
      "nan  ,  1.2821  ,  2.1346\n",
      "638\n",
      "0.30588394959534987  ,  0.815  ,  1.3365\n",
      "0.148670956003999  ,  0.8483  ,  1.3791\n",
      "0.11742860328356144  ,  0.8505  ,  1.3937\n",
      "639\n",
      "0.25109637626907305  ,  1.7112  ,  2.0539\n",
      "0.23620720822302893  ,  1.7738  ,  2.3378\n",
      "nan  ,  1.8033  ,  2.3966\n",
      "640\n",
      "0.09161351183275113  ,  1.1371  ,  1.4686\n",
      "0.020317430044667024  ,  1.085  ,  1.7203\n",
      "nan  ,  1.085  ,  1.7216\n",
      "641\n",
      "-0.02551727639620596  ,  0.7932  ,  1.563\n",
      "0.14861428793718462  ,  0.8355  ,  1.4469\n",
      "-0.07840322292459771  ,  0.8232  ,  1.4893\n",
      "642\n",
      "0.22486147893691266  ,  1.2964  ,  0.9002\n",
      "0.029425742814948676  ,  1.0581  ,  1.2513\n",
      "-0.14183611340141883  ,  1.0582  ,  1.2978\n",
      "643\n",
      "0.16449164551424136  ,  1.1495  ,  1.4074\n",
      "-0.12359878991857316  ,  1.1514  ,  1.3197\n",
      "-0.12821946529987371  ,  1.1537  ,  1.3629\n",
      "644\n",
      "0.03732635636837606  ,  0.779  ,  1.4606\n",
      "0.14022870818846003  ,  0.8503  ,  1.295\n",
      "-0.05208702732243853  ,  0.8382  ,  1.3241\n",
      "645\n",
      "0.46381663764843895  ,  0.8608  ,  1.0234\n",
      "-0.018304852925666523  ,  0.8691  ,  1.3606\n",
      "-0.06944987693358846  ,  0.8534  ,  1.4035\n",
      "646\n",
      "0.04628468505010484  ,  1.0063  ,  1.4693\n",
      "0.007308490872276105  ,  1.0265  ,  1.3995\n",
      "-0.21923111702254716  ,  1.0165  ,  1.4488\n",
      "647\n",
      "0.27526940946527245  ,  0.5659  ,  1.1824\n",
      "0.08315088021337327  ,  0.5642  ,  1.2607\n",
      "nan  ,  0.556  ,  1.2765\n",
      "648\n",
      "0.1669946649776393  ,  0.9856  ,  1.2745\n",
      "-0.09884862755567256  ,  1.026  ,  1.0501\n",
      "0.2730353511915544  ,  1.0232  ,  1.071\n",
      "649\n",
      "0.16174680611613299  ,  0.8333  ,  0.821\n",
      "0.0004624299366730168  ,  0.7399  ,  1.0748\n",
      "0.01116719689144317  ,  0.7445  ,  1.0157\n",
      "650\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "651\n",
      "0.29220830099180284  ,  0.9846  ,  1.6206\n",
      "0.016780627616667338  ,  1.0137  ,  1.7047\n",
      "nan  ,  1.0137  ,  1.7047\n",
      "652\n",
      "0.32007104135448017  ,  0.6731  ,  1.3227\n",
      "-0.007347783125106977  ,  0.7738  ,  1.3062\n",
      "0.2787674173544677  ,  0.7933  ,  1.2742\n",
      "653\n",
      "-0.020032632592748113  ,  0.7451  ,  1.5696\n",
      "-0.004925472767008915  ,  0.8723  ,  1.3752\n",
      "-0.000689856180233395  ,  0.8113  ,  1.4526\n",
      "654\n",
      "0.3610727678604787  ,  0.7801  ,  1.272\n",
      "0.00935833544775008  ,  0.7792  ,  1.4357\n",
      "-0.06308696492903652  ,  0.7764  ,  1.4392\n",
      "655\n",
      "0.3254368297553086  ,  0.7874  ,  1.1431\n",
      "0.028978529810107605  ,  0.4917  ,  1.3651\n",
      "-0.029224978084434507  ,  0.5857  ,  1.3006\n",
      "656\n",
      "0.16584357495091487  ,  0.5374  ,  1.1458\n",
      "0.011292562034692841  ,  0.5168  ,  1.2094\n",
      "-0.04167746855344855  ,  0.5311  ,  1.1881\n",
      "657\n",
      "0.22737440533935993  ,  0.3209  ,  1.3218\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "658\n",
      "0.08449923850269103  ,  0.5527  ,  1.1656\n",
      "0.042086208283951626  ,  0.8063  ,  0.8673\n",
      "-0.10008208691815193  ,  0.7954  ,  0.8783\n",
      "659\n",
      "0.2780298228654804  ,  0.5345  ,  1.4452\n",
      "-0.10978297667755026  ,  0.5802  ,  1.4348\n",
      "0.03664344928698484  ,  0.5801  ,  1.4338\n",
      "660\n",
      "0.13864645534764847  ,  0.3187  ,  1.0555\n",
      "0.022696160817178186  ,  0.4076  ,  1.0036\n",
      "-0.008115396698082918  ,  0.377  ,  1.0247\n",
      "661\n",
      "0.037727047266175845  ,  2.0446  ,  1.2789\n",
      "0.0795134791712192  ,  0.934  ,  1.4678\n",
      "-0.13891827013955058  ,  0.9423  ,  1.4337\n",
      "662\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "663\n",
      "0.12374426306237254  ,  2.3464  ,  1.536\n",
      "0.03143125131518567  ,  0.3073  ,  0.7525\n",
      "0.03563982967929455  ,  0.3298  ,  0.7363\n",
      "664\n",
      "-0.0009748123706155858  ,  0.5357  ,  1.137\n",
      "0.07974669009032657  ,  0.5733  ,  1.0655\n",
      "-0.02646217085752756  ,  0.6083  ,  1.0224\n",
      "665\n",
      "0.33009062566637715  ,  1.3029  ,  0.95\n",
      "-0.02733078640019718  ,  0.9741  ,  1.4499\n",
      "0.11740962104235961  ,  0.976  ,  1.4453\n",
      "666\n",
      "0.027026624463435518  ,  0.2159  ,  0.8487\n",
      "-0.02002395297019155  ,  0.2037  ,  0.8527\n",
      "nan  ,  0.2033  ,  0.8528\n",
      "667\n",
      "0.11891752237255211  ,  1.1051  ,  1.5721\n",
      "nan  ,  1.072  ,  1.7601\n",
      "nan  ,  1.072  ,  1.7601\n",
      "668\n",
      "0.1255055736132601  ,  1.7628  ,  1.4147\n",
      "-0.01129932938358685  ,  0.7851  ,  1.4671\n",
      "0.026293262613925734  ,  0.7993  ,  1.4334\n",
      "669\n",
      "0.16421828421240686  ,  1.0415  ,  1.5307\n",
      "-0.11473184327235043  ,  1.0657  ,  1.5804\n",
      "-0.05005281376643721  ,  1.0919  ,  1.3997\n",
      "670\n",
      "0.3757618098510535  ,  0.6636  ,  1.1402\n",
      "-0.07995099680150547  ,  0.6788  ,  1.3118\n",
      "-0.0234147008374617  ,  0.6826  ,  1.3\n",
      "671\n",
      "-0.006667533020490391  ,  0.4851  ,  1.2856\n",
      "nan  ,  0.485  ,  1.2857\n",
      "nan  ,  0.485  ,  1.2857\n",
      "672\n",
      "0.27667953175659116  ,  0.4938  ,  1.1303\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "673\n",
      "0.1938975756011756  ,  1.2521  ,  1.468\n",
      "-0.015369202705192856  ,  1.3098  ,  1.8128\n",
      "0.20110597599871471  ,  1.3102  ,  1.8143\n",
      "674\n",
      "-0.004998164210615671  ,  0.5428  ,  1.1609\n",
      "nan  ,  0.5411  ,  1.1629\n",
      "nan  ,  0.5411  ,  1.1629\n",
      "675\n",
      "0.14191157371375696  ,  1.3683  ,  1.015\n",
      "0.061543720356037966  ,  1.1023  ,  1.4553\n",
      "-0.2263332813448169  ,  1.1032  ,  1.4647\n",
      "676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2643854921156092  ,  0.579  ,  1.3199\n",
      "0.004992986208059321  ,  0.585  ,  1.3947\n",
      "nan  ,  0.5835  ,  1.397\n",
      "677\n",
      "0.006005053016537855  ,  1.232  ,  1.5408\n",
      "0.14702359238429463  ,  1.192  ,  1.4541\n",
      "-0.016699528538586035  ,  1.2027  ,  1.4727\n",
      "678\n",
      "-0.011527504551414207  ,  0.984  ,  1.4073\n",
      "0.10345641017296837  ,  0.9657  ,  1.2375\n",
      "0.05135333658080953  ,  0.9681  ,  1.2435\n",
      "679\n",
      "0.14807160553796753  ,  1.1352  ,  1.1625\n",
      "nan  ,  1.0945  ,  1.5329\n",
      "nan  ,  1.0945  ,  1.5329\n",
      "680\n",
      "0.21274655899089778  ,  0.6279  ,  1.2349\n",
      "0.19538912533236266  ,  0.6814  ,  1.1262\n",
      "-0.23329088319726543  ,  0.7467  ,  1.0485\n",
      "681\n",
      "0.17037744792745854  ,  1.3382  ,  1.6305\n",
      "0.0994643909291637  ,  1.3185  ,  1.5274\n",
      "0.3298278052651416  ,  1.3183  ,  1.5182\n",
      "682\n",
      "0.2114404743413021  ,  1.0366  ,  1.3133\n",
      "0.018148756542264294  ,  0.9699  ,  1.5258\n",
      "0.09516263023025173  ,  0.9665  ,  1.5334\n",
      "683\n",
      "0.36774154525478203  ,  1.0033  ,  1.2556\n",
      "-0.18707690791875622  ,  1.1205  ,  1.379\n",
      "-0.1437795726745642  ,  1.1217  ,  1.2982\n",
      "684\n",
      "0.09963869433589574  ,  0.6026  ,  0.8284\n",
      "0.06603535166647842  ,  0.4318  ,  0.9777\n",
      "0.1974795369701178  ,  0.4421  ,  0.9644\n",
      "685\n",
      "0.03304959112996322  ,  0.4486  ,  1.0908\n",
      "-0.03761931700114672  ,  0.4614  ,  1.078\n",
      "-0.08491605820362515  ,  0.4786  ,  1.0536\n",
      "686\n",
      "0.27210511719528446  ,  0.7372  ,  1.284\n",
      "-0.0183601392137527  ,  0.8648  ,  1.0499\n",
      "0.047417345855388364  ,  0.8621  ,  1.0539\n",
      "687\n",
      "0.26294533286623945  ,  1.4092  ,  1.5892\n",
      "-0.12233917066168236  ,  1.5018  ,  1.5225\n",
      "0.3072888375324442  ,  1.505  ,  1.5571\n",
      "688\n",
      "0.2839729677861973  ,  0.8502  ,  1.2646\n",
      "0.02739415648683978  ,  0.9868  ,  1.0013\n",
      "-0.2919490238068958  ,  0.9806  ,  1.0188\n",
      "689\n",
      "0.14213988696059957  ,  1.6966  ,  1.3387\n",
      "-0.0050048873270021246  ,  0.526  ,  1.1493\n",
      "nan  ,  0.526  ,  1.1493\n",
      "690\n",
      "0.1700175711281321  ,  0.4885  ,  1.2296\n",
      "-0.0043118261580729015  ,  0.4915  ,  1.2401\n",
      "nan  ,  0.4915  ,  1.2401\n",
      "691\n",
      "0.18514138222862206  ,  0.5443  ,  1.0995\n",
      "-0.07887641024845499  ,  0.7047  ,  0.9987\n",
      "-0.03048060364706745  ,  0.609  ,  1.0758\n",
      "692\n",
      "0.13834845130566523  ,  0.7468  ,  1.3334\n",
      "-0.24717719141775404  ,  0.7946  ,  1.2651\n",
      "0.28163428147769565  ,  0.7699  ,  1.2855\n",
      "693\n",
      "0.20291181291798255  ,  0.3248  ,  0.9283\n",
      "nan  ,  0.3157  ,  0.9632\n",
      "nan  ,  0.3157  ,  0.9632\n",
      "694\n",
      "0.2858545017273979  ,  0.898  ,  1.2188\n",
      "0.12431915253150376  ,  0.9379  ,  1.2183\n",
      "0.18909277764487206  ,  0.9407  ,  1.2061\n",
      "695\n",
      "0.15683420275881624  ,  0.6346  ,  1.1959\n",
      "-8.298132461724648e-05  ,  0.723  ,  1.0812\n",
      "0.033763916792972304  ,  0.727  ,  1.0771\n",
      "696\n",
      "0.322036661108401  ,  0.8051  ,  1.0544\n",
      "0.09415088623284146  ,  0.7873  ,  1.2725\n",
      "-0.05014681037295536  ,  0.8178  ,  1.2195\n",
      "697\n",
      "0.03686239685516714  ,  1.8756  ,  1.6779\n",
      "nan  ,  0.3362  ,  1.1518\n",
      "nan  ,  0.3362  ,  1.1518\n",
      "698\n",
      "0.10868261629736306  ,  0.5212  ,  1.2601\n",
      "-0.1315874425284657  ,  0.5508  ,  1.2438\n",
      "nan  ,  0.522  ,  1.2622\n",
      "699\n",
      "0.050173670392646794  ,  0.5289  ,  1.2376\n",
      "-0.0021854717373177603  ,  0.7148  ,  1.0249\n",
      "-0.016350315824244267  ,  0.6534  ,  1.0869\n",
      "700\n",
      "0.1125269465679796  ,  0.3581  ,  1.0484\n",
      "-0.07368236626222052  ,  0.4609  ,  0.9801\n",
      "0.06146508118159938  ,  0.5087  ,  0.9401\n",
      "701\n",
      "0.29780599190961726  ,  0.8811  ,  1.1666\n",
      "0.01605375534037132  ,  0.9565  ,  1.161\n",
      "0.011952340126643077  ,  0.9596  ,  1.1497\n",
      "702\n",
      "0.014622987380649911  ,  0.2089  ,  0.9756\n",
      "-0.024553977499288934  ,  0.2126  ,  0.9747\n",
      "-0.02074257087800087  ,  0.2443  ,  0.9591\n",
      "703\n",
      "0.028025265620024553  ,  0.6046  ,  1.3271\n",
      "nan  ,  0.6046  ,  1.3289\n",
      "nan  ,  0.6046  ,  1.3289\n",
      "704\n",
      "0.10338560379057554  ,  1.1897  ,  1.4665\n",
      "nan  ,  1.191  ,  1.4689\n",
      "nan  ,  1.191  ,  1.4689\n",
      "705\n",
      "0.6344512832221874  ,  0.5389  ,  0.8184\n",
      "-0.014416554326074301  ,  0.6677  ,  1.2442\n",
      "nan  ,  0.6675  ,  1.2446\n",
      "706\n",
      "0.4717084710832738  ,  1.1515  ,  1.6387\n",
      "-0.07143829681150188  ,  1.2503  ,  1.9621\n",
      "nan  ,  1.2497  ,  1.9638\n",
      "707\n",
      "0.41275695554597125  ,  0.8025  ,  1.6051\n",
      "-0.003254762717435798  ,  0.8223  ,  1.6726\n",
      "nan  ,  0.822  ,  1.673\n",
      "708\n",
      "0.19765415856762147  ,  0.8666  ,  1.0621\n",
      "nan  ,  0.6219  ,  1.3491\n",
      "nan  ,  0.6219  ,  1.3491\n",
      "709\n",
      "0.08633212256562017  ,  0.5871  ,  0.8693\n",
      "0.09661060488327328  ,  0.5669  ,  0.8148\n",
      "0.04933132711387535  ,  0.5732  ,  0.8184\n",
      "710\n",
      "0.03231120031733661  ,  0.7644  ,  1.1135\n",
      "0.1750035598920841  ,  0.4751  ,  1.0732\n",
      "0.08527692159636423  ,  0.5534  ,  1.0179\n",
      "711\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "712\n",
      "0.3424879435766015  ,  1.0606  ,  0.9314\n",
      "0.023831913185848028  ,  1.2858  ,  1.4482\n",
      "nan  ,  1.2859  ,  1.4483\n",
      "713\n",
      "0.2228049231636352  ,  0.9791  ,  1.3237\n",
      "0.08610958738833399  ,  1.1062  ,  1.0486\n",
      "-0.40391638598251295  ,  1.115  ,  1.0356\n",
      "714\n",
      "0.4152541055295664  ,  0.9838  ,  1.3118\n",
      "-0.007157080845886385  ,  1.1045  ,  1.679\n",
      "nan  ,  1.1045  ,  1.679\n",
      "715\n",
      "0.016883232383456508  ,  0.9056  ,  1.5943\n",
      "0.26948025457403413  ,  1.01  ,  1.2956\n",
      "-0.22711529436313901  ,  1.0453  ,  1.2748\n",
      "716\n",
      "0.20481624070833132  ,  0.8292  ,  1.5054\n",
      "-0.02380105858510059  ,  0.8924  ,  1.4485\n",
      "-0.08775086046506597  ,  0.895  ,  1.4419\n",
      "717\n",
      "-0.01502332630961748  ,  0.5803  ,  1.1068\n",
      "-0.02149652602434747  ,  0.6309  ,  0.9999\n",
      "0.03507151956265786  ,  0.6311  ,  0.9963\n",
      "718\n",
      "0.08068324707464168  ,  0.4616  ,  1.1955\n",
      "0.09971187591857444  ,  0.6058  ,  1.059\n",
      "0.013693520411414634  ,  0.5778  ,  1.0896\n",
      "719\n",
      "-0.026535416394060134  ,  1.1326  ,  1.471\n",
      "nan  ,  1.1323  ,  1.4711\n",
      "nan  ,  1.1323  ,  1.4711\n",
      "720\n",
      "0.22028231191023961  ,  0.9681  ,  1.4013\n",
      "-0.022259200540788098  ,  1.0105  ,  1.3835\n",
      "-0.1087769503025675  ,  1.0073  ,  1.3914\n",
      "721\n",
      "0.12638591817600536  ,  1.1057  ,  1.5237\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "722\n",
      "0.525460818359717  ,  0.4424  ,  1.447\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "723\n",
      "0.029688727298172582  ,  0.7584  ,  1.3647\n",
      "0.11302011556404493  ,  0.7764  ,  1.293\n",
      "0.019890651956015172  ,  0.7774  ,  1.3058\n",
      "724\n",
      "0.0738767673809869  ,  0.7665  ,  1.3129\n",
      "0.009174177441188768  ,  0.8073  ,  1.1958\n",
      "-0.03131213763906411  ,  0.827  ,  1.149\n",
      "725\n",
      "0.06322438860265416  ,  1.1555  ,  0.9978\n",
      "0.18543882556090663  ,  0.6865  ,  1.0842\n",
      "-0.08414439260744415  ,  0.6997  ,  1.0877\n",
      "726\n",
      "0.4512186863884404  ,  0.4606  ,  1.5396\n",
      "-0.01012560080135976  ,  0.4647  ,  1.5586\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "727\n",
      "0.5138250381381307  ,  0.5012  ,  1.1523\n",
      "0.07159857924951604  ,  0.6558  ,  1.1348\n",
      "nan  ,  0.5337  ,  1.277\n",
      "728\n",
      "0.02307613411078201  ,  0.7449  ,  1.4044\n",
      "-0.06273377718363177  ,  0.7672  ,  1.3622\n",
      "0.011626073977208724  ,  0.8183  ,  1.2493\n",
      "729\n",
      "nan  ,  0.6408  ,  1.0592\n",
      "0.07729369588992926  ,  0.6417  ,  1.0515\n",
      "nan  ,  0.6408  ,  1.0592\n",
      "730\n",
      "0.009219614528294246  ,  0.4941  ,  1.3617\n",
      "-0.07552977811118725  ,  0.4942  ,  1.3632\n",
      "0.008201600700550631  ,  0.5159  ,  1.3387\n",
      "731\n",
      "0.31933396968586614  ,  0.7752  ,  1.3728\n",
      "-0.08202616435465042  ,  0.8683  ,  1.3001\n",
      "-0.03578746976344539  ,  0.8783  ,  1.2515\n",
      "732\n",
      "0.11956557201748057  ,  0.7746  ,  1.4052\n",
      "-0.006816268539083651  ,  0.7776  ,  1.4013\n",
      "-0.04287876052118672  ,  0.7778  ,  1.3991\n",
      "733\n",
      "0.03254941737189495  ,  0.5225  ,  1.0953\n",
      "-0.018173380319362775  ,  0.4976  ,  1.0137\n",
      "0.02281007549871153  ,  0.4507  ,  1.0417\n",
      "734\n",
      "0.06749029694615853  ,  1.6933  ,  1.1815\n",
      "0.2909068188768029  ,  1.181  ,  1.4094\n",
      "0.4385981065437422  ,  1.1711  ,  1.3767\n",
      "735\n",
      "0.07205402202871766  ,  0.2366  ,  0.7079\n",
      "-0.030549456466660553  ,  0.1505  ,  0.6883\n",
      "0.06746843993292773  ,  0.1516  ,  0.6867\n",
      "736\n",
      "0.028835277961433127  ,  1.1892  ,  1.1923\n",
      "-0.10323981671944368  ,  0.7484  ,  1.2835\n",
      "nan  ,  0.7432  ,  1.2892\n",
      "737\n",
      "0.46292620152820896  ,  0.7309  ,  1.5762\n",
      "0.0009543806498957816  ,  0.765  ,  1.6857\n",
      "nan  ,  0.765  ,  1.6857\n",
      "738\n",
      "0.443695664872927  ,  1.0019  ,  1.3075\n",
      "0.01143425120209624  ,  1.0529  ,  1.3793\n",
      "nan  ,  1.0551  ,  1.3859\n",
      "739\n",
      "0.0032439063906887717  ,  0.577  ,  1.3513\n",
      "-0.03072442851708348  ,  0.5779  ,  1.3505\n",
      "0.02099560588592398  ,  0.6502  ,  1.2556\n",
      "740\n",
      "0.32006710746433625  ,  0.8518  ,  1.3638\n",
      "0.07904881424487113  ,  0.8785  ,  1.5609\n",
      "-0.0687616871737571  ,  0.8757  ,  1.5778\n",
      "741\n",
      "0.020596531386424772  ,  0.7287  ,  1.4792\n",
      "-0.007103135657899827  ,  0.7287  ,  1.4792\n",
      "nan  ,  0.7287  ,  1.4792\n",
      "742\n",
      "0.12199570733079114  ,  0.6478  ,  1.3387\n",
      "-0.07885257317795194  ,  0.6597  ,  1.3514\n",
      "nan  ,  0.6517  ,  1.3606\n",
      "743\n",
      "0.16483115676940763  ,  0.9445  ,  1.4025\n",
      "-0.004959911104875751  ,  0.9508  ,  1.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04947512213668587  ,  0.9499  ,  1.3961\n",
      "744\n",
      "0.2636988967857514  ,  0.9314  ,  1.2239\n",
      "0.0603984626130206  ,  0.9641  ,  1.1066\n",
      "-0.04315937467363763  ,  0.9655  ,  1.1425\n",
      "745\n",
      "0.28743456822623337  ,  0.4982  ,  1.1613\n",
      "-0.1006350140914144  ,  0.6005  ,  1.1343\n",
      "-0.05530750511604169  ,  0.5666  ,  1.1571\n",
      "746\n",
      "-0.010532802090489332  ,  0.9241  ,  1.3958\n",
      "-0.007198008019062044  ,  0.9238  ,  1.3964\n",
      "nan  ,  0.9238  ,  1.3964\n",
      "747\n",
      "0.034015087171371194  ,  0.4355  ,  1.0856\n",
      "-0.024109484036579868  ,  0.4768  ,  1.0426\n",
      "-0.028556570206180867  ,  0.4847  ,  1.0336\n",
      "748\n",
      "-0.04125949472883166  ,  0.8383  ,  0.8771\n",
      "0.0015306645832980428  ,  0.6409  ,  1.051\n",
      "0.08626925924485274  ,  0.6348  ,  1.0698\n",
      "749\n",
      "0.18320033646701558  ,  0.9415  ,  1.053\n",
      "0.08501294655596692  ,  0.9127  ,  1.2586\n",
      "-0.15308882743386126  ,  0.9166  ,  1.2603\n",
      "750\n",
      "0.5890631977432914  ,  1.0977  ,  1.4449\n",
      "nan  ,  1.2599  ,  1.7359\n",
      "nan  ,  1.2599  ,  1.7359\n",
      "751\n",
      "0.18532208286912993  ,  1.6049  ,  1.3292\n",
      "0.013230776158581991  ,  0.4876  ,  0.7981\n",
      "0.007351861453067246  ,  0.4421  ,  0.8207\n",
      "752\n",
      "0.2661929566452981  ,  0.3426  ,  0.9088\n",
      "nan  ,  0.2766  ,  0.9737\n",
      "nan  ,  0.2766  ,  0.9737\n",
      "753\n",
      "-0.0006145244182153911  ,  1.0081  ,  0.9811\n",
      "-0.14206084086225113  ,  0.9551  ,  1.1196\n",
      "-0.1560267409672677  ,  0.9423  ,  1.1931\n",
      "754\n",
      "-0.011562915571669309  ,  0.8034  ,  1.2528\n",
      "-0.01248914347668523  ,  0.8054  ,  1.2461\n",
      "nan  ,  0.8034  ,  1.2534\n",
      "755\n",
      "nan  ,  0.6401  ,  1.2414\n",
      "0.1439690951832193  ,  0.6397  ,  1.2398\n",
      "nan  ,  0.6401  ,  1.2414\n",
      "756\n",
      "0.33607396692282354  ,  0.6055  ,  1.3491\n",
      "-0.021618005543396785  ,  0.7297  ,  1.3018\n",
      "nan  ,  0.6142  ,  1.4292\n",
      "757\n",
      "0.0359966778976304  ,  1.1366  ,  1.6476\n",
      "0.025873846345288276  ,  1.1373  ,  1.648\n",
      "nan  ,  1.1373  ,  1.6481\n",
      "758\n",
      "0.16614789261194243  ,  1.1339  ,  0.738\n",
      "0.15743832039328995  ,  0.9207  ,  0.8481\n",
      "-0.017472111041526284  ,  0.9116  ,  0.8811\n",
      "759\n",
      "0.47404767021383676  ,  1.0659  ,  1.5341\n",
      "0.25663109922931227  ,  1.137  ,  1.6395\n",
      "0.16906911831358928  ,  1.1433  ,  1.6336\n",
      "760\n",
      "0.2062786156081991  ,  0.4985  ,  1.3296\n",
      "-0.004490220665392888  ,  0.5418  ,  1.2928\n",
      "0.022934248822660205  ,  0.5374  ,  1.2976\n",
      "761\n",
      "0.17525422357438364  ,  0.7464  ,  1.2334\n",
      "-0.1188017851716944  ,  0.7503  ,  1.3285\n",
      "0.021497978127144244  ,  0.7751  ,  1.2509\n",
      "762\n",
      "0.4787707706755853  ,  0.7672  ,  0.8229\n",
      "-0.19409575864833803  ,  0.9591  ,  1.1779\n",
      "-0.041994344691984646  ,  0.9387  ,  1.1327\n",
      "763\n",
      "0.34131266078241845  ,  1.0544  ,  1.364\n",
      "0.0460066948868116  ,  1.0971  ,  1.4445\n",
      "-0.05202238838424161  ,  1.0954  ,  1.4299\n",
      "764\n",
      "0.2618406593259529  ,  0.9668  ,  1.2102\n",
      "-0.1084676705215123  ,  0.994  ,  1.4454\n",
      "0.028429560230268467  ,  0.9946  ,  1.4326\n",
      "765\n",
      "0.06511385415078953  ,  0.3925  ,  1.0832\n",
      "0.1222645111308249  ,  0.3925  ,  1.0831\n",
      "nan  ,  0.3926  ,  1.0833\n",
      "766\n",
      "0.0534230806279013  ,  0.417  ,  1.1384\n",
      "0.044989975669574744  ,  0.5267  ,  1.0347\n",
      "0.008938985264126597  ,  0.5696  ,  1.0015\n",
      "767\n",
      "0.11846277927919927  ,  0.3744  ,  0.7936\n",
      "-0.016640408538698196  ,  0.2672  ,  0.7462\n",
      "-0.03492784597696802  ,  0.4001  ,  0.6775\n",
      "768\n",
      "0.13747370186802363  ,  0.8273  ,  1.7394\n",
      "nan  ,  0.83  ,  1.7606\n",
      "nan  ,  0.83  ,  1.7606\n",
      "769\n",
      "0.29325526296976695  ,  1.1167  ,  1.0043\n",
      "0.09795283442494679  ,  1.1881  ,  1.4847\n",
      "-0.03593754972061718  ,  1.19  ,  1.4958\n",
      "770\n",
      "0.07742285109010473  ,  0.6637  ,  1.3139\n",
      "nan  ,  0.6643  ,  1.3178\n",
      "nan  ,  0.6643  ,  1.3178\n",
      "771\n",
      "0.024033551671177333  ,  0.8272  ,  1.423\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "772\n",
      "0.4305827140919835  ,  1.3253  ,  1.3685\n",
      "-0.01232771010329151  ,  1.4279  ,  1.5093\n",
      "0.1061403735968835  ,  1.1132  ,  1.8341\n",
      "773\n",
      "0.17757992715322993  ,  0.9807  ,  1.7226\n",
      "0.07934943191842757  ,  1.0069  ,  1.7144\n",
      "-0.013252621320604912  ,  0.9919  ,  1.7654\n",
      "774\n",
      "0.011553500873604777  ,  0.6495  ,  1.3202\n",
      "0.022488959553394316  ,  0.709  ,  1.2105\n",
      "-0.020984683826245028  ,  0.721  ,  1.1924\n",
      "775\n",
      "-0.016506521166502752  ,  1.0337  ,  1.7049\n",
      "776\n",
      "0.13237278016084786  ,  1.336  ,  1.7916\n",
      "-0.11045679171470153  ,  1.3122  ,  1.7144\n",
      "0.13968248812367207  ,  1.3223  ,  1.762\n",
      "777\n",
      "778\n",
      "0.252415339238706  ,  0.7175  ,  1.0474\n",
      "-0.0456576439099536  ,  0.756  ,  1.0934\n",
      "-0.20791494452081719  ,  0.7565  ,  1.0892\n",
      "779\n",
      "780\n",
      "0.4436270626852461  ,  0.8432  ,  0.8732\n",
      "nan  ,  0.7059  ,  1.3333\n",
      "nan  ,  0.7059  ,  1.3333\n",
      "781\n",
      "782\n",
      "0.28215361776923975  ,  0.8601  ,  1.5311\n",
      "-0.019320038616262455  ,  0.8824  ,  1.5807\n",
      "-0.05130503138926511  ,  0.887  ,  1.5665\n",
      "783\n",
      "784\n",
      "0.21951883769015113  ,  0.9358  ,  1.4074\n",
      "0.0036375649964747424  ,  1.0477  ,  1.1488\n",
      "-0.34888754449983084  ,  1.0424  ,  1.1642\n",
      "785\n",
      "786\n",
      "0.18332282173588776  ,  0.7587  ,  1.2665\n",
      "0.1835430242998053  ,  0.7933  ,  1.1372\n",
      "-0.16754060775822335  ,  0.8203  ,  1.0985\n",
      "787\n",
      "788\n",
      "-0.011141010128801894  ,  0.6158  ,  1.4388\n",
      "-0.08686410265953415  ,  0.6622  ,  1.3774\n",
      "0.042399398503550643  ,  0.6753  ,  1.3564\n",
      "789\n",
      "790\n",
      "0.027937007769917456  ,  0.5549  ,  0.9921\n",
      "0.06924682643986191  ,  0.232  ,  0.8844\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "791\n",
      "792\n",
      "0.27911506913960593  ,  0.628  ,  1.1813\n",
      "-0.011517425746627782  ,  0.7052  ,  1.1853\n",
      "-0.04236615619304734  ,  0.684  ,  1.2125\n",
      "793\n",
      "794\n",
      "0.05427928691496945  ,  0.7355  ,  1.1951\n",
      "-0.05899970489711533  ,  0.6272  ,  1.0448\n",
      "-0.01868788889969805  ,  0.5751  ,  1.0789\n",
      "795\n",
      "796\n",
      "0.19279698452585609  ,  1.1538  ,  0.9775\n",
      "nan  ,  0.828  ,  1.4744\n",
      "nan  ,  0.828  ,  1.4744\n",
      "797\n",
      "798\n",
      "0.39644306922750355  ,  0.9867  ,  1.5457\n",
      "0.31833294215119207  ,  1.0001  ,  1.472\n",
      "-0.059854103998344635  ,  1.0052  ,  1.5047\n",
      "799\n",
      "800\n",
      "0.2806094281928192  ,  0.7381  ,  1.2257\n",
      "-0.11889704214815683  ,  0.8696  ,  1.0101\n",
      "-0.07767962411598381  ,  0.8534  ,  1.0314\n",
      "801\n",
      "802\n",
      "0.12469173190049818  ,  0.4963  ,  0.94\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "803\n",
      "804\n",
      "0.11485447374421491  ,  0.7725  ,  1.316\n",
      "0.09123840748694055  ,  0.8002  ,  1.2473\n",
      "0.1491953556337853  ,  0.7971  ,  1.2683\n",
      "805\n",
      "806\n",
      "0.07028438729361193  ,  0.5315  ,  1.2715\n",
      "0.006548773891284405  ,  0.6674  ,  1.1131\n",
      "-0.034461588040801634  ,  0.6675  ,  1.1139\n",
      "807\n",
      "808\n",
      "0.014937943928802133  ,  0.8412  ,  1.5434\n",
      "-0.0694914427821719  ,  0.8698  ,  1.4882\n",
      "nan  ,  0.8413  ,  1.5434\n",
      "809\n",
      "810\n",
      "0.03799985254285441  ,  0.5775  ,  1.1208\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "811\n",
      "812\n",
      "0.027431847864764162  ,  0.5946  ,  0.96\n",
      "-0.010983844267918402  ,  0.6628  ,  0.805\n",
      "-0.07273720851656204  ,  0.5935  ,  0.8845\n",
      "813\n",
      "814\n",
      "0.0014534440624374917  ,  0.9317  ,  1.6161\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "815\n",
      "816\n",
      "0.02846251456582786  ,  0.6346  ,  1.4282\n",
      "-0.08881260855672742  ,  0.7075  ,  1.3506\n",
      "-0.0322363104031194  ,  0.6165  ,  1.4348\n",
      "817\n",
      "818\n",
      "0.1648000350959875  ,  1.9758  ,  1.0667\n",
      "0.030867272711092804  ,  0.5617  ,  0.8187\n",
      "-0.06024671307316647  ,  0.5169  ,  0.8615\n",
      "819\n",
      "820\n",
      "0.1289391253240869  ,  0.4421  ,  1.1279\n",
      "-0.11007762210667792  ,  0.569  ,  1.023\n",
      "0.025898441674860256  ,  0.5956  ,  0.9809\n",
      "821\n",
      "822\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "823\n",
      "824\n",
      "0.3215257048258192  ,  0.7999  ,  1.1879\n",
      "0.09530887801789861  ,  0.8294  ,  1.3379\n",
      "0.05427671171634615  ,  0.8176  ,  1.3877\n",
      "825\n",
      "826\n",
      "0.4237661363300121  ,  0.5945  ,  1.4556\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "827\n",
      "828\n",
      "0.4293858143523659  ,  0.6956  ,  1.5964\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "829\n",
      "830\n",
      "0.36045518050895187  ,  0.9557  ,  0.9015\n",
      "-0.11322324669924008  ,  1.0211  ,  1.4021\n",
      "nan  ,  1.0213  ,  1.4041\n",
      "831\n",
      "832\n",
      "0.10778627084719998  ,  2.4964  ,  2.1717\n",
      "0.08308877221834277  ,  0.3269  ,  0.8603\n",
      "0.21240667013643494  ,  0.3878  ,  0.8252\n",
      "833\n",
      "834\n",
      "0.010967675034256129  ,  0.6051  ,  1.1647\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "835\n",
      "836\n",
      "-0.009012855622355348  ,  0.8611  ,  1.4233\n",
      "-0.03802913834349604  ,  0.9005  ,  1.3223\n",
      "-0.035780109965117934  ,  0.8803  ,  1.3696\n",
      "837\n",
      "838\n",
      "0.05040846574115026  ,  0.5518  ,  1.1679\n",
      "0.07536726751745423  ,  0.5541  ,  1.1001\n",
      "0.019148655094999408  ,  0.5051  ,  1.1575\n",
      "839\n",
      "840\n",
      "0.05052294476077389  ,  0.5366  ,  1.1593\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "841\n",
      "842\n",
      "0.08505300930226203  ,  0.4978  ,  1.1566\n",
      "0.11735462587623462  ,  0.5379  ,  1.1018\n",
      "-0.03544455611824005  ,  0.5611  ,  1.0857\n",
      "843\n",
      "844\n",
      "0.11349550351255402  ,  1.2621  ,  1.1953\n",
      "0.05006714144123512  ,  0.8375  ,  1.5919\n",
      "nan  ,  0.8372  ,  1.5933\n",
      "845\n",
      "846\n",
      "0.15465586499121564  ,  0.9985  ,  0.8307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07181334426873306  ,  0.6389  ,  1.0869\n",
      "-0.0217984700383929  ,  0.6374  ,  1.0918\n",
      "847\n",
      "848\n",
      "0.2604492650517052  ,  0.429  ,  1.2118\n",
      "-0.00572244520536957  ,  0.3714  ,  1.3116\n",
      "nan  ,  0.3713  ,  1.3116\n",
      "849\n",
      "850\n",
      "-0.03329450329410796  ,  0.6265  ,  1.0605\n",
      "-0.03195005226822101  ,  0.5802  ,  1.0904\n",
      "0.0286585311626782  ,  0.5896  ,  1.0623\n",
      "851\n",
      "852\n",
      "0.13272894568345603  ,  0.6841  ,  1.0972\n",
      "-0.05851901592410131  ,  0.6049  ,  1.1082\n",
      "-0.012943557339128678  ,  0.6643  ,  1.0605\n",
      "853\n",
      "854\n",
      "0.5283998291914382  ,  0.6186  ,  1.6058\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "855\n",
      "856\n",
      "0.3496442919766116  ,  0.7711  ,  1.0941\n",
      "0.06457149859037462  ,  0.8099  ,  1.1936\n",
      "0.14856318026992124  ,  0.8063  ,  1.1619\n",
      "857\n",
      "858\n",
      "0.18075373074992282  ,  0.7545  ,  1.4868\n",
      "0.07446035822024644  ,  0.774  ,  1.4458\n",
      "0.11648499797668446  ,  0.7738  ,  1.4496\n",
      "859\n",
      "860\n",
      "0.49800960963061897  ,  0.582  ,  1.505\n",
      "-0.006899299762771255  ,  0.6122  ,  1.5665\n",
      "0.05838895486398485  ,  0.6193  ,  1.5578\n",
      "861\n",
      "862\n",
      "0.22438722192664495  ,  0.5236  ,  1.1953\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "863\n",
      "864\n",
      "0.02554389545055164  ,  0.8513  ,  1.5592\n",
      "0.09826971507473009  ,  0.8935  ,  1.4374\n",
      "-0.014120475335702536  ,  0.8935  ,  1.4444\n",
      "865\n",
      "866\n",
      "0.10820625569106619  ,  0.4352  ,  1.0036\n",
      "0.05990881104989332  ,  0.4328  ,  1.0176\n",
      "0.19271291474536834  ,  0.444  ,  1.0042\n",
      "867\n",
      "868\n",
      "0.38363750420878084  ,  0.9993  ,  1.3052\n",
      "0.066591863451616  ,  1.1339  ,  1.3329\n",
      "-0.6858476616900899  ,  1.1303  ,  1.341\n",
      "869\n",
      "870\n",
      "0.18685167144524745  ,  1.0332  ,  1.5149\n",
      "0.1060207600945043  ,  1.0406  ,  1.3638\n",
      "0.31897572254453643  ,  1.0588  ,  1.2687\n",
      "871\n",
      "872\n",
      "0.11749127535919744  ,  1.045  ,  1.5789\n",
      "0.21110380261794812  ,  1.0521  ,  1.6611\n",
      "0.2221903200808257  ,  1.0605  ,  1.6451\n",
      "873\n",
      "874\n",
      "0.32221955215290327  ,  0.5719  ,  1.1466\n",
      "0.07695422843891084  ,  0.586  ,  1.2261\n",
      "nan  ,  0.586  ,  1.2262\n",
      "875\n",
      "876\n",
      "0.27396372983528067  ,  0.5568  ,  1.067\n",
      "0.04314363160849057  ,  0.4787  ,  1.2098\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "877\n",
      "878\n",
      "0.2917655237869291  ,  0.9345  ,  1.2039\n",
      "0.002522816808668682  ,  0.9607  ,  1.3292\n",
      "0.00837093777250644  ,  0.971  ,  1.3075\n",
      "879\n",
      "880\n",
      "0.3430060002073494  ,  2.3782  ,  1.7554\n",
      "-0.02558338615238657  ,  0.8199  ,  1.5161\n",
      "0.037910792642037325  ,  0.8262  ,  1.4936\n",
      "881\n",
      "882\n",
      "0.31266054956725203  ,  1.211  ,  0.8938\n",
      "-0.036135444373779226  ,  1.0353  ,  1.4075\n",
      "0.03411421403987518  ,  1.0366  ,  1.3935\n",
      "883\n",
      "884\n",
      "0.035446349191267275  ,  0.7992  ,  1.2184\n",
      "-0.08190797183841299  ,  0.8294  ,  1.0548\n",
      "-0.11470366543028163  ,  0.815  ,  1.0994\n",
      "885\n",
      "886\n",
      "0.2841961503250636  ,  0.9611  ,  1.2477\n",
      "0.1061133387950087  ,  1.0204  ,  1.3304\n",
      "0.08028900753353259  ,  1.0319  ,  1.4319\n",
      "887\n",
      "888\n",
      "0.18992707091771105  ,  0.7392  ,  1.3035\n",
      "0.051157607999809715  ,  0.7724  ,  1.2849\n",
      "-0.019394055450764763  ,  0.7762  ,  1.2823\n",
      "889\n",
      "890\n",
      "0.03310730535269756  ,  0.9298  ,  1.8266\n",
      "-0.11784432985918636  ,  1.0503  ,  1.6485\n",
      "0.09246829239918095  ,  0.948  ,  1.8001\n",
      "891\n",
      "892\n",
      "0.09977424850079655  ,  0.68  ,  1.4357\n",
      "0.008323181338014183  ,  0.7467  ,  1.3433\n",
      "-0.07881117084307959  ,  0.7918  ,  1.2823\n",
      "893\n",
      "894\n",
      "-0.07799426691430016  ,  1.1631  ,  1.4285\n",
      "0.12929921014223766  ,  1.1132  ,  1.3151\n",
      "-0.11212593845265856  ,  1.1072  ,  1.2829\n",
      "895\n",
      "896\n",
      "0.45540291107598035  ,  0.1949  ,  0.866\n",
      "nan  ,  0.2069  ,  0.9251\n",
      "-0.04954417709429439  ,  0.2362  ,  0.9106\n",
      "897\n",
      "898\n",
      "0.05315829966749741  ,  0.52  ,  0.5708\n",
      "-0.17135912057191433  ,  0.3417  ,  0.6081\n",
      "-0.042885743826098686  ,  0.3514  ,  0.5886\n",
      "899\n",
      "900\n",
      "-0.010870405888406064  ,  0.353  ,  0.9716\n",
      "0.050111261047433395  ,  0.4142  ,  0.9098\n",
      "0.026885264304232923  ,  0.4399  ,  0.8884\n",
      "901\n",
      "902\n",
      "nan  ,  0.1898  ,  0.7118\n",
      "0.05120661702327314  ,  0.4371  ,  0.5759\n",
      "0.021711004746960687  ,  0.2469  ,  0.6772\n",
      "903\n",
      "904\n",
      "0.1641176639408864  ,  0.2203  ,  0.7123\n",
      "0.04096793317340556  ,  0.2425  ,  0.7004\n",
      "-0.021812963130409327  ,  0.2957  ,  0.6625\n",
      "905\n",
      "906\n",
      "0.08423841474873961  ,  0.3078  ,  0.6614\n",
      "0.022947018383113322  ,  0.3035  ,  0.6286\n",
      "0.0750523181381812  ,  0.2472  ,  0.6706\n",
      "907\n",
      "908\n",
      "0.33441760311575514  ,  0.8358  ,  0.4872\n",
      "0.007448416645631791  ,  0.4034  ,  0.4271\n",
      "-0.01877718705215107  ,  0.319  ,  0.4671\n",
      "909\n",
      "910\n",
      "-0.029150902151943478  ,  0.4566  ,  0.5862\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "911\n",
      "912\n",
      "-0.0798253135817488  ,  0.4861  ,  0.8484\n",
      "0.03927177843162459  ,  0.6788  ,  0.6184\n",
      "-0.052285448003060085  ,  0.7093  ,  0.6015\n",
      "913\n",
      "914\n",
      "-0.013006878502944717  ,  0.2216  ,  0.7789\n",
      "nan  ,  0.2208  ,  0.779\n",
      "nan  ,  0.2208  ,  0.779\n",
      "915\n",
      "916\n",
      "0.07148080647638959  ,  0.5952  ,  0.6554\n",
      "0.07523624820034132  ,  0.2656  ,  0.6934\n",
      "-0.02774536062321156  ,  0.3055  ,  0.6652\n",
      "917\n",
      "918\n",
      "0.20763432028430717  ,  0.6231  ,  0.3476\n",
      "-0.08177791600489306  ,  1.0005  ,  0.3005\n",
      "-0.003837475914734968  ,  0.9102  ,  0.2781\n",
      "919\n",
      "920\n",
      "-0.08062187540925989  ,  0.8073  ,  0.7432\n",
      "0.11059958126528383  ,  0.694  ,  0.7069\n",
      "0.01203940628060602  ,  0.6547  ,  0.7485\n",
      "921\n",
      "922\n",
      "0.09986170065139462  ,  0.3065  ,  0.8933\n",
      "0.09933520488582626  ,  0.3661  ,  0.8405\n",
      "0.016071238917077325  ,  0.3424  ,  0.8625\n",
      "923\n",
      "924\n",
      "0.10193326669890938  ,  0.1832  ,  0.6706\n",
      "-0.05983496537821358  ,  0.309  ,  0.6128\n",
      "-0.019385316576544694  ,  0.2719  ,  0.6292\n",
      "925\n",
      "926\n",
      "0.05152729422182512  ,  0.9214  ,  0.9336\n",
      "0.016600230030656103  ,  0.2627  ,  0.7501\n",
      "-0.05345535760533701  ,  0.2447  ,  0.7584\n",
      "927\n",
      "928\n",
      "0.06158178842782758  ,  0.3026  ,  0.8412\n",
      "0.1802611294971258  ,  0.3003  ,  0.8453\n",
      "-0.03816485599579603  ,  0.3046  ,  0.8412\n",
      "929\n",
      "930\n",
      "0.13108679451744687  ,  3.095  ,  1.5192\n",
      "0.0161952953953458  ,  0.3264  ,  0.8655\n",
      "0.03515592302392821  ,  0.3583  ,  0.8459\n",
      "931\n",
      "932\n",
      "0.19898432475722538  ,  0.7907  ,  0.6307\n",
      "0.06389492249915919  ,  0.4711  ,  0.7684\n",
      "-0.0034258064441714826  ,  0.3951  ,  0.8513\n",
      "933\n",
      "934\n",
      "-0.0035950238999080623  ,  0.2741  ,  0.8207\n",
      "0.012751854520601682  ,  0.3802  ,  0.7361\n",
      "-0.00630184117275473  ,  0.4312  ,  0.7001\n",
      "935\n",
      "936\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "937\n",
      "938\n",
      "0.20626976910092604  ,  0.4353  ,  1.083\n",
      "0.1573442869649772  ,  0.4759  ,  1.0427\n",
      "0.12556176648723594  ,  0.5045  ,  1.0148\n",
      "939\n",
      "940\n",
      "-0.02782320224118849  ,  1.5808  ,  0.8159\n",
      "0.0038577047497938347  ,  0.5018  ,  0.7834\n",
      "-0.021715495427256034  ,  0.4971  ,  0.7862\n",
      "941\n",
      "942\n",
      "nan  ,  0.3254  ,  1.012\n",
      "nan  ,  0.3254  ,  1.012\n",
      "nan  ,  0.3254  ,  1.012\n",
      "943\n",
      "944\n",
      "0.14394815392703847  ,  0.4996  ,  0.6395\n",
      "-0.04793327362522007  ,  0.4038  ,  0.7158\n",
      "-0.00787874794735876  ,  0.369  ,  0.7477\n",
      "945\n",
      "946\n",
      "0.18602027557452605  ,  0.368  ,  0.9091\n",
      "-0.10184230845624997  ,  0.4324  ,  0.8761\n",
      "0.04228597609140956  ,  0.4794  ,  0.8267\n",
      "947\n",
      "948\n",
      "0.1957494728908369  ,  0.6654  ,  0.6035\n",
      "0.1407993481390454  ,  0.5322  ,  0.705\n",
      "0.07343243668802155  ,  0.5576  ,  0.6817\n",
      "949\n",
      "950\n",
      "-0.0020157049774816834  ,  0.2588  ,  0.5149\n",
      "-0.021158438621838277  ,  0.5521  ,  0.2639\n",
      "0.016499766728734724  ,  0.5546  ,  0.263\n",
      "951\n",
      "952\n",
      "0.29106250585326277  ,  1.7857  ,  0.863\n",
      "0.1025433965218922  ,  0.5524  ,  0.9628\n",
      "-0.038917251622141484  ,  0.5493  ,  0.9665\n",
      "953\n",
      "954\n",
      "-0.045351612887290046  ,  0.5663  ,  1.1726\n",
      "-0.006465414053692453  ,  0.7097  ,  0.9595\n",
      "0.04322682030021313  ,  0.6823  ,  0.9925\n",
      "955\n",
      "956\n",
      "0.005940986881066699  ,  2.1518  ,  1.2926\n",
      "-0.07896500555716839  ,  0.3583  ,  0.4827\n",
      "-0.08560879306678391  ,  0.3012  ,  0.5256\n",
      "957\n",
      "958\n",
      "-0.005006054076742375  ,  0.2881  ,  0.7295\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "959\n",
      "960\n",
      "0.012340059616054652  ,  0.2364  ,  0.868\n",
      "-0.11058714384063514  ,  0.2558  ,  0.8544\n",
      "-0.04348683313386081  ,  0.2851  ,  0.8355\n",
      "961\n",
      "962\n",
      "0.08222350553233584  ,  1.3261  ,  1.0695\n",
      "-0.004544944600006287  ,  0.3054  ,  0.9341\n",
      "nan  ,  0.224  ,  0.9738\n",
      "963\n",
      "964\n",
      "0.317847357838864  ,  4.0103  ,  1.8411\n",
      "-0.14250262658222423  ,  0.5301  ,  0.8396\n",
      "-0.050104398321491356  ,  0.5127  ,  0.8527\n",
      "965\n",
      "966\n",
      "0.05209480894578089  ,  0.1209  ,  0.6711\n",
      "nan  ,  0.121  ,  0.6713\n",
      "nan  ,  0.121  ,  0.6713\n",
      "967\n",
      "968\n",
      "0.30368936182841877  ,  2.8307  ,  1.641\n",
      "0.21425185527153506  ,  0.2597  ,  0.7977\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "969\n",
      "970\n",
      "0.131745081022065  ,  0.2731  ,  0.6808\n",
      "0.03693491033221221  ,  0.4005  ,  0.5959\n",
      "0.035357964930772624  ,  0.5037  ,  0.5332\n",
      "971\n",
      "972\n",
      "0.7931763683013543  ,  0.2665  ,  0.6686\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "973\n",
      "974\n",
      "0.053131151835416335  ,  0.3008  ,  0.8572\n",
      "-0.156655136265328  ,  0.3149  ,  0.8491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08669936213376503  ,  0.3601  ,  0.8042\n",
      "975\n",
      "976\n",
      "0.19693029856172156  ,  1.0911  ,  0.7386\n",
      "nan  ,  0.2412  ,  0.7456\n",
      "nan  ,  0.2412  ,  0.7456\n",
      "977\n",
      "978\n",
      "0.27840674328872356  ,  0.3853  ,  0.5284\n",
      "-0.04152739876665724  ,  0.2118  ,  0.6235\n",
      "nan  ,  0.2112  ,  0.6239\n",
      "979\n",
      "980\n",
      "0.10134159432475659  ,  0.1079  ,  0.3833\n",
      "0.008687655279837891  ,  0.1395  ,  0.3669\n",
      "-0.020111551079092144  ,  0.1659  ,  0.3513\n",
      "981\n",
      "982\n",
      "-0.012541276228042703  ,  0.2837  ,  0.7794\n",
      "-0.10528099779941644  ,  0.6444  ,  0.5139\n",
      "-0.034084583610139586  ,  0.5588  ,  0.561\n",
      "983\n",
      "984\n",
      "-0.00477458281691138  ,  0.3409  ,  0.8786\n",
      "nan  ,  0.288  ,  0.8972\n",
      "nan  ,  0.288  ,  0.8972\n",
      "985\n",
      "986\n",
      "0.0368091536436542  ,  0.284  ,  0.7167\n",
      "-0.016908071017531563  ,  0.2035  ,  0.7327\n",
      "0.049077451727625745  ,  0.2114  ,  0.7275\n",
      "987\n",
      "988\n",
      "nan  ,  0.3431  ,  1.0153\n",
      "-0.05852063806537862  ,  0.3581  ,  1.0023\n",
      "0.004527209838928558  ,  0.3529  ,  1.0065\n",
      "989\n",
      "990\n",
      "0.018303751341755985  ,  0.2489  ,  0.7461\n",
      "nan  ,  0.2487  ,  0.7466\n",
      "-0.06528621506665874  ,  0.2578  ,  0.7388\n",
      "991\n",
      "992\n",
      "0.10098666097778533  ,  0.3761  ,  0.8505\n",
      "0.045266471736275724  ,  0.4716  ,  0.7561\n",
      "-0.010188052703245213  ,  0.4461  ,  0.7818\n",
      "993\n",
      "994\n",
      "nan  ,  0.2211  ,  0.7955\n",
      "-0.08890869502695524  ,  0.2287  ,  0.7918\n",
      "-0.0066585079231215715  ,  0.2223  ,  0.7947\n",
      "995\n",
      "996\n",
      "0.2841695576685561  ,  0.6362  ,  0.7115\n",
      "-0.03465710771370435  ,  0.4756  ,  0.7244\n",
      "-0.027565756577622287  ,  0.5229  ,  0.6902\n",
      "997\n",
      "998\n",
      "0.03497208484626465  ,  0.1742  ,  0.7101\n",
      "0.00680600440278309  ,  0.1738  ,  0.7109\n",
      "nan  ,  0.1738  ,  0.7109\n",
      "999\n",
      "1000\n",
      "0.03185293521349246  ,  0.6627  ,  0.6237\n",
      "-0.007107218239225036  ,  0.2545  ,  0.6337\n",
      "-0.022884001225237222  ,  0.1997  ,  0.6704\n",
      "1001\n",
      "1002\n",
      "0.019861767297792956  ,  0.7784  ,  0.4127\n",
      "-0.14087855295479623  ,  0.7925  ,  0.2652\n",
      "-0.1689778506465266  ,  0.7042  ,  0.2697\n",
      "1003\n",
      "1004\n",
      "0.49273199853203276  ,  0.3515  ,  0.6245\n",
      "-0.029202232289959204  ,  0.3492  ,  0.7602\n",
      "-0.0013077181939223255  ,  0.3568  ,  0.7539\n",
      "1005\n",
      "1006\n",
      "0.158478681689275  ,  0.3489  ,  0.817\n",
      "nan  ,  0.322  ,  0.8655\n",
      "nan  ,  0.322  ,  0.8655\n",
      "1007\n",
      "1008\n",
      "-0.016417329825076946  ,  0.2314  ,  0.7446\n",
      "-0.062214432170246324  ,  0.3442  ,  0.6645\n",
      "-0.028149236501199788  ,  0.3147  ,  0.6837\n",
      "1009\n",
      "1010\n",
      "0.21077486881305135  ,  0.8591  ,  0.591\n",
      "0.049387957013734246  ,  0.4505  ,  0.7966\n",
      "0.05313457104954851  ,  0.4315  ,  0.8186\n",
      "1011\n",
      "1012\n",
      "0.08318951069465731  ,  0.3797  ,  0.8507\n",
      "-0.08078511877032715  ,  0.3239  ,  0.894\n",
      "0.03252046157970033  ,  0.3352  ,  0.8822\n",
      "1013\n",
      "1014\n",
      "0.06930871992895013  ,  0.3606  ,  1.2461\n",
      "-0.047288561975747226  ,  0.5623  ,  1.1406\n",
      "0.017666133950368375  ,  0.4224  ,  1.2122\n",
      "1015\n",
      "1016\n",
      "0.012547916062738083  ,  0.4159  ,  0.8495\n",
      "-0.04963256983171292  ,  0.3082  ,  0.8695\n",
      "0.07756813677290282  ,  0.4019  ,  0.8099\n",
      "1017\n",
      "1018\n",
      "0.04312086441115417  ,  0.4252  ,  0.8768\n",
      "-0.013123290098331032  ,  0.6849  ,  0.5853\n",
      "0.021794669422446723  ,  0.6253  ,  0.6307\n",
      "1019\n",
      "1020\n",
      "0.22188626153901458  ,  0.4881  ,  0.8531\n",
      "-0.012578988934294457  ,  0.2916  ,  0.8404\n",
      "-0.02458869738411165  ,  0.2929  ,  0.8393\n",
      "1021\n",
      "1022\n",
      "0.05477972380397892  ,  1.4995  ,  0.6061\n",
      "-0.09635849509068926  ,  0.6127  ,  0.4699\n",
      "-0.07659897364261062  ,  0.5711  ,  0.4912\n",
      "1023\n",
      "1024\n",
      "-0.012985701623824192  ,  0.2156  ,  0.9009\n",
      "0.011202651155667903  ,  0.3864  ,  0.814\n",
      "-0.03395337091145721  ,  0.2879  ,  0.8626\n",
      "1025\n",
      "1026\n",
      "0.028353527414716213  ,  6.9169  ,  3.4812\n",
      "0.10835418242994997  ,  0.3483  ,  0.6164\n",
      "0.08886842578682089  ,  0.1872  ,  0.6937\n",
      "1027\n",
      "1028\n",
      "0.12015685044072255  ,  1.0287  ,  0.9482\n",
      "-0.014899707845874957  ,  0.3044  ,  1.0882\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "1029\n",
      "1030\n",
      "0.2779846002716334  ,  0.6632  ,  0.5501\n",
      "-0.016520728309998674  ,  0.622  ,  0.5832\n",
      "-0.14761437410612202  ,  0.5823  ,  0.6083\n",
      "1031\n",
      "1032\n",
      "0.2530518110572424  ,  0.3692  ,  0.9284\n",
      "-0.12210435924518998  ,  0.3586  ,  0.9891\n",
      "0.05502045065382458  ,  0.3549  ,  0.9879\n",
      "1033\n",
      "1034\n",
      "0.19091171390136974  ,  0.2051  ,  0.5606\n",
      "0.011416063164436881  ,  0.3123  ,  0.4939\n",
      "-0.10132259832102589  ,  0.2802  ,  0.5168\n",
      "1035\n",
      "1036\n",
      "-0.017741244262789606  ,  0.3189  ,  0.893\n",
      "-0.07593112933245066  ,  0.4078  ,  0.8163\n",
      "0.031218630830231645  ,  0.4714  ,  0.762\n",
      "1037\n",
      "1038\n",
      "0.4912401759297612  ,  0.2921  ,  0.9655\n",
      "-0.009618539829020351  ,  0.3105  ,  1.0874\n",
      "-0.05066485524506527  ,  0.3133  ,  1.0854\n",
      "1039\n",
      "1040\n",
      "0.15551104602805596  ,  1.4189  ,  0.6878\n",
      "-0.026188574569777197  ,  0.4562  ,  0.6738\n",
      "0.015063377437454962  ,  0.4347  ,  0.6915\n",
      "1041\n",
      "1042\n",
      "0.0649381361837919  ,  0.7245  ,  0.5173\n",
      "-0.022124318196296983  ,  0.4102  ,  0.5069\n",
      "-0.0021418724445773554  ,  0.4773  ,  0.4634\n",
      "1043\n",
      "1044\n",
      "0.08291394628357847  ,  0.2562  ,  0.7419\n",
      "-0.1330889502537932  ,  0.3157  ,  0.6999\n",
      "-0.003221453256165124  ,  0.3556  ,  0.6664\n",
      "1045\n",
      "1046\n",
      "0.1787546735012252  ,  2.7225  ,  1.3984\n",
      "0.07762793741131296  ,  0.3953  ,  0.7421\n",
      "-0.000789030559915879  ,  0.338  ,  0.78\n",
      "1047\n",
      "1048\n",
      "0.06727053603030769  ,  0.3714  ,  0.7777\n",
      "-0.1180272376188014  ,  0.6647  ,  0.5428\n",
      "-0.0425344289863032  ,  0.6949  ,  0.5251\n",
      "1049\n",
      "1050\n",
      "0.11545608697844814  ,  0.4473  ,  0.8762\n",
      "-0.022787331500293176  ,  0.6721  ,  0.7097\n",
      "0.01759196866956224  ,  0.6862  ,  0.7011\n",
      "1051\n",
      "1052\n",
      "0.01837261955693023  ,  1.0383  ,  0.6181\n",
      "0.02556211221865503  ,  0.4823  ,  0.5784\n",
      "0.010716237086947519  ,  0.499  ,  0.5642\n",
      "1053\n",
      "1054\n",
      "0.31008206253118364  ,  0.3546  ,  0.67\n",
      "0.03494408166845715  ,  0.6932  ,  0.4394\n",
      "0.13130212280267337  ,  0.6909  ,  0.4407\n",
      "1055\n",
      "1056\n",
      "0.1677240268727278  ,  0.1797  ,  0.7145\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "1057\n",
      "1058\n",
      "0.1917075618656465  ,  0.4765  ,  0.6856\n",
      "0.023688264055009033  ,  0.3027  ,  0.8091\n",
      "0.10539818473827511  ,  0.3283  ,  0.7821\n",
      "1059\n",
      "1060\n",
      "0.19814313204206357  ,  0.56  ,  0.6324\n",
      "0.27782520301666014  ,  0.681  ,  0.5417\n",
      "-0.07829349936804439  ,  0.6928  ,  0.5379\n",
      "1061\n",
      "1062\n",
      "0.45143897815970085  ,  0.469  ,  0.8197\n",
      "0.12562428850932356  ,  0.57  ,  0.8882\n",
      "0.08144661202902682  ,  0.4648  ,  0.9934\n",
      "1063\n",
      "1064\n",
      "0.17609126416279047  ,  0.5093  ,  0.6521\n",
      "0.033576669689901  ,  0.4823  ,  0.6569\n",
      "0.019193527369349244  ,  0.5574  ,  0.585\n",
      "1065\n",
      "1066\n",
      "0.07202089894871992  ,  0.1497  ,  0.636\n",
      "-0.014364423473932355  ,  0.2507  ,  0.5875\n",
      "-0.06141753947596846  ,  0.2442  ,  0.5902\n",
      "1067\n",
      "1068\n",
      "0.22105435337758483  ,  0.7419  ,  0.4681\n",
      "0.1040380499985069  ,  0.6052  ,  0.478\n",
      "-0.12091618494087059  ,  0.6728  ,  0.4391\n",
      "1069\n",
      "1070\n",
      "0.1150890738934509  ,  0.3591  ,  0.7515\n",
      "0.022015034437287084  ,  0.3412  ,  0.7039\n",
      "0.059886363530699184  ,  0.3134  ,  0.7191\n",
      "1071\n",
      "1072\n",
      "0.007109689531601848  ,  3.2112  ,  1.7068\n",
      "0.06632798741743023  ,  0.1849  ,  0.7932\n",
      "nan  ,  0.1737  ,  0.7998\n",
      "1073\n",
      "1074\n",
      "0.1354379484950039  ,  0.2179  ,  0.6654\n",
      "0.000883378426338767  ,  0.2161  ,  0.6738\n",
      "0.02076162106544371  ,  0.2575  ,  0.6413\n",
      "1075\n",
      "1076\n",
      "0.12332699252987586  ,  0.5906  ,  0.533\n",
      "0.0768164973775648  ,  0.3546  ,  0.569\n",
      "-0.07326708049735203  ,  0.2083  ,  0.6658\n",
      "1077\n",
      "1078\n",
      "0.026999217911338448  ,  0.5776  ,  0.7963\n",
      "0.04940851144179308  ,  0.4718  ,  0.6387\n",
      "0.07885743506148785  ,  0.4814  ,  0.6321\n",
      "1079\n",
      "1080\n",
      "0.13437284491783932  ,  1.048  ,  0.7818\n",
      "0.06298764589946729  ,  0.1771  ,  0.5486\n",
      "0.00563888727134664  ,  0.1877  ,  0.5448\n",
      "1081\n",
      "1082\n",
      "0.05806446594556754  ,  0.258  ,  0.7911\n",
      "-0.051927534470142415  ,  0.2783  ,  0.7765\n",
      "-0.05667098056037585  ,  0.3395  ,  0.7275\n",
      "1083\n",
      "1084\n",
      "0.11506030322498535  ,  1.2157  ,  0.5959\n",
      "-0.042156057512417466  ,  0.2915  ,  0.659\n",
      "-0.037926546182178986  ,  0.3167  ,  0.6418\n",
      "1085\n",
      "1086\n",
      "0.3825639611071895  ,  0.2028  ,  0.7483\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "1087\n",
      "1088\n",
      "-0.0029340322221895485  ,  0.187  ,  0.6811\n",
      "-0.03689327289176419  ,  0.2626  ,  0.6371\n",
      "-0.003959177968135805  ,  0.2693  ,  0.631\n",
      "1089\n",
      "1090\n",
      "0.016335781574559945  ,  0.782  ,  0.7183\n",
      "0.039398217275497846  ,  0.4425  ,  0.8039\n",
      "0.003026257772169026  ,  0.3673  ,  0.8636\n",
      "1091\n",
      "1092\n",
      "0.04829594150930848  ,  3.2981  ,  1.7525\n",
      "0.0568659570468001  ,  0.4683  ,  0.8733\n",
      "0.039652846375374085  ,  0.2637  ,  0.9705\n",
      "1093\n",
      "1094\n",
      "0.17140161906222948  ,  0.5809  ,  0.8105\n",
      "-0.15587525467987326  ,  0.5905  ,  0.7672\n",
      "-0.03664648773948831  ,  0.5969  ,  0.7484\n",
      "1095\n",
      "1096\n",
      "-0.12811343379334061  ,  0.4333  ,  0.8684\n",
      "-0.0013256244173594244  ,  0.5557  ,  0.6991\n",
      "0.07167966916727596  ,  0.5397  ,  0.7133\n",
      "1097\n",
      "1098\n",
      "0.2502260809870997  ,  1.3359  ,  0.7978\n",
      "0.2145215494394495  ,  0.4496  ,  0.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046440063766043455  ,  0.4532  ,  0.8026\n",
      "1099\n",
      "1100\n",
      "0.04911129469253348  ,  1.7662  ,  1.0877\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "1101\n",
      "1102\n",
      "0.2464211021344235  ,  2.2133  ,  1.1246\n",
      "0.15459996235253953  ,  0.4198  ,  0.7574\n",
      "-0.05299770198936781  ,  0.3892  ,  0.7882\n",
      "1103\n",
      "1104\n",
      "0.018024356601354048  ,  0.4248  ,  1.0879\n",
      "0.02362098618673423  ,  0.5177  ,  0.9923\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "1105\n",
      "1106\n",
      "0.1439538663606464  ,  0.2824  ,  0.632\n",
      "0.09094834063034049  ,  0.4984  ,  0.4629\n",
      "-0.027803462248960915  ,  0.5501  ,  0.4356\n",
      "1107\n",
      "1108\n",
      "0.11987207905950846  ,  0.3522  ,  0.6128\n",
      "0.14025296620210184  ,  0.521  ,  0.4572\n",
      "0.140452829429592  ,  0.5475  ,  0.4453\n",
      "1109\n",
      "1110\n",
      "0.23788047446513078  ,  0.4902  ,  0.8553\n",
      "-0.04496427941034957  ,  0.6792  ,  0.72\n",
      "0.015325523348022913  ,  0.6624  ,  0.7325\n",
      "1111\n",
      "1112\n",
      "0.10811907106204457  ,  0.354  ,  0.7972\n",
      "0.003915749011328306  ,  0.344  ,  0.8165\n",
      "-0.022770632591290974  ,  0.4265  ,  0.7366\n",
      "1113\n",
      "1114\n",
      "0.13791548190006575  ,  0.8466  ,  0.5652\n",
      "0.022528399269673052  ,  0.5449  ,  0.4541\n",
      "0.014092573256769849  ,  0.5804  ,  0.4392\n",
      "1115\n",
      "1116\n",
      "-0.0013936761658146666  ,  0.378  ,  1.0103\n",
      "0.05998191553004003  ,  0.3959  ,  0.9892\n",
      "-0.03055494094123666  ,  0.3858  ,  1.0016\n",
      "1117\n",
      "1118\n",
      "-0.011865071243514042  ,  0.2225  ,  0.7281\n",
      "0.01174645655481479  ,  0.2483  ,  0.7085\n",
      "0.021239109644001466  ,  0.2596  ,  0.7005\n",
      "1119\n",
      "1120\n",
      "0.027406048910044736  ,  0.6396  ,  0.9249\n",
      "0.08575647767053193  ,  0.4796  ,  0.8083\n",
      "0.005774662241828762  ,  0.4435  ,  0.8338\n",
      "1121\n",
      "1122\n",
      "0.1588326636468067  ,  1.0999  ,  0.5134\n",
      "-0.03371547848560469  ,  0.6364  ,  0.4905\n",
      "0.06168987649929249  ,  0.6351  ,  0.4912\n",
      "1123\n",
      "1124\n",
      "-0.048928524793445394  ,  0.3719  ,  0.7785\n",
      "0.03013538439193374  ,  0.659  ,  0.5581\n",
      "0.03561647648537938  ,  0.6257  ,  0.5722\n",
      "1125\n",
      "1126\n",
      "0.17317897554063844  ,  0.4001  ,  0.6401\n",
      "0.0598555443742954  ,  0.6484  ,  0.4463\n",
      "-0.008309076435307726  ,  0.6392  ,  0.4518\n",
      "1127\n",
      "1128\n",
      "0.03869429439428805  ,  0.2685  ,  0.856\n",
      "0.038267762582334594  ,  0.3256  ,  0.8126\n",
      "-0.0431959340032581  ,  0.3242  ,  0.8138\n",
      "1129\n",
      "1130\n",
      "0.30644811971530905  ,  0.3762  ,  0.8418\n",
      "0.0020423339494875428  ,  0.5785  ,  0.7005\n",
      "-0.0630092162355359  ,  0.6308  ,  0.6614\n",
      "1131\n",
      "1132\n",
      "0.162272741579005  ,  0.5635  ,  0.6552\n",
      "0.1380759031943631  ,  0.3901  ,  0.663\n",
      "-0.013915389358452006  ,  0.3753  ,  0.6744\n",
      "1133\n",
      "1134\n",
      "0.5617776254090031  ,  0.237  ,  0.7668\n",
      "0.03311166410061397  ,  0.2444  ,  0.8114\n",
      "0.04142717312636858  ,  0.2983  ,  0.7723\n",
      "1135\n",
      "1136\n",
      "0.24576689083436015  ,  0.2736  ,  0.6507\n",
      "-0.03953121045198158  ,  0.2456  ,  0.6935\n",
      "-0.0076549401880565415  ,  0.251  ,  0.6901\n",
      "1137\n",
      "1138\n",
      "0.08929067741813167  ,  0.2412  ,  0.808\n",
      "0.05040846637474781  ,  0.2656  ,  0.7907\n",
      "-0.05637767774868073  ,  0.2629  ,  0.7929\n",
      "1139\n",
      "1140\n",
      "0.0028745216854743176  ,  0.3331  ,  0.824\n",
      "-0.11717631493625011  ,  0.3634  ,  0.7933\n",
      "0.028463742886081615  ,  0.3635  ,  0.7911\n",
      "1141\n",
      "1142\n",
      "-0.01367767247948756  ,  0.4122  ,  0.9136\n",
      "0.04624310257516294  ,  0.7027  ,  0.7412\n",
      "-0.05029252525236549  ,  0.5563  ,  0.8131\n",
      "1143\n",
      "1144\n",
      "0.08911972728414937  ,  0.2613  ,  0.7189\n",
      "0.05036240691874269  ,  0.3974  ,  0.6302\n",
      "0.03370190927108877  ,  0.3343  ,  0.6662\n",
      "1145\n",
      "1146\n",
      "0.11711552602515417  ,  0.3774  ,  0.7523\n",
      "-0.08032028522332191  ,  0.5919  ,  0.5838\n",
      "-0.08526355632970634  ,  0.5954  ,  0.5807\n",
      "1147\n",
      "1148\n",
      "0.3042928178730777  ,  0.7562  ,  0.601\n",
      "-0.006011607186505641  ,  0.5504  ,  0.7847\n",
      "-0.07131875361016912  ,  0.5384  ,  0.796\n",
      "1149\n",
      "1150\n",
      "0.21509551040920183  ,  1.2456  ,  0.9979\n",
      "0.0912980241835585  ,  0.4121  ,  0.5876\n",
      "0.018957891929663857  ,  0.211  ,  0.7144\n",
      "1151\n",
      "64\n",
      "0.11502701441100427  ,  0.5806  ,  1.7446\n",
      "0.2377333396670119  ,  0.7715  ,  1.5463\n",
      "nan  ,  0.5813  ,  1.7471\n",
      "65\n",
      "0.6407551181670574  ,  0.8402  ,  1.7373\n",
      "0.005491260598126768  ,  0.5992  ,  2.4139\n",
      "nan  ,  0.5953  ,  2.4162\n",
      "66\n",
      "0.7044222778724666  ,  1.1616  ,  2.2552\n",
      "0.4812434960164843  ,  1.3529  ,  2.7013\n",
      "nan  ,  1.4011  ,  2.8426\n",
      "67\n",
      "0.4582480342945661  ,  2.7174  ,  3.3416\n",
      "0.1626572720183242  ,  2.9187  ,  3.6546\n",
      "0.034590461120046906  ,  3.0065  ,  3.7473\n",
      "68\n",
      "nan  ,  0.3359  ,  1.2555\n",
      "0.013740695369163012  ,  0.336  ,  1.2554\n",
      "nan  ,  0.3359  ,  1.2555\n",
      "69\n",
      "0.22485074833059365  ,  0.9982  ,  1.2526\n",
      "0.17699565259705113  ,  0.755  ,  1.4869\n",
      "0.003503029486106537  ,  0.767  ,  1.5058\n",
      "70\n",
      "nan  ,  0.3984  ,  1.546\n",
      "nan  ,  0.3984  ,  1.546\n",
      "nan  ,  0.3984  ,  1.546\n",
      "71\n",
      "0.24527787161176237  ,  0.7323  ,  1.7521\n",
      "-0.04926220831996955  ,  0.8197  ,  1.6755\n",
      "-0.04924930033497105  ,  0.785  ,  1.7064\n",
      "72\n",
      "0.5824886685248651  ,  0.6462  ,  1.3143\n",
      "0.016986778038638576  ,  0.6974  ,  1.728\n",
      "nan  ,  0.6687  ,  1.7612\n",
      "73\n",
      "0.13584771523109823  ,  0.6953  ,  1.6556\n",
      "0.1799933976702994  ,  0.6801  ,  1.6678\n",
      "nan  ,  0.6774  ,  1.7122\n",
      "74\n",
      "0.5219269088286609  ,  0.7027  ,  1.7817\n",
      "0.4816252554993826  ,  0.7467  ,  1.9413\n",
      "0.028025218526536687  ,  0.8211  ,  1.9114\n",
      "75\n",
      "0.9539724525885636  ,  0.3846  ,  0.8757\n",
      "0.06798187051562343  ,  0.9193  ,  2.9885\n",
      "nan  ,  0.8849  ,  3.0265\n",
      "76\n",
      "-0.021987838072369703  ,  0.8428  ,  2.7446\n",
      "0.16816243800119568  ,  0.8793  ,  2.6403\n",
      "nan  ,  0.8318  ,  2.7464\n",
      "77\n",
      "-0.011867115411431688  ,  1.2077  ,  2.2163\n",
      "-0.05210777369050919  ,  1.2322  ,  2.1352\n",
      "-0.01029129206191028  ,  1.2301  ,  2.1392\n",
      "78\n",
      "0.09611985080952584  ,  1.1388  ,  1.9008\n",
      "0.414628926187552  ,  1.1001  ,  1.9804\n",
      "-0.14410269860016017  ,  1.1131  ,  2.0119\n",
      "79\n",
      "0.5681655146334228  ,  0.7559  ,  1.5072\n",
      "-0.06902871437739913  ,  0.8851  ,  1.8304\n",
      "0.07545637972426626  ,  0.8163  ,  1.8805\n",
      "80\n",
      "0.13676767486050245  ,  0.4764  ,  1.4508\n",
      "0.014755306345966227  ,  0.4778  ,  1.4712\n",
      "0.11668242090277232  ,  0.4798  ,  1.4699\n",
      "81\n",
      "0.15513032203883703  ,  0.6037  ,  1.4951\n",
      "0.1513483839091358  ,  0.6118  ,  1.4637\n",
      "0.0082707875382667  ,  0.7027  ,  1.3857\n",
      "82\n",
      "0.4426312616548472  ,  0.1282  ,  0.672\n",
      "0.5716901029730163  ,  0.13  ,  0.639\n",
      "0.000840606978771499  ,  0.4089  ,  0.573\n",
      "83\n",
      "0.4624415322333098  ,  0.6891  ,  1.6444\n",
      "0.22445952700625268  ,  0.7328  ,  1.8612\n",
      "-0.02409613225556559  ,  0.7717  ,  1.8345\n",
      "84\n",
      "0.6709103995562642  ,  1.4256  ,  1.2457\n",
      "0.3124235774021841  ,  1.8212  ,  2.2368\n",
      "-0.15160622288112702  ,  1.8886  ,  2.1602\n",
      "85\n",
      "0.7664649393004714  ,  0.9878  ,  2.2021\n",
      "0.46308159945397664  ,  1.2178  ,  2.6706\n",
      "nan  ,  1.2393  ,  2.8407\n",
      "86\n",
      "0.013524707857997597  ,  0.6678  ,  2.1326\n",
      "0.045732997948893316  ,  0.6862  ,  2.11\n",
      "nan  ,  0.6588  ,  2.1379\n",
      "87\n",
      "0.11200019596585421  ,  0.5705  ,  1.3764\n",
      "0.4330638560745714  ,  0.4646  ,  1.3878\n",
      "0.07441562079797992  ,  0.4794  ,  1.4067\n",
      "88\n",
      "0.6779882092525062  ,  0.9906  ,  2.2117\n",
      "0.40059674642143794  ,  1.0464  ,  2.1554\n",
      "nan  ,  1.0354  ,  2.3476\n",
      "89\n",
      "0.46985738000718974  ,  0.9477  ,  1.6512\n",
      "0.010922911734787587  ,  1.0872  ,  1.8218\n",
      "0.01958926529158693  ,  1.0505  ,  1.8614\n",
      "90\n",
      "0.24748581994396338  ,  0.2325  ,  1.0675\n",
      "0.003052297998555605  ,  0.2086  ,  1.1175\n",
      "0.04121155408829786  ,  0.2242  ,  1.1113\n",
      "91\n",
      "0.003116539871692914  ,  0.5836  ,  1.7196\n",
      "0.08226512692905762  ,  0.6744  ,  1.6356\n",
      "0.01942363111164818  ,  0.5845  ,  1.7187\n",
      "92\n",
      "0.43854470636921  ,  0.3573  ,  0.9253\n",
      "0.04041889444916874  ,  0.3926  ,  1.0555\n",
      "nan  ,  0.3927  ,  1.0555\n",
      "93\n",
      "nan  ,  1.0234  ,  2.539\n",
      "0.032223800035515615  ,  1.0246  ,  2.5365\n",
      "nan  ,  1.0234  ,  2.539\n",
      "94\n",
      "0.5330549370798574  ,  1.072  ,  1.8544\n",
      "0.3057625628560507  ,  1.044  ,  2.3123\n",
      "nan  ,  1.1148  ,  2.4814\n",
      "95\n",
      "nan  ,  1.4183  ,  3.1236\n",
      "0.06425585674822812  ,  1.4178  ,  3.1227\n",
      "nan  ,  1.4183  ,  3.1236\n",
      "96\n",
      "0.08911163410394987  ,  0.6672  ,  1.4648\n",
      "0.05812348713310138  ,  0.6692  ,  1.4623\n",
      "-0.04064234267220401  ,  0.6723  ,  1.4615\n",
      "97\n",
      "nan  ,  0.8753  ,  2.2828\n",
      "nan  ,  0.8753  ,  2.2828\n",
      "nan  ,  0.8753  ,  2.2828\n",
      "98\n",
      "0.08945387174569762  ,  0.8434  ,  1.9703\n",
      "0.06164037021284238  ,  0.8432  ,  1.9711\n",
      "-0.031885420443506854  ,  0.8866  ,  1.9098\n",
      "99\n",
      "0.532589924789356  ,  0.78  ,  1.5792\n",
      "0.13147855067244585  ,  0.8623  ,  1.8495\n",
      "0.010925547429885652  ,  0.6296  ,  2.0328\n",
      "100\n",
      "0.009773708350198869  ,  0.5921  ,  2.0204\n",
      "nan  ,  0.5917  ,  2.0212\n",
      "nan  ,  0.5917  ,  2.0212\n",
      "101\n",
      "0.02653000014223462  ,  0.743  ,  2.0766\n",
      "0.10489642278533429  ,  0.7488  ,  2.0616\n",
      "nan  ,  0.7394  ,  2.0835\n",
      "102\n",
      "0.0008859713464253487  ,  1.099  ,  1.8276\n",
      "0.18576126403480156  ,  1.1551  ,  1.5655\n",
      "-0.03621875727590028  ,  1.1328  ,  1.6768\n",
      "103\n",
      "0.7177489545976437  ,  1.2242  ,  2.0103\n",
      "0.48029459954713905  ,  1.4513  ,  1.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  ,  1.5312  ,  2.5708\n",
      "104\n",
      "0.05635807155358015  ,  1.1434  ,  2.6949\n",
      "0.11461204112700993  ,  1.1571  ,  2.6629\n",
      "-0.04456691284852704  ,  1.1483  ,  2.689\n",
      "105\n",
      "0.38942039912590404  ,  0.3325  ,  0.9805\n",
      "0.03761584300221633  ,  0.8626  ,  1.2306\n",
      "-0.001322189241683072  ,  0.3807  ,  1.0575\n",
      "106\n",
      "0.010630010680949395  ,  0.7328  ,  2.0006\n",
      "nan  ,  0.7328  ,  2.0006\n",
      "nan  ,  0.7328  ,  2.0006\n",
      "107\n",
      "0.0400778470825683  ,  1.113  ,  2.6158\n",
      "0.19342566367242975  ,  1.1448  ,  2.518\n",
      "0.009416327372612844  ,  1.1232  ,  2.6001\n",
      "108\n",
      "0.013346116736056022  ,  0.4307  ,  1.4883\n",
      "0.13786677016147209  ,  0.6375  ,  1.3462\n",
      "nan  ,  0.4307  ,  1.4883\n",
      "109\n",
      "0.0617863324730847  ,  0.6953  ,  1.7908\n",
      "0.41652107021078727  ,  0.6938  ,  1.7317\n",
      "0.07117858424654423  ,  0.7378  ,  1.7446\n",
      "110\n",
      "0.08474294197727618  ,  0.5443  ,  2.0505\n",
      "0.14456448988098114  ,  0.7453  ,  1.9067\n",
      "nan  ,  0.5453  ,  2.0531\n",
      "111\n",
      "0.19677826816696864  ,  0.7596  ,  1.6443\n",
      "0.07062159387960981  ,  2.0126  ,  1.6474\n",
      "-0.04276769477474153  ,  0.8178  ,  1.6261\n",
      "112\n",
      "0.0803222290464757  ,  0.6957  ,  2.1756\n",
      "0.47488135010662896  ,  0.7187  ,  2.0142\n",
      "nan  ,  0.6962  ,  2.1789\n",
      "113\n",
      "0.03461803167050979  ,  0.6354  ,  2.112\n",
      "-0.0028632043779301297  ,  0.6344  ,  2.1141\n",
      "nan  ,  0.6344  ,  2.1141\n",
      "114\n",
      "0.5700758047405587  ,  0.6976  ,  1.9905\n",
      "0.13938907743872614  ,  0.7173  ,  2.0793\n",
      "nan  ,  0.7157  ,  2.0862\n",
      "115\n",
      "0.324992084385195  ,  0.5855  ,  1.24\n",
      "0.2055050114635333  ,  0.4841  ,  1.0392\n",
      "-0.07952582770245273  ,  0.3562  ,  1.1062\n",
      "116\n",
      "0.26924964233599574  ,  0.8615  ,  2.4551\n",
      "0.5241284397548593  ,  0.8684  ,  2.106\n",
      "0.009236258620369968  ,  0.8951  ,  2.5368\n",
      "117\n",
      "0.5926759238275369  ,  0.8897  ,  1.4756\n",
      "0.31760586481844383  ,  2.092  ,  1.8053\n",
      "-0.00929338785755017  ,  0.9628  ,  2.0644\n",
      "118\n",
      "0.34881595268038407  ,  0.5746  ,  1.5784\n",
      "0.12565974055910895  ,  0.6623  ,  1.6472\n",
      "-0.02069858295249811  ,  0.5666  ,  1.7448\n",
      "119\n",
      "0.014797785586160628  ,  0.4661  ,  1.3235\n",
      "-0.05376810169350443  ,  0.5016  ,  1.2938\n",
      "0.06174157783986831  ,  0.5527  ,  1.2458\n",
      "120\n",
      "0.037578573135599945  ,  0.5253  ,  1.369\n",
      "0.3483831804740615  ,  0.514  ,  1.2528\n",
      "nan  ,  0.5257  ,  1.3694\n",
      "121\n",
      "0.9127723419511563  ,  0.4345  ,  2.0103\n",
      "0.5382600382641194  ,  0.5563  ,  2.2494\n",
      "0.108493683795253  ,  0.7167  ,  2.3454\n",
      "122\n",
      "0.38468517210415726  ,  1.0914  ,  1.3972\n",
      "0.014646441557710572  ,  0.7529  ,  1.5791\n",
      "0.22128701123857658  ,  0.7839  ,  1.5082\n",
      "123\n",
      "0.277481101936387  ,  0.3258  ,  1.1383\n",
      "0.4014061989603215  ,  0.3522  ,  1.0703\n",
      "-0.1447340243717437  ,  0.6696  ,  0.9486\n",
      "124\n",
      "0.13936796768476165  ,  0.5775  ,  1.7285\n",
      "0.328514557779255  ,  0.578  ,  1.6529\n",
      "nan  ,  0.5802  ,  1.7346\n",
      "125\n",
      "0.07200678684225005  ,  0.6323  ,  1.6977\n",
      "0.014916577976623666  ,  0.6332  ,  1.6993\n",
      "nan  ,  0.6332  ,  1.6993\n",
      "126\n",
      "0.665199423127492  ,  1.4273  ,  1.4948\n",
      "-0.34774538793421206  ,  1.7655  ,  2.2766\n",
      "-0.22964254769262388  ,  1.7073  ,  2.4186\n",
      "127\n",
      "0.398137323096829  ,  0.1747  ,  0.7457\n",
      "0.19208301447078685  ,  0.2123  ,  0.7668\n",
      "-0.02887163690394351  ,  0.3584  ,  0.7125\n",
      "128\n",
      "0.4205249480512074  ,  0.2861  ,  0.9397\n",
      "0.44899433422748125  ,  0.2915  ,  0.9461\n",
      "0.1903946812756822  ,  0.3769  ,  0.9359\n",
      "129\n",
      "0.4701623506210878  ,  0.6102  ,  1.2377\n",
      "0.08744495628626546  ,  0.6781  ,  1.4616\n",
      "-0.002220928636041484  ,  0.6944  ,  1.453\n",
      "130\n",
      "-0.010387190220017894  ,  0.6878  ,  2.0586\n",
      "0.18492100935793587  ,  0.8763  ,  1.8515\n",
      "nan  ,  0.6876  ,  2.0588\n",
      "131\n",
      "0.01133324217873007  ,  1.3812  ,  2.5972\n",
      "0.24329440379691183  ,  1.7423  ,  1.8693\n",
      "nan  ,  1.3814  ,  2.5973\n",
      "132\n",
      "-0.004426111549875638  ,  1.544  ,  2.2886\n",
      "0.13522114281436695  ,  1.5508  ,  2.0232\n",
      "-0.03303177757375964  ,  1.5539  ,  2.1346\n",
      "133\n",
      "0.3694776608633738  ,  2.0083  ,  1.9595\n",
      "0.2759283867952399  ,  1.1731  ,  2.1271\n",
      "0.034613899660523126  ,  1.1558  ,  2.3822\n",
      "134\n",
      "0.17032964956904398  ,  0.5063  ,  1.4005\n",
      "-0.12661745964776194  ,  0.6274  ,  1.3597\n",
      "-0.05396220196324433  ,  0.5665  ,  1.3598\n",
      "135\n",
      "0.45276315856839683  ,  0.8505  ,  2.1977\n",
      "0.10457259986328815  ,  0.8774  ,  2.2711\n",
      "nan  ,  0.8774  ,  2.2806\n",
      "136\n",
      "0.27675484226552366  ,  2.2537  ,  2.1828\n",
      "0.030375253562697897  ,  0.4725  ,  1.1412\n",
      "nan  ,  0.3371  ,  1.1911\n",
      "137\n",
      "0.5174532256361144  ,  0.3781  ,  1.2021\n",
      "0.267014070266637  ,  0.6969  ,  1.0856\n",
      "nan  ,  0.3905  ,  1.3252\n",
      "138\n",
      "nan  ,  1.2004  ,  2.7137\n",
      "nan  ,  1.2004  ,  2.7137\n",
      "nan  ,  1.2004  ,  2.7137\n",
      "139\n",
      "0.3276696547890207  ,  0.4849  ,  1.4524\n",
      "0.0390935307268419  ,  0.5025  ,  1.5268\n",
      "0.07203599474264147  ,  0.518  ,  1.5167\n",
      "140\n",
      "0.5521712683299983  ,  0.5809  ,  1.4694\n",
      "0.37717185268529263  ,  0.5725  ,  1.7194\n",
      "0.11712770436249115  ,  0.5985  ,  1.7694\n",
      "141\n",
      "0.11461243008073058  ,  0.7429  ,  1.5712\n",
      "0.39203072290809116  ,  0.7038  ,  1.4309\n",
      "0.09109253640617872  ,  0.8032  ,  1.4733\n",
      "142\n",
      "0.12629292517986096  ,  0.4615  ,  1.3071\n",
      "0.07314810772760999  ,  0.8171  ,  1.0395\n",
      "-0.10102892169127753  ,  0.556  ,  1.2236\n",
      "143\n",
      "0.18692278120330985  ,  0.8733  ,  1.7083\n",
      "0.23162751397265044  ,  0.8668  ,  1.6985\n",
      "0.22955283941651863  ,  0.9686  ,  1.5419\n",
      "144\n",
      "0.025665638230152058  ,  1.0459  ,  2.3865\n",
      "0.4468540488702429  ,  0.974  ,  2.1465\n",
      "nan  ,  1.0034  ,  2.4413\n",
      "145\n",
      "0.4531457689841768  ,  0.4887  ,  1.3339\n",
      "0.04925527234745342  ,  0.6526  ,  1.4787\n",
      "0.038820458514818204  ,  0.5056  ,  1.5469\n",
      "146\n",
      "0.08484481658977738  ,  0.5842  ,  2.0542\n",
      "-0.005425377641143292  ,  0.5896  ,  2.0573\n",
      "nan  ,  0.5862  ,  2.0592\n",
      "147\n",
      "0.6374763792990741  ,  0.4122  ,  1.3264\n",
      "-0.0569850364325607  ,  0.4878  ,  1.5735\n",
      "-0.018089721043374776  ,  0.4835  ,  1.5705\n",
      "148\n",
      "0.6090808248635767  ,  0.67  ,  1.6829\n",
      "0.008315890963838378  ,  0.7566  ,  2.074\n",
      "nan  ,  0.7566  ,  2.0741\n",
      "149\n",
      "0.03280836284928444  ,  0.8745  ,  2.7004\n",
      "0.6448387038530963  ,  0.8377  ,  2.3599\n",
      "-0.03228120807628909  ,  0.9102  ,  2.6678\n",
      "150\n",
      "0.37995576875368775  ,  0.4111  ,  1.3306\n",
      "0.3706534055541887  ,  0.4226  ,  1.3599\n",
      "0.07257165465098685  ,  0.4286  ,  1.3905\n",
      "151\n",
      "0.3613758264948453  ,  0.7072  ,  1.903\n",
      "0.5820677253411669  ,  0.688  ,  1.7605\n",
      "nan  ,  0.7205  ,  1.9542\n",
      "152\n",
      "0.1895562677140222  ,  0.6806  ,  1.8621\n",
      "0.29412850902002274  ,  0.7008  ,  1.7915\n",
      "0.0035020985799211167  ,  0.6851  ,  1.8852\n",
      "153\n",
      "-0.0049506361674229084  ,  0.798  ,  2.0311\n",
      "0.12379619258242723  ,  0.9133  ,  1.8826\n",
      "-0.12240029295188828  ,  0.8274  ,  1.9961\n",
      "154\n",
      "0.026415731378029005  ,  0.9623  ,  2.9716\n",
      "0.08412897273042298  ,  1.0154  ,  2.9243\n",
      "-0.037481487274465534  ,  1.0155  ,  2.9243\n",
      "155\n",
      "0.47755856367250077  ,  1.0032  ,  1.5147\n",
      "-0.016212206761658618  ,  0.531  ,  1.6042\n",
      "-0.056644426486285884  ,  0.5293  ,  1.6039\n",
      "156\n",
      "0.23467812901133966  ,  1.2112  ,  1.4842\n",
      "-0.06455104471739129  ,  1.5267  ,  1.3719\n",
      "nan  ,  0.5538  ,  1.3935\n",
      "157\n",
      "0.3516112300724713  ,  0.5519  ,  1.7548\n",
      "-0.001883088716084066  ,  0.5469  ,  1.8715\n",
      "nan  ,  0.5469  ,  1.8715\n",
      "158\n",
      "0.3938588859045541  ,  0.5218  ,  1.7106\n",
      "-0.02022295710603203  ,  0.5389  ,  1.84\n",
      "nan  ,  0.5259  ,  1.8462\n",
      "159\n",
      "0.5912150808924657  ,  0.464  ,  1.3562\n",
      "0.4172048129715303  ,  0.5148  ,  1.5213\n",
      "0.011774153628076356  ,  0.5197  ,  1.6429\n",
      "160\n",
      "0.1171378650191358  ,  0.5062  ,  1.9763\n",
      "0.1779335655699978  ,  0.5681  ,  1.9132\n",
      "nan  ,  0.5071  ,  1.9811\n",
      "161\n",
      "nan  ,  0.7883  ,  2.2\n",
      "0.09716330567083734  ,  0.8002  ,  2.1699\n",
      "nan  ,  0.7883  ,  2.2\n",
      "162\n",
      "-0.004537165544589322  ,  0.6435  ,  2.1103\n",
      "0.35325338103187803  ,  0.6295  ,  2.05\n",
      "nan  ,  0.6417  ,  2.111\n",
      "163\n",
      "0.5053054540250544  ,  0.4999  ,  1.398\n",
      "0.23219621216034558  ,  0.5369  ,  1.5594\n",
      "0.07217666177578375  ,  0.5527  ,  1.5578\n",
      "164\n",
      "0.2719055809267444  ,  0.8714  ,  1.9338\n",
      "0.32811600742887753  ,  0.9188  ,  1.9318\n",
      "-0.1976777832155952  ,  0.8877  ,  2.1063\n",
      "165\n",
      "0.44813238057508314  ,  0.7406  ,  1.7299\n",
      "0.003472789605489854  ,  0.7935  ,  1.8931\n",
      "nan  ,  0.7934  ,  1.8932\n",
      "166\n",
      "0.15883455783537484  ,  0.8382  ,  2.2273\n",
      "0.3878634724412448  ,  0.8447  ,  2.0711\n",
      "nan  ,  0.8399  ,  2.2338\n",
      "167\n",
      "0.43618351841082487  ,  0.3013  ,  1.2682\n",
      "0.3762457990222866  ,  0.3048  ,  1.2789\n",
      "nan  ,  0.3077  ,  1.3019\n",
      "168\n",
      "0.6428015088725954  ,  0.4519  ,  1.4487\n",
      "0.0128344834287966  ,  0.4899  ,  1.824\n",
      "nan  ,  0.4888  ,  1.825\n",
      "169\n",
      "0.012744102589845912  ,  1.1734  ,  2.4707\n",
      "0.6395304552473517  ,  1.0571  ,  2.2146\n",
      "nan  ,  1.1553  ,  2.4921\n",
      "170\n",
      "0.0604894890517763  ,  0.9399  ,  2.0703\n",
      "0.31481340346809866  ,  1.0331  ,  1.7363\n",
      "nan  ,  0.94  ,  2.0705\n",
      "171\n",
      "0.326422039369584  ,  1.4165  ,  2.0869\n",
      "0.40570991583847993  ,  1.4547  ,  2.111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09064226194122098  ,  1.5285  ,  2.2231\n",
      "172\n",
      "0.05145536123880001  ,  1.0818  ,  1.9441\n",
      "0.07889228388478395  ,  1.0834  ,  1.925\n",
      "0.1368010096385263  ,  1.0828  ,  1.944\n",
      "173\n",
      "0.6170580180197699  ,  1.0665  ,  1.3051\n",
      "0.006220957306260531  ,  1.1396  ,  2.0006\n",
      "0.13351233073604338  ,  1.1456  ,  1.9709\n",
      "174\n",
      "nan  ,  0.7701  ,  2.0416\n",
      "0.4955105223408057  ,  0.8367  ,  1.6294\n",
      "nan  ,  0.7701  ,  2.0416\n",
      "175\n",
      "0.6763169481688673  ,  0.7244  ,  1.5054\n",
      "0.14060870051290889  ,  0.7957  ,  2.2416\n",
      "0.00936788124789524  ,  0.7931  ,  2.2629\n",
      "176\n",
      "0.7541388176151443  ,  0.7297  ,  1.4094\n",
      "0.06411200339033055  ,  0.9693  ,  2.3712\n",
      "nan  ,  0.9643  ,  2.3843\n",
      "177\n",
      "0.09063057963611958  ,  0.5246  ,  1.5973\n",
      "0.18908103107336394  ,  0.5255  ,  1.5684\n",
      "nan  ,  0.5183  ,  1.6143\n",
      "178\n",
      "nan  ,  0.8999  ,  2.5554\n",
      "0.03267143102885694  ,  0.9313  ,  2.518\n",
      "nan  ,  0.8999  ,  2.5554\n",
      "179\n",
      "0.07681720414399607  ,  0.4341  ,  1.2347\n",
      "-0.14629557496812293  ,  0.693  ,  1.0889\n",
      "-0.04333570519613255  ,  0.4904  ,  1.184\n",
      "180\n",
      "0.7093935009510851  ,  0.7404  ,  2.4728\n",
      "0.17113476659952098  ,  0.7885  ,  2.6949\n",
      "nan  ,  0.7775  ,  2.7323\n",
      "181\n",
      "0.18210891663801163  ,  1.1023  ,  2.2518\n",
      "0.018462506864173445  ,  1.1161  ,  2.2523\n",
      "0.23247770857685518  ,  1.1057  ,  2.2592\n",
      "182\n",
      "0.02750804528535524  ,  0.4908  ,  1.9071\n",
      "0.4087739135772282  ,  1.1689  ,  1.5276\n",
      "nan  ,  0.4909  ,  1.9072\n",
      "183\n",
      "0.6193137194975863  ,  0.6421  ,  1.963\n",
      "0.018360206657137893  ,  0.6947  ,  2.388\n",
      "0.00019019533402623548  ,  0.694  ,  2.3889\n",
      "184\n",
      "0.019344310145878275  ,  0.8462  ,  2.3545\n",
      "0.0233101719537486  ,  0.8439  ,  2.3581\n",
      "nan  ,  0.8439  ,  2.3581\n",
      "185\n",
      "0.7269512361560527  ,  0.3615  ,  0.712\n",
      "0.09883478582924557  ,  0.1817  ,  0.5749\n",
      "0.04832060562052572  ,  0.2436  ,  0.5487\n",
      "186\n",
      "0.3799790910343033  ,  1.809  ,  2.3187\n",
      "0.14987333936379255  ,  1.7624  ,  1.959\n",
      "-0.06274464517890499  ,  1.7964  ,  2.1664\n",
      "187\n",
      "0.15780867428633705  ,  0.3703  ,  1.1841\n",
      "0.08344858517004548  ,  0.5516  ,  1.0608\n",
      "-0.06617383153084525  ,  0.5516  ,  1.0608\n",
      "188\n",
      "0.4100764166950199  ,  0.7911  ,  2.1706\n",
      "0.4199994357543948  ,  0.8246  ,  2.0079\n",
      "nan  ,  0.7999  ,  2.2089\n",
      "189\n",
      "-0.03982662911756685  ,  1.1674  ,  1.9312\n",
      "0.12774944790184242  ,  1.235  ,  1.6577\n",
      "0.1551373715617468  ,  1.2242  ,  1.7078\n",
      "190\n",
      "0.1143261917119162  ,  0.6841  ,  1.3897\n",
      "0.05648525130267352  ,  0.4464  ,  1.2547\n",
      "0.08616486623534013  ,  0.4916  ,  1.2174\n",
      "191\n",
      "0.09177796758327053  ,  0.7217  ,  2.3825\n",
      "0.5135213075040834  ,  0.8982  ,  1.839\n",
      "nan  ,  0.7222  ,  2.385\n",
      "192\n",
      "0.025707087930096056  ,  1.1055  ,  1.6703\n",
      "0.33049450315556916  ,  1.0815  ,  1.3415\n",
      "0.0930210080282372  ,  1.1063  ,  1.5466\n",
      "193\n",
      "0.0145247957044276  ,  1.523  ,  2.4653\n",
      "0.031907838361975686  ,  1.5669  ,  2.123\n",
      "0.1472672324377637  ,  1.5395  ,  2.2062\n",
      "194\n",
      "0.018456915760421404  ,  0.8412  ,  1.5779\n",
      "0.024651588544744384  ,  1.7002  ,  1.0428\n",
      "0.07323038925002165  ,  0.8821  ,  1.4822\n",
      "195\n",
      "0.354428584934806  ,  0.5786  ,  1.9144\n",
      "0.3615373957671727  ,  0.6182  ,  1.818\n",
      "nan  ,  0.5842  ,  1.9416\n",
      "196\n",
      "0.8484363114689578  ,  0.5111  ,  2.316\n",
      "0.2873593872729446  ,  0.6954  ,  2.3976\n",
      "-0.21734751352439252  ,  0.7104  ,  2.4207\n",
      "197\n",
      "0.9051590972167969  ,  0.5972  ,  2.2513\n",
      "0.5310252675190473  ,  0.7705  ,  2.8062\n",
      "0.03297351217725955  ,  0.939  ,  2.7553\n",
      "198\n",
      "0.03839266623371339  ,  1.7772  ,  2.0947\n",
      "0.1622915344602912  ,  1.6562  ,  1.4985\n",
      "0.13115217957480368  ,  1.7527  ,  2.0031\n",
      "199\n",
      "0.6965879089003458  ,  0.7836  ,  1.9785\n",
      "0.14036128448268864  ,  0.9328  ,  2.308\n",
      "nan  ,  0.9051  ,  2.363\n",
      "200\n",
      "0.43149703489415253  ,  0.9963  ,  1.987\n",
      "nan  ,  1.0263  ,  2.4059\n",
      "nan  ,  1.0263  ,  2.4059\n",
      "201\n",
      "0.5023483453860962  ,  0.745  ,  2.0651\n",
      "0.3349016589698053  ,  0.7834  ,  2.2268\n",
      "nan  ,  0.7999  ,  2.3339\n",
      "202\n",
      "0.04937597313039126  ,  1.0468  ,  2.1744\n",
      "-0.10391228308198938  ,  1.3226  ,  1.9143\n",
      "0.17688779558704262  ,  1.0786  ,  2.1051\n",
      "203\n",
      "0.09408106875355336  ,  0.7773  ,  1.6352\n",
      "0.23106380346934025  ,  0.7649  ,  1.6184\n",
      "0.1877156116327245  ,  0.9243  ,  1.4203\n",
      "204\n",
      "0.5386492593283652  ,  1.1587  ,  1.645\n",
      "-0.0002724939934727011  ,  0.6021  ,  1.7688\n",
      "nan  ,  0.5855  ,  1.7826\n",
      "205\n",
      "0.1138536508667182  ,  0.3703  ,  1.398\n",
      "0.08769422642595669  ,  0.4257  ,  1.3661\n",
      "0.014976972032451777  ,  0.371  ,  1.4056\n",
      "206\n",
      "0.38647070488282875  ,  0.8429  ,  1.2893\n",
      "-0.10859514377405773  ,  1.3627  ,  1.4672\n",
      "0.02723362797642958  ,  0.8242  ,  1.4561\n",
      "207\n",
      "0.41817679568028576  ,  0.7447  ,  2.0383\n",
      "nan  ,  0.7919  ,  2.1901\n",
      "nan  ,  0.7919  ,  2.1901\n",
      "208\n",
      "0.047811828552972974  ,  0.5247  ,  1.6284\n",
      "0.17297469232903978  ,  0.6612  ,  1.5008\n",
      "-0.04093743003235681  ,  0.7048  ,  1.4894\n",
      "209\n",
      "0.21611247654276763  ,  1.2028  ,  1.755\n",
      "0.14966575433481505  ,  0.9511  ,  1.6403\n",
      "0.08305548028150761  ,  0.8436  ,  1.8275\n",
      "210\n",
      "0.7052998672311706  ,  1.1315  ,  1.6274\n",
      "0.4567143916461759  ,  1.4508  ,  2.5891\n",
      "nan  ,  1.55  ,  2.7652\n",
      "211\n",
      "0.5872624855709341  ,  0.7977  ,  1.9989\n",
      "0.4403671861822028  ,  0.8713  ,  1.9844\n",
      "nan  ,  0.8562  ,  2.1869\n",
      "212\n",
      "0.098697365765904  ,  0.5158  ,  1.2838\n",
      "0.16980599922089085  ,  0.5152  ,  1.2811\n",
      "-0.011976731579614878  ,  0.5425  ,  1.2571\n",
      "213\n",
      "0.23761282145785556  ,  1.9519  ,  2.7736\n",
      "-0.03415018246022416  ,  1.9631  ,  2.7236\n",
      "0.011999432265090985  ,  1.9541  ,  2.7614\n",
      "214\n",
      "0.4554661032384082  ,  0.8163  ,  1.741\n",
      "0.08349259220727978  ,  1.8463  ,  2.2453\n",
      "-0.004669908341434206  ,  0.8807  ,  1.8979\n",
      "215\n",
      "0.1959404017148411  ,  0.6885  ,  1.5726\n",
      "0.02606748729466414  ,  0.7115  ,  1.559\n",
      "-0.09125741308627165  ,  0.7595  ,  1.5018\n",
      "216\n",
      "0.8446534286423578  ,  0.4201  ,  1.3963\n",
      "nan  ,  0.5182  ,  2.1769\n",
      "nan  ,  0.5182  ,  2.1769\n",
      "217\n",
      "0.4679820964827188  ,  0.9362  ,  1.5711\n",
      "0.00911860333626772  ,  0.5427  ,  1.7758\n",
      "nan  ,  0.5084  ,  1.7952\n",
      "218\n",
      "0.3332616336984817  ,  1.9787  ,  2.8224\n",
      "0.05519915753388168  ,  2.0005  ,  2.7317\n",
      "-0.09129893590899593  ,  2.0228  ,  2.5792\n",
      "219\n",
      "0.40760058746912875  ,  1.8248  ,  2.0868\n",
      "0.39292466094782097  ,  0.5996  ,  1.8548\n",
      "nan  ,  0.5885  ,  1.9335\n",
      "220\n",
      "0.024192086227046508  ,  0.9851  ,  1.5943\n",
      "0.04410113560520111  ,  0.9806  ,  1.5905\n",
      "0.035918380595428186  ,  0.9982  ,  1.51\n",
      "221\n",
      "nan  ,  0.5078  ,  1.6611\n",
      "0.3712663611447265  ,  0.5119  ,  1.6008\n",
      "nan  ,  0.5078  ,  1.6611\n",
      "222\n",
      "0.4076853357954112  ,  1.2768  ,  2.1704\n",
      "0.17046824692764417  ,  0.8361  ,  2.6742\n",
      "nan  ,  0.8296  ,  2.723\n",
      "223\n",
      "0.7638590688116775  ,  0.6982  ,  1.8343\n",
      "0.3584377711419084  ,  0.9745  ,  2.4934\n",
      "0.03526436506220143  ,  0.8176  ,  2.8098\n",
      "224\n",
      "0.4251104088920662  ,  0.3499  ,  1.1005\n",
      "0.2306783075002963  ,  0.4802  ,  0.9871\n",
      "-0.14232922402930076  ,  0.5725  ,  0.9584\n",
      "225\n",
      "0.3768559005524557  ,  1.7634  ,  2.7763\n",
      "nan  ,  1.8411  ,  2.9739\n",
      "nan  ,  1.8411  ,  2.9739\n",
      "226\n",
      "0.2219261750528193  ,  0.558  ,  1.4031\n",
      "-0.0672972618331429  ,  0.7452  ,  1.2593\n",
      "-0.07540936729728852  ,  0.6336  ,  1.3345\n",
      "227\n",
      "0.48685703481790976  ,  0.6047  ,  1.8557\n",
      "0.331691146755632  ,  0.6252  ,  1.819\n",
      "0.13073820120404928  ,  0.6267  ,  1.896\n",
      "228\n",
      "0.1371877742745491  ,  0.4428  ,  1.1784\n",
      "0.0592852785964894  ,  0.4751  ,  1.1383\n",
      "0.13479736541656986  ,  0.5429  ,  1.0832\n",
      "229\n",
      "0.4977796184653855  ,  0.4263  ,  0.8057\n",
      "0.24130478050805032  ,  0.4119  ,  0.8785\n",
      "0.12935525265888875  ,  0.4703  ,  0.8519\n",
      "230\n",
      "0.08988763979941873  ,  0.7072  ,  1.3794\n",
      "0.39363166554162277  ,  0.6972  ,  1.3405\n",
      "-0.26421328376587944  ,  0.7478  ,  1.3068\n",
      "231\n",
      "0.6422069100175265  ,  0.5777  ,  1.5191\n",
      "0.27313195490570275  ,  0.7924  ,  1.7626\n",
      "nan  ,  0.6343  ,  1.9895\n",
      "232\n",
      "0.08543015544027306  ,  0.5081  ,  1.6475\n",
      "0.11001684961049275  ,  0.5193  ,  1.6375\n",
      "0.03510596845062526  ,  0.5334  ,  1.6424\n",
      "233\n",
      "0.32829200695451194  ,  0.6302  ,  1.7311\n",
      "0.007455176781554291  ,  0.6697  ,  1.833\n",
      "0.017199394915918657  ,  0.6645  ,  1.8398\n",
      "234\n",
      "0.5049272744277872  ,  0.8022  ,  1.5385\n",
      "0.29512936217275054  ,  0.7697  ,  1.9203\n",
      "nan  ,  0.7728  ,  1.988\n",
      "235\n",
      "0.3740951620217248  ,  1.6368  ,  1.9831\n",
      "0.5101474577671329  ,  2.0164  ,  2.2674\n",
      "0.17522447843807018  ,  2.1255  ,  2.2181\n",
      "236\n",
      "0.03940536697832175  ,  1.028  ,  1.7659\n",
      "-0.026334618850641867  ,  1.0249  ,  1.8394\n",
      "-0.0011197695697921922  ,  1.0468  ,  1.7621\n",
      "237\n",
      "0.26311922093554463  ,  0.3649  ,  0.9048\n",
      "0.33223803720165784  ,  0.4838  ,  0.7484\n",
      "0.08836957348901282  ,  0.4732  ,  0.8028\n",
      "238\n",
      "0.7043336234085849  ,  0.5015  ,  1.0795\n",
      "-0.01188493501887986  ,  0.3958  ,  1.4469\n",
      "nan  ,  0.3944  ,  1.4473\n",
      "239\n",
      "0.09595307519181566  ,  0.4581  ,  1.3443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10763500352507738  ,  0.5401  ,  1.2736\n",
      "0.03593387157670897  ,  0.5445  ,  1.2714\n",
      "240\n",
      "0.0030028748954999264  ,  0.5601  ,  1.9897\n",
      "0.10501806561806767  ,  0.6156  ,  1.9343\n",
      "0.032411648481983635  ,  0.5877  ,  1.9676\n",
      "241\n",
      "0.18470810973999013  ,  0.7196  ,  1.6373\n",
      "0.09400958001531003  ,  0.7265  ,  1.6345\n",
      "0.03339777449461724  ,  0.5768  ,  1.7557\n",
      "242\n",
      "0.32108403020661347  ,  0.5635  ,  1.3817\n",
      "0.12621920637923514  ,  0.5248  ,  1.5263\n",
      "nan  ,  0.5249  ,  1.5302\n",
      "243\n",
      "0.28977759339904446  ,  0.2056  ,  1.122\n",
      "nan  ,  0.2065  ,  1.1515\n",
      "nan  ,  0.2065  ,  1.1515\n",
      "244\n",
      "0.39411104907160854  ,  2.5497  ,  4.1626\n",
      "-0.023456832564319748  ,  0.9453  ,  2.7035\n",
      "nan  ,  0.9269  ,  2.7168\n",
      "245\n",
      "nan  ,  1.2999  ,  2.2069\n",
      "0.2640013653998463  ,  1.317  ,  1.9142\n",
      "nan  ,  1.2999  ,  2.2069\n",
      "246\n",
      "0.7206626823559006  ,  0.811  ,  1.95\n",
      "-0.03616245584742692  ,  0.9367  ,  2.2398\n",
      "0.00024191426438093896  ,  0.9089  ,  2.2605\n",
      "247\n",
      "0.26571036243463  ,  0.7386  ,  1.6958\n",
      "-0.0284779614393548  ,  0.7593  ,  1.7697\n",
      "-0.028541526668377754  ,  0.8018  ,  1.6956\n",
      "248\n",
      "0.6518532237370631  ,  0.8076  ,  1.9096\n",
      "0.007296417019111677  ,  0.9148  ,  2.3929\n",
      "0.010973477650430715  ,  0.9154  ,  2.3921\n",
      "249\n",
      "0.498016744730722  ,  0.5678  ,  1.9366\n",
      "0.13023673239541309  ,  1.0193  ,  1.678\n",
      "-0.009533052319861323  ,  0.7622  ,  1.8521\n",
      "250\n",
      "0.5119428466909175  ,  0.8477  ,  1.6095\n",
      "0.3030170178927437  ,  0.9277  ,  1.9019\n",
      "0.05728353015221929  ,  0.97  ,  1.9221\n",
      "251\n",
      "0.28810295280314024  ,  0.537  ,  1.4166\n",
      "0.38435670244287123  ,  0.7775  ,  1.1238\n",
      "-0.14460256987796438  ,  0.6127  ,  1.3884\n",
      "252\n",
      "0.29022397193722843  ,  0.688  ,  1.6848\n",
      "0.6171685399595556  ,  0.5952  ,  1.494\n",
      "0.03629293570691989  ,  0.654  ,  1.8358\n",
      "253\n",
      "0.5922690566807476  ,  0.7327  ,  1.5404\n",
      "0.3903442073735687  ,  0.9374  ,  1.6421\n",
      "-0.08427313448966535  ,  0.8063  ,  2.0152\n",
      "254\n",
      "0.4069542205766845  ,  0.5965  ,  1.293\n",
      "0.10815283185043062  ,  0.3914  ,  1.2491\n",
      "-0.1012056336566908  ,  0.4003  ,  1.2443\n",
      "255\n",
      "0.14762079196471148  ,  0.1662  ,  0.6717\n",
      "0.1400349256106976  ,  0.19  ,  0.6595\n",
      "-0.08327524018699163  ,  0.2232  ,  0.6411\n",
      "256\n",
      "0.050820832539493856  ,  0.8511  ,  1.6748\n",
      "-0.08085111691791838  ,  0.8619  ,  1.6537\n",
      "0.025268255528396778  ,  0.8546  ,  1.6686\n",
      "257\n",
      "0.7506061315365451  ,  0.8099  ,  1.8946\n",
      "0.5138836063059853  ,  0.9793  ,  2.3263\n",
      "0.631497259769322  ,  1.0387  ,  2.2867\n",
      "258\n",
      "0.051492455304965976  ,  0.8615  ,  1.7359\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "nan  ,  0.8624  ,  1.7377\n",
      "259\n",
      "0.2352961586288691  ,  0.4524  ,  0.9911\n",
      "0.25546063002548985  ,  0.4601  ,  0.9912\n",
      "-0.011705979752275986  ,  0.5083  ,  0.9369\n",
      "260\n",
      "0.19552940666255175  ,  1.1728  ,  1.1111\n",
      "0.04277159442345899  ,  0.7539  ,  1.5154\n",
      "nan  ,  0.7539  ,  1.5164\n",
      "261\n",
      "0.033706369932708424  ,  0.8414  ,  2.0291\n",
      "-0.017987546671866004  ,  0.8464  ,  2.024\n",
      "nan  ,  0.8415  ,  2.0292\n",
      "262\n",
      "-0.01127503807835999  ,  1.0018  ,  2.1993\n",
      "0.22355368575172602  ,  1.0487  ,  2.1117\n",
      "0.3846819609893964  ,  1.0406  ,  2.1359\n",
      "263\n",
      "-0.018197988836097315  ,  0.5574  ,  1.6261\n",
      "0.07040484115672369  ,  0.5558  ,  1.6251\n",
      "nan  ,  0.5552  ,  1.6264\n",
      "264\n",
      "0.06924951021165679  ,  0.5126  ,  1.2868\n",
      "-0.03374378553686165  ,  0.444  ,  1.3329\n",
      "0.12098354957525341  ,  0.4519  ,  1.3242\n",
      "265\n",
      "0.5387440825717833  ,  0.8065  ,  1.7266\n",
      "0.06596638052157412  ,  0.8633  ,  1.9662\n",
      "nan  ,  0.8632  ,  1.9664\n",
      "266\n",
      "0.21716445240523882  ,  0.7318  ,  1.2732\n",
      "nan  ,  0.7208  ,  1.3886\n",
      "nan  ,  0.7208  ,  1.3886\n",
      "267\n",
      "-0.014897963186742955  ,  0.7649  ,  1.7498\n",
      "0.10092546779886291  ,  0.7939  ,  1.6966\n",
      "-0.05263734762027557  ,  0.7932  ,  1.7017\n",
      "268\n",
      "0.13975810537196545  ,  1.2589  ,  2.1447\n",
      "0.09880838857116647  ,  1.2627  ,  2.1511\n",
      "nan  ,  1.2628  ,  2.1513\n",
      "269\n",
      "0.2274150554321596  ,  0.9679  ,  1.8231\n",
      "0.20767681159154425  ,  0.9645  ,  1.7853\n",
      "0.13409936562200714  ,  0.9779  ,  1.8102\n",
      "270\n",
      "0.5457216391985061  ,  1.6759  ,  1.9999\n",
      "-0.007907297950230676  ,  1.9837  ,  2.7294\n",
      "nan  ,  1.9837  ,  2.7294\n",
      "271\n",
      "0.05355986010578189  ,  0.6819  ,  1.4503\n",
      "0.1899501752110426  ,  0.5671  ,  1.5288\n",
      "nan  ,  0.5583  ,  1.556\n",
      "272\n",
      "0.16029628536461407  ,  0.5416  ,  1.6097\n",
      "0.05175753014566527  ,  0.5453  ,  1.6161\n",
      "nan  ,  0.5416  ,  1.6211\n",
      "273\n",
      "0.2999773335879578  ,  0.9358  ,  1.7893\n",
      "0.022789215427879407  ,  0.8698  ,  2.0487\n",
      "nan  ,  0.8526  ,  2.0736\n",
      "274\n",
      "nan  ,  0.8095  ,  2.077\n",
      "0.006067474321194169  ,  0.8097  ,  2.0767\n",
      "nan  ,  0.8095  ,  2.077\n",
      "275\n",
      "-0.0007426131982131873  ,  0.6126  ,  1.1486\n",
      "nan  ,  0.6126  ,  1.1486\n",
      "nan  ,  0.6126  ,  1.1486\n",
      "276\n",
      "0.11608645253898128  ,  1.0605  ,  2.0807\n",
      "-0.0055426515487580486  ,  1.0599  ,  2.1068\n",
      "nan  ,  1.0597  ,  2.107\n",
      "277\n",
      "0.38402939046465934  ,  1.2835  ,  1.3934\n",
      "-0.150442817270488  ,  1.0796  ,  1.8787\n",
      "-0.11524445727542196  ,  1.0437  ,  1.9144\n",
      "278\n",
      "0.04854080613055524  ,  0.6363  ,  1.7503\n",
      "0.0661567391374572  ,  0.6471  ,  1.7422\n",
      "nan  ,  0.6337  ,  1.7583\n",
      "279\n",
      "0.25762066397470257  ,  0.6294  ,  1.4208\n",
      "-0.10972514550443732  ,  0.6501  ,  1.4372\n",
      "0.049085074855382736  ,  0.6501  ,  1.4371\n",
      "280\n",
      "0.43237061231886686  ,  0.7199  ,  1.4237\n",
      "nan  ,  0.7536  ,  1.5149\n",
      "nan  ,  0.7536  ,  1.5149\n",
      "281\n",
      "-0.007867064250847364  ,  1.0054  ,  2.3082\n",
      "0.2352526584621501  ,  1.0684  ,  2.2101\n",
      "0.008144857116035041  ,  1.0592  ,  2.2316\n",
      "282\n",
      "0.09304630056677238  ,  0.6482  ,  1.3986\n",
      "0.1459085661992495  ,  0.6494  ,  1.3822\n",
      "0.05501640230218249  ,  0.7544  ,  1.2492\n",
      "283\n",
      "0.17453129498619538  ,  0.6715  ,  1.5898\n",
      "0.04103522942412094  ,  0.5219  ,  1.7102\n",
      "nan  ,  0.5204  ,  1.7121\n",
      "284\n",
      "0.01981505892417329  ,  0.5652  ,  1.1485\n",
      "-0.04180231486207232  ,  0.5925  ,  1.0993\n",
      "0.12946279202635178  ,  0.5908  ,  1.1017\n",
      "285\n",
      "0.26433434584755655  ,  0.9538  ,  1.3833\n",
      "-0.16518529794469491  ,  0.9906  ,  1.4308\n",
      "0.17135289810867632  ,  0.9913  ,  1.3828\n",
      "286\n",
      "-0.016640001523847946  ,  1.2812  ,  1.8752\n",
      "0.1519287452573791  ,  1.2696  ,  1.8136\n",
      "0.0682076610417506  ,  1.2788  ,  1.839\n",
      "287\n",
      "nan  ,  0.8943  ,  2.0395\n",
      "0.05636689950363433  ,  0.9006  ,  2.0304\n",
      "nan  ,  0.8943  ,  2.0395\n",
      "288\n",
      "0.5024245280623526  ,  1.428  ,  2.097\n",
      "-0.30512746874463514  ,  1.5697  ,  2.363\n",
      "0.017424973511373437  ,  1.5613  ,  2.3419\n",
      "289\n",
      "0.03067554624499946  ,  0.7843  ,  2.009\n",
      "-0.012044749424570185  ,  0.7851  ,  2.0082\n",
      "0.04032339677553673  ,  0.7876  ,  2.0052\n",
      "290\n",
      "0.1468811172368415  ,  1.1787  ,  2.231\n",
      "0.011554418136487355  ,  1.1822  ,  2.221\n",
      "0.13078286310075876  ,  1.1824  ,  2.2267\n",
      "291\n",
      "0.4971413550982  ,  0.8409  ,  1.9533\n",
      "nan  ,  0.8753  ,  2.0967\n",
      "nan  ,  0.8753  ,  2.0967\n",
      "292\n",
      "0.033673774853805155  ,  1.4872  ,  1.2193\n",
      "-0.05317599439787408  ,  1.3171  ,  1.6622\n",
      "-0.16221632324634633  ,  1.3168  ,  1.6656\n",
      "293\n",
      "0.2836309867181298  ,  1.0427  ,  2.1096\n",
      "0.007273125240937437  ,  1.0616  ,  2.0692\n",
      "0.02755199664071301  ,  1.0616  ,  2.0692\n",
      "294\n",
      "0.4616971634020899  ,  0.8551  ,  2.1874\n",
      "0.0162793969674503  ,  0.7298  ,  2.6063\n",
      "nan  ,  0.7176  ,  2.6151\n",
      "295\n",
      "0.18175064928003512  ,  0.9343  ,  1.8784\n",
      "0.05477808686633689  ,  0.9358  ,  1.9345\n",
      "-0.09375405063954012  ,  0.9401  ,  1.9282\n",
      "296\n",
      "0.02739651424967747  ,  0.6846  ,  1.5094\n",
      "0.07115721349888102  ,  0.7129  ,  1.4537\n",
      "0.03177237502891644  ,  0.6884  ,  1.504\n",
      "297\n",
      "-0.016342426832073386  ,  1.1607  ,  1.9633\n",
      "-0.00608869515876766  ,  1.1943  ,  1.8242\n",
      "0.06321998729524181  ,  1.1878  ,  1.8413\n",
      "298\n",
      "0.26768409938482984  ,  1.4131  ,  2.7218\n",
      "-0.019197694490254595  ,  1.4254  ,  2.8352\n",
      "-0.12309901641172416  ,  1.4393  ,  2.8023\n",
      "299\n",
      "0.051183816782795946  ,  0.4464  ,  1.1142\n",
      "0.012956993339318565  ,  0.4322  ,  1.1303\n",
      "0.05367846336291617  ,  0.4773  ,  1.082\n",
      "300\n",
      "nan  ,  0.7732  ,  2.2247\n",
      "-0.0007759244742272277  ,  0.7733  ,  2.2247\n",
      "nan  ,  0.7732  ,  2.2247\n",
      "301\n",
      "0.12834251311650052  ,  1.2316  ,  1.8798\n",
      "0.23108696478076124  ,  1.2343  ,  1.8838\n",
      "-0.10198104308268133  ,  1.24  ,  1.8626\n",
      "302\n",
      "nan  ,  0.486  ,  1.2905\n",
      "0.19305579335539208  ,  0.5577  ,  1.2071\n",
      "-0.08543714160285487  ,  0.5177  ,  1.2579\n",
      "303\n",
      "0.10004978658192074  ,  1.0331  ,  1.6536\n",
      "0.16142310363363355  ,  1.0627  ,  1.5741\n",
      "-0.11592401459267972  ,  1.0622  ,  1.586\n",
      "304\n",
      "-0.002226517414463666  ,  1.5962  ,  2.1758\n",
      "0.26151449421894457  ,  1.5914  ,  2.1359\n",
      "0.09780264786263665  ,  1.5934  ,  2.146\n",
      "305\n",
      "nan  ,  0.761  ,  1.907\n",
      "nan  ,  0.761  ,  1.907\n",
      "nan  ,  0.761  ,  1.907\n",
      "306\n",
      "0.8768306256517163  ,  0.4373  ,  1.1229\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "nan  ,  0.5332  ,  2.3629\n",
      "307\n",
      "0.48048648251703974  ,  0.6597  ,  1.0511\n",
      "nan  ,  0.563  ,  1.1967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  ,  0.563  ,  1.1967\n",
      "308\n",
      "0.00402970222203908  ,  0.4952  ,  1.7212\n",
      "-0.0031275705421386947  ,  0.4949  ,  1.7215\n",
      "nan  ,  0.4949  ,  1.7215\n",
      "309\n",
      "0.10044755752450493  ,  1.1739  ,  1.8079\n",
      "0.031229043075313108  ,  1.1766  ,  1.7858\n",
      "-0.07532148882551755  ,  1.1772  ,  1.7819\n",
      "310\n",
      "0.3456507178009241  ,  0.8127  ,  1.9053\n",
      "0.14760851417737902  ,  0.8172  ,  1.926\n",
      "nan  ,  0.8173  ,  1.9267\n",
      "311\n",
      "nan  ,  0.763  ,  1.7097\n",
      "0.059647307999655695  ,  0.7636  ,  1.7061\n",
      "nan  ,  0.763  ,  1.7097\n",
      "312\n",
      "0.8748270500453034  ,  0.3679  ,  1.0886\n",
      "nan  ,  0.5086  ,  2.3385\n",
      "nan  ,  0.5086  ,  2.3385\n",
      "313\n",
      "0.32607137991780977  ,  0.6808  ,  1.0725\n",
      "nan  ,  0.5113  ,  1.3129\n",
      "nan  ,  0.5113  ,  1.3129\n",
      "314\n",
      "nan  ,  0.7027  ,  1.9405\n",
      "-0.007292658013563748  ,  0.7028  ,  1.9404\n",
      "nan  ,  0.7027  ,  1.9405\n",
      "315\n",
      "-0.016952980448651917  ,  0.4114  ,  1.0865\n",
      "0.08702623754822336  ,  0.4291  ,  1.0673\n",
      "0.15068231966016998  ,  0.4278  ,  1.0695\n",
      "316\n",
      "-0.007407627082213597  ,  0.6581  ,  1.6988\n",
      "0.062437599573447175  ,  0.6622  ,  1.6913\n",
      "-0.12819070127985333  ,  0.6947  ,  1.6556\n",
      "317\n",
      "0.10975274566359494  ,  1.1669  ,  2.3679\n",
      "0.0113517159817099  ,  1.1676  ,  2.4012\n",
      "nan  ,  1.1661  ,  2.4048\n",
      "318\n",
      "0.1311604662090752  ,  0.3007  ,  0.8403\n",
      "-0.058671613346109264  ,  0.3625  ,  0.7857\n",
      "-0.034639997442802634  ,  0.3584  ,  0.7888\n",
      "319\n",
      "0.6173194685042238  ,  1.4297  ,  2.0871\n",
      "-0.08144682205256538  ,  1.4837  ,  2.6494\n",
      "-0.154007455530026  ,  1.4827  ,  2.6516\n",
      "320\n",
      "0.13517199319898426  ,  1.4228  ,  1.4806\n",
      "0.06278686756049766  ,  1.2308  ,  1.9087\n",
      "-0.10447017605163338  ,  1.2295  ,  1.9171\n",
      "321\n",
      "0.12660270862069195  ,  0.3783  ,  1.1439\n",
      "nan  ,  0.2651  ,  1.2055\n",
      "nan  ,  0.2651  ,  1.2055\n",
      "322\n",
      "0.22132327289978282  ,  1.41  ,  1.3061\n",
      "nan  ,  1.4461  ,  1.935\n",
      "nan  ,  1.4461  ,  1.935\n",
      "323\n",
      "0.29112080869798507  ,  1.2996  ,  1.4367\n",
      "nan  ,  0.7677  ,  1.8125\n",
      "-0.0488000053860692  ,  0.7681  ,  1.8119\n",
      "324\n",
      "0.5873876804925591  ,  1.0044  ,  1.7123\n",
      "-0.014700071529409973  ,  1.1209  ,  2.3884\n",
      "-0.06901339895441204  ,  1.1265  ,  2.3766\n",
      "325\n",
      "0.0513869079077378  ,  0.6896  ,  1.5345\n",
      "nan  ,  0.6899  ,  1.5352\n",
      "nan  ,  0.6899  ,  1.5352\n",
      "326\n",
      "nan  ,  0.6536  ,  1.8912\n",
      "nan  ,  0.6536  ,  1.8912\n",
      "nan  ,  0.6536  ,  1.8912\n",
      "327\n",
      "0.02947984100753551  ,  0.7293  ,  1.4415\n",
      "nan  ,  0.7293  ,  1.4415\n",
      "nan  ,  0.7293  ,  1.4415\n",
      "328\n",
      "-0.0022839996050957496  ,  0.5243  ,  1.2586\n",
      "-0.03315457531304997  ,  0.5408  ,  1.2457\n",
      "-0.06321933808558301  ,  0.7112  ,  1.0622\n",
      "329\n",
      "0.5172151989248873  ,  0.6141  ,  1.3709\n",
      "nan  ,  0.6631  ,  1.5563\n",
      "nan  ,  0.6631  ,  1.5563\n",
      "330\n",
      "0.3358220610470408  ,  0.8009  ,  1.9772\n",
      "0.1024453552724805  ,  0.8078  ,  2.0192\n",
      "nan  ,  0.8079  ,  2.0201\n",
      "331\n",
      "0.05661793179106266  ,  1.3107  ,  2.3116\n",
      "-0.06127378688782256  ,  1.3196  ,  2.3074\n",
      "-0.41555529931732554  ,  1.3153  ,  2.3215\n",
      "332\n",
      "0.24364155627004386  ,  1.1329  ,  0.9686\n",
      "-0.029322694510961755  ,  0.968  ,  1.2636\n",
      "0.0326790128000186  ,  0.9548  ,  1.2946\n",
      "333\n",
      "0.16438589996391612  ,  0.7829  ,  1.4765\n",
      "0.04493498063997465  ,  0.813  ,  1.4376\n",
      "0.07728478135085244  ,  0.8133  ,  1.4377\n",
      "334\n",
      "0.058884520019076195  ,  0.8444  ,  1.6272\n",
      "-0.09559136346969233  ,  0.9003  ,  1.5156\n",
      "0.0686474055014869  ,  0.8841  ,  1.5414\n",
      "335\n",
      "0.06574488724374425  ,  0.5379  ,  1.0146\n",
      "-0.08312468661679792  ,  0.8929  ,  0.772\n",
      "-0.05915378922336417  ,  0.5586  ,  0.9695\n",
      "336\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "nan  ,  0.8807  ,  1.6685\n",
      "337\n",
      "0.2633430693859405  ,  0.6515  ,  1.0476\n",
      "0.022023617326715306  ,  0.6265  ,  1.1528\n",
      "0.04802216765898812  ,  0.6233  ,  1.1584\n",
      "338\n",
      "0.0077637904117908215  ,  1.1207  ,  1.8448\n",
      "nan  ,  1.1207  ,  1.8448\n",
      "nan  ,  1.1207  ,  1.8448\n",
      "339\n",
      "0.050054648512665056  ,  0.2826  ,  0.9588\n",
      "-0.007759243893683586  ,  0.2825  ,  0.9596\n",
      "nan  ,  0.2825  ,  0.9596\n",
      "340\n",
      "0.08636406287017842  ,  0.9474  ,  1.6139\n",
      "0.05203705635931471  ,  0.9545  ,  1.5674\n",
      "0.06360721864097767  ,  0.9588  ,  1.5529\n",
      "341\n",
      "0.06961098496355098  ,  0.3987  ,  1.0574\n",
      "-0.08948661971719633  ,  0.5559  ,  0.9376\n",
      "0.0680775018778409  ,  0.5782  ,  0.9023\n",
      "342\n",
      "-0.10621278036600372  ,  1.2836  ,  2.0134\n",
      "0.19220487982912748  ,  1.2418  ,  1.9703\n",
      "-0.019484866186322444  ,  1.2478  ,  1.9973\n",
      "343\n",
      "0.6195945182148306  ,  1.4277  ,  2.3307\n",
      "0.4414695394350441  ,  1.3317  ,  2.7995\n",
      "-0.2828403160464094  ,  1.3712  ,  2.7866\n",
      "344\n",
      "0.27652315688067447  ,  1.3375  ,  1.4113\n",
      "0.06709287506528594  ,  0.4654  ,  1.4007\n",
      "nan  ,  0.358  ,  1.4638\n",
      "345\n",
      "0.029150692820079233  ,  0.6578  ,  1.3835\n",
      "0.07036516387746289  ,  0.7035  ,  1.3097\n",
      "-0.05557357673912079  ,  0.7037  ,  1.3096\n",
      "346\n",
      "0.11266384320254551  ,  0.7677  ,  1.4912\n",
      "nan  ,  0.7692  ,  1.4957\n",
      "nan  ,  0.7692  ,  1.4957\n",
      "347\n",
      "-0.011154879752962588  ,  0.9335  ,  1.8479\n",
      "0.0709045189652992  ,  0.9686  ,  1.7583\n",
      "-0.003873873912444207  ,  0.9691  ,  1.7655\n",
      "348\n",
      "0.07611162961181611  ,  1.4579  ,  1.5949\n",
      "0.06311973184584703  ,  1.1879  ,  2.0885\n",
      "nan  ,  1.1876  ,  2.0974\n",
      "349\n",
      "0.12623184045447197  ,  0.8809  ,  1.5878\n",
      "0.03582298176388103  ,  0.8828  ,  1.5897\n",
      "nan  ,  0.8818  ,  1.5942\n",
      "350\n",
      "0.4521439621119311  ,  0.975  ,  1.5258\n",
      "0.1104288611916571  ,  0.9124  ,  1.9158\n",
      "-0.14747744114338535  ,  0.8927  ,  1.9592\n",
      "351\n",
      "0.16116325109215976  ,  1.2181  ,  2.1114\n",
      "0.2769694272821515  ,  1.2231  ,  2.0798\n",
      "nan  ,  1.2285  ,  2.1302\n",
      "352\n",
      "0.15047559382474193  ,  0.8878  ,  1.7701\n",
      "-0.025412760182430428  ,  0.8898  ,  1.7682\n",
      "nan  ,  0.888  ,  1.7709\n",
      "353\n",
      "0.2050714638311984  ,  0.4649  ,  1.3659\n",
      "-0.0023889110331788963  ,  0.4044  ,  1.446\n",
      "nan  ,  0.4044  ,  1.446\n",
      "354\n",
      "-0.034775881674773405  ,  0.9681  ,  1.6318\n",
      "-0.031456103702732344  ,  0.9965  ,  1.5283\n",
      "0.06549013939474524  ,  1.0026  ,  1.5096\n",
      "355\n",
      "0.28122634086917075  ,  0.8562  ,  1.367\n",
      "-0.13557476004396313  ,  0.7694  ,  1.4945\n",
      "-0.029800135363197887  ,  0.7799  ,  1.4625\n",
      "356\n",
      "0.4794555455827439  ,  0.6366  ,  1.7241\n",
      "0.09158797214693079  ,  0.6637  ,  1.8428\n",
      "nan  ,  0.6586  ,  1.8511\n",
      "357\n",
      "-0.0079047190105737  ,  0.3785  ,  1.3823\n",
      "0.11260262615282582  ,  0.4489  ,  1.3326\n",
      "-0.008109261051947073  ,  0.4728  ,  1.323\n",
      "358\n",
      "0.08802337503568625  ,  0.5816  ,  1.162\n",
      "0.07890015957487179  ,  0.6521  ,  1.0516\n",
      "-0.14338487777880485  ,  0.6489  ,  1.0585\n",
      "359\n",
      "0.32577947426573445  ,  1.0759  ,  1.3611\n",
      "-0.051709111776440976  ,  1.1503  ,  1.3417\n",
      "0.1246893361646728  ,  1.1501  ,  1.3428\n",
      "360\n",
      "0.5313164428360507  ,  1.2077  ,  2.1114\n",
      "-0.007904326550563747  ,  1.26  ,  2.4055\n",
      "nan  ,  1.26  ,  2.4055\n",
      "361\n",
      "0.13232378852864815  ,  1.0212  ,  1.7728\n",
      "-0.023532555467732152  ,  1.0368  ,  1.8179\n",
      "nan  ,  1.0051  ,  1.8886\n",
      "362\n",
      "0.20564906131714297  ,  0.592  ,  1.2643\n",
      "-0.003126225345047121  ,  0.6381  ,  1.222\n",
      "-0.03188740783277198  ,  0.6354  ,  1.2256\n",
      "363\n",
      "0.29655740858829993  ,  1.0628  ,  1.9855\n",
      "nan  ,  1.0609  ,  2.1441\n",
      "nan  ,  1.0609  ,  2.1441\n",
      "364\n",
      "0.03402725864543241  ,  0.4105  ,  1.3091\n",
      "nan  ,  0.4108  ,  1.3093\n",
      "nan  ,  0.4108  ,  1.3093\n",
      "365\n",
      "0.11652759528395243  ,  0.3304  ,  0.9973\n",
      "0.03452537822579973  ,  0.292  ,  1.0327\n",
      "0.08567863418967664  ,  0.2975  ,  1.0292\n",
      "366\n",
      "0.00523819799670411  ,  0.6372  ,  1.8039\n",
      "nan  ,  0.6372  ,  1.8039\n",
      "nan  ,  0.6372  ,  1.8039\n",
      "367\n",
      "-8.677926015082302e-05  ,  0.6106  ,  1.2292\n",
      "0.14347082280034623  ,  0.6557  ,  1.1289\n",
      "0.12066265967350365  ,  0.6336  ,  1.1776\n",
      "368\n",
      "0.011079802729361179  ,  0.8054  ,  1.6348\n",
      "-0.04492333303260908  ,  0.8558  ,  1.5678\n",
      "nan  ,  0.8054  ,  1.6351\n",
      "369\n",
      "0.1458992630422867  ,  0.9794  ,  2.0844\n",
      "nan  ,  0.982  ,  2.0937\n",
      "nan  ,  0.982  ,  2.0937\n",
      "370\n",
      "0.031603147964288834  ,  0.8217  ,  1.8083\n",
      "0.028407491727252814  ,  0.8216  ,  1.8108\n",
      "nan  ,  0.8211  ,  1.8119\n",
      "371\n",
      "0.4714114506587192  ,  1.0124  ,  2.0806\n",
      "-0.0905725671036319  ,  1.0112  ,  2.4159\n",
      "-0.04683671281797773  ,  1.0184  ,  2.4025\n",
      "372\n",
      "0.16572320347219252  ,  0.5642  ,  1.719\n",
      "0.032462644494288456  ,  0.5662  ,  1.7332\n",
      "nan  ,  0.564  ,  1.7359\n",
      "373\n",
      "0.042709752674065495  ,  0.7324  ,  1.3575\n",
      "0.0018423622305620592  ,  0.7351  ,  1.3552\n",
      "0.0042752778612627305  ,  0.7702  ,  1.2722\n",
      "374\n",
      "0.030468483155916565  ,  1.6239  ,  2.7309\n",
      "nan  ,  1.624  ,  2.7311\n",
      "nan  ,  1.624  ,  2.7311\n",
      "375\n",
      "0.09739423812877973  ,  0.9327  ,  2.1587\n",
      "0.06601847444337164  ,  0.9093  ,  2.203\n",
      "nan  ,  0.9041  ,  2.2136\n",
      "376\n",
      "-0.00746456314886963  ,  0.9352  ,  1.9722\n",
      "0.26175221963545403  ,  0.9316  ,  1.959\n",
      "nan  ,  0.9349  ,  1.9727\n",
      "377\n",
      "0.25887298097154043  ,  0.7485  ,  1.4259\n",
      "0.06210961779830096  ,  0.844  ,  1.3408\n",
      "0.042852096519965494  ,  0.8169  ,  1.3891\n",
      "378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42560813400362085  ,  1.1282  ,  1.3699\n",
      "-0.4596507542591217  ,  1.2844  ,  1.2374\n",
      "0.055175196214823315  ,  1.2694  ,  1.2732\n",
      "379\n",
      "nan  ,  0.856  ,  1.5604\n",
      "nan  ,  0.856  ,  1.5604\n",
      "nan  ,  0.856  ,  1.5604\n",
      "380\n",
      "0.3717427959274182  ,  1.2567  ,  2.1128\n",
      "0.06230985880290245  ,  1.294  ,  2.5032\n",
      "nan  ,  1.2932  ,  2.507\n",
      "381\n",
      "-0.02875459362677397  ,  0.5148  ,  1.2403\n",
      "0.051595609143304424  ,  0.5371  ,  1.2009\n",
      "-0.007232768104085919  ,  0.5342  ,  1.206\n",
      "382\n",
      "0.12724797881850128  ,  1.3553  ,  2.5953\n",
      "0.010714460128081173  ,  1.3688  ,  2.5946\n",
      "nan  ,  1.3618  ,  2.6171\n",
      "383\n",
      "nan  ,  0.6506  ,  1.4881\n",
      "nan  ,  0.6506  ,  1.4881\n",
      "nan  ,  0.6506  ,  1.4881\n",
      "384\n",
      "0.20709710826374267  ,  0.7968  ,  1.2545\n",
      "0.0007575627602540453  ,  0.6497  ,  1.4568\n",
      "-0.026846661333030163  ,  0.6681  ,  1.4309\n",
      "385\n",
      "0.2887950452787166  ,  1.4447  ,  1.2171\n",
      "0.141481806006422  ,  0.9859  ,  1.7105\n",
      "-0.0169636305620661  ,  0.9789  ,  1.7543\n",
      "386\n",
      "0.2172829969996866  ,  0.5094  ,  1.3113\n",
      "-0.20315318244841726  ,  0.8459  ,  1.0239\n",
      "0.052793281658706476  ,  0.8036  ,  1.0492\n",
      "387\n",
      "-0.01588085331928559  ,  1.0185  ,  1.9461\n",
      "-0.1437084470356414  ,  1.0874  ,  1.8104\n",
      "-0.04040398139599513  ,  1.1018  ,  1.7771\n",
      "388\n",
      "0.0953220188827664  ,  0.9551  ,  1.5086\n",
      "0.14733514197844175  ,  0.9559  ,  1.5014\n",
      "-0.012619677471284306  ,  0.9674  ,  1.4402\n",
      "389\n",
      "0.01744780124188032  ,  1.3474  ,  1.7233\n",
      "0.0076836975293725854  ,  1.3548  ,  1.623\n",
      "-0.1456256874176052  ,  1.3427  ,  1.7464\n",
      "390\n",
      "-0.0049079729706114315  ,  0.7477  ,  1.6643\n",
      "-0.0075275646498779184  ,  0.7477  ,  1.6643\n",
      "nan  ,  0.7476  ,  1.6644\n",
      "391\n",
      "nan  ,  0.6243  ,  1.5689\n",
      "0.11366433067090584  ,  0.6261  ,  1.5644\n",
      "0.02486103673474112  ,  0.6301  ,  1.5625\n",
      "392\n",
      "0.6324549715219477  ,  0.7639  ,  1.3309\n",
      "-0.04289651677218857  ,  0.9353  ,  1.8738\n",
      "nan  ,  0.9138  ,  1.9164\n",
      "393\n",
      "0.07574023387588949  ,  0.4737  ,  2.2896\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "nan  ,  0.4739  ,  2.2907\n",
      "394\n",
      "0.3323777933202896  ,  0.8676  ,  1.9975\n",
      "nan  ,  0.8851  ,  2.083\n",
      "nan  ,  0.8851  ,  2.083\n",
      "395\n",
      "0.2510136736783132  ,  0.9591  ,  2.0404\n",
      "-0.0007462811615040709  ,  0.962  ,  2.1163\n",
      "nan  ,  0.962  ,  2.1165\n",
      "396\n",
      "0.046438596518368895  ,  0.9579  ,  1.8103\n",
      "-0.032512211628743216  ,  0.9626  ,  1.7908\n",
      "-0.1814083950169343  ,  0.9696  ,  1.7809\n",
      "397\n",
      "0.013342630935783428  ,  0.8937  ,  1.6114\n",
      "-0.07856596250211333  ,  0.9124  ,  1.5879\n",
      "nan  ,  0.8937  ,  1.6115\n",
      "398\n",
      "nan  ,  0.7659  ,  1.8275\n",
      "nan  ,  0.7659  ,  1.8275\n",
      "nan  ,  0.7659  ,  1.8275\n",
      "399\n",
      "0.23668838056143285  ,  2.4062  ,  2.2893\n",
      "nan  ,  0.6587  ,  2.2224\n",
      "nan  ,  0.6587  ,  2.2224\n",
      "400\n",
      "0.719981179931823  ,  0.8161  ,  1.337\n",
      "nan  ,  0.9001  ,  2.2427\n",
      "nan  ,  0.9001  ,  2.2427\n",
      "401\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "nan  ,  0.5974  ,  1.4687\n",
      "402\n",
      "0.3413564138027781  ,  1.4937  ,  2.0332\n",
      "0.19029165474470883  ,  1.5274  ,  2.0598\n",
      "-0.08649669994364437  ,  1.5315  ,  2.0775\n",
      "403\n",
      "0.547808984043453  ,  1.1863  ,  2.924\n",
      "0.35757463553514174  ,  1.4255  ,  2.6942\n",
      "0.06280553096150052  ,  1.4112  ,  2.7814\n",
      "404\n",
      "0.18355616704926114  ,  0.9531  ,  1.6606\n",
      "0.03407371542285845  ,  0.9597  ,  1.7002\n",
      "nan  ,  0.9597  ,  1.7002\n",
      "405\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "nan  ,  0.9517  ,  2.0183\n",
      "406\n",
      "0.3294644281731919  ,  1.311  ,  1.6792\n",
      "0.1569974002035561  ,  0.9614  ,  2.2198\n",
      "0.05355209595470112  ,  0.962  ,  2.2364\n",
      "407\n",
      "nan  ,  1.2703  ,  2.6999\n",
      "0.012460132723902836  ,  1.2703  ,  2.6999\n",
      "nan  ,  1.2703  ,  2.6999\n",
      "408\n",
      "0.3059501822560593  ,  0.8064  ,  1.62\n",
      "nan  ,  0.8393  ,  1.7605\n",
      "nan  ,  0.8393  ,  1.7605\n",
      "409\n",
      "0.00028476965142374647  ,  1.3061  ,  2.0397\n",
      "-0.0771979054936144  ,  1.3114  ,  2.0155\n",
      "0.018994632197459047  ,  1.3064  ,  2.0378\n",
      "410\n",
      "0.05958188402101496  ,  0.4057  ,  1.3734\n",
      "0.16372611674334595  ,  2.4714  ,  2.0913\n",
      "nan  ,  0.3307  ,  1.3698\n",
      "411\n",
      "0.163872528198579  ,  0.9081  ,  1.378\n",
      "0.08491512327122508  ,  0.8667  ,  1.5403\n",
      "0.030973833453307432  ,  0.8589  ,  1.5774\n",
      "412\n",
      "0.02418355088819247  ,  0.7547  ,  1.4884\n",
      "0.05662373756163743  ,  0.7617  ,  1.4674\n",
      "-0.021736716516662712  ,  0.7874  ,  1.4285\n",
      "413\n",
      "0.024628118316375645  ,  0.7306  ,  1.6012\n",
      "0.05328280060538387  ,  0.7322  ,  1.597\n",
      "nan  ,  0.7292  ,  1.6047\n",
      "414\n",
      "0.059441381428310736  ,  0.4494  ,  1.1397\n",
      "0.008718869982173156  ,  0.5103  ,  1.0713\n",
      "-0.08580352045440431  ,  0.5101  ,  1.0714\n",
      "415\n",
      "0.2513691592220125  ,  0.9634  ,  1.5431\n",
      "-0.04043183790839184  ,  1.0004  ,  1.6581\n",
      "-0.028604585359694797  ,  0.9914  ,  1.6578\n",
      "416\n",
      "0.04436106647006619  ,  0.9048  ,  1.7467\n",
      "nan  ,  0.8946  ,  1.7756\n",
      "0.020374493945039346  ,  0.902  ,  1.7573\n",
      "417\n",
      "0.15697771136670896  ,  0.5921  ,  1.3945\n",
      "-0.03176526731819608  ,  0.5948  ,  1.42\n",
      "nan  ,  0.5942  ,  1.4205\n",
      "418\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "nan  ,  0.7009  ,  2.2035\n",
      "419\n",
      "0.18046808548278592  ,  0.9545  ,  1.7567\n",
      "0.009724696591287328  ,  0.9621  ,  1.7864\n",
      "nan  ,  0.9621  ,  1.7865\n",
      "420\n",
      "0.18628535788254713  ,  0.6479  ,  1.0514\n",
      "0.014971466035408977  ,  0.4712  ,  1.2209\n",
      "-0.005230700663738555  ,  0.4727  ,  1.2194\n",
      "421\n",
      "0.22072691851069884  ,  0.672  ,  0.9601\n",
      "0.1019867213125143  ,  0.4771  ,  1.1018\n",
      "0.006058349848908442  ,  0.4591  ,  1.1261\n",
      "422\n",
      "0.025208676677443975  ,  0.9447  ,  1.1068\n",
      "0.18712013897672952  ,  0.9373  ,  1.1899\n",
      "0.2926768942262275  ,  0.9405  ,  1.2268\n",
      "423\n",
      "0.1191420820443918  ,  0.7518  ,  1.6525\n",
      "0.10129138579599213  ,  0.79  ,  1.6197\n",
      "-0.03077053883098507  ,  0.8013  ,  1.6114\n",
      "424\n",
      "0.5529739373454897  ,  0.7406  ,  1.1759\n",
      "-0.0026426640441553333  ,  0.6415  ,  1.5078\n",
      "0.011991542680054281  ,  0.6392  ,  1.5105\n",
      "425\n",
      "0.1786041036891285  ,  1.3611  ,  1.7826\n",
      "-0.08063589458358454  ,  1.3895  ,  1.8169\n",
      "-0.25262793359847735  ,  1.3838  ,  1.8626\n",
      "426\n",
      "0.23373343297805438  ,  0.378  ,  1.0926\n",
      "-0.1381203129424992  ,  0.6635  ,  0.8828\n",
      "-0.054220405678612596  ,  0.6166  ,  0.9108\n",
      "427\n",
      "nan  ,  0.3444  ,  1.01\n",
      "0.06242683871357831  ,  0.3539  ,  1.0007\n",
      "0.03502183646327238  ,  0.3568  ,  0.999\n",
      "428\n",
      "0.6708129763408391  ,  0.5165  ,  0.8756\n",
      "nan  ,  0.6046  ,  1.3573\n",
      "nan  ,  0.6046  ,  1.3573\n",
      "429\n",
      "0.01651696494029556  ,  0.4606  ,  1.739\n",
      "0.14049525611930985  ,  0.6354  ,  1.6301\n",
      "nan  ,  0.4602  ,  1.7395\n",
      "430\n",
      "0.03921160546962951  ,  1.1214  ,  1.8402\n",
      "-0.022185243392986997  ,  1.157  ,  1.7377\n",
      "0.00814984866418898  ,  1.1563  ,  1.74\n",
      "431\n",
      "0.047637208462761774  ,  0.2628  ,  0.8954\n",
      "-0.004717208261433136  ,  0.3427  ,  0.8451\n",
      "0.06919266986416403  ,  0.2952  ,  0.8731\n",
      "432\n",
      "0.014350705957265703  ,  1.1677  ,  1.7461\n",
      "0.15433119092381756  ,  1.1699  ,  1.6505\n",
      "-0.04589213129008467  ,  1.17  ,  1.654\n",
      "433\n",
      "0.37458945031397617  ,  0.6995  ,  2.0061\n",
      "0.12045162787389133  ,  0.9513  ,  1.8787\n",
      "nan  ,  0.7174  ,  2.0959\n",
      "434\n",
      "0.04594205078552936  ,  0.2128  ,  0.7414\n",
      "0.06957336572868558  ,  0.3926  ,  0.629\n",
      "0.015575904720241755  ,  0.3885  ,  0.6325\n",
      "435\n",
      "0.010505291555586993  ,  0.5722  ,  1.0996\n",
      "nan  ,  0.5723  ,  1.0996\n",
      "nan  ,  0.5723  ,  1.0996\n",
      "436\n",
      "0.4047793626676567  ,  1.063  ,  1.4641\n",
      "0.23486439581892388  ,  0.9711  ,  1.8928\n",
      "-0.08160750392916455  ,  0.9767  ,  1.8904\n",
      "437\n",
      "0.16814093780549283  ,  0.5819  ,  1.1788\n",
      "0.012153879466358007  ,  0.5656  ,  1.2253\n",
      "nan  ,  0.5194  ,  1.2783\n",
      "438\n",
      "0.12241472944062011  ,  1.6274  ,  1.2733\n",
      "0.06645652363165072  ,  0.5575  ,  1.2658\n",
      "-0.02994675636233851  ,  0.5784  ,  1.2423\n",
      "439\n",
      "0.17579198504649757  ,  0.9303  ,  1.8682\n",
      "nan  ,  0.9366  ,  1.8831\n",
      "nan  ,  0.9366  ,  1.8831\n",
      "440\n",
      "0.13972625005737332  ,  0.397  ,  1.168\n",
      "0.0012398948750048282  ,  0.3609  ,  1.2092\n",
      "nan  ,  0.3609  ,  1.2092\n",
      "441\n",
      "0.045122004167396576  ,  1.3666  ,  0.9357\n",
      "0.0756012346962905  ,  0.7845  ,  1.239\n",
      "-0.23882867719368653  ,  0.7752  ,  1.2599\n",
      "442\n",
      "nan  ,  0.6747  ,  2.143\n",
      "0.02072196257329084  ,  0.6747  ,  2.1428\n",
      "nan  ,  0.6747  ,  2.143\n",
      "443\n",
      "0.19156168495309164  ,  1.3862  ,  1.63\n",
      "nan  ,  1.0097  ,  2.1361\n",
      "nan  ,  1.0097  ,  2.1361\n",
      "444\n",
      "0.5933167978457794  ,  0.6975  ,  1.3046\n",
      "-0.12094079360006428  ,  0.8049  ,  1.6417\n",
      "nan  ,  0.7703  ,  1.6875\n",
      "445\n",
      "0.06910530854468688  ,  0.3048  ,  1.2788\n",
      "0.001917876360364302  ,  0.3429  ,  1.2718\n",
      "nan  ,  0.2958  ,  1.2878\n",
      "446\n",
      "-0.011084672813960198  ,  0.6559  ,  2.2085\n",
      "0.041450346151635245  ,  0.6669  ,  2.1979\n",
      "nan  ,  0.6548  ,  2.2088\n",
      "447\n",
      "0.003054822992432967  ,  1.1489  ,  2.4875\n",
      "0.016762120553204907  ,  1.1642  ,  2.459\n",
      "0.13352519721420292  ,  1.1645  ,  2.4586\n",
      "448\n",
      "0.12097053230300048  ,  0.3347  ,  1.0308\n",
      "-0.09590851194572282  ,  0.623  ,  0.8524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.027296796066472506  ,  0.415  ,  0.9699\n",
      "449\n",
      "nan  ,  0.5997  ,  1.5091\n",
      "-0.006207686233725475  ,  0.5997  ,  1.5091\n",
      "nan  ,  0.5997  ,  1.5091\n",
      "450\n",
      "nan  ,  0.8619  ,  2.4096\n",
      "-0.11874150151156956  ,  0.8718  ,  2.4038\n",
      "nan  ,  0.8619  ,  2.4096\n",
      "451\n",
      "0.2759777899037144  ,  0.7452  ,  2.0169\n",
      "-0.006058061137183339  ,  0.753  ,  2.0771\n",
      "nan  ,  0.753  ,  2.0771\n",
      "452\n",
      "0.010040479904676184  ,  1.1734  ,  1.6495\n",
      "0.003747877513601382  ,  1.1717  ,  1.6423\n",
      "nan  ,  1.1735  ,  1.6495\n",
      "453\n",
      "0.412895602805217  ,  0.7628  ,  1.7836\n",
      "0.12805752966488446  ,  0.8191  ,  1.7892\n",
      "-0.08080757955691387  ,  0.819  ,  1.7894\n",
      "454\n",
      "0.24056307070703184  ,  0.6396  ,  1.8016\n",
      "-0.00047991617463583763  ,  0.5765  ,  1.9288\n",
      "nan  ,  0.5747  ,  1.9301\n",
      "455\n",
      "0.028000485853461436  ,  0.8737  ,  1.4293\n",
      "-0.0004263335924371125  ,  0.8751  ,  1.4052\n",
      "-0.07352367755687338  ,  0.891  ,  1.3562\n",
      "456\n",
      "-0.05220952730417377  ,  1.0301  ,  1.4759\n",
      "0.06111343670569902  ,  1.0164  ,  1.3482\n",
      "0.05798048766929192  ,  1.0172  ,  1.3791\n",
      "457\n",
      "0.13482209577345178  ,  0.8708  ,  0.9576\n",
      "0.058042666514017294  ,  0.5937  ,  1.1562\n",
      "0.06601863168850143  ,  0.6129  ,  1.1369\n",
      "458\n",
      "0.39542714438648674  ,  0.7684  ,  1.4489\n",
      "0.31613794294088055  ,  0.8045  ,  1.5795\n",
      "0.018131976665038775  ,  0.805  ,  1.6036\n",
      "459\n",
      "0.005089441714203869  ,  0.9004  ,  1.6364\n",
      "nan  ,  0.9004  ,  1.6364\n",
      "nan  ,  0.9004  ,  1.6364\n",
      "460\n",
      "0.2838395739877324  ,  0.5615  ,  1.3536\n",
      "-0.21833823592547197  ,  0.8238  ,  1.1181\n",
      "-0.08656708544066478  ,  0.6971  ,  1.2168\n",
      "461\n",
      "0.21074335607995273  ,  0.4635  ,  1.1482\n",
      "0.0368060034419587  ,  0.4747  ,  1.1766\n",
      "0.07299065194101997  ,  0.5295  ,  1.1144\n",
      "462\n",
      "0.09150114438554502  ,  0.6057  ,  1.4024\n",
      "0.08027684064275796  ,  0.6107  ,  1.3963\n",
      "-0.11609085705282961  ,  0.6133  ,  1.3946\n",
      "463\n",
      "0.22825689930281867  ,  1.0599  ,  0.893\n",
      "0.11775333240847258  ,  0.5939  ,  1.224\n",
      "0.008403491163852998  ,  0.6539  ,  1.1648\n",
      "464\n",
      "0.029712280597061692  ,  1.0654  ,  1.5533\n",
      "-0.1951925532325774  ,  1.1417  ,  1.3936\n",
      "-0.13902666042658585  ,  1.0932  ,  1.4632\n",
      "465\n",
      "0.04770199809588056  ,  0.9919  ,  1.5853\n",
      "0.09939630867503599  ,  1.0437  ,  1.3874\n",
      "-0.1632341421263383  ,  1.0483  ,  1.3799\n",
      "466\n",
      "0.17383029279463316  ,  0.5179  ,  1.4181\n",
      "0.006093547245566862  ,  0.5034  ,  1.4636\n",
      "nan  ,  0.5033  ,  1.4638\n",
      "467\n",
      "0.17903132193824817  ,  1.223  ,  1.7654\n",
      "0.02478450638351952  ,  1.2576  ,  1.846\n",
      "nan  ,  1.2576  ,  1.8461\n",
      "468\n",
      "-0.01602957082959503  ,  0.7066  ,  1.8552\n",
      "-0.01711020896565748  ,  0.7273  ,  1.8287\n",
      "-0.03812333493275025  ,  0.7282  ,  1.8275\n",
      "469\n",
      "0.347311928486915  ,  1.0931  ,  1.6603\n",
      "-0.010722861267113946  ,  0.7956  ,  2.0884\n",
      "nan  ,  0.7947  ,  2.0891\n",
      "470\n",
      "0.17081356742939813  ,  1.0733  ,  1.2171\n",
      "0.03619777834303493  ,  0.9278  ,  1.5031\n",
      "-0.024875965604671056  ,  0.9693  ,  1.4313\n",
      "471\n",
      "0.04543768428285151  ,  0.9402  ,  2.1436\n",
      "-0.0070245950434659876  ,  0.9403  ,  2.1437\n",
      "nan  ,  0.9403  ,  2.1437\n",
      "472\n",
      "0.18844392989711495  ,  0.5457  ,  1.3596\n",
      "0.014672085567322782  ,  0.5459  ,  1.3778\n",
      "-0.00025062979434073256  ,  0.5525  ,  1.3702\n",
      "473\n",
      "nan  ,  0.8222  ,  1.7002\n",
      "nan  ,  0.8222  ,  1.7002\n",
      "nan  ,  0.8222  ,  1.7002\n",
      "474\n",
      "0.2133222587284257  ,  1.6263  ,  1.8723\n",
      "0.07615555795518536  ,  1.4652  ,  2.4252\n",
      "nan  ,  1.4654  ,  2.4262\n",
      "475\n",
      "0.15191887926679443  ,  1.1466  ,  1.868\n",
      "0.2105481195936586  ,  1.154  ,  1.8869\n",
      "-0.02147206155497588  ,  1.1558  ,  1.9032\n",
      "476\n",
      "0.08361127765492768  ,  1.074  ,  2.1746\n",
      "0.0321302594939723  ,  1.0792  ,  2.1796\n",
      "nan  ,  1.0756  ,  2.1925\n",
      "477\n",
      "nan  ,  0.5335  ,  1.4008\n",
      "0.09065153487685597  ,  0.5335  ,  1.4008\n",
      "nan  ,  0.5335  ,  1.4008\n",
      "478\n",
      "-0.09527344093185322  ,  1.4364  ,  1.7452\n",
      "0.0017744794714488494  ,  1.2309  ,  2.0889\n",
      "0.1149491487475106  ,  1.2308  ,  2.085\n",
      "479\n",
      "0.09673737771017253  ,  0.7914  ,  1.7835\n",
      "0.07645892132286869  ,  0.802  ,  1.7797\n",
      "nan  ,  0.7886  ,  1.8062\n",
      "480\n",
      "0.5456525307893424  ,  1.8809  ,  2.1572\n",
      "0.027291324103879726  ,  2.05  ,  2.3624\n",
      "-0.40072827411864376  ,  2.0485  ,  2.362\n",
      "481\n",
      "-0.00327219147795023  ,  1.0687  ,  1.9403\n",
      "0.048752193663011006  ,  1.0701  ,  1.9303\n",
      "nan  ,  1.0687  ,  1.9416\n",
      "482\n",
      "-0.03416651382359072  ,  0.6347  ,  1.2943\n",
      "-0.023690904638730238  ,  0.6658  ,  1.2302\n",
      "0.09075841346090371  ,  0.6593  ,  1.2425\n",
      "483\n",
      "0.05917480401576064  ,  0.6912  ,  2.0872\n",
      "-0.010222718281056014  ,  0.7555  ,  2.0503\n",
      "nan  ,  0.6811  ,  2.1043\n",
      "484\n",
      "0.028881478100210214  ,  0.6997  ,  1.8092\n",
      "0.015644406884667054  ,  0.7033  ,  1.8058\n",
      "-0.04212589919721548  ,  0.7155  ,  1.7901\n",
      "485\n",
      "0.04631548535731396  ,  1.1178  ,  1.691\n",
      "-0.13866100144482266  ,  1.1221  ,  1.6538\n",
      "0.05810628613462449  ,  1.1221  ,  1.6537\n",
      "486\n",
      "0.14742298490067868  ,  0.8119  ,  1.6632\n",
      "0.12727530615898414  ,  0.815  ,  1.6779\n",
      "nan  ,  0.815  ,  1.6781\n",
      "487\n",
      "-0.0024332031842831496  ,  0.454  ,  1.7793\n",
      "0.06659442268068588  ,  0.4596  ,  1.774\n",
      "nan  ,  0.4539  ,  1.7793\n",
      "488\n",
      "0.10623054810856754  ,  0.9044  ,  1.4749\n",
      "0.02162306157999079  ,  0.9157  ,  1.4792\n",
      "0.08653607346513242  ,  0.8968  ,  1.503\n",
      "489\n",
      "0.055459987350061184  ,  1.8008  ,  2.5304\n",
      "0.046434762057223286  ,  1.7922  ,  2.5826\n",
      "nan  ,  1.7928  ,  2.5835\n",
      "490\n",
      "0.1810727297105898  ,  0.8868  ,  1.198\n",
      "0.19597696841520623  ,  0.87  ,  1.2087\n",
      "-0.0772529177061698  ,  0.6998  ,  1.4809\n",
      "491\n",
      "0.2763270249490503  ,  1.3636  ,  1.553\n",
      "0.03534472733395329  ,  1.4413  ,  2.0242\n",
      "-0.11594555711566659  ,  1.4417  ,  2.0194\n",
      "492\n",
      "nan  ,  0.5235  ,  1.5411\n",
      "nan  ,  0.5235  ,  1.5411\n",
      "nan  ,  0.5235  ,  1.5411\n",
      "493\n",
      "0.12834715748623504  ,  1.0064  ,  1.0021\n",
      "0.0897030298700382  ,  0.8022  ,  1.2774\n",
      "0.017277447812124484  ,  0.8022  ,  1.2774\n",
      "494\n",
      "0.06036192347027238  ,  0.4742  ,  1.3887\n",
      "0.08455803068394142  ,  0.4845  ,  1.3793\n",
      "0.1642005306878636  ,  0.4849  ,  1.3809\n",
      "495\n",
      "0.265366918463256  ,  0.9019  ,  1.352\n",
      "-0.03215194611290433  ,  0.4087  ,  1.4787\n",
      "nan  ,  0.4024  ,  1.4817\n",
      "496\n",
      "-0.05605128651272835  ,  1.331  ,  2.0869\n",
      "0.07468579219811615  ,  1.2677  ,  2.1835\n",
      "-0.004511178097014255  ,  1.2591  ,  2.2134\n",
      "497\n",
      "0.27883238659130233  ,  2.2385  ,  2.0605\n",
      "0.0018623938378380803  ,  0.7286  ,  1.3456\n",
      "-0.07297777899969826  ,  0.7345  ,  1.3338\n",
      "498\n",
      "0.00025669646796322877  ,  0.6865  ,  1.9907\n",
      "-0.004700327186477448  ,  0.6864  ,  1.9911\n",
      "nan  ,  0.6864  ,  1.9911\n",
      "499\n",
      "0.3412334263756961  ,  1.0124  ,  2.8122\n",
      "0.16372876502070777  ,  1.0706  ,  2.7479\n",
      "nan  ,  1.0159  ,  2.8372\n",
      "500\n",
      "0.2655085398877491  ,  2.4504  ,  2.1804\n",
      "nan  ,  0.7438  ,  2.1814\n",
      "nan  ,  0.7438  ,  2.1814\n",
      "501\n",
      "0.06955707216199239  ,  0.3281  ,  1.0923\n",
      "-0.003746365320418523  ,  0.403  ,  1.0402\n",
      "-0.12424486668847273  ,  0.4058  ,  1.0383\n",
      "502\n",
      "0.14310629080160814  ,  1.0667  ,  1.5739\n",
      "-0.05856428354935191  ,  1.1036  ,  1.6097\n",
      "0.058816679307557074  ,  1.1037  ,  1.6125\n",
      "503\n",
      "0.05538128950578509  ,  0.2951  ,  1.0712\n",
      "nan  ,  0.2951  ,  1.0713\n",
      "-0.25354633184547015  ,  0.3071  ,  1.0635\n",
      "504\n",
      "0.18768651047488363  ,  0.5211  ,  1.3762\n",
      "0.07794541664844623  ,  0.5943  ,  1.3017\n",
      "0.002819527149680909  ,  0.6578  ,  1.252\n",
      "505\n",
      "0.4070431203460184  ,  0.7573  ,  1.5501\n",
      "-0.17805974488854043  ,  0.8559  ,  1.4601\n",
      "-0.21875513012589934  ,  0.8459  ,  1.4697\n",
      "506\n",
      "0.12466508266434495  ,  1.4151  ,  2.2791\n",
      "0.25213992715024647  ,  1.4202  ,  2.1758\n",
      "0.04930194985184551  ,  1.4254  ,  2.242\n",
      "507\n",
      "0.30108221594438433  ,  0.9249  ,  1.1627\n",
      "0.019403124141593293  ,  0.8173  ,  1.5046\n",
      "-0.09814276636120917  ,  0.839  ,  1.4601\n",
      "508\n",
      "1.0005610827906047e-05  ,  0.9853  ,  2.0219\n",
      "-0.02585064038286014  ,  0.9907  ,  2.0075\n",
      "-0.0003957914482131328  ,  1.0157  ,  1.9614\n",
      "509\n",
      "0.49277962268225606  ,  0.6751  ,  1.5601\n",
      "0.024533836744838583  ,  0.6606  ,  1.7861\n",
      "nan  ,  0.6606  ,  1.7862\n",
      "510\n",
      "0.6151806993984442  ,  0.7516  ,  1.686\n",
      "0.14605855279019275  ,  0.7928  ,  1.8065\n",
      "0.04237555292897541  ,  0.7956  ,  1.8053\n",
      "511\n",
      "0.03885664530340672  ,  0.1325  ,  0.7825\n",
      "nan  ,  0.1237  ,  0.7853\n",
      "nan  ,  0.1237  ,  0.7853\n",
      "512\n",
      "0.06126938343687106  ,  0.4753  ,  1.2769\n",
      "-0.02388812390082843  ,  0.6263  ,  1.1343\n",
      "0.07769041107129522  ,  0.6094  ,  1.1478\n",
      "513\n",
      "0.032606496759579336  ,  0.8779  ,  1.5632\n",
      "nan  ,  0.8779  ,  1.5636\n",
      "nan  ,  0.8779  ,  1.5636\n",
      "514\n",
      "0.21677122773908766  ,  0.8545  ,  1.263\n",
      "-0.02074372530555624  ,  0.6021  ,  1.4487\n",
      "-0.0198984489382716  ,  0.614  ,  1.434\n",
      "515\n",
      "0.08619220410399682  ,  1.5047  ,  2.2834\n",
      "-0.3014715686308909  ,  1.5161  ,  2.2974\n",
      "-0.00994564724420775  ,  1.5038  ,  2.2545\n",
      "516\n",
      "-0.005822063333567146  ,  0.9795  ,  2.1574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan  ,  0.9795  ,  2.1574\n",
      "nan  ,  0.9795  ,  2.1574\n",
      "517\n",
      "0.27184296674257485  ,  1.4461  ,  2.1145\n",
      "0.02344514237868157  ,  1.394  ,  2.5135\n",
      "nan  ,  1.3938  ,  2.5139\n",
      "518\n",
      "0.06512364804403742  ,  0.7258  ,  1.6482\n",
      "-0.06230615631194752  ,  0.7832  ,  1.566\n",
      "-0.04036046650031648  ,  0.7752  ,  1.5761\n",
      "519\n",
      "0.11422815584863732  ,  0.4532  ,  1.0932\n",
      "0.14809055461181508  ,  0.4355  ,  1.0996\n",
      "0.03221675154133975  ,  0.4405  ,  1.1066\n",
      "520\n",
      "0.3096212712918488  ,  0.7954  ,  1.1155\n",
      "nan  ,  0.6501  ,  1.4329\n",
      "nan  ,  0.6501  ,  1.4329\n",
      "521\n",
      "0.10589852977043268  ,  0.8307  ,  1.2481\n",
      "0.027547680858945288  ,  0.7765  ,  1.2789\n",
      "0.022482489529065366  ,  0.7401  ,  1.3261\n",
      "522\n",
      "nan  ,  0.5151  ,  1.664\n",
      "0.327450732483569  ,  0.516  ,  1.6539\n",
      "nan  ,  0.5151  ,  1.664\n",
      "523\n",
      "0.30907585640961055  ,  0.6406  ,  1.7981\n",
      "0.017791090270985806  ,  0.6358  ,  1.9073\n",
      "-0.005145994145047776  ,  0.6566  ,  1.889\n",
      "524\n",
      "-0.009827259853223122  ,  0.7339  ,  1.927\n",
      "0.051474897305358105  ,  0.7365  ,  1.9208\n",
      "0.010291162212225915  ,  0.7423  ,  1.9168\n",
      "525\n",
      "nan  ,  0.56  ,  1.5225\n",
      "0.015497144725822616  ,  0.56  ,  1.5225\n",
      "nan  ,  0.56  ,  1.5225\n",
      "526\n",
      "-0.017910334781262062  ,  0.8762  ,  1.7056\n",
      "0.002439959717466529  ,  0.8968  ,  1.6562\n",
      "-0.058724938597971586  ,  0.8992  ,  1.6516\n",
      "527\n",
      "0.3947897695249011  ,  0.9843  ,  2.0914\n",
      "0.13991542038946386  ,  1.0063  ,  2.1472\n",
      "0.10590194634439704  ,  1.0093  ,  2.1476\n",
      "528\n",
      "0.04452787719004791  ,  0.489  ,  0.9509\n",
      "nan  ,  0.4804  ,  0.9696\n",
      "nan  ,  0.4804  ,  0.9696\n",
      "529\n",
      "0.029822746700195215  ,  1.2353  ,  1.704\n",
      "-0.09622678269199507  ,  1.2334  ,  1.6392\n",
      "0.01425541947719837  ,  1.2298  ,  1.6043\n",
      "530\n",
      "0.06821306631446297  ,  0.7511  ,  1.5444\n",
      "-0.019860233510087415  ,  0.821  ,  1.4779\n",
      "-0.07970649181775669  ,  0.8171  ,  1.4752\n",
      "531\n",
      "0.0006693567480898078  ,  1.5254  ,  2.2955\n",
      "nan  ,  1.5254  ,  2.2955\n",
      "nan  ,  1.5254  ,  2.2955\n",
      "532\n",
      "0.25778304384753153  ,  0.835  ,  1.2337\n",
      "-0.041059326615056374  ,  0.8365  ,  1.3574\n",
      "0.07955171432193252  ,  0.8319  ,  1.3642\n",
      "533\n",
      "0.2143102886547275  ,  0.6501  ,  1.888\n",
      "-0.00496032872809538  ,  0.6404  ,  1.9254\n",
      "nan  ,  0.6403  ,  1.9255\n",
      "534\n",
      "0.3305038904798363  ,  1.102  ,  2.3211\n",
      "-0.010511106672216403  ,  1.1146  ,  2.3719\n",
      "nan  ,  1.1142  ,  2.3723\n",
      "535\n",
      "0.5505888027503033  ,  1.1542  ,  2.5663\n",
      "0.21298903782723747  ,  1.2021  ,  2.8801\n",
      "nan  ,  1.2035  ,  2.8847\n",
      "536\n",
      "0.14549969172755248  ,  0.8445  ,  1.4203\n",
      "-0.0054598584051948834  ,  0.6937  ,  1.6342\n",
      "nan  ,  0.6937  ,  1.6342\n",
      "537\n",
      "0.003822903720214723  ,  0.8965  ,  1.7824\n",
      "0.05271922626801979  ,  0.9203  ,  1.7266\n",
      "-0.05264600015003283  ,  0.9164  ,  1.7373\n",
      "538\n",
      "0.02712526593311882  ,  0.3192  ,  0.9858\n",
      "-0.024757333781178337  ,  0.3327  ,  0.9757\n",
      "-0.01810241592504239  ,  0.4456  ,  0.8881\n",
      "539\n",
      "0.016255983598361067  ,  0.4929  ,  1.4861\n",
      "0.07786531840501135  ,  0.5567  ,  1.4284\n",
      "-0.008246736654026783  ,  0.4963  ,  1.4834\n",
      "540\n",
      "nan  ,  0.8215  ,  1.646\n",
      "0.10294331302071208  ,  0.8227  ,  1.6326\n",
      "0.10041506991765789  ,  0.8596  ,  1.5751\n",
      "541\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "nan  ,  0.6115  ,  1.6651\n",
      "542\n",
      "0.24377226590942735  ,  1.2741  ,  1.6566\n",
      "-0.07190262686398038  ,  1.2925  ,  1.6298\n",
      "0.1041691170414753  ,  1.2922  ,  1.6423\n",
      "543\n",
      "nan  ,  0.7713  ,  1.5901\n",
      "-0.03961290532195479  ,  0.846  ,  1.4652\n",
      "-0.03561117035849913  ,  0.8461  ,  1.465\n",
      "544\n",
      "0.018057098662580068  ,  0.8471  ,  1.0458\n",
      "0.013212852940419552  ,  0.632  ,  1.2281\n",
      "-0.19984788774141488  ,  0.7558  ,  1.0625\n",
      "545\n",
      "-0.0018623934915129683  ,  0.9477  ,  1.7129\n",
      "-0.0026770631616601774  ,  0.9742  ,  1.6271\n",
      "0.0015527203885777703  ,  0.97  ,  1.6375\n",
      "546\n",
      "-0.019872830628233633  ,  1.435  ,  1.7285\n",
      "0.023123682020877875  ,  0.515  ,  1.4463\n",
      "nan  ,  0.4942  ,  1.4661\n",
      "547\n",
      "0.023403608858551465  ,  0.6466  ,  1.6698\n",
      "-0.09014288839506975  ,  0.6513  ,  1.6696\n",
      "nan  ,  0.6447  ,  1.6726\n",
      "548\n",
      "0.3504092897889829  ,  1.1715  ,  1.9548\n",
      "0.18105801649311176  ,  1.1844  ,  1.9795\n",
      "nan  ,  1.187  ,  1.9868\n",
      "549\n",
      "-0.038292759589867116  ,  1.0035  ,  1.9039\n",
      "0.008760506379381937  ,  1.024  ,  1.8347\n",
      "-0.10273012270134098  ,  1.0244  ,  1.8322\n",
      "550\n",
      "0.32235456459795375  ,  1.2004  ,  1.8443\n",
      "-0.008010825213993723  ,  0.9617  ,  2.273\n",
      "nan  ,  0.9584  ,  2.2766\n",
      "551\n",
      "0.42628905287273644  ,  0.9584  ,  1.8694\n",
      "-0.21914918008030124  ,  1.0821  ,  1.6916\n",
      "0.05350139697320176  ,  1.0685  ,  1.7069\n",
      "552\n",
      "0.696266454202972  ,  0.6578  ,  0.9564\n",
      "nan  ,  0.5836  ,  1.509\n",
      "nan  ,  0.5836  ,  1.509\n",
      "553\n",
      "-0.0005065388543993611  ,  0.7889  ,  1.6718\n",
      "0.06511314112715628  ,  0.8216  ,  1.6055\n",
      "nan  ,  0.778  ,  1.6827\n",
      "554\n",
      "0.15527563054357535  ,  0.5478  ,  1.1739\n",
      "-0.25141787223002054  ,  0.7092  ,  0.9894\n",
      "-0.31629182841168774  ,  0.6487  ,  1.0411\n",
      "555\n",
      "0.010617843579173706  ,  0.3215  ,  1.0697\n",
      "0.12169926647083272  ,  0.3553  ,  1.0379\n",
      "-0.04841805986658708  ,  0.4207  ,  0.9997\n",
      "556\n",
      "0.283151997492046  ,  0.9759  ,  2.074\n",
      "0.08795630094177995  ,  0.9819  ,  2.0924\n",
      "nan  ,  0.9815  ,  2.095\n",
      "557\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "0.10814874820917662  ,  0.3683  ,  1.442\n",
      "nan  ,  0.3652  ,  1.4453\n",
      "558\n",
      "0.6586026955414447  ,  1.0972  ,  1.5383\n",
      "0.2985881820060075  ,  1.0955  ,  2.2654\n",
      "nan  ,  1.0988  ,  2.2739\n",
      "559\n",
      "0.019308799201469478  ,  0.8602  ,  2.0442\n",
      "0.20078757402911554  ,  0.878  ,  1.9512\n",
      "nan  ,  0.8602  ,  2.0446\n",
      "560\n",
      "0.15037501857386884  ,  0.5865  ,  1.725\n",
      "-0.008618841290983809  ,  0.5868  ,  1.7548\n",
      "nan  ,  0.5586  ,  1.7751\n",
      "561\n",
      "nan  ,  0.7374  ,  2.3059\n",
      "0.04713457498798312  ,  0.7755  ,  2.2716\n",
      "nan  ,  0.7374  ,  2.3059\n",
      "562\n",
      "0.06523108863372  ,  0.3903  ,  1.241\n",
      "0.12029673316708804  ,  0.3903  ,  1.2404\n",
      "0.056813035081717075  ,  0.3932  ,  1.2387\n",
      "563\n",
      "0.07670527262909413  ,  1.2261  ,  2.1339\n",
      "nan  ,  1.2265  ,  2.1348\n",
      "nan  ,  1.2265  ,  2.1348\n",
      "564\n",
      "0.11239786311730939  ,  0.4441  ,  1.0769\n",
      "0.015402577594822092  ,  0.5361  ,  0.9852\n",
      "-0.020250402666709313  ,  0.5224  ,  0.9995\n",
      "565\n",
      "0.32449808736596775  ,  0.7175  ,  1.5273\n",
      "-0.11652597107583519  ,  0.9396  ,  1.3173\n",
      "0.11153967527147428  ,  0.7904  ,  1.4656\n",
      "566\n",
      "0.2504330907118963  ,  0.7302  ,  1.4626\n",
      "-0.003508140240161795  ,  0.8368  ,  1.4136\n",
      "-0.12585844652797415  ,  0.7867  ,  1.4755\n",
      "567\n",
      "0.2891792417251829  ,  0.9067  ,  1.3857\n",
      "nan  ,  0.5278  ,  1.4074\n",
      "nan  ,  0.5278  ,  1.4074\n",
      "568\n",
      "0.04083384199594757  ,  0.748  ,  1.6777\n",
      "0.07112676490062252  ,  0.7685  ,  1.641\n",
      "-0.08195937378139613  ,  0.7641  ,  1.6487\n",
      "569\n",
      "0.6605040934359321  ,  0.8078  ,  1.8285\n",
      "nan  ,  0.9157  ,  2.3808\n",
      "nan  ,  0.9157  ,  2.3808\n",
      "570\n",
      "-0.06091473177436035  ,  1.1469  ,  1.7516\n",
      "-0.03064214481668343  ,  1.246  ,  1.4165\n",
      "0.06365009388235507  ,  1.1565  ,  1.6693\n",
      "571\n",
      "0.0485433828837251  ,  0.7099  ,  1.4906\n",
      "0.017181682792296978  ,  0.7106  ,  1.4937\n",
      "nan  ,  0.7106  ,  1.4938\n",
      "572\n",
      "0.4156096897976246  ,  0.7962  ,  2.0436\n",
      "nan  ,  0.8035  ,  2.0864\n",
      "nan  ,  0.8035  ,  2.0864\n",
      "573\n",
      "0.021579581972671118  ,  0.8015  ,  1.6702\n",
      "-0.043451105292641935  ,  0.8109  ,  1.6512\n",
      "0.02138170968217384  ,  0.8106  ,  1.6516\n",
      "574\n",
      "0.19073329586676202  ,  0.8064  ,  1.363\n",
      "0.05413682083613251  ,  0.7176  ,  1.5174\n",
      "0.021963262908245462  ,  0.7479  ,  1.4813\n",
      "575\n",
      "0.3115302957354007  ,  0.9462  ,  1.9593\n",
      "-0.01739775773291477  ,  0.953  ,  1.9766\n",
      "nan  ,  0.9529  ,  1.9767\n",
      "576\n",
      "0.15350900231970638  ,  0.685  ,  1.5278\n",
      "0.02590391760454365  ,  0.676  ,  1.5687\n",
      "-0.05101276960681996  ,  0.7057  ,  1.5341\n",
      "577\n",
      "0.06868042298697548  ,  0.6621  ,  1.6206\n",
      "nan  ,  0.6627  ,  1.6222\n",
      "nan  ,  0.6627  ,  1.6222\n",
      "578\n",
      "-0.2420523740976345  ,  1.4179  ,  1.4727\n",
      "0.09214386661819798  ,  1.388  ,  1.4718\n",
      "-0.0335523620150984  ,  1.3981  ,  1.4997\n",
      "579\n",
      "0.6253189831557862  ,  0.6568  ,  1.2591\n",
      "0.07433912422748248  ,  0.6648  ,  1.7863\n",
      "nan  ,  0.6545  ,  1.8015\n",
      "580\n",
      "0.5941452887997758  ,  1.0331  ,  1.8403\n",
      "0.07238151609552808  ,  1.0957  ,  2.3634\n",
      "nan  ,  1.0957  ,  2.3638\n",
      "581\n",
      "0.017141670903478453  ,  0.6695  ,  1.2349\n",
      "-0.007348164217796063  ,  0.68  ,  1.208\n",
      "-0.059174055906860805  ,  0.6806  ,  1.2065\n",
      "582\n",
      "nan  ,  0.556  ,  1.9375\n",
      "0.1289644679644867  ,  1.1262  ,  1.6213\n",
      "nan  ,  0.556  ,  1.9375\n",
      "583\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "nan  ,  1.0532  ,  2.0879\n",
      "584\n",
      "0.1263594334014889  ,  1.5849  ,  0.9791\n",
      "-0.04317297123933513  ,  0.3468  ,  0.9057\n",
      "-0.03960590027961634  ,  0.519  ,  0.7938\n",
      "585\n",
      "0.07521931988046887  ,  0.6077  ,  1.0575\n",
      "0.03852279147401207  ,  0.517  ,  1.1424\n",
      "-0.1030258453765403  ,  0.5119  ,  1.149\n",
      "586\n",
      "0.12449408551847652  ,  1.4626  ,  1.4442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12158921972475503  ,  1.3747  ,  2.0446\n",
      "0.040211785067090326  ,  1.3709  ,  2.0222\n",
      "587\n",
      "0.13272416844998575  ,  0.2837  ,  0.8121\n",
      "0.06942726537641622  ,  0.3491  ,  0.7466\n",
      "0.0492753706794032  ,  0.2322  ,  0.8008\n",
      "588\n",
      "0.30031895290934363  ,  0.9706  ,  1.3671\n",
      "0.022064769454729252  ,  0.9987  ,  1.5934\n",
      "0.15888714095604078  ,  0.9986  ,  1.5965\n",
      "589\n",
      "0.1786166175340586  ,  0.8571  ,  2.155\n",
      "0.23381776208516172  ,  0.8678  ,  2.1429\n",
      "0.012010980577565184  ,  0.8706  ,  2.1615\n",
      "590\n",
      "0.03701196490412444  ,  0.5692  ,  1.639\n",
      "-0.08423571311682994  ,  0.6684  ,  1.5442\n",
      "0.05701326211380936  ,  0.6653  ,  1.5467\n",
      "591\n",
      "0.02123077013652082  ,  0.5552  ,  1.1949\n",
      "-0.08775769287145359  ,  0.5769  ,  1.1536\n",
      "-0.08367167082665411  ,  0.5344  ,  1.1852\n",
      "592\n",
      "nan  ,  0.654  ,  1.2922\n",
      "nan  ,  0.654  ,  1.2922\n",
      "nan  ,  0.654  ,  1.2922\n",
      "593\n",
      "0.120561784854735  ,  0.9034  ,  1.7941\n",
      "0.1322102536320422  ,  0.92  ,  1.7448\n",
      "nan  ,  0.9043  ,  1.7954\n",
      "594\n",
      "0.18792478416204025  ,  0.648  ,  1.4284\n",
      "0.029590999329192454  ,  0.8082  ,  1.2361\n",
      "0.18115504226269405  ,  0.8203  ,  1.2228\n",
      "595\n",
      "0.5734236840597869  ,  0.7818  ,  1.873\n",
      "0.09836749022352534  ,  0.8812  ,  2.0709\n",
      "-0.12087882978931057  ,  0.8523  ,  2.1191\n",
      "596\n",
      "-0.04694078851563562  ,  1.1435  ,  1.8026\n",
      "-0.22085567112839355  ,  1.1503  ,  1.7783\n",
      "0.01836793200989558  ,  1.1461  ,  1.7307\n",
      "597\n",
      "0.25346685140772607  ,  0.5895  ,  1.6588\n",
      "nan  ,  0.5984  ,  1.6989\n",
      "nan  ,  0.5984  ,  1.6989\n",
      "598\n",
      "0.12928753388440792  ,  1.1135  ,  2.1659\n",
      "-0.14775821301586226  ,  1.1116  ,  2.1968\n",
      "-0.05936325484731317  ,  1.1153  ,  2.1833\n",
      "599\n",
      "0.020028612397628313  ,  1.8422  ,  2.1464\n",
      "0.11300656950097052  ,  1.5139  ,  2.4797\n",
      "nan  ,  1.52  ,  2.5242\n",
      "600\n",
      "0.09603062505085384  ,  1.045  ,  1.3762\n",
      "0.2112449036951952  ,  1.0455  ,  1.3752\n",
      "nan  ,  1.0466  ,  1.3783\n",
      "601\n",
      "0.17487648393668076  ,  0.8173  ,  1.8209\n",
      "0.0471013564674379  ,  0.8544  ,  1.7708\n",
      "0.028165724216422994  ,  0.8285  ,  1.8137\n",
      "602\n",
      "-0.016933066104489233  ,  0.9659  ,  1.6911\n",
      "-0.07092886240677464  ,  0.9691  ,  1.6855\n",
      "0.023431944781462814  ,  0.9681  ,  1.6807\n",
      "603\n",
      "0.014042222603686844  ,  0.7078  ,  1.0957\n",
      "-0.08421357699946402  ,  0.7084  ,  1.1088\n",
      "-0.04159591020162772  ,  0.7137  ,  1.0558\n",
      "604\n",
      "0.17052156761198925  ,  1.2004  ,  1.6338\n",
      "0.03585870188540265  ,  1.2078  ,  1.6617\n",
      "0.12210347666508266  ,  1.2049  ,  1.6308\n",
      "605\n",
      "0.5074421105744225  ,  0.7672  ,  1.927\n",
      "0.058382321353744236  ,  0.7858  ,  1.9814\n",
      "0.015739615723937263  ,  0.7873  ,  1.98\n",
      "606\n",
      "0.23761028635214262  ,  0.9181  ,  2.0911\n",
      "nan  ,  0.9249  ,  2.1226\n",
      "nan  ,  0.9249  ,  2.1226\n",
      "607\n",
      "0.00714114156804315  ,  0.5444  ,  1.264\n",
      "-0.06050624785627363  ,  0.57  ,  1.2225\n",
      "0.020426494771771143  ,  0.572  ,  1.2173\n",
      "608\n",
      "0.18922199608609447  ,  1.0973  ,  1.0019\n",
      "-0.00499723058573873  ,  0.8472  ,  1.4587\n",
      "nan  ,  0.8378  ,  1.4816\n",
      "609\n",
      "-0.03998076830245969  ,  0.656  ,  1.3713\n",
      "-0.04390142884505652  ,  0.6784  ,  1.3206\n",
      "0.06868464184582371  ,  0.6784  ,  1.3206\n",
      "610\n",
      "0.3000927480122051  ,  1.0624  ,  0.9439\n",
      "0.03465131668692998  ,  0.4407  ,  1.2684\n",
      "0.04096111470283932  ,  0.4407  ,  1.2684\n",
      "611\n",
      "0.02930122701436382  ,  1.1222  ,  1.8305\n",
      "0.018419397629694946  ,  1.13  ,  1.7874\n",
      "0.0069529502971845455  ,  1.1286  ,  1.7929\n",
      "612\n",
      "nan  ,  1.5086  ,  1.9818\n",
      "-0.010657934852623981  ,  1.5016  ,  1.9627\n",
      "-0.08815552058243473  ,  1.5014  ,  1.9597\n",
      "613\n",
      "0.06891973968398689  ,  0.7994  ,  2.0011\n",
      "0.07795244902419153  ,  0.8217  ,  1.9744\n",
      "0.041097889015364875  ,  0.8217  ,  1.9744\n",
      "614\n",
      "0.6605093362878042  ,  0.8134  ,  1.3013\n",
      "nan  ,  0.5544  ,  1.5537\n",
      "nan  ,  0.5544  ,  1.5537\n",
      "615\n",
      "0.22480449760144522  ,  0.0828  ,  0.4741\n",
      "-0.041444273768781306  ,  0.2562  ,  0.4187\n",
      "-0.14321843924995042  ,  0.1952  ,  0.4373\n",
      "616\n",
      "0.052806899468737276  ,  1.0056  ,  1.5775\n",
      "-0.06273588713822431  ,  1.0301  ,  1.4644\n",
      "-0.12968820589441526  ,  1.0305  ,  1.4619\n",
      "617\n",
      "0.005814249078317828  ,  1.0332  ,  2.2004\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "nan  ,  1.0333  ,  2.2012\n",
      "618\n",
      "0.18701023692888574  ,  1.1008  ,  2.2249\n",
      "0.018735568229832005  ,  1.1023  ,  2.2288\n",
      "0.018537003537938735  ,  1.1107  ,  2.2086\n",
      "619\n",
      "0.372848286979385  ,  0.9893  ,  1.661\n",
      "0.22840062807907832  ,  1.0129  ,  1.6929\n",
      "0.02801119640006846  ,  1.0208  ,  1.7173\n",
      "620\n",
      "0.1268396116244693  ,  0.819  ,  1.7774\n",
      "0.052298108611275755  ,  0.8192  ,  1.7777\n",
      "nan  ,  0.8192  ,  1.7778\n",
      "621\n",
      "0.40417548735858133  ,  0.991  ,  1.3697\n",
      "0.14253828661994702  ,  0.8896  ,  1.825\n",
      "nan  ,  0.8865  ,  1.8439\n",
      "622\n",
      "0.13056593790799978  ,  0.8684  ,  2.0109\n",
      "0.24227331193635668  ,  0.8724  ,  1.9858\n",
      "nan  ,  0.8699  ,  2.0202\n",
      "623\n",
      "0.06765851310564211  ,  0.7049  ,  1.5478\n",
      "0.1844334090473409  ,  0.7051  ,  1.543\n",
      "nan  ,  0.705  ,  1.5479\n",
      "624\n",
      "0.11599964166528828  ,  0.8459  ,  1.544\n",
      "-0.018682781636319763  ,  0.8578  ,  1.5742\n",
      "-0.11953046344391258  ,  0.8772  ,  1.5169\n",
      "625\n",
      "0.03627130942262489  ,  0.5389  ,  1.7075\n",
      "0.00014225974749465162  ,  0.5148  ,  1.7248\n",
      "nan  ,  0.5148  ,  1.7248\n",
      "626\n",
      "0.052740002900010186  ,  0.4322  ,  1.3491\n",
      "0.0979493433194518  ,  0.4515  ,  1.3289\n",
      "nan  ,  0.4256  ,  1.3574\n",
      "627\n",
      "0.0814392213424848  ,  0.9514  ,  1.7432\n",
      "0.03142545433316004  ,  0.8734  ,  1.8914\n",
      "0.06272366509647917  ,  0.8753  ,  1.8901\n",
      "628\n",
      "0.17974742825519352  ,  1.6407  ,  1.0919\n",
      "0.005823194217981542  ,  0.742  ,  1.2503\n",
      "0.04302759570454688  ,  0.7404  ,  1.2535\n",
      "629\n",
      "0.3271737543413955  ,  0.8639  ,  1.2357\n",
      "-0.043784370752493355  ,  0.8733  ,  1.4924\n",
      "0.12476488300126017  ,  0.8837  ,  1.456\n",
      "630\n",
      "0.5428027291589784  ,  1.2481  ,  2.3367\n",
      "nan  ,  1.3036  ,  2.4833\n",
      "nan  ,  1.3036  ,  2.4833\n",
      "631\n",
      "0.7084443529592268  ,  1.1426  ,  1.9018\n",
      "0.11188034635276442  ,  1.3636  ,  2.383\n",
      "0.06996628637376381  ,  1.3662  ,  2.387\n",
      "632\n",
      "0.024865004848863066  ,  0.5178  ,  1.5603\n",
      "-0.028488272014447102  ,  0.5064  ,  1.5652\n",
      "nan  ,  0.5064  ,  1.5653\n",
      "633\n",
      "0.010355370395030846  ,  0.9488  ,  1.722\n",
      "-0.1657021119355917  ,  0.9511  ,  1.7274\n",
      "-0.08619844304837604  ,  0.959  ,  1.6946\n",
      "634\n",
      "0.0034227221064319835  ,  0.7329  ,  1.4779\n",
      "-0.03632939043432954  ,  0.7657  ,  1.419\n",
      "-0.0014906888298244934  ,  0.7555  ,  1.4343\n",
      "635\n",
      "0.24694460349298342  ,  0.7249  ,  1.6462\n",
      "0.11040689839284085  ,  0.8037  ,  1.6221\n",
      "0.07437073404479572  ,  0.7594  ,  1.6855\n",
      "636\n",
      "0.3943533048053886  ,  1.3979  ,  3.575\n",
      "-0.028762435443966214  ,  1.5452  ,  3.8181\n",
      "-0.07030487839463007  ,  1.5469  ,  3.8162\n",
      "637\n",
      "0.3742516714406348  ,  1.2185  ,  1.9811\n",
      "0.0007616763826231983  ,  1.2826  ,  2.1288\n",
      "nan  ,  1.2821  ,  2.1346\n",
      "638\n",
      "0.13375410174420302  ,  0.8473  ,  1.3933\n",
      "-0.07536186846013361  ,  0.8588  ,  1.364\n",
      "-0.11821032089954016  ,  0.8505  ,  1.3937\n",
      "639\n",
      "0.3821339984572466  ,  1.6723  ,  2.154\n",
      "0.18315276702902528  ,  1.7943  ,  2.3806\n",
      "nan  ,  1.8033  ,  2.3966\n",
      "640\n",
      "0.0889745633721867  ,  1.0934  ,  1.5874\n",
      "-0.214221449185485  ,  1.0954  ,  1.6994\n",
      "nan  ,  1.085  ,  1.7216\n",
      "641\n",
      "-0.010867405417416839  ,  0.7926  ,  1.5633\n",
      "0.12031148111688074  ,  0.8333  ,  1.4654\n",
      "-0.09451758698041629  ,  0.8232  ,  1.4893\n",
      "642\n",
      "0.21836983203469043  ,  1.107  ,  0.9188\n",
      "-0.218134652215137  ,  1.0595  ,  1.2903\n",
      "-0.16087694496666263  ,  1.0582  ,  1.2978\n",
      "643\n",
      "0.059543609146712584  ,  1.1682  ,  1.4285\n",
      "0.2535918587643215  ,  1.1551  ,  1.3837\n",
      "0.005504516418319078  ,  1.1537  ,  1.3629\n",
      "644\n",
      "0.24389055957439157  ,  0.8132  ,  1.3235\n",
      "-0.01769929705125899  ,  0.8429  ,  1.3157\n",
      "-0.0986237305427724  ,  0.8382  ,  1.3241\n",
      "645\n",
      "0.21993647021771387  ,  0.8763  ,  1.2585\n",
      "0.048752196177371906  ,  0.8478  ,  1.4201\n",
      "-0.07027606034749667  ,  0.8534  ,  1.4035\n",
      "646\n",
      "0.0058567022332553335  ,  1.045  ,  1.4021\n",
      "-0.07478171320065623  ,  1.0144  ,  1.4693\n",
      "0.07603190017829435  ,  1.0165  ,  1.4489\n",
      "647\n",
      "-0.047968348923284436  ,  0.5789  ,  1.2544\n",
      "nan  ,  0.556  ,  1.2765\n",
      "nan  ,  0.556  ,  1.2765\n",
      "648\n",
      "0.08330457039595332  ,  1.003  ,  1.2511\n",
      "0.2009465325247871  ,  1.0225  ,  1.067\n",
      "0.28572059727296784  ,  1.0232  ,  1.0709\n",
      "649\n",
      "0.1449284028520839  ,  0.738  ,  0.9531\n",
      "-0.042452565161397685  ,  0.7517  ,  0.9826\n",
      "-0.004565205091884912  ,  0.7445  ,  1.0157\n",
      "650\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "0.013820464021162151  ,  0.4576  ,  1.3369\n",
      "nan  ,  0.4569  ,  1.3377\n",
      "651\n",
      "0.2833160880933772  ,  1.0012  ,  1.6683\n",
      "nan  ,  1.0137  ,  1.7047\n",
      "nan  ,  1.0137  ,  1.7047\n",
      "652\n",
      "0.21669753278594026  ,  0.7859  ,  1.2291\n",
      "-0.08322349921703968  ,  0.8186  ,  1.2405\n",
      "-0.19990321839242384  ,  0.7933  ,  1.2742\n",
      "653\n",
      "0.00470251714957719  ,  0.7916  ,  1.4854\n",
      "0.04137224861280577  ,  0.8039  ,  1.4631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.009146948719744523  ,  0.8113  ,  1.4526\n",
      "654\n",
      "0.1860339720727261  ,  0.8129  ,  1.3575\n",
      "0.08361860803993369  ,  0.7818  ,  1.4313\n",
      "0.020958070739997323  ,  0.7764  ,  1.4392\n",
      "655\n",
      "0.07480390968982673  ,  0.589  ,  1.3014\n",
      "0.018585585352919824  ,  0.5956  ,  1.2938\n",
      "-0.03688874796652585  ,  0.5857  ,  1.3006\n",
      "656\n",
      "0.027527665166441142  ,  0.53  ,  1.1944\n",
      "0.005168816924472015  ,  0.531  ,  1.1882\n",
      "0.04567731258617822  ,  0.5311  ,  1.1881\n",
      "657\n",
      "0.11752862952266604  ,  0.3541  ,  1.3251\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "nan  ,  0.3225  ,  1.3507\n",
      "658\n",
      "0.15401789893362505  ,  0.5658  ,  1.1233\n",
      "0.06706454234497827  ,  0.7824  ,  0.8895\n",
      "0.21648004352477124  ,  0.7954  ,  0.8783\n",
      "659\n",
      "-0.015181391303149949  ,  0.5391  ,  1.4776\n",
      "0.128440327234144  ,  0.5742  ,  1.4274\n",
      "0.05386254687573414  ,  0.5801  ,  1.4338\n",
      "660\n",
      "0.13286469160485542  ,  0.3589  ,  1.0247\n",
      "0.06455449695038486  ,  0.3984  ,  1.0082\n",
      "0.046378923876586736  ,  0.377  ,  1.0247\n",
      "661\n",
      "0.06775260468650485  ,  1.0758  ,  1.101\n",
      "-0.12949202283921968  ,  0.9447  ,  1.4223\n",
      "-0.05546271404095845  ,  0.9423  ,  1.4337\n",
      "662\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "nan  ,  0.3325  ,  0.9675\n",
      "663\n",
      "0.06832843118062733  ,  1.897  ,  1.1647\n",
      "-0.004972059415786352  ,  0.3355  ,  0.7321\n",
      "0.06866568138946365  ,  0.3298  ,  0.7363\n",
      "664\n",
      "0.005794621848642668  ,  0.5323  ,  1.1381\n",
      "0.011720403906490866  ,  0.6083  ,  1.0221\n",
      "-0.03020695386788374  ,  0.6083  ,  1.0224\n",
      "665\n",
      "0.3163787338874725  ,  0.9563  ,  1.3201\n",
      "0.0721057054811671  ,  0.9754  ,  1.444\n",
      "0.10378275777342305  ,  0.976  ,  1.4453\n",
      "666\n",
      "0.004033766907705511  ,  0.2112  ,  0.8505\n",
      "nan  ,  0.2033  ,  0.8528\n",
      "nan  ,  0.2033  ,  0.8528\n",
      "667\n",
      "0.02159541532017677  ,  1.0723  ,  1.7563\n",
      "nan  ,  1.072  ,  1.7601\n",
      "nan  ,  1.072  ,  1.7601\n",
      "668\n",
      "0.08581187320872952  ,  0.7875  ,  1.452\n",
      "0.03986004068221632  ,  0.7975  ,  1.4372\n",
      "0.029887060812590804  ,  0.7993  ,  1.4334\n",
      "669\n",
      "-0.05381840462871921  ,  1.084  ,  1.4884\n",
      "-0.0027918105158646622  ,  1.0938  ,  1.396\n",
      "-0.04544395910934952  ,  1.0918  ,  1.3997\n",
      "670\n",
      "0.10554368197117792  ,  0.6744  ,  1.3207\n",
      "-0.0530238040235617  ,  0.6825  ,  1.3007\n",
      "-0.003161720910192803  ,  0.6826  ,  1.3\n",
      "671\n",
      "nan  ,  0.485  ,  1.2857\n",
      "nan  ,  0.485  ,  1.2857\n",
      "nan  ,  0.485  ,  1.2857\n",
      "672\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "nan  ,  0.4958  ,  1.1528\n",
      "673\n",
      "0.0053974986983363425  ,  1.3078  ,  1.8048\n",
      "0.1267954644845591  ,  1.3102  ,  1.8155\n",
      "0.012382936836929101  ,  1.3102  ,  1.8143\n",
      "674\n",
      "0.04778063585522842  ,  0.5739  ,  1.1131\n",
      "nan  ,  0.5411  ,  1.1629\n",
      "nan  ,  0.5411  ,  1.1629\n",
      "675\n",
      "0.033862431843574695  ,  1.1098  ,  1.5097\n",
      "0.23723352115098084  ,  1.1059  ,  1.4823\n",
      "-0.16517193724864535  ,  1.1033  ,  1.4647\n",
      "676\n",
      "0.08954421822085565  ,  0.6143  ,  1.3429\n",
      "0.012509502387822356  ,  0.5835  ,  1.397\n",
      "nan  ,  0.5835  ,  1.397\n",
      "677\n",
      "0.09545813705202143  ,  1.1952  ,  1.4596\n",
      "0.07828132764676238  ,  1.2016  ,  1.471\n",
      "0.0106551162117146  ,  1.2027  ,  1.4727\n",
      "678\n",
      "-0.09117613583269403  ,  0.9846  ,  1.3896\n",
      "0.02521073674995114  ,  0.968  ,  1.247\n",
      "0.06966711387700188  ,  0.9681  ,  1.2435\n",
      "679\n",
      "0.023994877292775458  ,  1.1191  ,  1.3175\n",
      "nan  ,  1.0945  ,  1.5329\n",
      "nan  ,  1.0945  ,  1.5329\n",
      "680\n",
      "0.11052697093278399  ,  0.6295  ,  1.2373\n",
      "-0.0655955065665929  ,  0.7486  ,  1.0459\n",
      "0.06879192594391231  ,  0.7467  ,  1.0485\n",
      "681\n",
      "0.08132536520305463  ,  1.3023  ,  1.5011\n",
      "0.24873634448396192  ,  1.3206  ,  1.5372\n",
      "0.1967021091719246  ,  1.3183  ,  1.5182\n",
      "682\n",
      "0.06708031375089948  ,  0.9311  ,  1.5984\n",
      "0.009883815962833312  ,  0.968  ,  1.53\n",
      "-0.061457347675721044  ,  0.9665  ,  1.5334\n",
      "683\n",
      "-0.11967735218039117  ,  1.0768  ,  1.6127\n",
      "-0.06760252343047173  ,  1.1225  ,  1.2979\n",
      "-0.03927253875807187  ,  1.1217  ,  1.2982\n",
      "684\n",
      "0.09790719727923629  ,  0.4308  ,  0.9745\n",
      "-0.017044251623821283  ,  0.4585  ,  0.9408\n",
      "0.16606009039521807  ,  0.4421  ,  0.9643\n",
      "685\n",
      "0.02737866466298424  ,  0.4499  ,  1.0883\n",
      "0.056938886565558545  ,  0.4799  ,  1.0512\n",
      "-0.05379621902824723  ,  0.4786  ,  1.0537\n",
      "686\n",
      "0.24529656164530222  ,  0.7868  ,  1.1162\n",
      "-0.11505881352735131  ,  0.8796  ,  1.0274\n",
      "0.29073761931507947  ,  0.8621  ,  1.0539\n",
      "687\n",
      "-0.27559079653592244  ,  1.4793  ,  1.2719\n",
      "-0.44757662141788646  ,  1.4845  ,  1.4515\n",
      "0.492260454500964  ,  1.505  ,  1.5571\n",
      "688\n",
      "-0.10383454990212442  ,  1.0418  ,  0.9449\n",
      "0.06652336676309362  ,  0.9801  ,  1.0176\n",
      "0.14231030414412765  ,  0.9806  ,  1.0188\n",
      "689\n",
      "0.1553228189503263  ,  0.9243  ,  0.8377\n",
      "nan  ,  0.526  ,  1.1493\n",
      "nan  ,  0.526  ,  1.1493\n",
      "690\n",
      "0.04148798458325279  ,  0.4916  ,  1.2398\n",
      "nan  ,  0.4915  ,  1.2401\n",
      "nan  ,  0.4915  ,  1.2401\n",
      "691\n",
      "0.042206087492169364  ,  0.6262  ,  1.0632\n",
      "0.0472698667220587  ,  0.5763  ,  1.106\n",
      "0.007816827627101744  ,  0.6089  ,  1.0758\n",
      "692\n",
      "0.38683204525611165  ,  0.7541  ,  1.2506\n",
      "-0.11647092866041053  ,  0.7954  ,  1.2313\n",
      "-0.19074694038643353  ,  0.7699  ,  1.2855\n",
      "693\n",
      "-0.003566212437030807  ,  0.3157  ,  0.9632\n",
      "nan  ,  0.3157  ,  0.9632\n",
      "nan  ,  0.3157  ,  0.9632\n",
      "694\n",
      "0.06451950139281268  ,  0.9367  ,  1.2732\n",
      "-0.3352509981214304  ,  0.9416  ,  1.1996\n",
      "0.27236437871012115  ,  0.9407  ,  1.2061\n",
      "695\n",
      "0.10231831976238803  ,  0.6976  ,  1.1455\n",
      "-0.024382530483575936  ,  0.7254  ,  1.079\n",
      "0.01751753983587634  ,  0.727  ,  1.0771\n",
      "696\n",
      "0.04881696676778611  ,  0.7638  ,  1.3178\n",
      "-0.03550531776869513  ,  0.8221  ,  1.2115\n",
      "-0.036764873227151995  ,  0.8178  ,  1.2195\n",
      "697\n",
      "-0.01853553300578213  ,  0.3429  ,  1.1494\n",
      "nan  ,  0.3362  ,  1.1518\n",
      "nan  ,  0.3362  ,  1.1518\n",
      "698\n",
      "nan  ,  0.522  ,  1.2622\n",
      "nan  ,  0.522  ,  1.2622\n",
      "nan  ,  0.522  ,  1.2622\n",
      "699\n",
      "0.12094039029807047  ,  0.5383  ,  1.2047\n",
      "0.039972257983264044  ,  0.6793  ,  1.0587\n",
      "-0.01300638017653797  ,  0.6534  ,  1.0869\n",
      "700\n",
      "-0.018335132640574077  ,  0.3587  ,  1.0608\n",
      "-0.06550138254735159  ,  0.5067  ,  0.9421\n",
      "-0.08414803747422787  ,  0.5087  ,  0.9401\n",
      "701\n",
      "0.19747594111911643  ,  0.942  ,  1.1361\n",
      "-0.1042536200794593  ,  0.96  ,  1.1516\n",
      "-0.042244471435535794  ,  0.9596  ,  1.1496\n",
      "702\n",
      "-0.0036706048163460906  ,  0.2062  ,  0.9768\n",
      "-0.028611611003666854  ,  0.2225  ,  0.9695\n",
      "0.009276661623472125  ,  0.2443  ,  0.9591\n",
      "703\n",
      "0.009534467776843239  ,  0.6081  ,  1.3246\n",
      "nan  ,  0.6046  ,  1.3289\n",
      "nan  ,  0.6046  ,  1.3289\n",
      "704\n",
      "0.3087996260440524  ,  1.1378  ,  1.372\n",
      "nan  ,  1.191  ,  1.4689\n",
      "nan  ,  1.191  ,  1.4689\n",
      "705\n",
      "0.4282969984215798  ,  0.6329  ,  1.1045\n",
      "nan  ,  0.6675  ,  1.2446\n",
      "nan  ,  0.6675  ,  1.2446\n",
      "706\n",
      "0.2498852880475722  ,  1.2444  ,  1.789\n",
      "-0.03287685923584918  ,  1.2498  ,  1.9636\n",
      "nan  ,  1.2497  ,  1.9638\n",
      "707\n",
      "0.2255138836533783  ,  0.8189  ,  1.6606\n",
      "nan  ,  0.822  ,  1.673\n",
      "nan  ,  0.822  ,  1.673\n",
      "708\n",
      "0.0202800859546231  ,  0.6881  ,  1.2714\n",
      "nan  ,  0.6219  ,  1.3491\n",
      "nan  ,  0.6219  ,  1.3491\n",
      "709\n",
      "0.0792463950572655  ,  0.4964  ,  0.9621\n",
      "0.09799833857627108  ,  0.5665  ,  0.8277\n",
      "-0.21420215744406956  ,  0.5732  ,  0.8184\n",
      "710\n",
      "-0.18002113170338896  ,  3.5793  ,  2.3501\n",
      "-0.16380428217767257  ,  0.6281  ,  0.9616\n",
      "-0.12558762846894062  ,  0.5535  ,  1.0179\n",
      "711\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "nan  ,  0.9033  ,  1.5336\n",
      "712\n",
      "0.29830371859561167  ,  1.199  ,  1.3256\n",
      "nan  ,  1.2859  ,  1.4483\n",
      "nan  ,  1.2859  ,  1.4483\n",
      "713\n",
      "0.048566716736352045  ,  1.06  ,  1.252\n",
      "-0.15472187357004816  ,  1.132  ,  1.0214\n",
      "0.1885498503810741  ,  1.115  ,  1.0356\n",
      "714\n",
      "0.11660937167883634  ,  1.0997  ,  1.6365\n",
      "nan  ,  1.1045  ,  1.679\n",
      "nan  ,  1.1045  ,  1.679\n",
      "715\n",
      "0.052097438395493675  ,  0.9032  ,  1.5759\n",
      "-0.167528020341162  ,  1.0752  ,  1.2343\n",
      "0.054808333307874754  ,  1.0453  ,  1.2748\n",
      "716\n",
      "-0.044570312844862285  ,  0.8369  ,  1.5789\n",
      "0.09142127421472046  ,  0.8823  ,  1.462\n",
      "-0.026998147409780085  ,  0.895  ,  1.4419\n",
      "717\n",
      "-0.01872623962125807  ,  0.5759  ,  1.1144\n",
      "0.026899560817560703  ,  0.6304  ,  0.9975\n",
      "0.018045104440128374  ,  0.6311  ,  0.9963\n",
      "718\n",
      "-0.016074544041362295  ,  0.4576  ,  1.2087\n",
      "-0.012656632756465416  ,  0.5771  ,  1.0904\n",
      "0.015922452014758372  ,  0.5778  ,  1.0896\n",
      "719\n",
      "0.03140541137982977  ,  1.1322  ,  1.4711\n",
      "0.003629890773179218  ,  1.1323  ,  1.4711\n",
      "nan  ,  1.1323  ,  1.4711\n",
      "720\n",
      "0.09491203788272085  ,  1.114  ,  1.0644\n",
      "0.011774578481274948  ,  1.0074  ,  1.3908\n",
      "-0.21213692934944764  ,  1.0073  ,  1.3914\n",
      "721\n",
      "0.04291416998447027  ,  1.1165  ,  1.5428\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "nan  ,  1.1171  ,  1.5453\n",
      "722\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "nan  ,  0.4516  ,  1.5059\n",
      "723\n",
      "-0.041557898589530184  ,  0.7598  ,  1.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12207902035929018  ,  0.7727  ,  1.3232\n",
      "0.017285147627839628  ,  0.7774  ,  1.3058\n",
      "724\n",
      "-0.015691739344083924  ,  0.7831  ,  1.2912\n",
      "0.18016928937236903  ,  0.822  ,  1.1564\n",
      "0.0020449607079489063  ,  0.827  ,  1.1489\n",
      "725\n",
      "0.04280047900954198  ,  0.7502  ,  1.0938\n",
      "0.10834340296949724  ,  0.6998  ,  1.0857\n",
      "-0.09906412047849  ,  0.6997  ,  1.0877\n",
      "726\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "nan  ,  0.4647  ,  1.5586\n",
      "727\n",
      "nan  ,  0.5337  ,  1.277\n",
      "nan  ,  0.5337  ,  1.277\n",
      "nan  ,  0.5337  ,  1.277\n",
      "728\n",
      "0.03197283737568707  ,  0.7649  ,  1.3442\n",
      "0.06371159912623023  ,  0.8231  ,  1.2397\n",
      "-0.026703568829901353  ,  0.8183  ,  1.2493\n",
      "729\n",
      "-0.0021030586837172435  ,  0.6409  ,  1.059\n",
      "nan  ,  0.6408  ,  1.0592\n",
      "nan  ,  0.6408  ,  1.0592\n",
      "730\n",
      "0.08513313076989891  ,  0.5807  ,  1.2706\n",
      "-0.05581791212434881  ,  0.5069  ,  1.3485\n",
      "0.023186456370465132  ,  0.5159  ,  1.3387\n",
      "731\n",
      "0.0970398343274335  ,  0.8491  ,  1.2772\n",
      "0.043460515765933815  ,  0.8865  ,  1.2323\n",
      "0.07030075459598219  ,  0.8783  ,  1.2515\n",
      "732\n",
      "-0.12284937859199435  ,  0.7842  ,  1.3975\n",
      "-0.003556177689636503  ,  0.776  ,  1.4061\n",
      "-0.055637492045333525  ,  0.7778  ,  1.3992\n",
      "733\n",
      "-0.047158348865476554  ,  0.4672  ,  1.0645\n",
      "-0.0752176164281828  ,  0.4396  ,  1.0506\n",
      "0.00497445600990464  ,  0.4506  ,  1.0417\n",
      "734\n",
      "-0.10126583974401601  ,  1.5487  ,  1.1124\n",
      "-0.2252146029081582  ,  1.167  ,  1.3639\n",
      "0.4481812623942158  ,  1.1711  ,  1.3767\n",
      "735\n",
      "0.0025319307193323107  ,  0.1445  ,  0.69\n",
      "0.04557142121083184  ,  0.15  ,  0.6873\n",
      "0.05990675710978746  ,  0.1516  ,  0.6867\n",
      "736\n",
      "0.06878518784988064  ,  0.7456  ,  1.2609\n",
      "nan  ,  0.7432  ,  1.2892\n",
      "nan  ,  0.7432  ,  1.2892\n",
      "737\n",
      "0.3548995723708052  ,  0.7685  ,  1.5743\n",
      "nan  ,  0.765  ,  1.6857\n",
      "nan  ,  0.765  ,  1.6857\n",
      "738\n",
      "0.08815730387052295  ,  1.0531  ,  1.3826\n",
      "nan  ,  1.0551  ,  1.3859\n",
      "nan  ,  1.0551  ,  1.3859\n",
      "739\n",
      "-0.05231771372141501  ,  0.5829  ,  1.3486\n",
      "-0.07778240276916247  ,  0.6282  ,  1.2865\n",
      "0.05864485186329651  ,  0.6502  ,  1.2556\n",
      "740\n",
      "0.16970098461377253  ,  0.9443  ,  1.3502\n",
      "-0.04376167999800605  ,  0.8762  ,  1.5767\n",
      "-0.06563685748225886  ,  0.8757  ,  1.5777\n",
      "741\n",
      "nan  ,  0.7287  ,  1.4792\n",
      "0.08111287696016578  ,  0.7298  ,  1.4758\n",
      "nan  ,  0.7287  ,  1.4792\n",
      "742\n",
      "0.020204924781141338  ,  0.6516  ,  1.3604\n",
      "-0.002550578220120969  ,  0.6517  ,  1.3606\n",
      "nan  ,  0.6517  ,  1.3606\n",
      "743\n",
      "0.12601515393317314  ,  0.9438  ,  1.3829\n",
      "0.1138138945398436  ,  0.9495  ,  1.3979\n",
      "0.08163395454637275  ,  0.9499  ,  1.3961\n",
      "744\n",
      "0.15643389573672412  ,  0.9485  ,  1.1347\n",
      "0.04501371361264006  ,  0.9651  ,  1.1272\n",
      "0.09240189569349017  ,  0.9655  ,  1.1425\n",
      "745\n",
      "-0.03309704363803461  ,  0.4826  ,  1.2486\n",
      "0.10804300758840285  ,  0.5632  ,  1.1591\n",
      "-0.09409757553160128  ,  0.5666  ,  1.1571\n",
      "746\n",
      "-0.01956629038817547  ,  0.924  ,  1.3961\n",
      "nan  ,  0.9238  ,  1.3964\n",
      "nan  ,  0.9238  ,  1.3964\n",
      "747\n",
      "0.11341047446031405  ,  0.5881  ,  0.9277\n",
      "0.0057696765100770965  ,  0.5032  ,  1.0151\n",
      "0.044796483368572323  ,  0.4847  ,  1.0336\n",
      "748\n",
      "-0.07048772457238119  ,  0.6739  ,  1.0052\n",
      "-0.007767252228127698  ,  0.6362  ,  1.0653\n",
      "0.08083100310021096  ,  0.6348  ,  1.0698\n",
      "749\n",
      "-0.1278361472785256  ,  0.9235  ,  1.3243\n",
      "0.07342869094001489  ,  0.9083  ,  1.3046\n",
      "0.035539136884719554  ,  0.9166  ,  1.2603\n",
      "750\n",
      "0.39136278350386433  ,  1.1349  ,  1.2666\n",
      "nan  ,  1.2599  ,  1.7359\n",
      "nan  ,  1.2599  ,  1.7359\n",
      "751\n",
      "0.10525467027094257  ,  0.4722  ,  0.8308\n",
      "-0.029023464942224374  ,  0.4348  ,  0.8246\n",
      "0.036755522375783924  ,  0.4421  ,  0.8207\n",
      "752\n",
      "-0.039240177176849356  ,  0.8716  ,  1.0238\n",
      "nan  ,  0.2766  ,  0.9737\n",
      "nan  ,  0.2766  ,  0.9737\n",
      "753\n",
      "-0.04885545448308033  ,  0.985  ,  1.036\n",
      "0.05314433479736445  ,  0.9435  ,  1.2166\n",
      "-0.13174491604246324  ,  0.9423  ,  1.1932\n",
      "754\n",
      "0.06990322804764068  ,  0.8027  ,  1.2525\n",
      "-0.02177070914929723  ,  0.8042  ,  1.2482\n",
      "nan  ,  0.8034  ,  1.2534\n",
      "755\n",
      "-0.006469546785628577  ,  0.6401  ,  1.2414\n",
      "nan  ,  0.6401  ,  1.2414\n",
      "nan  ,  0.6401  ,  1.2414\n",
      "756\n",
      "0.02286274850256559  ,  0.6211  ,  1.4202\n",
      "nan  ,  0.6142  ,  1.4292\n",
      "nan  ,  0.6142  ,  1.4292\n",
      "757\n",
      "0.05046438503147741  ,  1.1366  ,  1.6467\n",
      "nan  ,  1.1373  ,  1.6481\n",
      "nan  ,  1.1373  ,  1.6481\n",
      "758\n",
      "-0.17090535117471162  ,  0.8513  ,  1.209\n",
      "-0.09555986232741494  ,  0.9043  ,  0.8971\n",
      "-0.043155670929446596  ,  0.9116  ,  0.8811\n",
      "759\n",
      "0.17591135083634055  ,  1.1401  ,  1.6524\n",
      "0.08245106117709089  ,  1.1424  ,  1.6374\n",
      "0.1537282070147787  ,  1.1433  ,  1.6336\n",
      "760\n",
      "nan  ,  0.5008  ,  1.3375\n",
      "0.003902070312971088  ,  0.5136  ,  1.323\n",
      "0.01038540171993552  ,  0.5374  ,  1.2976\n",
      "761\n",
      "-0.08460364698579598  ,  0.7458  ,  1.3401\n",
      "-0.0236933111094239  ,  0.7735  ,  1.2549\n",
      "0.042774524976323704  ,  0.7751  ,  1.2509\n",
      "762\n",
      "-0.11102213944356565  ,  0.9638  ,  1.1912\n",
      "-0.023721337998955327  ,  0.9402  ,  1.1357\n",
      "0.16410469436305183  ,  0.9387  ,  1.1327\n",
      "763\n",
      "0.2181497135932169  ,  1.0588  ,  1.2658\n",
      "0.1435941862486107  ,  1.0994  ,  1.4413\n",
      "-0.031085075193286595  ,  1.0954  ,  1.4299\n",
      "764\n",
      "0.0998667087775494  ,  0.9809  ,  1.4796\n",
      "-0.04071872302157424  ,  0.9935  ,  1.4438\n",
      "-0.002880459493500358  ,  0.9946  ,  1.4326\n",
      "765\n",
      "0.22166128069902308  ,  0.3914  ,  1.0775\n",
      "nan  ,  0.3926  ,  1.0833\n",
      "nan  ,  0.3926  ,  1.0833\n",
      "766\n",
      "0.022175974159213626  ,  0.4214  ,  1.1353\n",
      "-0.055143097063839026  ,  0.5769  ,  0.996\n",
      "0.0036622668098923745  ,  0.5696  ,  1.0015\n",
      "767\n",
      "0.1280135629181567  ,  0.6436  ,  0.6166\n",
      "-0.01692655015754418  ,  0.3973  ,  0.6792\n",
      "0.056396395646010955  ,  0.4001  ,  0.6775\n",
      "768\n",
      "nan  ,  0.83  ,  1.7606\n",
      "nan  ,  0.83  ,  1.7606\n",
      "nan  ,  0.83  ,  1.7606\n",
      "769\n",
      "0.05641307426864163  ,  1.1962  ,  1.4938\n",
      "-0.045203474659956076  ,  1.1858  ,  1.4769\n",
      "0.01719835709601249  ,  1.19  ,  1.4958\n",
      "770\n",
      "-0.04827094357199265  ,  0.6715  ,  1.3143\n",
      "-0.005484469831085337  ,  0.6643  ,  1.3178\n",
      "nan  ,  0.6643  ,  1.3178\n",
      "771\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "nan  ,  0.8275  ,  1.4233\n",
      "772\n",
      "0.08225826792836227  ,  0.9699  ,  2.0229\n",
      "-0.018192727735554824  ,  1.1036  ,  1.8473\n",
      "0.09063419982713708  ,  1.1132  ,  1.834\n",
      "773\n",
      "0.1440886191036684  ,  0.9976  ,  1.6968\n",
      "-0.15603083081964256  ,  0.9958  ,  1.7554\n",
      "-0.07617289086107523  ,  0.9919  ,  1.7654\n",
      "774\n",
      "0.05452714443949604  ,  0.6492  ,  1.3193\n",
      "0.062235770449124816  ,  0.7397  ,  1.1628\n",
      "0.08548014827242276  ,  0.721  ,  1.1924\n",
      "775\n",
      "776\n",
      "-0.0037524521047028496  ,  1.344  ,  1.8206\n",
      "-0.10462412316802966  ,  1.312  ,  1.724\n",
      "-0.15465059280526383  ,  1.3223  ,  1.7619\n",
      "777\n",
      "778\n",
      "0.15883564721753282  ,  0.801  ,  0.9672\n",
      "0.038604742701475334  ,  0.7626  ,  1.0741\n",
      "-0.21477339323472266  ,  0.7565  ,  1.0892\n",
      "779\n",
      "780\n",
      "0.05327276849483329  ,  0.7056  ,  1.3324\n",
      "0.051889373916714984  ,  0.7055  ,  1.328\n",
      "nan  ,  0.7059  ,  1.3333\n",
      "781\n",
      "782\n",
      "0.17045367639985798  ,  0.881  ,  1.561\n",
      "0.0735340883390179  ,  0.8856  ,  1.5691\n",
      "-0.00731779528181244  ,  0.8871  ,  1.5663\n",
      "783\n",
      "784\n",
      "0.10477485932377649  ,  0.9861  ,  1.269\n",
      "-0.3528580518941532  ,  1.0515  ,  1.1486\n",
      "0.006615352934683202  ,  1.0424  ,  1.1642\n",
      "785\n",
      "786\n",
      "0.2310614829132417  ,  0.7515  ,  1.2508\n",
      "-0.21294457567124275  ,  0.8244  ,  1.0904\n",
      "0.08655601079394414  ,  0.8203  ,  1.0985\n",
      "787\n",
      "788\n",
      "-0.09424131503845852  ,  0.6174  ,  1.4395\n",
      "-0.009523173258246562  ,  0.666  ,  1.3682\n",
      "0.03513124827279271  ,  0.6753  ,  1.3564\n",
      "789\n",
      "790\n",
      "0.05759793082933682  ,  0.2656  ,  0.8688\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "nan  ,  0.2319  ,  0.8848\n",
      "791\n",
      "792\n",
      "0.2119706250289186  ,  0.6493  ,  1.2239\n",
      "0.017021414977007536  ,  0.6822  ,  1.2151\n",
      "0.03734407865048298  ,  0.684  ,  1.2125\n",
      "793\n",
      "794\n",
      "-0.05508796261936216  ,  0.8347  ,  1.131\n",
      "0.13962915649508967  ,  0.5708  ,  1.0818\n",
      "0.02004862287866835  ,  0.5751  ,  1.0789\n",
      "795\n",
      "796\n",
      "0.10700947907069713  ,  0.8649  ,  1.3221\n",
      "nan  ,  0.828  ,  1.4744\n",
      "nan  ,  0.828  ,  1.4744\n",
      "797\n",
      "798\n",
      "0.18224043711740007  ,  0.9911  ,  1.5473\n",
      "-0.21850439899826535  ,  1.0069  ,  1.5129\n",
      "-0.08566106918833674  ,  1.0052  ,  1.5048\n",
      "799\n",
      "800\n",
      "0.20692013671721543  ,  0.7784  ,  1.117\n",
      "0.02503756573204861  ,  0.8486  ,  1.0396\n",
      "0.03127918923348377  ,  0.8534  ,  1.0314\n",
      "801\n",
      "802\n",
      "-0.011613142284947135  ,  0.4282  ,  0.9415\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "nan  ,  0.3345  ,  0.9707\n",
      "803\n",
      "804\n",
      "0.11522275005138459  ,  0.7771  ,  1.3267\n",
      "0.04988785664726645  ,  0.7971  ,  1.2681\n",
      "-0.09938133779373262  ,  0.7971  ,  1.2683\n",
      "805\n",
      "806\n",
      "0.06318896643844524  ,  0.5336  ,  1.2711\n",
      "-0.022011637676745806  ,  0.6694  ,  1.1121\n",
      "0.05571720418917048  ,  0.6675  ,  1.114\n",
      "807\n",
      "808\n",
      "0.05264064923596642  ,  0.8411  ,  1.5386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025429193875135068  ,  0.8414  ,  1.5427\n",
      "nan  ,  0.8413  ,  1.5434\n",
      "809\n",
      "810\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "nan  ,  0.5776  ,  1.1209\n",
      "811\n",
      "812\n",
      "0.0651766945819487  ,  0.5066  ,  1.0163\n",
      "0.04729850346412669  ,  0.5937  ,  0.8835\n",
      "0.05680528559561954  ,  0.5934  ,  0.8845\n",
      "813\n",
      "814\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "nan  ,  0.9308  ,  1.6174\n",
      "815\n",
      "816\n",
      "0.008920991337225577  ,  0.9189  ,  1.2167\n",
      "0.008376143265834435  ,  0.6269  ,  1.422\n",
      "-0.023009457751998405  ,  0.6165  ,  1.4348\n",
      "817\n",
      "818\n",
      "0.03846016948077734  ,  0.7442  ,  0.7114\n",
      "0.03168884830126236  ,  0.4854  ,  0.8947\n",
      "-0.009299601222332995  ,  0.5168  ,  0.8615\n",
      "819\n",
      "820\n",
      "0.08703085896495023  ,  0.4435  ,  1.1322\n",
      "0.15802633593376786  ,  0.5975  ,  0.9761\n",
      "-0.04331200960907744  ,  0.5956  ,  0.9809\n",
      "821\n",
      "822\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "nan  ,  0.7652  ,  1.4901\n",
      "823\n",
      "824\n",
      "0.03455004534704808  ,  0.8082  ,  1.4011\n",
      "0.04184848651962626  ,  0.8154  ,  1.3949\n",
      "0.06415411736435814  ,  0.8176  ,  1.3877\n",
      "825\n",
      "826\n",
      "0.23498293531397657  ,  0.6154  ,  1.4429\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "nan  ,  0.6053  ,  1.5126\n",
      "827\n",
      "828\n",
      "0.22261700113788704  ,  0.7172  ,  1.6276\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "nan  ,  0.7173  ,  1.6613\n",
      "829\n",
      "830\n",
      "0.24699924311866314  ,  1.0074  ,  1.3745\n",
      "0.1274948817757013  ,  1.0209  ,  1.4028\n",
      "nan  ,  1.0213  ,  1.4041\n",
      "831\n",
      "832\n",
      "0.0872823282570283  ,  0.5961  ,  0.7921\n",
      "-0.08372039467403669  ,  0.3977  ,  0.8197\n",
      "0.09897832751732241  ,  0.3878  ,  0.8252\n",
      "833\n",
      "834\n",
      "0.1088502140671736  ,  0.6044  ,  1.162\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "nan  ,  0.6052  ,  1.1647\n",
      "835\n",
      "836\n",
      "-0.16031512914643714  ,  0.8662  ,  1.435\n",
      "-0.09388098756057127  ,  0.8774  ,  1.3828\n",
      "-0.025920180526924005  ,  0.8803  ,  1.3696\n",
      "837\n",
      "838\n",
      "0.01701686173587338  ,  0.5935  ,  1.0789\n",
      "0.006150082544000545  ,  0.5026  ,  1.1604\n",
      "0.0027699954633500466  ,  0.5051  ,  1.1575\n",
      "839\n",
      "840\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "nan  ,  0.5368  ,  1.1598\n",
      "841\n",
      "842\n",
      "-0.03611275060924794  ,  0.4915  ,  1.1759\n",
      "-0.09065359369110158  ,  0.5624  ,  1.0853\n",
      "-0.0768339167002011  ,  0.5611  ,  1.0857\n",
      "843\n",
      "844\n",
      "-0.032584053257004815  ,  1.7617  ,  1.2625\n",
      "nan  ,  0.8372  ,  1.5933\n",
      "nan  ,  0.8372  ,  1.5933\n",
      "845\n",
      "846\n",
      "0.06223142382376141  ,  0.7147  ,  0.9756\n",
      "-0.004407837362545047  ,  0.6438  ,  1.0809\n",
      "-0.03634308705878043  ,  0.6375  ,  1.0917\n",
      "847\n",
      "848\n",
      "0.019337243362243236  ,  0.3719  ,  1.3108\n",
      "nan  ,  0.3713  ,  1.3116\n",
      "nan  ,  0.3713  ,  1.3116\n",
      "849\n",
      "850\n",
      "0.01429489666474705  ,  0.6431  ,  0.994\n",
      "-0.05151546930358704  ,  0.5886  ,  1.0653\n",
      "-0.04154613963985765  ,  0.5895  ,  1.0623\n",
      "851\n",
      "852\n",
      "0.14409748568174946  ,  0.9015  ,  0.945\n",
      "0.02412483193239995  ,  0.7035  ,  1.0341\n",
      "0.01898640052548488  ,  0.6643  ,  1.0605\n",
      "853\n",
      "854\n",
      "0.6818278157879465  ,  0.5525  ,  1.3814\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "nan  ,  0.6565  ,  1.7691\n",
      "855\n",
      "856\n",
      "0.14914032663721602  ,  0.7945  ,  1.1372\n",
      "-0.0837516229422363  ,  0.8071  ,  1.1675\n",
      "0.18412816469388188  ,  0.8063  ,  1.1619\n",
      "857\n",
      "858\n",
      "-0.044122654125540256  ,  0.7578  ,  1.4966\n",
      "0.08432244112481063  ,  0.7737  ,  1.4497\n",
      "0.004932833495659671  ,  0.7738  ,  1.4496\n",
      "859\n",
      "860\n",
      "-0.016900399440927475  ,  0.601  ,  1.579\n",
      "-0.020829514095266025  ,  0.6202  ,  1.5569\n",
      "0.024179451972786807  ,  0.6193  ,  1.5578\n",
      "861\n",
      "862\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "nan  ,  0.5273  ,  1.2161\n",
      "863\n",
      "864\n",
      "-0.007506542054126223  ,  0.8514  ,  1.5593\n",
      "-0.009553542857548038  ,  0.8918  ,  1.4486\n",
      "-0.013404303116311508  ,  0.8935  ,  1.4444\n",
      "865\n",
      "866\n",
      "-0.04396375089064034  ,  0.447  ,  1.0099\n",
      "-0.2127103291541749  ,  0.4575  ,  0.9887\n",
      "0.2608538892378408  ,  0.444  ,  1.0042\n",
      "867\n",
      "868\n",
      "0.5136331990541526  ,  0.902  ,  1.554\n",
      "0.3224838709451783  ,  1.1217  ,  1.3467\n",
      "-0.631467210557204  ,  1.1303  ,  1.341\n",
      "869\n",
      "870\n",
      "0.11399240684887617  ,  1.0352  ,  1.5197\n",
      "-0.14958407094509663  ,  1.0609  ,  1.2598\n",
      "0.387155930639121  ,  1.0588  ,  1.2687\n",
      "871\n",
      "872\n",
      "-0.06319036333453745  ,  1.1272  ,  1.4916\n",
      "-0.13679315794174376  ,  1.0618  ,  1.6446\n",
      "-0.1877432267183562  ,  1.0605  ,  1.6451\n",
      "873\n",
      "874\n",
      "0.05944157155239385  ,  0.5854  ,  1.2217\n",
      "nan  ,  0.586  ,  1.2262\n",
      "nan  ,  0.586  ,  1.2262\n",
      "875\n",
      "876\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "nan  ,  0.4774  ,  1.2123\n",
      "877\n",
      "878\n",
      "-0.0681135062364571  ,  0.8885  ,  1.5393\n",
      "-0.04046219773174894  ,  0.9846  ,  1.2811\n",
      "0.08530350432966638  ,  0.971  ,  1.3075\n",
      "879\n",
      "880\n",
      "0.17341019534137533  ,  0.8417  ,  1.405\n",
      "-0.07826715786758796  ,  0.8201  ,  1.5172\n",
      "-0.03995711163422314  ,  0.8262  ,  1.4937\n",
      "881\n",
      "882\n",
      "0.2782540857229303  ,  1.0562  ,  1.137\n",
      "0.05961847777305178  ,  1.0353  ,  1.4152\n",
      "0.015641563552577537  ,  1.0366  ,  1.3935\n",
      "883\n",
      "884\n",
      "-0.03052313363611841  ,  0.7994  ,  1.2164\n",
      "-0.16564352043159192  ,  0.8182  ,  1.0857\n",
      "0.054005116235704115  ,  0.815  ,  1.0994\n",
      "885\n",
      "886\n",
      "-0.045969701326040724  ,  1.0347  ,  1.4548\n",
      "0.06659482804695835  ,  1.0314  ,  1.4296\n",
      "0.05641663317315769  ,  1.0319  ,  1.4319\n",
      "887\n",
      "888\n",
      "0.018857109265392264  ,  0.7428  ,  1.3759\n",
      "0.3049667100390386  ,  0.7699  ,  1.2912\n",
      "-0.04116818139519717  ,  0.7762  ,  1.2823\n",
      "889\n",
      "890\n",
      "-0.045964552074278964  ,  1.7903  ,  1.2572\n",
      "0.19677907868887384  ,  0.9342  ,  1.8157\n",
      "0.16674550858143936  ,  0.948  ,  1.8001\n",
      "891\n",
      "892\n",
      "-0.046121985334291384  ,  0.6887  ,  1.4416\n",
      "0.060746412673539446  ,  0.8127  ,  1.2534\n",
      "0.058682579260546486  ,  0.7918  ,  1.2823\n",
      "893\n",
      "894\n",
      "-0.09641046691098278  ,  1.1623  ,  1.4273\n",
      "-0.16648932239424402  ,  1.1051  ,  1.2739\n",
      "-0.09986135180995229  ,  1.1072  ,  1.2829\n",
      "895\n",
      "896\n",
      "0.16984678542524126  ,  0.213  ,  0.9192\n",
      "0.03702119218585069  ,  0.273  ,  0.8924\n",
      "0.006271176838242423  ,  0.2362  ,  0.9106\n",
      "897\n",
      "898\n",
      "-0.11488755185857849  ,  0.5566  ,  0.4874\n",
      "0.04789031913583122  ,  0.3681  ,  0.5761\n",
      "-0.004872218948792818  ,  0.3514  ,  0.5886\n",
      "899\n",
      "900\n",
      "0.16114438881066848  ,  0.5782  ,  0.7801\n",
      "0.011336956206452944  ,  0.4523  ,  0.8781\n",
      "0.023410772985646984  ,  0.4399  ,  0.8884\n",
      "901\n",
      "902\n",
      "-0.0027729412637093804  ,  0.1931  ,  0.71\n",
      "0.05060234150498559  ,  0.2829  ,  0.6561\n",
      "0.015044965278901437  ,  0.2469  ,  0.6772\n",
      "903\n",
      "904\n",
      "0.3440332626440131  ,  0.239  ,  0.6469\n",
      "0.010873342392394885  ,  0.3386  ,  0.6338\n",
      "0.012236409208904833  ,  0.2957  ,  0.6625\n",
      "905\n",
      "906\n",
      "0.06717595188715586  ,  0.2746  ,  0.6505\n",
      "0.06861708737228628  ,  0.3035  ,  0.6276\n",
      "0.0830593393239193  ,  0.2472  ,  0.6706\n",
      "907\n",
      "908\n",
      "0.09556009753889541  ,  0.6047  ,  0.3671\n",
      "0.008446332041680438  ,  0.2677  ,  0.4947\n",
      "-0.002191685562125089  ,  0.319  ,  0.4671\n",
      "909\n",
      "910\n",
      "-0.03214331988762164  ,  0.5078  ,  0.4687\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "nan  ,  0.1114  ,  0.5477\n",
      "911\n",
      "912\n",
      "-0.008038582593269497  ,  0.9775  ,  0.5151\n",
      "-0.09231001535041009  ,  0.7088  ,  0.6025\n",
      "-0.02579495237094943  ,  0.7093  ,  0.6015\n",
      "913\n",
      "914\n",
      "nan  ,  0.2208  ,  0.779\n",
      "nan  ,  0.2208  ,  0.779\n",
      "nan  ,  0.2208  ,  0.779\n",
      "915\n",
      "916\n",
      "0.15763343933174045  ,  0.2937  ,  0.6648\n",
      "-0.10980732670000808  ,  0.3659  ,  0.6265\n",
      "0.014974140121575762  ,  0.3055  ,  0.6652\n",
      "917\n",
      "918\n",
      "0.14446073724551767  ,  0.6848  ,  0.28\n",
      "-0.04768261303534353  ,  0.9303  ,  0.2829\n",
      "-0.02728942439442466  ,  0.9102  ,  0.2781\n",
      "919\n",
      "920\n",
      "-0.07411342653914929  ,  0.8357  ,  0.6205\n",
      "0.0006596730046980826  ,  0.655  ,  0.7481\n",
      "0.018516439766804515  ,  0.6547  ,  0.7485\n",
      "921\n",
      "922\n",
      "-0.03212767709645489  ,  0.3105  ,  0.8915\n",
      "0.1328613451673883  ,  0.3526  ,  0.853\n",
      "0.05245547098545355  ,  0.3424  ,  0.8625\n",
      "923\n",
      "924\n",
      "0.08574257031690545  ,  0.7511  ,  0.4781\n",
      "-0.00021072112131094705  ,  0.2088  ,  0.6611\n",
      "-0.006652307899761964  ,  0.2719  ,  0.6292\n",
      "925\n",
      "926\n",
      "0.0799422174682975  ,  1.1103  ,  0.5439\n",
      "-0.09164877754231299  ,  0.2044  ,  0.7829\n",
      "0.048201154609181666  ,  0.2447  ,  0.7584\n",
      "927\n",
      "928\n",
      "0.16964879763083163  ,  0.4654  ,  0.6941\n",
      "-0.009915702648181816  ,  0.3276  ,  0.8198\n",
      "-0.0312078120142639  ,  0.3046  ,  0.8412\n",
      "929\n",
      "930\n",
      "-0.09446383926962272  ,  0.4095  ,  0.8236\n",
      "-0.050572193247894026  ,  0.2874  ,  0.8924\n",
      "0.02378851174612647  ,  0.3583  ,  0.8459\n",
      "931\n",
      "932\n",
      "0.18092948316112423  ,  0.5211  ,  0.7104\n",
      "-0.0024337218646818676  ,  0.385  ,  0.8631\n",
      "0.036326669573324234  ,  0.3951  ,  0.8512\n",
      "933\n",
      "934\n",
      "-0.029900643002696313  ,  0.2778  ,  0.8183\n",
      "-0.01679150307925477  ,  0.3711  ,  0.7434\n",
      "-0.0005541615271790574  ,  0.4312  ,  0.7001\n",
      "935\n",
      "936\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "-0.12172758526973014  ,  0.3411  ,  0.7753\n",
      "nan  ,  0.3387  ,  0.7778\n",
      "937\n",
      "938\n",
      "0.08200272801711966  ,  0.4378  ,  1.0912\n",
      "0.19223257992951498  ,  0.4518  ,  1.0698\n",
      "0.11979951823283969  ,  0.5045  ,  1.0148\n",
      "939\n",
      "940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0445216447825654  ,  0.8531  ,  0.6323\n",
      "0.01754920601613564  ,  0.536  ,  0.7629\n",
      "0.02769279220434867  ,  0.4971  ,  0.7862\n",
      "941\n",
      "942\n",
      "-0.0940910536524566  ,  0.3699  ,  0.9881\n",
      "0.037129812707229363  ,  0.3548  ,  0.9871\n",
      "nan  ,  0.3254  ,  1.012\n",
      "943\n",
      "944\n",
      "0.03784171969342302  ,  0.6205  ,  0.5683\n",
      "0.11283513668118277  ,  0.3392  ,  0.7801\n",
      "0.13456101472305737  ,  0.369  ,  0.7477\n",
      "945\n",
      "946\n",
      "0.023311401218352616  ,  0.4603  ,  0.8527\n",
      "0.030087219368009968  ,  0.5366  ,  0.7781\n",
      "0.007455092441155206  ,  0.4794  ,  0.8267\n",
      "947\n",
      "948\n",
      "0.018972632077528744  ,  0.8197  ,  0.5113\n",
      "-0.05160785349205383  ,  0.5821  ,  0.6591\n",
      "0.20989802823722198  ,  0.5576  ,  0.6817\n",
      "949\n",
      "950\n",
      "0.06845951920311556  ,  0.4989  ,  0.2926\n",
      "-0.027625523089172644  ,  0.5245  ,  0.2728\n",
      "0.02403817056925199  ,  0.5546  ,  0.263\n",
      "951\n",
      "952\n",
      "-0.2676286313230682  ,  0.6128  ,  0.9454\n",
      "-0.06050809629825232  ,  0.5342  ,  0.9825\n",
      "-0.05632013073481777  ,  0.5493  ,  0.9665\n",
      "953\n",
      "954\n",
      "0.15265658096045773  ,  0.6312  ,  1.0411\n",
      "0.021318926569334012  ,  0.6897  ,  0.9832\n",
      "-0.015660837320261647  ,  0.6823  ,  0.9925\n",
      "955\n",
      "956\n",
      "-0.0722938073373341  ,  0.9208  ,  0.3699\n",
      "0.19860570792021368  ,  0.2451  ,  0.5729\n",
      "-0.007022461636785715  ,  0.3012  ,  0.5256\n",
      "957\n",
      "958\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "nan  ,  0.2881  ,  0.7295\n",
      "959\n",
      "960\n",
      "0.02190373775954715  ,  0.2288  ,  0.8693\n",
      "-0.026059000154702847  ,  0.2582  ,  0.8518\n",
      "-0.030000992872724445  ,  0.2851  ,  0.8355\n",
      "961\n",
      "962\n",
      "nan  ,  0.224  ,  0.9738\n",
      "nan  ,  0.224  ,  0.9738\n",
      "nan  ,  0.224  ,  0.9738\n",
      "963\n",
      "964\n",
      "0.25746686854053547  ,  1.0132  ,  0.5667\n",
      "-0.06928686737303247  ,  0.5017  ,  0.8645\n",
      "-0.01821029401645657  ,  0.5127  ,  0.8527\n",
      "965\n",
      "966\n",
      "0.08102270095212036  ,  0.1211  ,  0.6692\n",
      "nan  ,  0.121  ,  0.6713\n",
      "nan  ,  0.121  ,  0.6713\n",
      "967\n",
      "968\n",
      "0.21760051281899997  ,  0.2991  ,  0.75\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "nan  ,  0.2503  ,  0.8119\n",
      "969\n",
      "970\n",
      "-0.009722761334059398  ,  0.2826  ,  0.6882\n",
      "0.028049421800588566  ,  0.5055  ,  0.5319\n",
      "0.039004191181639496  ,  0.5037  ,  0.5332\n",
      "971\n",
      "972\n",
      "0.7561464997929767  ,  0.2558  ,  0.9384\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "nan  ,  0.2926  ,  1.0945\n",
      "973\n",
      "974\n",
      "0.25933124869652013  ,  0.4215  ,  0.7296\n",
      "0.08747560643897732  ,  0.3622  ,  0.8023\n",
      "0.029639390894692065  ,  0.3601  ,  0.8042\n",
      "975\n",
      "976\n",
      "0.23480397029393  ,  0.9551  ,  0.5272\n",
      "0.036295766497426926  ,  0.2782  ,  0.7155\n",
      "nan  ,  0.2412  ,  0.7456\n",
      "977\n",
      "978\n",
      "0.09783675844569303  ,  0.4619  ,  0.4726\n",
      "nan  ,  0.2112  ,  0.6239\n",
      "nan  ,  0.2112  ,  0.6239\n",
      "979\n",
      "980\n",
      "0.024191462902766525  ,  0.1229  ,  0.378\n",
      "0.05900117766066726  ,  0.1483  ,  0.3612\n",
      "-0.0225682470787289  ,  0.1659  ,  0.3513\n",
      "981\n",
      "982\n",
      "-0.13983790780806168  ,  0.6045  ,  0.5622\n",
      "-0.031068979975099296  ,  0.5556  ,  0.5634\n",
      "0.01468679949652154  ,  0.5588  ,  0.561\n",
      "983\n",
      "984\n",
      "0.28321186735048787  ,  0.4858  ,  0.7151\n",
      "nan  ,  0.288  ,  0.8972\n",
      "nan  ,  0.288  ,  0.8972\n",
      "985\n",
      "986\n",
      "0.13008578245332916  ,  0.4748  ,  0.5754\n",
      "0.00779385747276768  ,  0.2036  ,  0.7327\n",
      "-0.0545768659402392  ,  0.2114  ,  0.7275\n",
      "987\n",
      "988\n",
      "0.20763107252961968  ,  0.3429  ,  1.0148\n",
      "-0.04360381858985652  ,  0.3518  ,  1.0076\n",
      "-0.060630703123835096  ,  0.3529  ,  1.0065\n",
      "989\n",
      "990\n",
      "0.03273966365869495  ,  0.4289  ,  0.6168\n",
      "-0.09303729651132887  ,  0.2605  ,  0.7375\n",
      "0.006276316889150189  ,  0.2578  ,  0.7388\n",
      "991\n",
      "992\n",
      "0.08549519532554026  ,  0.5459  ,  0.6952\n",
      "-0.01756770168780393  ,  0.4458  ,  0.7821\n",
      "0.03916088149704967  ,  0.4461  ,  0.7818\n",
      "993\n",
      "994\n",
      "nan  ,  0.2211  ,  0.7955\n",
      "0.06345824369720393  ,  0.2578  ,  0.7713\n",
      "0.033760892089612284  ,  0.2223  ,  0.7947\n",
      "995\n",
      "996\n",
      "0.18655137236522468  ,  0.9596  ,  0.499\n",
      "0.027207732197745232  ,  0.5191  ,  0.6925\n",
      "-0.039140444830611174  ,  0.5228  ,  0.6902\n",
      "997\n",
      "998\n",
      "0.06317528187859814  ,  0.1783  ,  0.7063\n",
      "nan  ,  0.1738  ,  0.7109\n",
      "nan  ,  0.1738  ,  0.7109\n",
      "999\n",
      "1000\n",
      "0.05201637215634747  ,  0.5209  ,  0.5327\n",
      "0.04226997914997404  ,  0.2103  ,  0.6628\n",
      "-0.028706528964049696  ,  0.1997  ,  0.6704\n",
      "1001\n",
      "1002\n",
      "0.1585906269551158  ,  0.6473  ,  0.2812\n",
      "-0.0040461959677076074  ,  0.7251  ,  0.267\n",
      "-0.09112912583150606  ,  0.7041  ,  0.2697\n",
      "1003\n",
      "1004\n",
      "0.15933857791239858  ,  0.3249  ,  0.7719\n",
      "0.005958083910139875  ,  0.3454  ,  0.763\n",
      "0.012370481386351235  ,  0.3568  ,  0.7539\n",
      "1005\n",
      "1006\n",
      "-0.031975388788871476  ,  0.4231  ,  0.7776\n",
      "nan  ,  0.322  ,  0.8655\n",
      "nan  ,  0.322  ,  0.8655\n",
      "1007\n",
      "1008\n",
      "0.16765534051581554  ,  0.489  ,  0.5789\n",
      "0.0592357597230082  ,  0.3453  ,  0.6622\n",
      "0.04367454802305357  ,  0.3147  ,  0.6837\n",
      "1009\n",
      "1010\n",
      "0.13908120752048547  ,  0.7116  ,  0.6096\n",
      "0.05184158584906706  ,  0.4373  ,  0.8116\n",
      "0.008536980862227482  ,  0.4315  ,  0.8186\n",
      "1011\n",
      "1012\n",
      "-0.01912661821258862  ,  0.3207  ,  0.8966\n",
      "-0.048943221121804596  ,  0.3271  ,  0.8901\n",
      "0.07828862829543493  ,  0.3352  ,  0.8822\n",
      "1013\n",
      "1014\n",
      "0.233397920433011  ,  0.6123  ,  1.0821\n",
      "-0.05437508544628197  ,  0.3998  ,  1.2256\n",
      "0.006771656745537004  ,  0.4224  ,  1.2122\n",
      "1015\n",
      "1016\n",
      "-0.005690449649768458  ,  0.6553  ,  0.7022\n",
      "0.058844968157269466  ,  0.4319  ,  0.7923\n",
      "-0.054502188988966915  ,  0.4019  ,  0.8099\n",
      "1017\n",
      "1018\n",
      "-0.014000574210051287  ,  0.5397  ,  0.719\n",
      "0.01173774588457332  ,  0.621  ,  0.6343\n",
      "0.00826332379429678  ,  0.6253  ,  0.6307\n",
      "1019\n",
      "1020\n",
      "0.13575237774774623  ,  0.9501  ,  0.5973\n",
      "0.09666050151935712  ,  0.3335  ,  0.8055\n",
      "0.01960698522905292  ,  0.2929  ,  0.8393\n",
      "1021\n",
      "1022\n",
      "-0.12918533444255298  ,  1.1705  ,  0.4564\n",
      "0.08146507826626724  ,  0.5563  ,  0.5009\n",
      "-0.03280764547079555  ,  0.5711  ,  0.4912\n",
      "1023\n",
      "1024\n",
      "-0.003043566111759045  ,  0.2146  ,  0.901\n",
      "0.053574316496460175  ,  0.3007  ,  0.8558\n",
      "0.007485978924065107  ,  0.2879  ,  0.8626\n",
      "1025\n",
      "1026\n",
      "-0.00940657423311426  ,  0.1599  ,  0.7073\n",
      "0.07913078697577629  ,  0.2345  ,  0.6702\n",
      "0.03801752970810246  ,  0.1872  ,  0.6937\n",
      "1027\n",
      "1028\n",
      "-0.027498531993462166  ,  0.31  ,  1.0872\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "nan  ,  0.3035  ,  1.0888\n",
      "1029\n",
      "1030\n",
      "0.36549106365829964  ,  0.5643  ,  0.5941\n",
      "-0.03002496349627521  ,  0.5775  ,  0.6117\n",
      "-0.0134241116313016  ,  0.5823  ,  0.6083\n",
      "1031\n",
      "1032\n",
      "0.13761157296889803  ,  0.3332  ,  0.9987\n",
      "-0.024613638517684798  ,  0.3487  ,  0.9933\n",
      "0.04219543259447523  ,  0.3548  ,  0.9879\n",
      "1033\n",
      "1034\n",
      "0.18459495914594792  ,  0.2019  ,  0.567\n",
      "-0.11184880273126306  ,  0.3485  ,  0.4719\n",
      "-0.13381387182899343  ,  0.2802  ,  0.5168\n",
      "1035\n",
      "1036\n",
      "-0.12718658990318374  ,  0.338  ,  0.8845\n",
      "0.1299052251910921  ,  0.5365  ,  0.7113\n",
      "-0.07914514198805168  ,  0.4714  ,  0.762\n",
      "1037\n",
      "1038\n",
      "0.19891239976057476  ,  0.3116  ,  1.0669\n",
      "nan  ,  0.3104  ,  1.0874\n",
      "-0.04835274266690489  ,  0.3133  ,  1.0854\n",
      "1039\n",
      "1040\n",
      "0.09774102890556488  ,  0.789  ,  0.4865\n",
      "-0.06264561488010104  ,  0.3966  ,  0.7325\n",
      "0.03420853761941247  ,  0.4347  ,  0.6915\n",
      "1041\n",
      "1042\n",
      "0.04445619734220734  ,  0.8631  ,  0.3795\n",
      "0.013480426551570536  ,  0.411  ,  0.5045\n",
      "0.01724601173808068  ,  0.4773  ,  0.4634\n",
      "1043\n",
      "1044\n",
      "0.2099288537758116  ,  0.5822  ,  0.5184\n",
      "-0.04492737316287501  ,  0.3645  ,  0.6602\n",
      "0.01751822333448654  ,  0.3556  ,  0.6663\n",
      "1045\n",
      "1046\n",
      "-0.011924546365650032  ,  0.4453  ,  0.7256\n",
      "-0.08095216835420704  ,  0.3096  ,  0.7996\n",
      "-0.01268019856506904  ,  0.338  ,  0.78\n",
      "1047\n",
      "1048\n",
      "0.00932708085612538  ,  0.6691  ,  0.5461\n",
      "0.1450649277178057  ,  0.6915  ,  0.5264\n",
      "-0.02539945185699933  ,  0.6949  ,  0.5251\n",
      "1049\n",
      "1050\n",
      "0.07808921702352727  ,  0.6949  ,  0.7089\n",
      "0.013611448167948827  ,  0.6845  ,  0.7021\n",
      "0.019462415921838824  ,  0.6862  ,  0.7011\n",
      "1051\n",
      "1052\n",
      "-0.008996748228151169  ,  0.6955  ,  0.4464\n",
      "0.02648953754818763  ,  0.4926  ,  0.5697\n",
      "-0.010243146802972355  ,  0.499  ,  0.5642\n",
      "1053\n",
      "1054\n",
      "0.15184377235814886  ,  0.6197  ,  0.472\n",
      "0.29213909351545975  ,  0.6636  ,  0.4511\n",
      "0.1083400556181128  ,  0.6909  ,  0.4407\n",
      "1055\n",
      "1056\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "nan  ,  0.1776  ,  0.7237\n",
      "1057\n",
      "1058\n",
      "-0.15419074844002417  ,  0.8935  ,  0.6577\n",
      "0.15840576245127544  ,  0.3295  ,  0.7804\n",
      "0.07510366500391066  ,  0.3283  ,  0.7821\n",
      "1059\n",
      "1060\n",
      "0.12031678305625325  ,  0.7865  ,  0.4904\n",
      "-0.05585723439556864  ,  0.6896  ,  0.5399\n",
      "-0.05200193627974175  ,  0.6928  ,  0.5379\n",
      "1061\n",
      "1062\n",
      "0.2570804445341956  ,  0.4387  ,  0.9788\n",
      "-0.010391840140463262  ,  0.4617  ,  0.9966\n",
      "0.04034420772229731  ,  0.4648  ,  0.9934\n",
      "1063\n",
      "1064\n",
      "0.21145245443568686  ,  0.6466  ,  0.5035\n",
      "0.03845100577323741  ,  0.5602  ,  0.5824\n",
      "-0.018641262520218173  ,  0.5574  ,  0.585\n",
      "1065\n",
      "1066\n",
      "0.07067141537161994  ,  0.1497  ,  0.6371\n",
      "-0.030053846385123845  ,  0.2475  ,  0.5887\n",
      "-0.05324496050400524  ,  0.2443  ,  0.5902\n",
      "1067\n",
      "1068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.023549248408195375  ,  0.7537  ,  0.4123\n",
      "0.13158502928274848  ,  0.6404  ,  0.4559\n",
      "-0.11640658387226756  ,  0.6728  ,  0.4391\n",
      "1069\n",
      "1070\n",
      "0.0871262746147324  ,  0.8329  ,  0.5498\n",
      "-0.006926746219699333  ,  0.3209  ,  0.7151\n",
      "0.053014822943482996  ,  0.3134  ,  0.7191\n",
      "1071\n",
      "1072\n",
      "-0.00296166849246679  ,  1.1428  ,  0.5849\n",
      "0.025148253825220807  ,  0.1902  ,  0.7918\n",
      "nan  ,  0.1737  ,  0.7998\n",
      "1073\n",
      "1074\n",
      "-0.007846866892623781  ,  0.2156  ,  0.6742\n",
      "-0.007843845182136974  ,  0.3064  ,  0.6061\n",
      "0.03244184733354863  ,  0.2575  ,  0.6413\n",
      "1075\n",
      "1076\n",
      "0.011609979582556771  ,  0.4203  ,  0.5434\n",
      "-0.05139268703009123  ,  0.2  ,  0.6719\n",
      "-0.07883903134852688  ,  0.2083  ,  0.6658\n",
      "1077\n",
      "1078\n",
      "-0.017625136835732268  ,  0.4896  ,  0.6638\n",
      "-0.01751705206628768  ,  0.536  ,  0.5935\n",
      "0.07526297648884725  ,  0.4814  ,  0.6321\n",
      "1079\n",
      "1080\n",
      "0.05146353249940349  ,  0.5958  ,  0.4584\n",
      "0.020360967465564282  ,  0.2013  ,  0.5392\n",
      "0.0075136121559476144  ,  0.1877  ,  0.5448\n",
      "1081\n",
      "1082\n",
      "0.18333491870054297  ,  0.3125  ,  0.7361\n",
      "-0.10457572118960634  ,  0.3026  ,  0.7574\n",
      "-0.024072070563246492  ,  0.3395  ,  0.7275\n",
      "1083\n",
      "1084\n",
      "0.022372116022797168  ,  0.6022  ,  0.5011\n",
      "0.005690547662285916  ,  0.3085  ,  0.647\n",
      "-0.029534946118213064  ,  0.3167  ,  0.6418\n",
      "1085\n",
      "1086\n",
      "0.3646097849469314  ,  0.2097  ,  0.7426\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "nan  ,  0.2099  ,  0.7877\n",
      "1087\n",
      "1088\n",
      "-0.013369750285517585  ,  0.2119  ,  0.67\n",
      "-0.05527604325448185  ,  0.2971  ,  0.6162\n",
      "0.015241681490911967  ,  0.2693  ,  0.631\n",
      "1089\n",
      "1090\n",
      "0.12457312340630883  ,  1.3791  ,  0.5981\n",
      "0.05901834448997846  ,  0.3942  ,  0.8411\n",
      "-0.010006093190043122  ,  0.3672  ,  0.8636\n",
      "1091\n",
      "1092\n",
      "-0.031699617269743394  ,  2.7206  ,  1.2252\n",
      "nan  ,  0.2255  ,  0.9899\n",
      "0.03395250475042144  ,  0.2637  ,  0.9705\n",
      "1093\n",
      "1094\n",
      "0.2516274147205425  ,  0.8615  ,  0.5565\n",
      "-0.10020090318529765  ,  0.6119  ,  0.7366\n",
      "0.01707927352154231  ,  0.5969  ,  0.7484\n",
      "1095\n",
      "1096\n",
      "0.07641610184939682  ,  0.5501  ,  0.7007\n",
      "-0.0698567413540463  ,  0.5204  ,  0.7321\n",
      "-0.04513316073600286  ,  0.5397  ,  0.7133\n",
      "1097\n",
      "1098\n",
      "0.2015420109378802  ,  0.5592  ,  0.7315\n",
      "0.0162692673401992  ,  0.4608  ,  0.7981\n",
      "-0.02385710369349823  ,  0.4532  ,  0.8026\n",
      "1099\n",
      "1100\n",
      "0.10302249641131912  ,  0.644  ,  0.7558\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "nan  ,  0.4486  ,  0.9842\n",
      "1101\n",
      "1102\n",
      "0.21196546389354287  ,  0.4443  ,  0.7151\n",
      "-0.06696287812181717  ,  0.3776  ,  0.7997\n",
      "-0.06834753425068839  ,  0.3892  ,  0.7882\n",
      "1103\n",
      "1104\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "0.03329734716547616  ,  0.4492  ,  1.0616\n",
      "nan  ,  0.4248  ,  1.0879\n",
      "1105\n",
      "1106\n",
      "0.10973645261961691  ,  0.3755  ,  0.5533\n",
      "0.033971011149177395  ,  0.4678  ,  0.4838\n",
      "-0.020450244481249637  ,  0.5501  ,  0.4356\n",
      "1107\n",
      "1108\n",
      "-0.030474939133558455  ,  0.7721  ,  0.3779\n",
      "-0.13416127011011628  ,  0.5564  ,  0.4409\n",
      "-0.06832812949301337  ,  0.5476  ,  0.4453\n",
      "1109\n",
      "1110\n",
      "-0.10475891543266277  ,  0.5691  ,  0.8513\n",
      "0.06713629116908316  ,  0.6613  ,  0.7333\n",
      "0.009481726202669688  ,  0.6624  ,  0.7325\n",
      "1111\n",
      "1112\n",
      "0.0082523391173689  ,  0.3231  ,  0.8394\n",
      "-0.031022462269619404  ,  0.4418  ,  0.7233\n",
      "-0.011236802130793807  ,  0.4265  ,  0.7366\n",
      "1113\n",
      "1114\n",
      "-0.054811894237243385  ,  0.9067  ,  0.4008\n",
      "-0.04211684368886747  ,  0.6208  ,  0.4247\n",
      "0.028727033887256694  ,  0.5804  ,  0.4392\n",
      "1115\n",
      "1116\n",
      "0.030626132681073275  ,  0.3956  ,  0.9913\n",
      "0.0426704167733706  ,  0.3969  ,  0.9894\n",
      "-0.0005978645697386199  ,  0.3858  ,  1.0016\n",
      "1117\n",
      "1118\n",
      "0.011691573605309011  ,  0.4283  ,  0.6043\n",
      "0.021763933047473007  ,  0.2593  ,  0.7007\n",
      "0.020960415700020888  ,  0.2596  ,  0.7005\n",
      "1119\n",
      "1120\n",
      "-0.04673659862187783  ,  0.5412  ,  0.8057\n",
      "-0.012550336749338819  ,  0.4357  ,  0.8389\n",
      "-0.06456720002807015  ,  0.4435  ,  0.8338\n",
      "1121\n",
      "1122\n",
      "-0.05423245324015248  ,  0.9381  ,  0.4061\n",
      "0.11005783795671627  ,  0.5953  ,  0.5202\n",
      "0.030334991340819156  ,  0.6351  ,  0.4912\n",
      "1123\n",
      "1124\n",
      "0.11291545323797401  ,  0.8744  ,  0.499\n",
      "-0.056815845161761094  ,  0.6166  ,  0.5764\n",
      "-0.01555177712034813  ,  0.6257  ,  0.5722\n",
      "1125\n",
      "1126\n",
      "0.17831251532404746  ,  0.5187  ,  0.5244\n",
      "-0.048895436581268416  ,  0.6413  ,  0.4507\n",
      "0.03109882848733638  ,  0.6392  ,  0.4518\n",
      "1127\n",
      "1128\n",
      "-0.030361865555078707  ,  0.2791  ,  0.8518\n",
      "-0.004854794460495035  ,  0.2691  ,  0.8563\n",
      "-0.04166740950993838  ,  0.3242  ,  0.8138\n",
      "1129\n",
      "1130\n",
      "0.5057917262715035  ,  0.8962  ,  0.4722\n",
      "0.02840870108368826  ,  0.6152  ,  0.6724\n",
      "-0.05314459706901268  ,  0.6308  ,  0.6614\n",
      "1131\n",
      "1132\n",
      "0.058999133766244063  ,  0.6476  ,  0.5731\n",
      "0.03686970089193744  ,  0.3719  ,  0.6763\n",
      "-0.03676464876603928  ,  0.3753  ,  0.6744\n",
      "1133\n",
      "1134\n",
      "0.24427498766120895  ,  0.2793  ,  0.7733\n",
      "0.08061027731610665  ,  0.2464  ,  0.8088\n",
      "-0.04738907026095732  ,  0.2982  ,  0.7723\n",
      "1135\n",
      "1136\n",
      "0.1487615301626728  ,  0.3056  ,  0.6515\n",
      "-0.020134232985160257  ,  0.251  ,  0.6901\n",
      "0.02795015082445919  ,  0.251  ,  0.6901\n",
      "1137\n",
      "1138\n",
      "nan  ,  0.2414  ,  0.8085\n",
      "0.11063372393668902  ,  0.2739  ,  0.7849\n",
      "0.014183592293923379  ,  0.263  ,  0.7929\n",
      "1139\n",
      "1140\n",
      "0.09209773959498388  ,  0.3767  ,  0.7768\n",
      "0.005325872437632944  ,  0.3697  ,  0.7863\n",
      "0.07074968484454777  ,  0.3635  ,  0.7911\n",
      "1141\n",
      "1142\n",
      "0.18325849011335976  ,  0.5518  ,  0.8089\n",
      "-0.026612424653235253  ,  0.527  ,  0.8289\n",
      "-0.020246176811475926  ,  0.5563  ,  0.8131\n",
      "1143\n",
      "1144\n",
      "0.13459153082897465  ,  0.9643  ,  0.51\n",
      "-0.0683191688153393  ,  0.3267  ,  0.6709\n",
      "0.01695165639105977  ,  0.3343  ,  0.6662\n",
      "1145\n",
      "1146\n",
      "0.14898151564365583  ,  0.6838  ,  0.5285\n",
      "-0.06610402674720499  ,  0.6504  ,  0.5518\n",
      "-0.10164716672353956  ,  0.5954  ,  0.5807\n",
      "1147\n",
      "1148\n",
      "0.06940056608259684  ,  0.5376  ,  0.7952\n",
      "0.06450599915829786  ,  0.5341  ,  0.8\n",
      "0.0006419113747806203  ,  0.5384  ,  0.796\n",
      "1149\n",
      "1150\n",
      "-0.11269199857514454  ,  0.2573  ,  0.6913\n",
      "0.07153599266176452  ,  0.3212  ,  0.6396\n",
      "-0.0378121190706454  ,  0.211  ,  0.7144\n",
      "1151\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "'''\n",
    "responses = {\n",
    "                '.9.9':{'best':{},'random':{},'worst':{}},\n",
    "                '0.80.9':{'best':{},'random':{},'worst':{}},\n",
    "                '0.60.8':{'best':{},'random':{},'worst':{}},\n",
    "                '0.40.7':{'best':{},'random':{},'worst':{}},\n",
    "                '0.20.6':{'best':{},'random':{},'worst':{}}\n",
    "            }\n",
    "'''\n",
    "\n",
    "for size in responses:\n",
    "    if size == '.9.9':\n",
    "        rang = range(778,1152)\n",
    "    else:\n",
    "        rang = range(64,1152)\n",
    "    for node in rang:\n",
    "        print(node)\n",
    "        for v in ['best','random','worst']:\n",
    "            try:\n",
    "                if v == 'best':\n",
    "                    submodel_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/%s_%s.pt'%(str(node),size))\n",
    "                else:\n",
    "                    submodel_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/%s_models/%s_%s.pt'%(v,str(node),size))\n",
    "                submodel = submodel_dict['model']\n",
    "                model_act,submodel_act = same_node_subgraph_responses(node,model,submodel, 'small_SPAN', params,batch_size = 18)\n",
    "\n",
    "                #print(v)\n",
    "\n",
    "                diffs = torch.abs(model_act-submodel_act)\n",
    "                av,sd = round(float(torch.mean(diffs)),4),round(float(torch.std(diffs)),4)\n",
    "\n",
    "                model_act,submodel_act = model_act.cpu().numpy(),submodel_act.cpu().numpy()\n",
    "                corr = pearsonr(submodel_act,model_act)[0] \n",
    "\n",
    "                print(str(corr)+'  ,  '+str(av)+ '  ,  '+str(sd))\n",
    "                responses[size][v][node] = (corr,av,sd)\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 0.3984, 1.546)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing nans\n",
    "from copy import deepcopy\n",
    "nantup = deepcopy(responses['0.80.9']['worst'][70])\n",
    "nantup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(responses,open('./prepped_models/alexnet_sparse/subgraphs/info/subgraph_corellations.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_act,submodel_act = same_node_subgraph_responses(node,model,submodel, 'small_SPAN', params,batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "rgb(0,100,80)"
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          1,
          2,
          7,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(0,100,80,0.2)",
         "hoverinfo": "skip",
         "line": {
          "color": "rgba(255,255,255,0)"
         },
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          10,
          9,
          8,
          7,
          6,
          5,
          4,
          3,
          2,
          1
         ],
         "y": [
          2,
          3,
          8,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          9,
          8,
          7,
          6,
          5,
          4,
          3,
          5,
          1,
          0
         ]
        }
       ],
       "layout": {
        "paper_bgcolor": "rgba(0,0,0,0)",
        "plot_bgcolor": "rgba(0,0,0,0)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"38c427eb-2b2d-4402-a754-851bd93bbfa2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"38c427eb-2b2d-4402-a754-851bd93bbfa2\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '38c427eb-2b2d-4402-a754-851bd93bbfa2',\n",
       "                        [{\"line\": {\"color\": \"rgb(0,100,80)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [1, 2, 7, 4, 5, 6, 7, 8, 9, 10]}, {\"fill\": \"toself\", \"fillcolor\": \"rgba(0,100,80,0.2)\", \"hoverinfo\": \"skip\", \"line\": {\"color\": \"rgba(255,255,255,0)\"}, \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1], \"y\": [2, 3, 8, 5, 6, 7, 8, 9, 10, 11, 9, 8, 7, 6, 5, 4, 3, 5, 1, 0]}],\n",
       "                        {\"paper_bgcolor\": \"rgba(0,0,0,0)\", \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('38c427eb-2b2d-4402-a754-851bd93bbfa2');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Plotting\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y = [1, 2, 7, 4, 5, 6, 7, 8, 9, 10]\n",
    "y_upper = [2, 3, 8, 5, 6, 7, 8, 9, 10, 11]\n",
    "y_lower = [0, 1, 5, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        line=dict(color='rgb(0,100,80)'),\n",
    "        mode='lines'\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=x+x[::-1], # x, then x reversed\n",
    "        y=y_upper+y_lower[::-1], # upper, then lower reversed\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(0,100,80,0.2)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "layout = Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.layout = layout\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subgraph visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lucent_edited.optvis import render\n",
    "from lucent_edited.modelzoo.util import get_model_layers\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualize  'size' equivalent subgraphs \n",
    "model_dis.to('cuda:2')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "version = 'worst'\n",
    "node = 438\n",
    "size_model_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/%s_models/%s_.9.9.pt'%(version,str(node)))\n",
    "size_model = size_model_dict['model']\n",
    "size_model.to('cuda:0')\n",
    "name = None\n",
    "for name, module in size_model.named_modules():\n",
    "    pass\n",
    "param_f = lambda: param.image(224,batch=1)\n",
    "obj =  objectives.neuron(name, 0, batch=0) \n",
    "_ = render.render_vis(size_model, obj, param_f, verbose=True, show_inline=True,show_image=True, save_image=False,image_name = 'prepped_models/alexnet_sparse/subgraphs/visualizations/%s_.9.9_target.jpg'%str(node))\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize subgraphs of different sizes\n",
    "model_dis.to('cuda:2')\n",
    "\n",
    "start = time.time()\n",
    "sizes = ['0.80.9','0.60.8','0.40.7','0.20.6']\n",
    "node = 200\n",
    "for size in sizes:\n",
    "    size_model_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/%s_%s.pt'%(str(node),size))\n",
    "    size_model = size_model_dict['model']\n",
    "    size_model.to('cuda:0')\n",
    "    name = None\n",
    "    for name, module in size_model.named_modules():\n",
    "        pass\n",
    "    param_f = lambda: param.image(224,batch=1)\n",
    "    obj =  objectives.neuron(name, 0, batch=0) \n",
    "    _ = render.render_vis(size_model, obj, param_f, verbose=True, show_inline=True,show_image=True, save_image=False,image_name = 'prepped_models/alexnet_sparse/subgraphs/visualizations/%s_.9.9_target.jpg'%str(node))\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get subgraph sizes\n",
    "\n",
    "#visualize subgraphs of different sizes\n",
    "model_dis.to('cuda:2')\n",
    "\n",
    "\n",
    "sizes = ['.9.9','0.80.9','0.60.8','0.40.7','0.20.6']\n",
    "node = 200\n",
    "for size in sizes:\n",
    "    size_model_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/%s_%s.pt'%(str(node),size))\n",
    "    print(len(size_model_dict['edge_df']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs of different sizes and types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"1\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-2.0327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-2.6406, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-2.7777, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-2.4577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-3.8017, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-2.6600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-2.0181, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "1\n",
      "tensor(-4.3398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 1 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000000       0.000000  \n",
      "1        0.000000       0.000000  \n",
      "2        0.000000       0.000000  \n",
      "3        0.000053       0.000028  \n",
      "4        0.000053       0.000077  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"3\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.0240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.0462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.1278, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.0614, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.0633, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.0622, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.0203, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "3\n",
      "tensor(-0.1101, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 3 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"5\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(0.1733, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(-0.0815, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(-0.0343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(-0.0093, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(0.0647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(-0.0010, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(-0.0827, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "5\n",
      "tensor(0.0050, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 5 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"7\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-0.9460, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-1.1815, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-1.3876, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-1.2486, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-1.4769, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-1.6958, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-1.2418, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "7\n",
      "tensor(-2.2419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 7 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"9\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0675, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0762, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0770, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0744, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0513, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.0798, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "9\n",
      "tensor(-0.1043, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 9 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"11\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0929, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0944, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0931, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0790, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0876, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0886, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.1019, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "11\n",
      "tensor(-0.0919, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 11 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"13\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0414, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0310, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0400, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "13\n",
      "tensor(-0.0116, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 13 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"15\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.0320, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.5174, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.2509, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.9967, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.1496, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(0.3423, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.2326, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "15\n",
      "tensor(-1.1745, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 15 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"17\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(-0.0567, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(0.0083, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(0.1099, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(0.0424, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(0.1458, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(-0.1122, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(0.0738, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "17\n",
      "tensor(-0.0334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 17 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"19\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-1.1371, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-1.3867, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(0.3343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-1.1985, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-1.0833, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-1.9933, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-1.1310, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "19\n",
      "tensor(-0.6349, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 19 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"21\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(0.2591, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(-0.1375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(-0.7694, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(1.2105, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(0.3967, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(0.0861, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(-0.3052, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "21\n",
      "tensor(1.0863, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 21 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"23\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0743, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0391, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0528, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0259, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0256, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0541, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "23\n",
      "tensor(-0.0719, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 23 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"25\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0515, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0665, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0735, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0219, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0313, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "25\n",
      "tensor(-0.0715, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 25 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"27\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0523, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0593, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0331, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0192, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0413, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "27\n",
      "tensor(-0.0558, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 27 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"29\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1020, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1743, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1595, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1663, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.0987, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1540, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "29\n",
      "tensor(-0.1324, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 29 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"31\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.8671, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.7959, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.7164, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.9110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.7494, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.8218, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.7842, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "31\n",
      "tensor(-1.7027, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 31 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"33\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0299, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0383, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0359, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0402, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0394, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0276, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "33\n",
      "tensor(-0.0241, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 33 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"35\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(-1.0766, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(-0.5288, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(-0.5714, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(0.3233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(0.0887, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(0.2823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(0.3856, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "35\n",
      "tensor(1.4774, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 35 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"37\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(0.1696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(0.9381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(0.2870, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(0.6509, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(1.2638, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(0.4848, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(0.0995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "37\n",
      "tensor(-0.3427, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 37 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"39\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-2.0187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-1.8920, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-1.9797, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-1.8719, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-1.9765, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-1.8522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-1.8741, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "39\n",
      "tensor(-2.2029, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 39 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"41\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0390, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0271, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0279, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0232, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0247, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0402, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "41\n",
      "tensor(-0.0556, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 41 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"43\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0277, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(0.0040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0732, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0096, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0186, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "43\n",
      "tensor(-0.0442, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 43 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"45\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7333, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7251, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7661, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7192, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.8311, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7495, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7746, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "45\n",
      "tensor(-1.7929, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 45 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"47\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.1647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.0781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(-0.0349, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.1078, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.0141, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.0944, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.0145, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "47\n",
      "tensor(0.0076, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 47 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"49\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(0.0110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(0.0006, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(-0.0034, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(-0.0147, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(-0.0543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(0.0024, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(-0.0238, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "49\n",
      "tensor(-0.1692, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 49 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"51\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-2.1336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-2.4494, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-0.7805, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-0.7252, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-1.4925, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-2.1763, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(-2.5949, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "51\n",
      "tensor(0.1263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 51 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"53\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(-0.0565, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(-0.3542, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(0.4889, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(-0.4454, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(0.6592, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(-0.0915, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(0.1877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "53\n",
      "tensor(1.6215, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 53 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"55\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0381, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0349, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0521, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0437, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0424, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 55 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0492, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "55\n",
      "tensor(-0.0405, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 55 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933792   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"57\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0554, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0464, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0584, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0658, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0426, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0525, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "57\n",
      "tensor(-0.0223, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 57 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"59\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.1263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.1260, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.0603, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.0653, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.0275, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.0234, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.0020, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "59\n",
      "tensor(-0.0173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 59 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"61\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.1979, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.1970, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.1930, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.1981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.1927, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.1852, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(-0.2043, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "61\n",
      "tensor(0.0010, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 61 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"63\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0250, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0258, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0194, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0255, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0291, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_0\n",
      "63\n",
      "tensor(-0.0221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 63 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0             0.0            0.0  \n",
      "1             0.0            0.0  \n",
      "2             0.0            0.0  \n",
      "3             0.0            0.0  \n",
      "4             0.0            0.0  \n",
      "...           ...            ...  \n",
      "250043        0.0            0.0  \n",
      "250044        0.0            0.0  \n",
      "250045        0.0            0.0  \n",
      "250046        0.0            0.0  \n",
      "250047        0.0            0.0  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 1\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 1\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 1\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "layer: 0\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"65\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-4.0077, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-3.2758, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-3.1294, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-5.0336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-2.6246, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-2.3591, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-3.8040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "1\n",
      "tensor(-4.9882, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 65 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       7.662084e-06   1.667728e-05  \n",
      "1       7.662084e-06   2.941219e-05  \n",
      "2       7.662084e-06   9.083406e-06  \n",
      "3       3.412519e-07   1.626944e-07  \n",
      "4       3.412519e-07   7.571344e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"67\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(-0.3134, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(0.6772, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(1.9805, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(1.5928, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(2.0919, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(4.3490, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(1.7393, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "3\n",
      "tensor(-1.4097, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 67 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003       0.000007  \n",
      "1        0.000003       0.000013  \n",
      "2        0.000003       0.000004  \n",
      "3        0.000015       0.000007  \n",
      "4        0.000015       0.000033  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"69\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-1.0325, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-2.4813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-2.0186, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-3.3898, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-2.4162, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-1.7066, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-2.8298, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "5\n",
      "tensor(-2.2048, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 69 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002       0.000005  \n",
      "1        0.000002       0.000008  \n",
      "2        0.000002       0.000003  \n",
      "3        0.000003       0.000002  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"71\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-4.0582, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-4.1794, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-5.6500, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-2.9538, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-4.1643, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-5.1045, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-4.9677, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "7\n",
      "tensor(-4.1506, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 71 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000011  \n",
      "1        0.000005       0.000018  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"73\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-3.2511, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-1.9496, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-2.3737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-2.0416, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-2.9594, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-3.3698, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-2.0131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "9\n",
      "tensor(-1.2430, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 73 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003       0.000006  \n",
      "1        0.000003       0.000010  \n",
      "2        0.000003       0.000003  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"75\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-0.6543, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-1.5266, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-0.7559, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 75 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-0.9529, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-0.7594, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-0.0847, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-1.3797, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "11\n",
      "tensor(-0.7359, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 75 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002       0.000005  \n",
      "1        0.000002       0.000008  \n",
      "2        0.000002       0.000002  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"77\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-4.7813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-0.1987, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-3.2023, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-3.7250, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-0.2516, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-1.0988, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-2.2938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "13\n",
      "tensor(-18.4526, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 77 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000077       0.000183  \n",
      "1        0.000077       0.000313  \n",
      "2        0.000077       0.000094  \n",
      "3        0.000016       0.000008  \n",
      "4        0.000016       0.000036  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"79\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-4.1436, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-6.6422, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-2.7524, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-3.5203, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-2.9707, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-5.3382, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-4.0722, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 79 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "15\n",
      "tensor(-5.7912, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 79 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.067550e-05   4.916694e-05  \n",
      "1       2.067550e-05   8.401489e-05  \n",
      "2       2.067550e-05   2.529316e-05  \n",
      "3       7.484737e-07   3.437720e-07  \n",
      "4       7.484737e-07   1.751731e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"81\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-4.4741, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-5.5893, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-5.4199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-6.7007, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-4.9885, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-4.0569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-5.5368, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "17\n",
      "tensor(-2.0258, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 81 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000020       0.000046  \n",
      "1        0.000020       0.000081  \n",
      "2        0.000020       0.000024  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"83\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-5.1102, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-4.6526, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-5.5191, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-3.7869, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-5.2624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-4.2651, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-5.1124, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "19\n",
      "tensor(-1.5386, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 83 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002       0.000005  \n",
      "1        0.000002       0.000008  \n",
      "2        0.000002       0.000002  \n",
      "3        0.000004       0.000002  \n",
      "4        0.000004       0.000008  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"85\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-2.1246, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.7599, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.6602, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.5317, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.3340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.6123, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.9133, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "21\n",
      "tensor(-1.6235, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 85 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.954348e-06   4.546981e-06  \n",
      "1       1.954348e-06   7.794953e-06  \n",
      "2       1.954348e-06   2.380046e-06  \n",
      "3       1.104171e-07   4.913729e-08  \n",
      "4       1.104171e-07   2.424370e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"87\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-4.8725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-4.8191, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-3.7137, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-6.3088, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-4.4809, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-2.9903, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-2.9690, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "23\n",
      "tensor(-4.4858, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 87 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.341844e-05   1.150171e-04  \n",
      "1       5.341844e-05   1.989051e-04  \n",
      "2       5.341844e-05   6.319829e-05  \n",
      "3       4.145533e-09   1.877999e-09  \n",
      "4       4.145533e-09   8.907236e-09  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"89\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-2.4462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-2.2904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-1.5534, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 89 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-2.5494, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-0.6484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-4.4862, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(-1.3052, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "25\n",
      "tensor(0.8430, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 89 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       9.506909e-09   2.192175e-08  \n",
      "1       9.506909e-09   3.760225e-08  \n",
      "2       9.506909e-09   1.141318e-08  \n",
      "3       6.025665e-07   2.927120e-07  \n",
      "4       6.025665e-07   1.338759e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"91\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-7.7438, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-5.6100, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-6.2407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-4.7507, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-5.7712, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-7.1624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-6.3232, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "27\n",
      "tensor(-10.8493, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 91 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       6.593819e-06   1.523081e-05  \n",
      "1       6.593819e-06   2.614622e-05  \n",
      "2       6.593819e-06   8.122108e-06  \n",
      "3       6.150971e-09   2.698850e-09  \n",
      "4       6.150971e-09   1.371242e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"93\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-3.0840, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-2.0932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-3.3174, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-2.6853, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-3.1829, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-3.2209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-2.7189, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 93 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "29\n",
      "tensor(-2.8653, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 93 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004   9.420632e-06  \n",
      "1        0.000004   1.590275e-05  \n",
      "2        0.000004   4.789491e-06  \n",
      "3        0.000001   5.297217e-07  \n",
      "4        0.000001   2.569246e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"95\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(-1.0397, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(-2.1694, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(-0.5480, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(0.0341, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(-1.8965, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(-1.4422, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(0.2689, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "31\n",
      "tensor(-0.2532, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 95 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933792   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002   4.301455e-06  \n",
      "1        0.000002   7.362513e-06  \n",
      "2        0.000002   2.221561e-06  \n",
      "3        0.000001   4.647693e-07  \n",
      "4        0.000001   2.231325e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"97\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-2.0385, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-2.0936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-3.8354, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-2.3290, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-3.7361, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-1.3845, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-1.9334, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "33\n",
      "tensor(-3.2540, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 97 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003       0.000007  \n",
      "1        0.000003       0.000012  \n",
      "2        0.000003       0.000004  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000016  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"99\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-3.1098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-4.2551, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-2.5687, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-3.0134, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-3.3329, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-2.7233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-2.6443, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "35\n",
      "tensor(-3.3261, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 99 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.291115e-05   3.086950e-05  \n",
      "1       1.291115e-05   5.275008e-05  \n",
      "2       1.291115e-05   1.614987e-05  \n",
      "3       7.581260e-07   3.494127e-07  \n",
      "4       7.581260e-07   1.754214e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"101\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-1.7721, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-1.6860, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-2.2234, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-1.4810, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-1.9098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-1.5582, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-2.4082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "37\n",
      "tensor(-1.1747, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 101 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       4.023989e-06   9.061877e-06  \n",
      "1       4.023989e-06   1.553958e-05  \n",
      "2       4.023989e-06   4.697682e-06  \n",
      "3       6.450205e-07   2.890212e-07  \n",
      "4       6.450205e-07   1.411210e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"103\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(-0.5270, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(0.1853, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(1.1199, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 103 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(-0.6970, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(-0.1851, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(-1.2173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(-0.6592, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "39\n",
      "tensor(1.7806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 103 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000013       0.000032  \n",
      "1        0.000013       0.000054  \n",
      "2        0.000013       0.000016  \n",
      "3        0.000022       0.000010  \n",
      "4        0.000022       0.000050  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"105\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-14.2590, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-8.2363, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-9.9989, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-12.9130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-9.9573, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-8.4816, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-11.2985, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "41\n",
      "tensor(-9.4542, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 105 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       9.789696e-07       0.000002  \n",
      "1       9.789696e-07       0.000004  \n",
      "2       9.789696e-07       0.000001  \n",
      "3       3.785565e-06       0.000002  \n",
      "4       3.785565e-06       0.000008  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00       0.000000  \n",
      "250044  0.000000e+00       0.000000  \n",
      "250045  0.000000e+00       0.000000  \n",
      "250046  0.000000e+00       0.000000  \n",
      "250047  0.000000e+00       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"107\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-4.1035, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-3.7922, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-3.0832, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-2.4140, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-3.1757, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-3.2398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-3.5844, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "43\n",
      "tensor(-5.0063, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 107 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       9.792469e-07       0.000002  \n",
      "1       9.792469e-07       0.000004  \n",
      "2       9.792469e-07       0.000001  \n",
      "3       7.298947e-06       0.000003  \n",
      "4       7.298947e-06       0.000016  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00       0.000000  \n",
      "250044  0.000000e+00       0.000000  \n",
      "250045  0.000000e+00       0.000000  \n",
      "250046  0.000000e+00       0.000000  \n",
      "250047  0.000000e+00       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"109\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-9.9904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-7.5065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-9.1765, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-6.1392, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-10.6933, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-9.1835, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-8.8925, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "45\n",
      "tensor(-3.0925, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 109 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000022  \n",
      "1        0.000010       0.000039  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000005       0.000002  \n",
      "4        0.000005       0.000012  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"111\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-3.3380, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-6.0598, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-2.6507, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-2.2860, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-3.9469, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-4.9213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(-4.9305, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "47\n",
      "tensor(0.8825, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 111 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.835931e-06   1.247732e-05  \n",
      "1       5.835931e-06   2.159146e-05  \n",
      "2       5.835931e-06   6.453253e-06  \n",
      "3       2.629467e-07   1.175121e-07  \n",
      "4       2.629467e-07   5.838063e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"113\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-3.2112, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-3.0583, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-2.0782, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-3.0728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-2.5932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-3.6911, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-3.7532, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "49\n",
      "tensor(-4.0804, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 113 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007   1.640342e-05  \n",
      "1        0.000007   2.776316e-05  \n",
      "2        0.000007   8.275315e-06  \n",
      "3        0.000001   4.499251e-07  \n",
      "4        0.000001   2.503853e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"115\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-9.3521, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-6.1780, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-8.0322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-8.6766, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-10.2725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-10.0167, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-9.5873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "51\n",
      "tensor(-18.8288, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 115 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000015   3.593347e-05  \n",
      "1        0.000015   6.219641e-05  \n",
      "2        0.000015   1.905253e-05  \n",
      "3        0.000001   4.384235e-07  \n",
      "4        0.000001   2.358814e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"117\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-3.8981, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-2.3932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-3.0350, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 117 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-2.7180, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-1.9807, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-2.7343, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-2.7457, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "53\n",
      "tensor(-6.6769, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 117 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002       0.000004  \n",
      "1        0.000002       0.000007  \n",
      "2        0.000002       0.000002  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"119\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-11.6692, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-8.4283, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-7.5399, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-9.4345, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-6.2902, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-11.0877, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-9.8767, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "55\n",
      "tensor(-8.7621, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 119 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       9.236127e-07   2.209992e-06  \n",
      "1       9.236127e-07   3.758058e-06  \n",
      "2       9.236127e-07   1.179764e-06  \n",
      "3       7.013689e-07   3.276407e-07  \n",
      "4       7.013689e-07   1.518785e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"121\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-7.6706, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-7.4824, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-6.5899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-7.8872, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-8.7596, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-7.3702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-8.1844, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 121 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "57\n",
      "tensor(-6.1151, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 121 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.128050e-09   4.921970e-09  \n",
      "1       2.128050e-09   8.244114e-09  \n",
      "2       2.128050e-09   2.516017e-09  \n",
      "3       5.526322e-07   2.309971e-07  \n",
      "4       5.526322e-07   1.220023e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"123\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-11.4681, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-9.3837, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-14.3781, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-12.0949, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-10.1375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-7.9647, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-11.3269, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "59\n",
      "tensor(-10.3605, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 123 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004       0.000009  \n",
      "1        0.000004       0.000016  \n",
      "2        0.000004       0.000005  \n",
      "3        0.000002       0.000001  \n",
      "4        0.000002       0.000005  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"125\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-5.0650, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-3.0903, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-7.8190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-6.3994, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-2.3904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-6.3018, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-5.9785, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "61\n",
      "tensor(-5.0662, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 125 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.933475e-07   6.713337e-07  \n",
      "1       2.933475e-07   1.158642e-06  \n",
      "2       2.933475e-07   3.508562e-07  \n",
      "3       2.430829e-06   1.128342e-06  \n",
      "4       2.430829e-06   5.439223e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"127\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-18.3089, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-12.6154, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-11.8717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-15.9125, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-13.9941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-12.7468, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-17.0717, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "63\n",
      "tensor(-9.0419, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 127 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003       0.000006  \n",
      "1        0.000003       0.000010  \n",
      "2        0.000003       0.000003  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"129\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-1.6402, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-1.4792, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-5.4703, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-2.8259, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-3.4245, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-0.8564, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-4.6071, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "65\n",
      "tensor(-1.5480, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 129 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.656238e-06   6.185494e-06  \n",
      "1       2.656238e-06   1.058840e-05  \n",
      "2       2.656238e-06   3.210291e-06  \n",
      "3       6.514281e-07   3.044178e-07  \n",
      "4       6.514281e-07   1.424039e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"131\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-6.5442, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-5.3725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-0.3353, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 131 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-3.6685, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-2.4912, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-4.3928, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-3.1775, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "67\n",
      "tensor(-0.3489, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 131 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       8.414913e-06   1.981470e-05  \n",
      "1       8.414913e-06   3.313286e-05  \n",
      "2       8.414913e-06   9.966775e-06  \n",
      "3       1.918143e-08   8.892267e-09  \n",
      "4       1.918143e-08   4.252622e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"133\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.7142, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.5574, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.8158, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.8129, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.7883, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.9600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-1.6658, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "69\n",
      "tensor(-0.8188, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 133 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002   5.526882e-06  \n",
      "1        0.000002   9.393478e-06  \n",
      "2        0.000002   2.867093e-06  \n",
      "3        0.000002   9.616597e-07  \n",
      "4        0.000002   4.988338e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"135\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.8199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.3404, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.1726, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.6649, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.1122, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.3729, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-2.1242, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "71\n",
      "tensor(-3.0628, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 135 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.785030e-07   1.312288e-06  \n",
      "1       5.785030e-07   2.253544e-06  \n",
      "2       5.785030e-07   6.780210e-07  \n",
      "3       1.168824e-06   5.589280e-07  \n",
      "4       1.168824e-06   2.592645e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"137\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-7.3296, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-5.1286, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-7.3946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-5.3784, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-5.0237, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-6.4454, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-6.5225, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "73\n",
      "tensor(-5.9144, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 137 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.225622e-09   2.911479e-09  \n",
      "1       1.225622e-09   4.939454e-09  \n",
      "2       1.225622e-09   1.517049e-09  \n",
      "3       3.245741e-06   1.471716e-06  \n",
      "4       3.245741e-06   7.277729e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"139\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-4.7675, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-5.5997, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-4.0636, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-5.2060, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-5.6040, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-5.1517, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-4.9190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "75\n",
      "tensor(-6.2266, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 139 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003   6.380177e-06  \n",
      "1        0.000003   1.088968e-05  \n",
      "2        0.000003   3.282963e-06  \n",
      "3        0.000002   9.164410e-07  \n",
      "4        0.000002   4.482480e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"141\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-2.1050, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-1.5099, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-1.6111, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-3.1084, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-2.8688, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-2.4952, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(-2.6145, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "77\n",
      "tensor(0.5355, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 141 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       9.941418e-07       0.000002  \n",
      "1       9.941418e-07       0.000004  \n",
      "2       9.941418e-07       0.000001  \n",
      "3       5.844781e-06       0.000002  \n",
      "4       5.844781e-06       0.000013  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00       0.000000  \n",
      "250044  0.000000e+00       0.000000  \n",
      "250045  0.000000e+00       0.000000  \n",
      "250046  0.000000e+00       0.000000  \n",
      "250047  0.000000e+00       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"143\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-6.5167, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-4.0371, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-5.0915, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-3.3992, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-2.8380, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-2.8802, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-3.3761, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "79\n",
      "tensor(-5.7813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 143 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.757274e-05   4.078336e-05  \n",
      "1       1.757274e-05   6.988300e-05  \n",
      "2       1.757274e-05   2.117819e-05  \n",
      "3       7.032122e-07   3.123096e-07  \n",
      "4       7.032122e-07   1.542996e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"145\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-3.9340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-6.0678, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-2.1696, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 145 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-3.2583, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-3.1059, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-2.1537, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-3.6355, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "81\n",
      "tensor(-4.0918, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 145 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002       0.000004  \n",
      "1        0.000002       0.000007  \n",
      "2        0.000002       0.000002  \n",
      "3        0.000014       0.000006  \n",
      "4        0.000014       0.000030  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"147\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-16.7061, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-15.5273, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-22.6963, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-19.4995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-15.5356, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-19.2009, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-17.5379, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "83\n",
      "tensor(-10.6412, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 147 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.665508e-06   6.057262e-06  \n",
      "1       2.665508e-06   1.022522e-05  \n",
      "2       2.665508e-06   3.086391e-06  \n",
      "3       6.283556e-07   2.821197e-07  \n",
      "4       6.283556e-07   1.527379e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"149\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-4.9489, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-4.9707, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-5.0461, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-4.7209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-4.3107, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-4.7344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-6.4428, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 149 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "85\n",
      "tensor(-1.5856, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 149 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000022  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000002       0.000001  \n",
      "4        0.000002       0.000005  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"151\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-2.7300, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-2.0687, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-2.1156, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-3.0536, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-2.9072, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-1.7207, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-3.7415, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "87\n",
      "tensor(-3.6396, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 151 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004   9.143184e-06  \n",
      "1        0.000004   1.564073e-05  \n",
      "2        0.000004   4.739547e-06  \n",
      "3        0.000002   7.939046e-07  \n",
      "4        0.000002   3.781240e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"153\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-3.4278, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-3.4531, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-3.6596, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-2.8857, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-3.0727, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-3.2908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-4.1997, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "89\n",
      "tensor(-1.7968, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 153 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008   1.854858e-05  \n",
      "1        0.000008   3.172108e-05  \n",
      "2        0.000008   9.762643e-06  \n",
      "3        0.000002   7.344349e-07  \n",
      "4        0.000002   3.450269e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"155\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-2.8452, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-3.8683, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-2.9899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-3.1466, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-3.8338, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-2.6423, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-2.8138, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "91\n",
      "tensor(-1.9344, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 155 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       9.965960e-06   2.333959e-05  \n",
      "1       9.965960e-06   3.995662e-05  \n",
      "2       9.965960e-06   1.219466e-05  \n",
      "3       6.588228e-07   3.052157e-07  \n",
      "4       6.588228e-07   1.507370e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"157\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-2.8409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-2.1771, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-3.7623, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-2.8108, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-1.2850, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-3.2881, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-2.6513, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "93\n",
      "tensor(-1.9605, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 157 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000025       0.000059  \n",
      "1        0.000025       0.000100  \n",
      "2        0.000025       0.000031  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"159\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-5.2899, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-4.8179, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-5.0904, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 159 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-4.3923, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-2.9874, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-3.6758, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-5.7118, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "95\n",
      "tensor(-4.1666, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 159 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007   1.629768e-05  \n",
      "1        0.000007   2.792348e-05  \n",
      "2        0.000007   8.483773e-06  \n",
      "3        0.000002   8.017970e-07  \n",
      "4        0.000002   4.082467e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"161\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-1.6930, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-3.8570, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-3.3053, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-3.6478, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-1.6580, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-3.3055, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-2.7216, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "97\n",
      "tensor(-0.7879, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 161 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.332549e-08   3.322162e-08  \n",
      "1       1.332549e-08   5.522092e-08  \n",
      "2       1.332549e-08   1.645180e-08  \n",
      "3       3.431733e-07   1.699795e-07  \n",
      "4       3.431733e-07   8.079481e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"163\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-3.5519, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-3.5599, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-2.4567, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-2.9696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-2.1521, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-2.4567, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-3.5034, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "99\n",
      "tensor(-4.9636, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 163 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002       0.000005  \n",
      "1        0.000002       0.000008  \n",
      "2        0.000002       0.000002  \n",
      "3        0.000003       0.000002  \n",
      "4        0.000003       0.000008  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"165\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-3.1994, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-3.5948, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-2.6862, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-3.0696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-2.3407, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-3.7806, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(-2.5253, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "101\n",
      "tensor(0.6941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 165 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.265199e-05   3.038036e-05  \n",
      "1       1.265199e-05   5.192270e-05  \n",
      "2       1.265199e-05   1.590741e-05  \n",
      "3       2.664554e-07   1.303562e-07  \n",
      "4       2.664554e-07   6.131490e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"167\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-5.9896, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-8.5932, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-7.6718, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-6.6233, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-10.3420, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-6.1255, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-7.9709, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "103\n",
      "tensor(-6.3889, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 167 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000024  \n",
      "1        0.000011       0.000041  \n",
      "2        0.000011       0.000012  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"169\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-0.9198, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-1.2139, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-0.9283, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-0.8053, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-1.1418, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-0.7831, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-0.9964, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "105\n",
      "tensor(-0.5631, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 169 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.162155e-08   5.050173e-08  \n",
      "1       2.162155e-08   8.660983e-08  \n",
      "2       2.162155e-08   2.637826e-08  \n",
      "3       4.391324e-09   2.061759e-09  \n",
      "4       4.391324e-09   9.501747e-09  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"171\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(-0.3313, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(-0.6763, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(0.0790, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(-0.1485, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(-0.0679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(0.0187, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(0.4427, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "107\n",
      "tensor(1.3417, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 171 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000020       0.000047  \n",
      "1        0.000020       0.000079  \n",
      "2        0.000020       0.000024  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000006  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"173\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-1.9141, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-1.1888, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-1.4291, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 173 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-1.9633, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-0.4305, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(0.2695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-0.7822, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "109\n",
      "tensor(-1.8705, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 173 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000014       0.000034  \n",
      "1        0.000014       0.000058  \n",
      "2        0.000014       0.000018  \n",
      "3        0.000003       0.000002  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"175\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-2.1653, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.8072, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.6131, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.3421, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.7702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.7023, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.3753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "111\n",
      "tensor(-1.7013, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 175 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005   1.252609e-05  \n",
      "1        0.000005   2.150270e-05  \n",
      "2        0.000005   6.696750e-06  \n",
      "3        0.000002   7.689877e-07  \n",
      "4        0.000002   3.955476e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"177\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-3.2558, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-4.7476, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-4.7220, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-4.5171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-2.9979, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-4.1720, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-5.3041, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 177 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "113\n",
      "tensor(-9.3611, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 177 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       3.407216e-06   8.733396e-06  \n",
      "1       3.407216e-06   1.454129e-05  \n",
      "2       3.407216e-06   4.273066e-06  \n",
      "3       8.867511e-07   3.986345e-07  \n",
      "4       8.867511e-07   2.026881e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"179\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-12.3612, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-8.8778, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-6.4689, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-12.4086, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-14.0618, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-9.0993, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-9.8568, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "115\n",
      "tensor(-19.4405, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 179 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000001   3.169115e-06  \n",
      "1        0.000001   5.380293e-06  \n",
      "2        0.000001   1.694060e-06  \n",
      "3        0.000001   6.787502e-07  \n",
      "4        0.000001   3.201446e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"181\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-1.3130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-0.3160, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-1.3967, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-0.8810, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-0.2950, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-1.0130, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-1.4387, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "117\n",
      "tensor(-1.5409, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 181 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.480102e-05   3.283025e-05  \n",
      "1       1.480102e-05   5.660635e-05  \n",
      "2       1.480102e-05   1.752665e-05  \n",
      "3       1.268131e-07   5.954736e-08  \n",
      "4       1.268131e-07   2.788987e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"183\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-2.0242, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-2.8037, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-2.6438, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-2.4495, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-2.7655, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-3.3671, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-3.0397, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "119\n",
      "tensor(-3.8875, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 183 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       8.659882e-06   1.882543e-05  \n",
      "1       8.659882e-06   3.326275e-05  \n",
      "2       8.659882e-06   1.024894e-05  \n",
      "3       2.599180e-08   1.228497e-08  \n",
      "4       2.599180e-08   5.771368e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"185\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-1.9862, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-3.2937, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-1.8090, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-2.2785, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-2.8437, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-2.9247, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-2.4656, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "121\n",
      "tensor(-1.6145, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 185 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       8.868002e-06   2.025853e-05  \n",
      "1       8.868002e-06   3.477627e-05  \n",
      "2       8.868002e-06   1.053046e-05  \n",
      "3       1.194691e-09   5.649730e-10  \n",
      "4       1.194691e-09   2.631900e-09  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"187\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-5.5805, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-6.6992, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-7.0371, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 187 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-12.2901, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-9.3383, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-8.0733, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-9.0046, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "123\n",
      "tensor(-5.5452, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 187 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004       0.000008  \n",
      "1        0.000004       0.000014  \n",
      "2        0.000004       0.000004  \n",
      "3        0.000002       0.000001  \n",
      "4        0.000002       0.000005  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"189\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(-1.2520, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(-2.0190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(-3.2652, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(-3.5336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(0.0058, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(-2.6816, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(-1.6259, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "125\n",
      "tensor(2.0067, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 189 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002   3.571346e-06  \n",
      "1        0.000002   6.125590e-06  \n",
      "2        0.000002   1.791326e-06  \n",
      "3        0.000001   6.307100e-07  \n",
      "4        0.000001   3.099535e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"191\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-3.3199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-3.8593, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-2.8843, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-3.2501, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-3.5152, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-2.8420, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-3.2939, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "127\n",
      "tensor(-1.3853, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 191 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.922249e-05   4.129149e-05  \n",
      "1       1.922249e-05   7.136637e-05  \n",
      "2       1.922249e-05   2.266235e-05  \n",
      "3       5.696721e-07   2.577155e-07  \n",
      "4       5.696721e-07   1.212675e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"193\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-0.5787, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-4.0727, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-0.8318, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-2.0916, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-0.9554, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-0.1628, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-1.1421, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "129\n",
      "tensor(-0.1023, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 193 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.910227e-06   1.326373e-05  \n",
      "1       5.910227e-06   2.274041e-05  \n",
      "2       5.910227e-06   6.844249e-06  \n",
      "3       3.231266e-07   1.483531e-07  \n",
      "4       3.231266e-07   7.133050e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"195\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-3.9626, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-4.3943, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-3.4117, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-4.9663, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-4.6689, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-4.1969, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-3.2015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "131\n",
      "tensor(-7.9715, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 195 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.241894e-06   1.348633e-05  \n",
      "1       5.241894e-06   2.284854e-05  \n",
      "2       5.241894e-06   6.749486e-06  \n",
      "3       4.674907e-07   2.197901e-07  \n",
      "4       4.674907e-07   1.059074e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"197\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-8.6222, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-10.8927, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-11.0117, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-11.1995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-8.3285, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-10.6340, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-9.9560, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "133\n",
      "tensor(-7.5588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 197 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       6.342364e-07   1.460025e-06  \n",
      "1       6.342364e-07   2.462718e-06  \n",
      "2       6.342364e-07   7.222026e-07  \n",
      "3       2.809762e-06   1.278707e-06  \n",
      "4       2.809762e-06   6.313547e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"199\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-2.1960, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-2.2124, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-1.3772, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-2.1487, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-2.2657, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-2.2427, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-1.9672, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "135\n",
      "tensor(-2.4244, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 199 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000013  \n",
      "1        0.000005       0.000022  \n",
      "2        0.000005       0.000007  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"201\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-3.7644, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-3.1213, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-3.2003, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 201 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-3.5015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-3.9634, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-2.8403, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-3.2545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "137\n",
      "tensor(-1.9710, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 201 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.002826e-06   1.104546e-05  \n",
      "1       5.002826e-06   1.900149e-05  \n",
      "2       5.002826e-06   5.873047e-06  \n",
      "3       2.133369e-07   9.003943e-08  \n",
      "4       2.133369e-07   5.053467e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"203\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-1.7871, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-3.6616, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-4.8371, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-2.3285, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-2.6958, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-4.0118, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-3.9209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "139\n",
      "tensor(-3.0988, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 203 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000026   6.307633e-05  \n",
      "1        0.000026   1.078967e-04  \n",
      "2        0.000026   3.234019e-05  \n",
      "3        0.000002   8.400393e-07  \n",
      "4        0.000002   3.948802e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"205\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-4.8065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-3.6375, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-5.5957, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-5.1268, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-5.2922, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-5.7122, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-6.5697, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "141\n",
      "tensor(-3.1490, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 205 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003   6.770032e-06  \n",
      "1        0.000003   1.166477e-05  \n",
      "2        0.000003   3.454900e-06  \n",
      "3        0.000001   4.809570e-07  \n",
      "4        0.000001   2.367995e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"207\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.0946, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.0445, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.1609, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.4067, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-0.7938, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.1215, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.3258, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "143\n",
      "tensor(-1.1194, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 207 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       5.919252e-07   1.330289e-06  \n",
      "1       5.919252e-07   2.275675e-06  \n",
      "2       5.919252e-07   6.848034e-07  \n",
      "3       2.801432e-09   1.328387e-09  \n",
      "4       2.801432e-09   6.198177e-09  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"209\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-1.5578, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-1.8502, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-2.9553, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-2.1350, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-1.8847, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-1.3743, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-2.0312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "145\n",
      "tensor(-2.5624, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 209 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000025       0.000061  \n",
      "1        0.000025       0.000105  \n",
      "2        0.000025       0.000031  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"211\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-2.8061, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-2.9595, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-3.2107, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-3.0395, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-2.5761, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-2.9576, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-2.2929, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "147\n",
      "tensor(-0.3199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 211 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       3.489847e-07   8.174497e-07  \n",
      "1       3.489847e-07   1.382488e-06  \n",
      "2       3.489847e-07   4.160635e-07  \n",
      "3       3.607684e-07   1.687536e-07  \n",
      "4       3.607684e-07   8.043047e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"213\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-0.2346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-1.4039, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-1.5162, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-1.0113, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-1.0787, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-1.1966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-2.1202, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "149\n",
      "tensor(-4.3319, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 213 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000014       0.000007  \n",
      "4        0.000014       0.000032  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"215\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-4.5049, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-5.3263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-5.4636, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 215 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-5.0540, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-3.3945, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-4.2725, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-4.5645, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "151\n",
      "tensor(-4.3679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 215 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003       0.000007  \n",
      "1        0.000003       0.000011  \n",
      "2        0.000003       0.000003  \n",
      "3        0.000003       0.000001  \n",
      "4        0.000003       0.000007  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"217\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-5.0836, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-4.0601, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-5.3894, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-5.7839, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-5.5038, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-6.0274, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-3.9323, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "153\n",
      "tensor(-3.7082, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 217 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.382396e-06   5.286814e-06  \n",
      "1       2.382396e-06   9.048603e-06  \n",
      "2       2.382396e-06   2.784690e-06  \n",
      "3       5.040731e-09   2.294284e-09  \n",
      "4       5.040731e-09   1.092993e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"219\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-4.4651, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-3.7534, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-3.6263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-5.5902, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-4.7115, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-5.1988, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-4.6162, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "155\n",
      "tensor(-2.1627, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 219 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       8.830029e-07   1.950046e-06  \n",
      "1       8.830029e-07   3.377556e-06  \n",
      "2       8.830029e-07   1.031788e-06  \n",
      "3       2.331926e-08   1.125999e-08  \n",
      "4       2.331926e-08   5.172702e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"221\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-3.8576, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-3.7494, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-2.8452, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-3.8123, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-2.6182, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-3.4451, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-2.8353, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "157\n",
      "tensor(-3.1974, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 221 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       3.305950e-06   7.310708e-06  \n",
      "1       3.305950e-06   1.259529e-05  \n",
      "2       3.305950e-06   3.825632e-06  \n",
      "3       3.509383e-07   1.713570e-07  \n",
      "4       3.509383e-07   7.873432e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"223\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-2.9198, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-2.8600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-2.0969, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-2.6151, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-2.2327, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-3.0328, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-2.7336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "159\n",
      "tensor(-3.3151, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 223 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.389862e-06   5.234455e-06  \n",
      "1       2.389862e-06   9.224898e-06  \n",
      "2       2.389862e-06   2.834160e-06  \n",
      "3       4.611592e-07   1.962663e-07  \n",
      "4       4.611592e-07   1.139826e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"225\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-9.6547, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-0.2209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-2.0240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-2.0626, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-0.5681, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-0.9387, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(0.9177, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "161\n",
      "tensor(-7.4760, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 225 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000031       0.000069  \n",
      "1        0.000031       0.000119  \n",
      "2        0.000031       0.000036  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"227\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-3.6975, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-4.9212, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-5.1265, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-5.0850, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-3.9113, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-4.7512, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-4.2028, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "163\n",
      "tensor(-3.4188, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 227 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000002   4.079219e-06  \n",
      "1        0.000002   7.000529e-06  \n",
      "2        0.000002   2.203027e-06  \n",
      "3        0.000001   4.628431e-07  \n",
      "4        0.000001   2.182414e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"229\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-4.3683, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-3.5444, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-3.9189, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 229 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-3.6942, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-3.2881, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-5.8973, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-4.3241, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "165\n",
      "tensor(-7.1243, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 229 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000017       0.000044  \n",
      "1        0.000017       0.000075  \n",
      "2        0.000017       0.000022  \n",
      "3        0.000017       0.000008  \n",
      "4        0.000017       0.000040  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"231\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-3.6051, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-3.6098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-4.5966, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-4.3009, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-5.2318, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-4.2935, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-5.3670, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "167\n",
      "tensor(-2.6487, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 231 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       4.861282e-07   1.138951e-06  \n",
      "1       4.861282e-07   1.930155e-06  \n",
      "2       4.861282e-07   5.886057e-07  \n",
      "3       1.345162e-08   6.116612e-09  \n",
      "4       1.345162e-08   2.976751e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"233\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-1.5129, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-2.6080, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-2.3397, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-2.7576, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-2.3331, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-2.6752, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-2.8345, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "169\n",
      "tensor(-1.5881, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 233 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005   1.228391e-05  \n",
      "1        0.000005   2.114418e-05  \n",
      "2        0.000005   6.262130e-06  \n",
      "3        0.000002   8.800661e-07  \n",
      "4        0.000002   4.336779e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"235\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(0.7590, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(0.5383, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(1.5765, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(0.4654, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(-0.9435, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(-0.4231, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(1.8824, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "171\n",
      "tensor(1.8785, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 235 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010   2.254971e-05  \n",
      "1        0.000010   3.888458e-05  \n",
      "2        0.000010   1.159605e-05  \n",
      "3        0.000002   8.910240e-07  \n",
      "4        0.000002   4.480880e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"237\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-3.1488, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-4.1949, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-5.1219, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-4.4453, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-4.2994, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-4.5286, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-3.3569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "173\n",
      "tensor(-5.5417, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 237 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000013  \n",
      "1        0.000006       0.000023  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000013  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"239\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-6.8297, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-8.7861, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-7.6621, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-7.3830, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-9.8221, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-6.5180, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-7.0317, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "175\n",
      "tensor(-11.5428, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 239 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.905551e-09   7.374765e-09  \n",
      "1       2.905551e-09   1.250962e-08  \n",
      "2       2.905551e-09   3.724675e-09  \n",
      "3       6.369073e-06   3.009025e-06  \n",
      "4       6.369073e-06   1.478430e-05  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"241\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-2.9245, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.8199, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.4711, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.6953, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.5526, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.1171, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.7897, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "177\n",
      "tensor(-3.9127, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 241 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       6.166345e-06   1.436974e-05  \n",
      "1       6.166345e-06   2.459326e-05  \n",
      "2       6.166345e-06   7.468653e-06  \n",
      "3       3.632421e-07   1.597418e-07  \n",
      "4       3.632421e-07   7.985312e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"243\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-12.5688, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-13.8534, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-13.8669, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 243 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-11.0866, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-11.9070, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-13.0995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-12.3017, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "179\n",
      "tensor(-19.1178, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 243 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       8.861418e-08   2.033503e-07  \n",
      "1       8.861418e-08   3.500088e-07  \n",
      "2       8.861418e-08   1.092997e-07  \n",
      "3       4.327451e-06   1.927423e-06  \n",
      "4       4.327451e-06   9.660973e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"245\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-1.8863, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-0.8168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-0.3042, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-2.1259, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-0.7537, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-0.8692, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-0.2328, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "181\n",
      "tensor(-3.5298, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 245 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       2.339772e-06   5.431489e-06  \n",
      "1       2.339772e-06   9.352234e-06  \n",
      "2       2.339772e-06   2.929422e-06  \n",
      "3       1.866999e-07   8.146149e-08  \n",
      "4       1.866999e-07   4.157853e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"247\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-3.5960, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-3.2341, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-1.8467, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-1.2545, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-0.4744, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-1.9052, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(-1.1743, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "183\n",
      "tensor(0.0418, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 247 reached, halted forward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.116108e-06   2.467374e-06  \n",
      "1       1.116108e-06   4.251393e-06  \n",
      "2       1.116108e-06   1.324049e-06  \n",
      "3       2.131610e-07   9.534451e-08  \n",
      "4       2.131610e-07   4.585972e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"249\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-10.4991, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-9.4275, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-12.0829, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-8.5022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-8.4728, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-7.8844, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-8.6753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "185\n",
      "tensor(-12.2923, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 249 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       3.027337e-06   7.209033e-06  \n",
      "1       3.027337e-06   1.224895e-05  \n",
      "2       3.027337e-06   3.857936e-06  \n",
      "3       8.159946e-07   3.758511e-07  \n",
      "4       8.159946e-07   1.777494e-06  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"251\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-4.9068, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-4.0573, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-5.7078, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-5.2325, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-6.8270, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-5.2797, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-5.2140, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "187\n",
      "tensor(-7.2521, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 251 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000003   5.788992e-06  \n",
      "1        0.000003   1.000413e-05  \n",
      "2        0.000003   3.099989e-06  \n",
      "3        0.000002   8.640138e-07  \n",
      "4        0.000002   4.070465e-06  \n",
      "...           ...            ...  \n",
      "250043   0.000000   0.000000e+00  \n",
      "250044   0.000000   0.000000e+00  \n",
      "250045   0.000000   0.000000e+00  \n",
      "250046   0.000000   0.000000e+00  \n",
      "250047   0.000000   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"253\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-3.0441, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-2.9503, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-2.9679, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-3.2600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-3.1201, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-2.4295, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-2.4923, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "189\n",
      "tensor(-3.6070, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 253 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.134941e-07   2.781468e-07  \n",
      "1       1.134941e-07   4.749066e-07  \n",
      "2       1.134941e-07   1.398668e-07  \n",
      "3       3.435441e-07   1.562112e-07  \n",
      "4       3.435441e-07   7.710281e-07  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"255\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-19.7987, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-20.2384, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-16.9499, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-14.3486, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-15.8347, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-16.3610, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-16.0410, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_3\n",
      "191\n",
      "tensor(-5.7186, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 255 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "           grad_rank  actxgrad_rank  \n",
      "0       1.353005e-06   3.039543e-06  \n",
      "1       1.353005e-06   5.190368e-06  \n",
      "2       1.353005e-06   1.584811e-06  \n",
      "3       4.060210e-08   1.840006e-08  \n",
      "4       4.060210e-08   8.822690e-08  \n",
      "...              ...            ...  \n",
      "250043  0.000000e+00   0.000000e+00  \n",
      "250044  0.000000e+00   0.000000e+00  \n",
      "250045  0.000000e+00   0.000000e+00  \n",
      "250046  0.000000e+00   0.000000e+00  \n",
      "250047  0.000000e+00   0.000000e+00  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 2\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 2\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 2\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 0\n",
      "layer: 1\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"257\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-2.0274, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-2.0833, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 257 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-2.1078, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-1.6533, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-2.4022, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-1.9610, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-2.3209, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "1\n",
      "tensor(-2.4070, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 257 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000014  \n",
      "1        0.000007       0.000024  \n",
      "2        0.000007       0.000007  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"259\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-1.9600, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-4.8462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-4.2940, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-2.5106, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-3.2331, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-1.5813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-3.2369, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "3\n",
      "tensor(-6.9155, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 259 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000028  \n",
      "1        0.000012       0.000048  \n",
      "2        0.000012       0.000014  \n",
      "3        0.000019       0.000009  \n",
      "4        0.000019       0.000043  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"261\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-2.4813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-0.9069, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-2.0457, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-1.7192, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-1.8482, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-1.0823, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-0.7891, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 261 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "5\n",
      "tensor(-1.4212, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 261 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000029  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000005       0.000002  \n",
      "4        0.000005       0.000012  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"263\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-4.5322, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-3.6478, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-3.3671, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-3.4909, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-2.7353, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-3.8593, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-3.8459, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "7\n",
      "tensor(-3.0621, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 263 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000021  \n",
      "1        0.000010       0.000036  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"265\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-1.6346, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-1.9525, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-2.7312, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-3.5276, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-1.3666, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-0.5413, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-0.7205, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "9\n",
      "tensor(-7.3329, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 265 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000029  \n",
      "1        0.000012       0.000048  \n",
      "2        0.000012       0.000014  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"267\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-0.7261, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-2.3321, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-1.9134, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-2.6185, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-2.6398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-1.6223, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-1.3165, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "11\n",
      "tensor(-2.5459, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 267 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000035  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000005       0.000002  \n",
      "4        0.000005       0.000010  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"269\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-1.7214, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-1.3873, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-2.1514, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-1.4601, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-1.7696, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-1.8789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-0.0059, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "13\n",
      "tensor(-4.3831, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 269 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000028  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000029  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"271\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-3.0480, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 271 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-3.8737, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-2.6007, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-3.7954, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-2.7997, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-3.3979, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-3.6904, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "15\n",
      "tensor(-5.4121, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 271 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000028  \n",
      "1        0.000011       0.000046  \n",
      "2        0.000011       0.000015  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"273\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-3.2484, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-1.2759, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-3.0044, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-2.0242, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-3.1667, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-2.2702, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-2.2585, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "17\n",
      "tensor(-0.5394, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 273 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000024  \n",
      "1        0.000010       0.000039  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000013       0.000006  \n",
      "4        0.000013       0.000030  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"275\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-1.1813, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-0.1676, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-1.0973, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-0.1508, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-0.5535, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-1.1894, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 275 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(-0.8390, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "19\n",
      "tensor(0.0849, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 275 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000022  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"277\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.5485, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.5514, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.6009, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.6734, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.3722, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.5982, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(-1.6047, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "21\n",
      "tensor(1.1217, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 277 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004       0.000010  \n",
      "1        0.000004       0.000017  \n",
      "2        0.000004       0.000005  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"279\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-3.0522, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-2.5107, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-1.3492, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-2.6610, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-5.4114, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-2.7558, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-2.8065, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "23\n",
      "tensor(-3.1284, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 279 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000007       0.000016  \n",
      "1        0.000007       0.000027  \n",
      "2        0.000007       0.000008  \n",
      "3        0.000011       0.000005  \n",
      "4        0.000011       0.000024  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"281\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-3.7190, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-6.6206, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-1.9147, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-6.1240, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-6.2635, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-6.6753, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-7.5374, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "25\n",
      "tensor(-10.5628, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 281 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000032       0.000059  \n",
      "1        0.000032       0.000102  \n",
      "2        0.000032       0.000032  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"283\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-4.8989, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-7.4173, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-5.6241, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-4.1090, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-5.3695, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-9.4995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-7.3713, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "27\n",
      "tensor(-12.1292, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 283 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000018  \n",
      "1        0.000009       0.000031  \n",
      "2        0.000009       0.000010  \n",
      "3        0.000010       0.000004  \n",
      "4        0.000010       0.000021  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"285\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(-1.2323, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 285 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(-0.6997, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(0.4685, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(0.1636, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(-0.5385, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(-0.3941, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(-0.8849, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "29\n",
      "tensor(-0.4906, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 285 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000005       0.000012  \n",
      "1        0.000005       0.000020  \n",
      "2        0.000005       0.000006  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000020  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"287\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-6.9168, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-5.3908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-5.4306, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-4.6252, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-4.2153, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-4.9479, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-7.1161, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "31\n",
      "tensor(-0.3577, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 287 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000015       0.000035  \n",
      "1        0.000015       0.000059  \n",
      "2        0.000015       0.000018  \n",
      "3        0.000012       0.000006  \n",
      "4        0.000012       0.000027  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"289\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-2.6181, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-1.5736, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-2.5112, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-2.9612, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-2.5157, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-3.4312, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 289 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-1.8980, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "33\n",
      "tensor(-1.7302, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 289 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000023  \n",
      "1        0.000010       0.000040  \n",
      "2        0.000010       0.000013  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000018  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"291\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-2.2486, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-2.2244, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-2.4420, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-2.1720, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-2.7398, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-2.3433, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-1.6713, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "35\n",
      "tensor(-3.0861, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 291 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000014  \n",
      "1        0.000006       0.000024  \n",
      "2        0.000006       0.000007  \n",
      "3        0.000006       0.000003  \n",
      "4        0.000006       0.000014  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"293\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-1.6610, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-1.7000, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-1.9122, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-3.3110, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-1.9908, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-1.3159, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-3.4032, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "37\n",
      "tensor(-2.7211, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 293 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000026  \n",
      "1        0.000010       0.000043  \n",
      "2        0.000010       0.000012  \n",
      "3        0.000016       0.000007  \n",
      "4        0.000016       0.000035  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"295\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-1.4682, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-1.3462, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-1.2924, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-1.1850, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-2.9878, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-2.1863, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-1.2336, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "39\n",
      "tensor(-1.1046, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 295 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000004       0.000009  \n",
      "1        0.000004       0.000015  \n",
      "2        0.000004       0.000005  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"297\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-3.6135, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-2.2658, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-1.9976, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-0.1944, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-2.4735, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-1.2714, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-0.0951, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "41\n",
      "tensor(-4.6425, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 297 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000020  \n",
      "1        0.000009       0.000032  \n",
      "2        0.000009       0.000009  \n",
      "3        0.000007       0.000003  \n",
      "4        0.000007       0.000015  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"299\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-2.7757, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 299 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-2.7014, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-2.1083, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-2.2015, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-3.6569, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-3.5677, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-3.5649, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "43\n",
      "tensor(-4.2778, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 299 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000006       0.000015  \n",
      "1        0.000006       0.000025  \n",
      "2        0.000006       0.000008  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"301\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(-0.4593, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(-0.0308, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(0.3847, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(-1.2031, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(1.0057, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(-0.1181, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(-0.4099, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "45\n",
      "tensor(1.8936, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 301 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000010       0.000023  \n",
      "1        0.000010       0.000037  \n",
      "2        0.000010       0.000011  \n",
      "3        0.000009       0.000004  \n",
      "4        0.000009       0.000019  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"303\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-0.3159, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-1.6443, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-0.2926, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-1.6646, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-2.1640, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-0.5576, device='cuda:2', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target node 303 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-3.0609, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "47\n",
      "tensor(-2.2140, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 303 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000017  \n",
      "1        0.000008       0.000028  \n",
      "2        0.000008       0.000009  \n",
      "3        0.000011       0.000006  \n",
      "4        0.000011       0.000025  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"305\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-1.2439, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-3.0358, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-2.5987, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-4.7184, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-3.8263, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-2.0613, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-4.2995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "49\n",
      "tensor(-1.9369, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 305 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000012       0.000033  \n",
      "1        0.000012       0.000054  \n",
      "2        0.000012       0.000016  \n",
      "3        0.000015       0.000008  \n",
      "4        0.000015       0.000034  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"307\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-1.1119, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-0.7096, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-1.6980, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-2.6366, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-0.7685, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-1.3995, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(-1.4098, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "51\n",
      "tensor(0.4675, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 307 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011       0.000025  \n",
      "1        0.000011       0.000043  \n",
      "2        0.000011       0.000014  \n",
      "3        0.000008       0.000004  \n",
      "4        0.000008       0.000017  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"309\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(-0.2609, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(0.3588, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(-0.2759, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(0.0350, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(-0.1921, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(-0.3789, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(-0.2290, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "53\n",
      "tensor(0.5740, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 309 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000008       0.000021  \n",
      "1        0.000008       0.000034  \n",
      "2        0.000008       0.000010  \n",
      "3        0.000010       0.000005  \n",
      "4        0.000010       0.000023  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "Updating cached rank dfs with small_SPAN\n",
      "running model to get ranks for \"small_SPAN\" on target \"311\"\n",
      "using device cuda:2\n",
      "batch 0\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-0.5755, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 1\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-0.4216, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 2\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-1.5373, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 3\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-1.3236, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 4\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-1.6302, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 5\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-0.9945, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 6\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-1.6607, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "batch 7\n",
      "target reached, breaking model forward pass in features_6\n",
      "55\n",
      "tensor(-1.4586, device='cuda:2', grad_fn=<SelectBackward>)\n",
      "target node 311 reached, halted forward pass\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.312708   \n",
      "1              1   features_0      0            0           1  1.933793   \n",
      "2              2   features_0      0            0           2  0.614869   \n",
      "3              3   features_0      0            1           0  0.494262   \n",
      "4              4   features_0      0            1           1  1.509352   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.000000   \n",
      "250044    250044  features_10      4          255         252  0.000000   \n",
      "250045    250045  features_10      4          255         253  0.000000   \n",
      "250046    250046  features_10      4          255         254  0.000000   \n",
      "250047    250047  features_10      4          255         255  0.000000   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000009       0.000022  \n",
      "1        0.000009       0.000037  \n",
      "2        0.000009       0.000011  \n",
      "3        0.000015       0.000007  \n",
      "4        0.000015       0.000034  \n",
      "...           ...            ...  \n",
      "250043   0.000000       0.000000  \n",
      "250044   0.000000       0.000000  \n",
      "250045   0.000000       0.000000  \n",
      "250046   0.000000       0.000000  \n",
      "250047   0.000000       0.000000  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "maximum value 0 for rank type act and layer 3\n",
      "maximum value 0 for rank type act and layer 4\n",
      "maximum value 0 for rank type grad and layer 3\n",
      "maximum value 0 for rank type grad and layer 4\n",
      "maximum value 0 for rank type actxgrad and layer 3\n",
      "maximum value 0 for rank type actxgrad and layer 4\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "[0 1 2 3 4]\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "1602.560997247696\n"
     ]
    }
   ],
   "source": [
    "#extract subgraphs and same size subgraphs of multiple sizes\n",
    "\n",
    "#run through all subgraphs generating same size subgraphs\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "node_thresholds = [.8,.6,.4,.2]\n",
    "\n",
    "edge_thresholds = [.9,.8,.7,.6]\n",
    "\n",
    "\n",
    "\n",
    "model_dis.to('cuda:1')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for node in range(1,313,2):\n",
    "    \n",
    "    n_df,e_df=ranksdf_store('small_SPAN', str(node), [],model_dis=model_dis)\n",
    "    n_df = minmax_normalize_ranks_df(n_df,params)\n",
    "    for s in range(len(node_thresholds)):\n",
    "        threshed_n_df,threshed_e_df = hierarchical_accum_threshold(node_thresholds[s],edge_thresholds[s],rank_type,e_df,n_df)\n",
    "        sub_model = extract_subgraph(model,threshed_n_df,threshed_e_df,params)\n",
    "        sub_model.to('cuda:1')\n",
    "\n",
    "        sub_dict = {\n",
    "                   'model':sub_model,\n",
    "                   'gen_params':\n",
    "                        {'node_thresh':node_thresholds[s],\n",
    "                         'edge_thresh':edge_thresholds[s],\n",
    "                         'input':'small_SPAN',\n",
    "                         'output':str(node)\n",
    "                        },\n",
    "                    'node_df':threshed_n_df,\n",
    "                    'edge_df':threshed_e_df\n",
    "                  }\n",
    "        sub_dict_path = 'prepped_models/alexnet_sparse/subgraphs/models/%s_%s%s.pt'%(str(node),str(node_thresholds[s]),edge_thresholds[s])\n",
    "        torch.save(sub_dict,sub_dict_path)\n",
    "        #make subgraphs\n",
    "        for version in ['random','worst']:\n",
    "            for version in ['random','worst']:\n",
    "                save_path = 'prepped_models/alexnet_sparse/subgraphs/models/%s_models/%s_%s%s.pt'%(version,str(node),str(node_thresholds[s]),edge_thresholds[s])\n",
    "                n_sizes = get_layer_sizes_from_df(sub_dict['node_df'])\n",
    "                e_sizes = get_layer_sizes_from_df(sub_dict['edge_df'])\n",
    "                size_n_df,size_e_df = hierarchical_size_threshold(n_sizes,e_sizes,rank_type,n_df,e_df,selection=version)\n",
    "                size_model = extract_subgraph(model,size_n_df,size_e_df,params)\n",
    "                size_dict = {\n",
    "                   'model':size_model,\n",
    "                   'gen_params':\n",
    "                        {'node_sizes':n_sizes,\n",
    "                         'edge_sizes':e_sizes,\n",
    "                         'input':'small_SPAN',\n",
    "                         'output':node,\n",
    "                         'selection':version,\n",
    "                         'from_model':sub_dict_path\n",
    "                        },\n",
    "                    'node_df':size_n_df,\n",
    "                    'edge_df':size_e_df\n",
    "                  }\n",
    "                torch.save(size_dict,save_path)\n",
    "                \n",
    "print(time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/random_models/1000_0.20.6.pt')\n",
    "worst_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/worst_models/1000_0.20.6.pt')\n",
    "best_dict = torch.load('prepped_models/alexnet_sparse/subgraphs/models/1000_0.20.6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dict['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_dict['model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(random_dict['node_df'].loc[random_dict['node_df']['layer']==2]))\n",
    "print(len(best_dict['node_df'].loc[best_dict['node_df']['layer']==2]))\n",
    "print(len(worst_dict['node_df'].loc[worst_dict['node_df']['layer']==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dict['node_df'].loc[best_dict['node_df']['layer']==2].sort_values('node_num_by_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_dict['node_df'].loc[worst_dict['node_df']['layer']==2].sort_values('node_num_by_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeid_2_perlayerid(200,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruning_viz",
   "language": "python",
   "name": "pruning_viz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
