{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible models to visualizer are:\n",
      "['mnist_resize', 'alexnet_old.tar.gz', 'mnist_old', '.keep', 'mnist', 'old', 'alexnet10', 'letter_mixed_not_trained', 'imagenet10_sparse', 'alexnet_sparse_test', '.DS_Store', 'alexnet_sparse_full_model_10classes', 'imagenet10', 'alexnet_sparse', 'alexnet_lucent', 'mnist.tgz', 'alexnet', 'letter_mixed', 'googlenet10_test', '._.DS_Store', 'alexnet_corrupted', 'alexnet.tar.gz']\n",
      "\n",
      "You've chosen to visualize alexnet_sparse\n"
     ]
    }
   ],
   "source": [
    "#fetch command line argument (prepped model)\n",
    "#%reset\n",
    "import sys\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import torch\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('./prep_model_scripts/'))\n",
    "sys.path.insert(0, os.path.abspath('./visualizer_scripts/'))\n",
    "from visualizer_helper_functions import *\n",
    "from contrast_helper_functions import *\n",
    "from featureviz_helper_functions import *\n",
    "from ablation_functions import *\n",
    "from receptive_field import *\n",
    "from dissected_Conv2d import *\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "py.init_notebook_mode(connected=True)   #jupyter notebook only\n",
    "\n",
    "prepped_model_folder = 'alexnet_sparse'    #set this to a subfolder of prunned_models\n",
    "\n",
    "full_prepped_model_folder = os.path.abspath('prepped_models/%s'%prepped_model_folder)\n",
    "\n",
    "possible_models = os.listdir('prepped_models')\n",
    "print('possible models to visualizer are:')\n",
    "print(possible_models)\n",
    "\n",
    "print('\\nYou\\'ve chosen to visualize %s'%prepped_model_folder)\n",
    "\n",
    "\n",
    "sys.path.insert(0,'prepped_models/%s'%prepped_model_folder)\n",
    "\n",
    "import prep_model_params_used as prep_model_params\n",
    "\n",
    "params = {}\n",
    "params['prepped_model'] = prepped_model_folder\n",
    "params['prepped_model_path'] = full_prepped_model_folder\n",
    "params['device'] = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "\n",
    "#Non-GUI parameters\n",
    "\n",
    "#deepviz\n",
    "params['deepviz_param'] = None\n",
    "params['deepviz_optim'] = None\n",
    "params['deepviz_transforms'] = None\n",
    "params['deepviz_image_size'] = prep_model_params.deepviz_image_size\n",
    "\n",
    "#backend\n",
    "params['cuda'] = prep_model_params.cuda    #use gpu acceleration when running model forward\n",
    "params['input_image_directory'] = prep_model_params.input_img_path+'/'   #path to directory of imput images you want fed through the network\n",
    "params['preprocess'] = prep_model_params.preprocess     #torchvision transfrom to pass input images through\n",
    "params['label_file_path'] = prep_model_params.label_file_path\n",
    "params['criterion'] = prep_model_params.criterion\n",
    "params['rank_img_path'] = prep_model_params.rank_img_path\n",
    "params['num_workers'] = prep_model_params.num_workers\n",
    "params['seed'] = prep_model_params.seed\n",
    "params['batch_size'] = prep_model_params.batch_size\n",
    "#params['dynamic_act_cache_num'] = 4  #max number of input image activations 'dynamic_activations' will have simultaneously\n",
    "\n",
    " \n",
    "#aesthetic \n",
    "\n",
    "params['node_size'] = 12\n",
    "params['edge_size'] = 1\n",
    "params['max_node_inputs'] = 10    #there is a dropdown showing the top weighted edge inputs to nodes, how many maps in dropdown?\n",
    "params['layer_colors'] = ['rgba(31,119,180,', \n",
    "                          'rgba(255,127,14,',\n",
    "                          'rgba(44,160,44,', \n",
    "                          'rgba(214,39,40,',\n",
    "                          'rgba(39, 208, 214,', \n",
    "                          'rgba(242, 250, 17,',\n",
    "                          'rgba(196, 94, 255,',\n",
    "                          'rgba(193, 245, 5,',\n",
    "                          'rgba(245, 85, 5,',\n",
    "                          'rgba(5, 165, 245,',\n",
    "                          'rgba(245, 5, 105,',\n",
    "                          'rgba(218, 232, 23,',\n",
    "                          'rgba(148, 23, 232,',\n",
    "                          'rgba(23, 232, 166,',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#GUI parameters initialization (these parameters can be set in the GUI, but what values should they be initialized to?)\n",
    "target_category = 'overall'     #category of images edges and nodes are weighted based on (which subgraph) \n",
    "rank_type = 'actxgrad'       #weighting criterion (actxgrad, act, grad, or weight)\n",
    "projection = 'MDS smooth'           #how nodes within a layer are projected into the 2d plane (MDS or Grid)\n",
    "edge_threshold = [.7,1]     #what range do edge ranks need to be in to be visualized\n",
    "node_threshold = [.4,1]     #only relevant for hierarchical subgraph \n",
    "\n",
    "#### DONT EDIT BELOW initializations\n",
    "\n",
    "figure_init = go.Figure()\n",
    "figure_init.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[]))\n",
    "figure_init.update_layout(xaxis=dict(visible=False),\n",
    "                  yaxis=dict(visible=False),\n",
    "                  annotations = [dict(text=\"No Inputs\",\n",
    "                                      xref=\"paper\",\n",
    "                                      yref=\"paper\",\n",
    "                                      showarrow=False,\n",
    "                                      font=dict(size=28))]\n",
    "                 )\n",
    "\n",
    "params['max_edge_weight'] = 1  #for the edge threshold slider, this dynamically adjusted its max value to max edge rank\n",
    "                     #before there were multiple rank criterions, which made things confusing\n",
    "                     #so well just fix it to 1 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model:\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Model\n",
    "\n",
    "model_dis = dissect_model(deepcopy(prep_model_params.model),store_ranks=True,clear_ranks=True,cuda=params['cuda'],device=params['device']) #version of model with accessible preadd activations in Conv2d modules \n",
    "if params['cuda']:\n",
    "    model_dis.cuda()\n",
    "model_dis = model_dis.eval()    \n",
    "model_dis.to(params['device'])\n",
    "\n",
    "print('loaded model:')\n",
    "print(prep_model_params.model)\n",
    "        \n",
    "#del prep_model_params.model\n",
    "model = prep_model_params.model\n",
    "if params['cuda']:\n",
    "    model.cuda()\n",
    "model = model.eval()\n",
    "model.to(params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading misc graph data\n",
      "model has categories:\n",
      "['overall', 'Afghan_hound', 'African_chameleon', 'African_crocodile', 'African_elephant', 'African_grey', 'African_hunting_dog', 'Airedale', 'American_Staffordshire_terrier', 'American_alligator', 'American_black_bear', 'American_chameleon', 'American_coot', 'American_egret', 'American_lobster', 'Angora', 'Appenzeller', 'Arabian_camel', 'Arctic_fox', 'Australian_terrier', 'Band_Aid', 'Bedlington_terrier', 'Bernese_mountain_dog', 'Blenheim_spaniel', 'Border_collie', 'Border_terrier', 'Boston_bull', 'Bouvier_des_Flandres', 'Brabancon_griffon', 'Brittany_spaniel', 'CD_player', 'Cardigan_corgi', 'Chesapeake_Bay_retriever', 'Chihuahua', 'Christmas_stocking', 'Crock_Pot', 'Dandie_Dinmont', 'Doberman', 'Dungeness_crab', 'Dutch_oven', 'Egyptian_cat', 'English_foxhound', 'English_setter', 'English_springer', 'EntleBucher', 'Eskimo_dog', 'European_fire_salamander', 'European_gallinule', 'French_bulldog', 'French_horn', 'French_loaf', 'German_shepherd', 'German_short_haired_pointer', 'Gila_monster', 'Gordon_setter', 'Granny_Smith', 'Great_Dane', 'Great_Pyrenees', 'Greater_Swiss_Mountain_dog', 'Ibizan_hound', 'Indian_cobra', 'Indian_elephant', 'Irish_setter', 'Irish_terrier', 'Irish_water_spaniel', 'Irish_wolfhound', 'Italian_greyhound', 'Japanese_spaniel', 'Kerry_blue_terrier', 'Komodo_dragon', 'Labrador_retriever', 'Lakeland_terrier', 'Leonberg', 'Lhasa', 'Loafer', 'Madagascar_cat', 'Maltese_dog', 'Mexican_hairless', 'Model_T', 'Newfoundland', 'Norfolk_terrier', 'Norwegian_elkhound', 'Norwich_terrier', 'Old_English_sheepdog', 'Pekinese', 'Pembroke', 'Persian_cat', 'Petri_dish', 'Polaroid_camera', 'Pomeranian', 'Rhodesian_ridgeback', 'Rottweiler', 'Saint_Bernard', 'Saluki', 'Samoyed', 'Scotch_terrier', 'Scottish_deerhound', 'Sealyham_terrier', 'Shetland_sheepdog', 'Shih_Tzu', 'Siamese_cat', 'Siberian_husky', 'Staffordshire_bullterrier', 'Sussex_spaniel', 'Tibetan_mastiff', 'Tibetan_terrier', 'Walker_hound', 'Weimaraner', 'Welsh_springer_spaniel', 'West_Highland_white_terrier', 'Windsor_tie', 'Yorkshire_terrier', 'abacus', 'abaya', 'academic_gown', 'accordion', 'acorn', 'acorn_squash', 'acoustic_guitar', 'admiral', 'affenpinscher', 'agama', 'agaric', 'aircraft_carrier', 'airliner', 'airship', 'albatross', 'alligator_lizard', 'alp', 'altar', 'ambulance', 'amphibian', 'analog_clock', 'anemone_fish', 'ant', 'apiary', 'apron', 'armadillo', 'artichoke', 'ashcan', 'assault_rifle', 'axolotl', 'baboon', 'backpack', 'badger', 'bagel', 'bakery', 'balance_beam', 'bald_eagle', 'balloon', 'ballplayer', 'ballpoint', 'banana', 'banded_gecko', 'banjo', 'bannister', 'barbell', 'barber_chair', 'barbershop', 'barn', 'barn_spider', 'barometer', 'barracouta', 'barrel', 'barrow', 'baseball', 'basenji', 'basketball', 'basset', 'bassinet', 'bassoon', 'bath_towel', 'bathing_cap', 'bathtub', 'beach_wagon', 'beacon', 'beagle', 'beaker', 'bearskin', 'beaver', 'bee', 'bee_eater', 'beer_bottle', 'beer_glass', 'bell_cote', 'bell_pepper', 'bib', 'bicycle_built_for_two', 'bighorn', 'bikini', 'binder', 'binoculars', 'birdhouse', 'bison', 'bittern', 'black_and_gold_garden_spider', 'black_and_tan_coonhound', 'black_footed_ferret', 'black_grouse', 'black_stork', 'black_swan', 'black_widow', 'bloodhound', 'bluetick', 'boa_constrictor', 'boathouse', 'bobsled', 'bolete', 'bolo_tie', 'bonnet', 'book_jacket', 'bookcase', 'bookshop', 'borzoi', 'bottlecap', 'bow', 'bow_tie', 'box_turtle', 'boxer', 'brain_coral', 'brambling', 'brass', 'brassiere', 'breakwater', 'breastplate', 'briard', 'broccoli', 'broom', 'brown_bear', 'bubble', 'bucket', 'buckeye', 'buckle', 'bulbul', 'bull_mastiff', 'bullet_train', 'bulletproof_vest', 'bullfrog', 'burrito', 'bustard', 'butcher_shop', 'butternut_squash', 'cab', 'cabbage_butterfly', 'cairn', 'caldron', 'can_opener', 'candle', 'cannon', 'canoe', 'capuchin', 'car_mirror', 'car_wheel', 'carbonara', 'cardigan_sweater', 'cardoon', 'carousel', 'carpenters_kit', 'carton', 'cash_machine', 'cassette', 'cassette_player', 'castle', 'catamaran', 'cauliflower', 'cello', 'cellular_telephone', 'centipede', 'chain', 'chain_mail', 'chain_saw', 'chainlink_fence', 'chambered_nautilus', 'cheeseburger', 'cheetah', 'chest', 'chickadee', 'chiffonier', 'chime', 'chimpanzee', 'china_cabinet', 'chiton', 'chocolate_sauce', 'chow', 'church', 'cicada', 'cinema', 'cleaver', 'cliff', 'cliff_dwelling', 'cloak', 'clog', 'clumber', 'cocker_spaniel', 'cockroach', 'cocktail_shaker', 'coffee_mug', 'coffeepot', 'coho', 'coil', 'collie', 'colobus', 'combination_lock', 'comic_book', 'common_iguana', 'common_newt', 'computer_keyboard', 'conch', 'confectionery', 'consomme', 'container_ship', 'convertible', 'coral_fungus', 'coral_reef', 'corkscrew', 'corn', 'cornet', 'coucal', 'cougar', 'cowboy_boot', 'cowboy_hat', 'coyote', 'cradle', 'crane_bird', 'crane_equipment', 'crash_helmet', 'crate', 'crayfish', 'crib', 'cricket', 'croquet_ball', 'crossword_puzzle', 'crutch', 'cucumber', 'cuirass', 'cup', 'curly_coated_retriever', 'custard_apple', 'daisy', 'dalmatian', 'dam', 'damselfly', 'desk', 'desktop_computer', 'dhole', 'dial_telephone', 'diamondback', 'diaper', 'digital_clock', 'digital_watch', 'dingo', 'dining_table', 'dishrag', 'dishwasher', 'disk_brake', 'dock', 'dogsled', 'dome', 'doormat', 'dough', 'dowitcher', 'dragonfly', 'drake', 'drilling_platform', 'drum', 'drumstick', 'dugong', 'dumbbell', 'dung_beetle', 'ear', 'earthstar', 'echidna', 'eel', 'eft', 'eggnog', 'electric_fan', 'electric_guitar', 'electric_locomotive', 'electric_ray', 'entertainment_center', 'envelope', 'espresso', 'espresso_maker', 'face_powder', 'feather_boa', 'fiddler_crab', 'fig', 'file', 'fire_engine', 'fire_screen', 'fireboat', 'flagpole', 'flamingo', 'flat_coated_retriever', 'flatworm', 'flute', 'fly', 'folding_chair', 'football_helmet', 'forklift', 'fountain', 'fountain_pen', 'four_poster', 'fox_squirrel', 'freight_car', 'frilled_lizard', 'frying_pan', 'fur_coat', 'gar', 'garbage_truck', 'garden_spider', 'garter_snake', 'gas_pump', 'gasmask', 'gazelle', 'geyser', 'giant_panda', 'giant_schnauzer', 'gibbon', 'go_kart', 'goblet', 'golden_retriever', 'goldfinch', 'goldfish', 'golf_ball', 'golfcart', 'gondola', 'gong', 'goose', 'gorilla', 'gown', 'grand_piano', 'grasshopper', 'great_grey_owl', 'great_white_shark', 'green_lizard', 'green_mamba', 'green_snake', 'greenhouse', 'grey_fox', 'grey_whale', 'grille', 'grocery_store', 'groenendael', 'groom', 'ground_beetle', 'guacamole', 'guenon', 'guillotine', 'guinea_pig', 'gyromitra', 'hair_slide', 'hair_spray', 'half_track', 'hammer', 'hammerhead', 'hamper', 'hamster', 'hand_blower', 'hand_held_computer', 'handkerchief', 'hard_disc', 'hare', 'harmonica', 'harp', 'hartebeest', 'harvester', 'harvestman', 'hatchet', 'hay', 'head_cabbage', 'hen', 'hen_of_the_woods', 'hermit_crab', 'hip', 'hippopotamus', 'hog', 'hognose_snake', 'holster', 'home_theater', 'honeycomb', 'hook', 'hoopskirt', 'horizontal_bar', 'hornbill', 'horned_viper', 'horse_cart', 'hot_pot', 'hotdog', 'hourglass', 'house_finch', 'howler_monkey', 'hummingbird', 'hyena', 'iPod', 'ibex', 'ice_bear', 'ice_cream', 'ice_lolly', 'impala', 'indigo_bunting', 'indri', 'iron', 'isopod', 'jacamar', 'jack_o_lantern', 'jackfruit', 'jaguar', 'jay', 'jean', 'jeep', 'jellyfish', 'jersey', 'jigsaw_puzzle', 'jinrikisha', 'joystick', 'junco', 'keeshond', 'kelpie', 'killer_whale', 'kimono', 'king_crab', 'king_penguin', 'king_snake', 'kit_fox', 'kite', 'knee_pad', 'knot', 'koala', 'komondor', 'kuvasz', 'lab_coat', 'lacewing', 'ladle', 'ladybug', 'lakeside', 'lampshade', 'langur', 'laptop', 'lawn_mower', 'leaf_beetle', 'leafhopper', 'leatherback_turtle', 'lemon', 'lens_cap', 'leopard', 'lesser_panda', 'letter_opener', 'library', 'lifeboat', 'lighter', 'limousine', 'limpkin', 'liner', 'lion', 'lionfish', 'lipstick', 'little_blue_heron', 'llama', 'loggerhead', 'long_horned_beetle', 'lorikeet', 'lotion', 'loudspeaker', 'loupe', 'lumbermill', 'lycaenid', 'lynx', 'macaque', 'macaw', 'magnetic_compass', 'magpie', 'mailbag', 'mailbox', 'maillot_1', 'maillot_2', 'malamute', 'malinois', 'manhole_cover', 'mantis', 'maraca', 'marimba', 'marmoset', 'marmot', 'mashed_potato', 'mask', 'matchstick', 'maypole', 'maze', 'measuring_cup', 'meat_loaf', 'medicine_chest', 'meerkat', 'megalith', 'menu', 'microphone', 'microwave', 'military_uniform', 'milk_can', 'miniature_pinscher', 'miniature_poodle', 'miniature_schnauzer', 'minibus', 'miniskirt', 'minivan', 'mink', 'missile', 'mitten', 'mixing_bowl', 'mobile_home', 'modem', 'monarch', 'monastery', 'mongoose', 'monitor', 'moped', 'mortar', 'mortarboard', 'mosque', 'mosquito_net', 'motor_scooter', 'mountain_bike', 'mountain_tent', 'mouse', 'mousetrap', 'moving_van', 'mud_turtle', 'mushroom', 'muzzle', 'nail', 'neck_brace', 'necklace', 'nematode', 'night_snake', 'nipple', 'notebook', 'obelisk', 'oboe', 'ocarina', 'odometer', 'oil_filter', 'orange', 'orangutan', 'organ', 'oscilloscope', 'ostrich', 'otter', 'otterhound', 'overskirt', 'ox', 'oxcart', 'oxygen_mask', 'oystercatcher', 'packet', 'paddle', 'paddlewheel', 'padlock', 'paintbrush', 'pajama', 'palace', 'panpipe', 'paper_towel', 'papillon', 'parachute', 'parallel_bars', 'park_bench', 'parking_meter', 'partridge', 'passenger_car', 'patas', 'patio', 'pay_phone', 'peacock', 'pedestal', 'pelican', 'pencil_box', 'pencil_sharpener', 'perfume', 'photocopier', 'pick', 'pickelhaube', 'picket_fence', 'pickup', 'pier', 'piggy_bank', 'pill_bottle', 'pillow', 'pineapple', 'ping_pong_ball', 'pinwheel', 'pirate', 'pitcher', 'pizza', 'plane', 'planetarium', 'plastic_bag', 'plate', 'plate_rack', 'platypus', 'plow', 'plunger', 'pole', 'polecat', 'police_van', 'pomegranate', 'poncho', 'pool_table', 'pop_bottle', 'porcupine', 'pot', 'potpie', 'potters_wheel', 'power_drill', 'prairie_chicken', 'prayer_rug', 'pretzel', 'printer', 'prison', 'proboscis_monkey', 'projectile', 'projector', 'promontory', 'ptarmigan', 'puck', 'puffer', 'pug', 'punching_bag', 'purse', 'quail', 'quill', 'quilt', 'racer', 'racket', 'radiator', 'radio', 'radio_telescope', 'rain_barrel', 'ram', 'rapeseed', 'recreational_vehicle', 'red_backed_sandpiper', 'red_breasted_merganser', 'red_fox', 'red_wine', 'red_wolf', 'redbone', 'redshank', 'reel', 'reflex_camera', 'refrigerator', 'remote_control', 'restaurant', 'revolver', 'rhinoceros_beetle', 'rifle', 'ringlet', 'ringneck_snake', 'robin', 'rock_beauty', 'rock_crab', 'rock_python', 'rocking_chair', 'rooster', 'rotisserie', 'rubber_eraser', 'ruddy_turnstone', 'ruffed_grouse', 'rugby_ball', 'rule', 'running_shoe', 'safe', 'safety_pin', 'saltshaker', 'sandal', 'sandbar', 'sarong', 'sax', 'scabbard', 'scale', 'schipperke', 'school_bus', 'schooner', 'scoreboard', 'scorpion', 'screen', 'screw', 'screwdriver', 'scuba_diver', 'sea_anemone', 'sea_cucumber', 'sea_lion', 'sea_slug', 'sea_snake', 'sea_urchin', 'seashore', 'seat_belt', 'sewing_machine', 'shield', 'shoe_shop', 'shoji', 'shopping_basket', 'shopping_cart', 'shovel', 'shower_cap', 'shower_curtain', 'siamang', 'sidewinder', 'silky_terrier', 'ski', 'ski_mask', 'skunk', 'sleeping_bag', 'slide_rule', 'sliding_door', 'slot', 'sloth_bear', 'slug', 'small_SPAN', 'snail', 'snorkel', 'snow_leopard', 'snowmobile', 'snowplow', 'soap_dispenser', 'soccer_ball', 'sock', 'soft_coated_wheaten_terrier', 'solar_dish', 'sombrero', 'sorrel', 'soup_bowl', 'space_bar', 'space_heater', 'space_shuttle', 'spaghetti_squash', 'spatula', 'speedboat', 'spider_monkey', 'spider_web', 'spindle', 'spiny_lobster', 'spoonbill', 'sports_car', 'spotlight', 'spotted_salamander', 'squirrel_monkey', 'stage', 'standard_poodle', 'standard_schnauzer', 'starfish', 'steam_locomotive', 'steel_arch_bridge', 'steel_drum', 'stethoscope', 'stingray', 'stinkhorn', 'stole', 'stone_wall', 'stopwatch', 'stove', 'strainer', 'strawberry', 'street_sign', 'streetcar', 'stretcher', 'studio_couch', 'stupa', 'sturgeon', 'submarine', 'suit', 'sulphur_butterfly', 'sulphur_crested_cockatoo', 'sundial', 'sunglass', 'sunglasses', 'sunscreen', 'suspension_bridge', 'swab', 'sweatshirt', 'swimming_trunks', 'swing', 'switch', 'syringe', 'tabby', 'table_lamp', 'tailed_frog', 'tank', 'tape_player', 'tarantula', 'teapot', 'teddy', 'television', 'tench', 'tennis_ball', 'terrapin', 'thatch', 'theater_curtain', 'thimble', 'three_toed_sloth', 'thresher', 'throne', 'thunder_snake', 'tick', 'tiger', 'tiger_beetle', 'tiger_cat', 'tiger_shark', 'tile_roof', 'timber_wolf', 'titi', 'toaster', 'tobacco_shop', 'toilet_seat', 'toilet_tissue', 'torch', 'totem_pole', 'toucan', 'tow_truck', 'toy_poodle', 'toy_terrier', 'toyshop', 'tractor', 'traffic_light', 'trailer_truck', 'tray', 'tree_frog', 'trench_coat', 'triceratops', 'tricycle', 'trifle', 'trilobite', 'trimaran', 'tripod', 'triumphal_arch', 'trolleybus', 'trombone', 'tub', 'turnstile', 'tusker', 'typewriter_keyboard', 'umbrella', 'unicycle', 'upright', 'vacuum', 'valley', 'vase', 'vault', 'velvet', 'vending_machine', 'vestment', 'viaduct', 'vine_snake', 'violin', 'vizsla', 'volcano', 'volleyball', 'vulture', 'waffle_iron', 'walking_stick', 'wall_clock', 'wallaby', 'wallet', 'wardrobe', 'warplane', 'warthog', 'washbasin', 'washer', 'water_bottle', 'water_buffalo', 'water_jug', 'water_ouzel', 'water_snake', 'water_tower', 'weasel', 'web_site', 'weevil', 'whippet', 'whiptail', 'whiskey_jug', 'whistle', 'white_stork', 'white_wolf', 'wig', 'wild_boar', 'window_screen', 'window_shade', 'wine_bottle', 'wing', 'wire_haired_fox_terrier', 'wok', 'wolf_spider', 'wombat', 'wood_rabbit', 'wooden_spoon', 'wool', 'worm_fence', 'wreck', 'yawl', 'yellow_ladys_slipper', 'yurt', 'zebra', 'zucchini']\n"
     ]
    }
   ],
   "source": [
    "#load misc graph data\n",
    "print('loading misc graph data')\n",
    "misc_data = pickle.load(open('./prepped_models/%s/misc_graph_data.pkl'%prepped_model_folder,'rb'))\n",
    "params['layer_nodes'] = misc_data['layer_nodes']\n",
    "params['num_layers'] = misc_data['num_layers']\n",
    "params['num_nodes'] = misc_data['num_nodes']\n",
    "params['categories'] = misc_data['categories']\n",
    "params['num_img_chan'] = misc_data['num_img_chan']\n",
    "params['imgnode_positions'] = misc_data['imgnode_positions']\n",
    "params['imgnode_colors'] = misc_data['imgnode_colors']\n",
    "params['imgnode_names'] = misc_data['imgnode_names']\n",
    "params['prepped_model_path'] = full_prepped_model_folder\n",
    "params['ranks_data_path'] = full_prepped_model_folder+'/ranks/'\n",
    "\n",
    "\n",
    "print('model has categories:')\n",
    "print(params['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading nodes rank data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py:146: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading node position data\n"
     ]
    }
   ],
   "source": [
    "#load nodes df\n",
    "print('loading nodes rank data')\n",
    "target_node = 'loss'\n",
    "\n",
    "categories_nodes_df = pd.read_csv('prepped_models/%s/ranks/categories_nodes_ranks.csv'%prepped_model_folder)\n",
    "target_nodes_df = categories_nodes_df.loc[categories_nodes_df['category']==target_category]\n",
    "\n",
    "target_nodes_df = minmax_normalize_ranks_df(target_nodes_df,params,weight=False)\n",
    "\n",
    "weight_nodes_df = pd.read_csv('prepped_models/%s/ranks/weight_nodes_ranks.csv'%prepped_model_folder)\n",
    "\n",
    "weight_nodes_df = minmax_normalize_ranks_df(weight_nodes_df,params,weight=True)\n",
    "\n",
    "node_colors,node_weights = gen_node_colors(target_nodes_df,rank_type,params) \n",
    "\n",
    "#load node positions\n",
    "print('loading node position data')\n",
    "all_node_positions = pickle.load(open('./prepped_models/%s/node_positions.pkl'%prepped_model_folder,'rb'))\n",
    "\n",
    "if projection == 'Grid':\n",
    "    node_positions = all_node_positions[projection]\n",
    "else:\n",
    "    node_positions = all_node_positions[projection][rank_type]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading edge data\n"
     ]
    }
   ],
   "source": [
    "#load edges\n",
    "print('loading edge data')\n",
    "\n",
    "categories_edges_df = None\n",
    "if os.path.exists('prepped_models/%s/edge_ranks.csv'%prepped_model_folder):\n",
    "    categories_edges_df = pd.read_csv('prepped_models/%s/ranks/categories_edges_ranks.csv'%prepped_model_folder)   #load edges\n",
    "\n",
    "if categories_edges_df is not None:\n",
    "    #overall_edges_df = categories_edges_df.loc[categories_edges_df['category']=='overall']\n",
    "    target_edges_df = categories_edges_df.loc[categories_edges_df['category']==target_category]\n",
    "else:\n",
    "    #overall_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','overall_edges_rank.pt'))\n",
    "    target_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','%s_edges_rank.pt'%target_category))\n",
    "\n",
    "target_edges_df = minmax_normalize_ranks_df(target_edges_df,params,weight=False)\n",
    "\n",
    "weight_edges_df = pd.read_csv('prepped_models/%s/ranks/weight_edges_ranks.csv'%prepped_model_folder)\n",
    "  \n",
    "weight_edges_df = minmax_normalize_ranks_df(weight_edges_df,params,weight=True)    \n",
    "    \n",
    "edges_thresholded_df = get_thresholded_ranksdf(edge_threshold,rank_type,target_edges_df)\n",
    " \n",
    "    \n",
    "num_edges = len(target_edges_df)\n",
    "edges_df_columns = list(target_edges_df.columns)\n",
    "\n",
    "edge_positions, edge_colors, edge_widths, edge_weights, edge_names, max_edge_width_indices = gen_edge_graphdata(edges_thresholded_df, node_positions, rank_type, target_category,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading convolutional kernels\n"
     ]
    }
   ],
   "source": [
    "#Load Edge Kernels\n",
    "print('loading convolutional kernels')\n",
    "kernels = torch.load('prepped_models/%s/kernels.pt'%prepped_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Image names\n",
    "params['input_image_directory'] = prep_model_params.input_img_path+'/'\n",
    "params['input_image_list'] = os.listdir(params['input_image_directory'])\n",
    "params['input_image_list'].sort()\n",
    "input_image_name = params['input_image_list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features_-1',\n",
       "              OrderedDict([('j', 1.0),\n",
       "                           ('r', 1.0),\n",
       "                           ('start', 0.5),\n",
       "                           ('conv_stage', True),\n",
       "                           ('output_shape', [-1, 3, 224, 224])])),\n",
       "             ('features_0',\n",
       "              OrderedDict([('j', 4.0),\n",
       "                           ('r', 11.0),\n",
       "                           ('start', 3.5),\n",
       "                           ('input_shape', [-1, 3, 224, 224]),\n",
       "                           ('output_shape', [-1, 64, 55, 55])])),\n",
       "             ('features_1',\n",
       "              OrderedDict([('j', 4.0),\n",
       "                           ('r', 11.0),\n",
       "                           ('start', 3.5),\n",
       "                           ('input_shape', [-1, 64, 55, 55]),\n",
       "                           ('output_shape', [-1, 64, 55, 55])])),\n",
       "             ('features_2',\n",
       "              OrderedDict([('j', 8.0),\n",
       "                           ('r', 19.0),\n",
       "                           ('start', 7.5),\n",
       "                           ('input_shape', [-1, 64, 55, 55]),\n",
       "                           ('output_shape', [-1, 64, 27, 27])])),\n",
       "             ('features_3',\n",
       "              OrderedDict([('j', 8.0),\n",
       "                           ('r', 51.0),\n",
       "                           ('start', 7.5),\n",
       "                           ('input_shape', [-1, 64, 27, 27]),\n",
       "                           ('output_shape', [-1, 192, 27, 27])])),\n",
       "             ('features_4',\n",
       "              OrderedDict([('j', 8.0),\n",
       "                           ('r', 51.0),\n",
       "                           ('start', 7.5),\n",
       "                           ('input_shape', [-1, 192, 27, 27]),\n",
       "                           ('output_shape', [-1, 192, 27, 27])])),\n",
       "             ('features_5',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 67.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 192, 27, 27]),\n",
       "                           ('output_shape', [-1, 192, 13, 13])])),\n",
       "             ('features_6',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 99.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 192, 13, 13]),\n",
       "                           ('output_shape', [-1, 384, 13, 13])])),\n",
       "             ('features_7',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 99.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 384, 13, 13]),\n",
       "                           ('output_shape', [-1, 384, 13, 13])])),\n",
       "             ('features_8',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 131.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 384, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_9',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 131.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_10',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 163.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_11',\n",
       "              OrderedDict([('j', 16.0),\n",
       "                           ('r', 163.0),\n",
       "                           ('start', 15.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 13, 13])])),\n",
       "             ('features_12',\n",
       "              OrderedDict([('j', 32.0),\n",
       "                           ('r', 195.0),\n",
       "                           ('start', 31.5),\n",
       "                           ('input_shape', [-1, 256, 13, 13]),\n",
       "                           ('output_shape', [-1, 256, 6, 6])])),\n",
       "             ('input_size', (3, 224, 224))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields = None\n",
    "if os.path.exists('prepped_models/%s/receptive_fields.pkl'%prepped_model_folder):\n",
    "    receptive_fields = pickle.load(open('prepped_models/%s/receptive_fields.pkl'%prepped_model_folder,'rb'))\n",
    "    \n",
    "input_image_size = 224   #got to figure out a way not to hard-code this\n",
    "receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading activation maps\n"
     ]
    }
   ],
   "source": [
    "#Format Node Feature Maps\n",
    "print('loading activation maps')\n",
    "\n",
    "all_activations = {'nodes':{},'edges_in':{},'edges_out':{}}\n",
    "if os.path.exists('prepped_models/%s/input_img_activations.pt'%prepped_model_folder):\n",
    "    all_activations = torch.load('prepped_models/%s/input_img_activations.pt'%prepped_model_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden state, stores python values within the html itself\n",
    "state = {'projection':projection,'rank_type':rank_type,'edge_positions':edge_positions,'edge_colors': edge_colors, 'edge_widths':edge_widths,'edge_names':edge_names,\n",
    "         'edge_threshold':edge_threshold,'edge_weights':edge_weights,'max_edge_width_indices':max_edge_width_indices,\n",
    "         'node_positions':node_positions,'node_colors':node_colors,'node_weights':node_weights,'node_threshold':node_threshold,'target_category':target_category,'target_node':'loss',\n",
    "         'node_select_history':['0'],'edge_select_history':[edge_names[0][0]],'last_trigger':None,'input_image_name':input_image_name,\n",
    "         'imgnode_positions':params['imgnode_positions'],'imgnode_colors':params['imgnode_colors'],'imgnode_names':params['imgnode_names']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#App Component Layouts\n",
    "axis=dict(showbackground=False,\n",
    "          showspikes=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          #range=[0,0],\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=-1.00, y=-1.25, z=1.25)\n",
    ")\n",
    "\n",
    "\n",
    "network_graph_layout = go.Layout(\n",
    "         #title=\"%s through Prunned Cifar10 CNN\"%target_category,\n",
    "         #title = target_category,\n",
    "         #width=1000,\n",
    "         clickmode = 'event+select',\n",
    "         transition = {'duration': 20},\n",
    "         height=500,\n",
    "         #showlegend=False,\n",
    "         margin = dict(l=20, r=20, t=20, b=20),\n",
    "         scene=dict(\n",
    "             xaxis=dict(axis),\n",
    "             yaxis=dict(axis),\n",
    "             zaxis=dict(axis),\n",
    "             aspectmode =\"manual\", \n",
    "             aspectratio = dict(x=1, y=0.5, z=0.5) #adjusting this stretches the network layer-to-layer\n",
    "         ),\n",
    "         scene_camera = camera,\n",
    "         uirevision =  True   \n",
    "         #hovermode='closest',\n",
    "   )\n",
    "\n",
    "\n",
    "input_image_layout = go.Layout(#width=200, \n",
    "                      #height=200,\n",
    "                      uirevision = True,\n",
    "                      margin=dict(\n",
    "                        l=12,\n",
    "                        r=1,\n",
    "                        b=12,\n",
    "                        t=1,\n",
    "                        pad=10\n",
    "                        ),\n",
    "                        paper_bgcolor='rgba(0,0,0,0)',\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',\n",
    "                        xaxis=dict(range=(0,10),showline=False,showgrid=False,showticklabels=False),\n",
    "                        yaxis=dict(range=(0,10),showline=False,showgrid=False,showticklabels=False))\n",
    "\n",
    "\n",
    "node_actmap_layout = go.Layout(\n",
    "    #autosize=False,\n",
    "    #width=270,\n",
    "    #height=200,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=1,\n",
    "        pad=1\n",
    "    ))\n",
    "\n",
    "\n",
    "edge_inmap_layout = go.Layout(\n",
    "    #title = 'edge input map',\n",
    "    #autosize=False,\n",
    "    #width=270,\n",
    "    #height=200,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=10,\n",
    "        pad=1\n",
    "    ))\n",
    "\n",
    "\n",
    "edge_outmap_layout = go.Layout(\n",
    "    #title = 'edge output map',\n",
    "    #autosize=False,\n",
    "    #width=270,\n",
    "    #height=200,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=10,\n",
    "        pad=1\n",
    "    ))\n",
    "\n",
    "\n",
    "kernel_layout = go.Layout(\n",
    "    #title='kernel'\n",
    "    #autosize=False,\n",
    "    #width=180,\n",
    "    #height=120,\n",
    "    uirevision = True,\n",
    "    margin=dict(\n",
    "        l=1,\n",
    "        r=1,\n",
    "        b=1,\n",
    "        t=1,\n",
    "        pad=1\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building graph from browser \"state\"\n"
     ]
    }
   ],
   "source": [
    "#Generate Network Graph\n",
    "combined_traces = gen_networkgraph_traces(state,params)\n",
    "network_graph_fig=go.Figure(data=combined_traces, layout=network_graph_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up dash app\n"
     ]
    }
   ],
   "source": [
    "#Dash App Setup\n",
    "print('setting up dash app')\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_daq as daq\n",
    "from dash.exceptions import PreventUpdate\n",
    "#import utils.dash_reusable_components as drc\n",
    "import flask\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from flask_caching import Cache\n",
    "\n",
    "#external_stylesheets = ['https://codepen.io/amyoshino/pen/jzXypZ.css']\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(external_stylesheets = external_stylesheets)\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(full_prepped_model_folder+'/cache/'):\n",
    "    os.mkdir(full_prepped_model_folder+'/cache/')\n",
    "CACHE_CONFIG = {\n",
    "    # try 'filesystem' if you don't want to setup redis\n",
    "    'CACHE_TYPE': 'filesystem',\n",
    "    'CACHE_DIR': full_prepped_model_folder+'/cache/'}\n",
    "cache = Cache()\n",
    "cache.init_app(app.server, config=CACHE_CONFIG)\n",
    "    \n",
    "\n",
    "\n",
    "styles = {\n",
    "    'pre': {\n",
    "        'border': 'thin lightgrey solid',\n",
    "        'overflowX': 'scroll'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "theme =  {\n",
    "    'dark': True,\n",
    "    'detail': '#007439',\n",
    "    'primary': '#00EA64',\n",
    "    'secondary': '#6E6E6E',\n",
    "}\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "        html.Div(\n",
    "            children = [\n",
    "                \n",
    "            html.Div(\n",
    "                #Left side control panel\n",
    "                children = [\n",
    "                 html.Label('Subgraph Controls', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "                 html.Br(),\n",
    "                 html.Label('Input'),\n",
    "                 #dcc.Dropdown(\n",
    "                 #  id='weight-category',\n",
    "                 #  options=[{'label': i, 'value': i} for i in params['categories']],\n",
    "                 #   value=target_category\n",
    "                 #   ),\n",
    "                dcc.Input(id='input-category',value=state['target_category']),\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.Label('Output'),\n",
    "                 #dcc.Dropdown(\n",
    "                 #  id='weight-category',\n",
    "                 #  options=[{'label': i, 'value': i} for i in params['categories']],\n",
    "                 #   value=target_category\n",
    "                 #   ),\n",
    "                dcc.Dropdown(\n",
    "                    id='target-node',\n",
    "                    options=[\n",
    "                    {'label': i, 'value': i} for i in ['loss']+[str(node) for node in list(range(params['num_nodes']))]\n",
    "                    ],\n",
    "                    value=state['target_node']),\n",
    "                 html.Br(),\n",
    "                 html.Label('Subgraph Criterion'),\n",
    "                 dcc.Dropdown(\n",
    "                    id='subgraph-criterion',\n",
    "                    options=[\n",
    "                        {'label': 'Activations*Grads', 'value': 'actxgrad'},\n",
    "                        {'label': 'Activations', 'value': 'act'},\n",
    "                        {'label': 'Gradients', 'value': 'grad'},\n",
    "                        {'label': 'Weights', 'value': 'weight'},\n",
    "                        {'label': 'Hierarchical', 'value': 'hierarchical'}\n",
    "                        \n",
    "                    ],\n",
    "                    value='actxgrad'\n",
    "                    ),\n",
    "                 html.Br(),   \n",
    "                 html.Label('Layer Projection'),\n",
    "                 dcc.Dropdown(\n",
    "                    id = 'layer-projection',\n",
    "                    options=[\n",
    "                        {'label': 'MDS', 'value': 'MDS'},\n",
    "                        {'label': 'MDS smooth', 'value': 'MDS smooth'},\n",
    "                        {'label': 'Grid', 'value': 'Grid'},\n",
    "                        #{'label': 'SOM', 'value': 'SOM'}\n",
    "                    ],\n",
    "                    value='MDS smooth'\n",
    "                    ),\n",
    "\n",
    "                html.Br(),\n",
    "                html.Label('Edge Thresholds'),\n",
    "                    dcc.RangeSlider(\n",
    "                        id='edge-thresh-slider',\n",
    "                        min=0,\n",
    "                        max=np.ceil(params['max_edge_weight']*10)/10,\n",
    "                        step=0.001,\n",
    "                        marks={i/10: str(i/10) for i in range(0,int(np.ceil(params['max_edge_weight']*10))+1,int(round(np.ceil(params['max_edge_weight']*10)/5)))},\n",
    "                        value=edge_threshold,\n",
    "                    ),\n",
    "                html.Label('Node Thresholds'),\n",
    "                    dcc.RangeSlider(\n",
    "                        id='node-thresh-slider',\n",
    "                        min=0,\n",
    "                        max=1,\n",
    "                        step=0.001,\n",
    "                        marks={i/10: str(i/10.0) for i in range(0,11)},\n",
    "                        value=node_threshold,\n",
    "                    ),\n",
    "\n",
    "                ], className=\"two columns\",\n",
    "                ),\n",
    "                \n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='network-graph',\n",
    "                    figure=network_graph_fig\n",
    "                )\n",
    "                ], className= 'ten columns'\n",
    "                ),\n",
    "            ], className=\"row\"\n",
    "        ),\n",
    "\n",
    "\n",
    "                \n",
    "        html.Div([\n",
    "            html.Div([\n",
    "            html.Label('Input Image', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            dcc.Dropdown(id=\"dynamic-input-image-dropdown\",value=params['input_image_list'][0]),\n",
    "            #dcc.Dropdown(\n",
    "            #    id='input-image-dropdown',\n",
    "            #    options=[{'label': i, 'value': i} for i in params['input_image_list']+os.listdir(params['prepped_model_path']+'/visualizations/images/')],\n",
    "            #    value=input_image_name\n",
    "            #),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='img-actmap-graph',\n",
    "                style={\n",
    "               'width': '14vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=image2heatmap(params['input_image_directory']+input_image_name,input_image_layout),\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            )\n",
    "            ], className = \"two columns\"),\n",
    "\n",
    "            html.Div([\n",
    "            html.Label('Node', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            dcc.Dropdown(\n",
    "                id='node-actmap-dropdown',\n",
    "                options=[{'label': str(j), 'value': str(j)} for j in params['imgnode_names']]+[{'label': str(i), 'value': str(i)} for i in range(params['num_nodes'])],\n",
    "                value='0'\n",
    "            ),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='node-actmap-graph',\n",
    "                style={\n",
    "               'width': '18vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            dcc.Checklist(\n",
    "                id = 'relu-checkbox',\n",
    "                options = [{'label':'relu','value':'relu'}],\n",
    "                value = []\n",
    "                \n",
    "            ),\n",
    "            html.Div(id='node-sum', style={'whiteSpace': 'pre-line'}),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='node-deepviz-image',\n",
    "                style={\n",
    "               'width': '14vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            )\n",
    "            ], className = \"three columns\"),\n",
    "            \n",
    "            html.Div([\n",
    "            html.Label('Node Inputs', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            html.Br(),\n",
    "            html.Div(dcc.Graph(\n",
    "                id='node-inputs-graph',\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),style={'overflowY': 'scroll', 'height': 500})\n",
    "            ], className = \"three columns\"),\n",
    "\n",
    "            html.Div([\n",
    "            html.Label('Edge', style={'fontSize': 18,'font-weight':'bold'}),    \n",
    "            dcc.Input(\n",
    "                id='edge-actmaps-input',value=state['edge_names'][0][0], type='text'),\n",
    "            #html.Button(id='edge-kernel-button',n_clicks=0, children='Submit'),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Label('Kernel'),\n",
    "            dcc.Graph(\n",
    "                id='edge-kernel-graph',\n",
    "                style={\n",
    "               'width': '14vw',\n",
    "               'height':'10vw'\n",
    "                },\n",
    "                figure=go.Figure(data=go.Heatmap(\n",
    "                                    z = edgename_2_edge_figures(state['edge_names'][0][0], input_image_name, kernels, None,params)[0]),\n",
    "                                 layout=kernel_layout\n",
    "                                ),\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "               id='edge-deepviz-image',\n",
    "               style={\n",
    "              'width': '14vw',\n",
    "              'height':'14vw'\n",
    "               },\n",
    "               figure=figure_init,\n",
    "               config={\n",
    "                       'displayModeBar': False\n",
    "                       }\n",
    "            )\n",
    "            ], className = \"two columns\"),\n",
    "\n",
    "\n",
    "            html.Div([\n",
    "            html.Label('Edge Input'),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='edge-inmap-graph',\n",
    "                style={\n",
    "               'width': '18vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            html.Div(id='edgein-sum', style={'whiteSpace': 'pre-line'}),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Label('Edge Output'),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "                id='edge-outmap-graph',\n",
    "                style={\n",
    "               'width': '18vw',\n",
    "               'height':'14vw'\n",
    "                },\n",
    "                figure=figure_init,\n",
    "                config={\n",
    "                        'displayModeBar': False\n",
    "                        }\n",
    "            ),\n",
    "            html.Div(id='edgeout-sum', style={'whiteSpace': 'pre-line'}),\n",
    "\n",
    "            ], className = \"two columns\")\n",
    "\n",
    "\n",
    "         ], className= 'row'\n",
    "         ),\n",
    "    \n",
    "    \n",
    "    html.Div([\n",
    "            html.Div([\n",
    "            html.Label('Image Manipulations', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            html.Br(),\n",
    "            html.Label('rotation'),\n",
    "            dcc.Slider(\n",
    "                id='image-rotation-slider',\n",
    "                min=0,\n",
    "                max=350,\n",
    "                step=10,\n",
    "                marks={\n",
    "                        0:   '0°',\n",
    "                        20:  '20°',\n",
    "                        40:  '40°',\n",
    "                        60:  '60°',\n",
    "                        80:  '80°',\n",
    "                        100: '100°',\n",
    "                        120: '120°',\n",
    "                        140: '140°',\n",
    "                        160: '160°',\n",
    "                        180: '180°',\n",
    "                        200: '200°',\n",
    "                        220: '220°',\n",
    "                        240: '240°',\n",
    "                        260: '260°',\n",
    "                        280: '280°',\n",
    "                        300: '300°',\n",
    "                        320: '320°',\n",
    "                        340: '240°',\n",
    "                        },\n",
    "                included=False,\n",
    "                value=0,\n",
    "            ),\n",
    "            html.Br(),\n",
    "            html.Label('scaling'),\n",
    "            dcc.Slider(\n",
    "                id='image-scaling-slider',\n",
    "                min=-10,\n",
    "                max=10,\n",
    "                step=1,\n",
    "                marks={\n",
    "                        -8:  '.33',\n",
    "                        -6:  '.4',\n",
    "                        -4: '.5',\n",
    "                        -2: '.67',\n",
    "                         0: '1',\n",
    "                         2: '1.5',\n",
    "                         4: '2',\n",
    "                         6: '2.5',\n",
    "                         8: '3',\n",
    "                        },\n",
    "                included=False,\n",
    "                value=0,\n",
    "            ),            \n",
    "            html.Br(),\n",
    "            html.Label('colors'),\n",
    "\n",
    "                    html.Label('R',style={'fontSize': 10,'font-weight':'italic'}),\n",
    "                    dcc.Slider(\n",
    "                        id='image-r-slider',\n",
    "                        min=-1,\n",
    "                        max=1,\n",
    "                        step=.05,\n",
    "                        marks={\n",
    "                                -1:'-1',\n",
    "                                -.8:'-.8',\n",
    "                                -.6:'-.6',\n",
    "                                -.4:'-.4',\n",
    "                                 -.2:'-.2',\n",
    "                                 0:'0',\n",
    "                                 .2:'.2',\n",
    "                                 .4:'.4',\n",
    "                                 .6:'.6',\n",
    "                                 .8:'.8',\n",
    "                                  1:'1',\n",
    "                                },\n",
    "                        included=False,\n",
    "                        value=0,\n",
    "                    ),\n",
    " \n",
    "\n",
    "                    html.Label('G',style={'fontSize': 10,'font-weight':'italic'}),\n",
    "                    dcc.Slider(\n",
    "                        id='image-g-slider',\n",
    "                        min=-1,\n",
    "                        max=1,\n",
    "                        step=.05,\n",
    "                        marks={\n",
    "                                -1:'-1',\n",
    "                                -.8:'-.8',\n",
    "                                -.6:'-.6',\n",
    "                                -.4:'-.4',\n",
    "                                 -.2:'-.2',\n",
    "                                 0:'0',\n",
    "                                 .2:'.2',\n",
    "                                 .4:'.4',\n",
    "                                 .6:'.6',\n",
    "                                 .8:'.8',\n",
    "                                  1:'1',\n",
    "                                },\n",
    "                        included=False,\n",
    "                        value=0,\n",
    "                    ),\n",
    "    \n",
    "\n",
    "                    html.Label('B',style={'fontSize': 10,'font-weight':'italic'}),\n",
    "                    dcc.Slider(\n",
    "                        id='image-b-slider',\n",
    "                        min=-1,\n",
    "                        max=1,\n",
    "                        step=.05,\n",
    "                        marks={\n",
    "                                -1:'-1',\n",
    "                                -.8:'-.8',\n",
    "                                -.6:'-.6',\n",
    "                                -.4:'-.4',\n",
    "                                 -.2:'-.2',\n",
    "                                 0:'0',\n",
    "                                 .2:'.2',\n",
    "                                 .4:'.4',\n",
    "                                 .6:'.6',\n",
    "                                 .8:'.8',\n",
    "                                  1:'1',\n",
    "                                },\n",
    "                        included=False,\n",
    "                        value=0,\n",
    "                    )\n",
    "           \n",
    "            ], className = \"three columns\"),\n",
    "                \n",
    "                \n",
    "            html.Div([\n",
    "            html.Label('Feature Visualizations', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            html.Br(),\n",
    "            html.Div( style=dict(display='flex'),\n",
    "                children = [     \n",
    "                    daq.ToggleSwitch(\n",
    "                        id='featviz-nodeedge-toggle',\n",
    "                        label=['node','edge    '],\n",
    "                        style={'float': 'right','margin': 'auto'}\n",
    "                        #labelPosition='bottom'\n",
    "                    ), \n",
    "                    html.Label(''),\n",
    "                    daq.ToggleSwitch(\n",
    "                        id='featviz-channelneuron-toggle',\n",
    "                        label=['channel','neuron    '],\n",
    "                        style={'float': 'right','margin': 'auto'}\n",
    "                        #labelPosition='bottom'\n",
    "                    ),\n",
    "                    html.Label(''),\n",
    "                    daq.ToggleSwitch(\n",
    "                        id='featviz-positivenegative-toggle',\n",
    "                        label=['positive','negative    '],\n",
    "                        style={'float': 'right','margin': 'auto'}\n",
    "                        #labelPosition='bottom'\n",
    "                    )\n",
    "                ]),\n",
    "            html.Br(),\n",
    "            dcc.Graph(\n",
    "               id='featviz-image',\n",
    "               style={\n",
    "              'width': '14vw',\n",
    "              'height':'14vw'\n",
    "               },\n",
    "               figure=figure_init,\n",
    "               config={\n",
    "                       'displayModeBar': False\n",
    "                       }\n",
    "            ),\n",
    "            html.Button('Generate', id='featviz-button')\n",
    "            #html.Button('Generate', id='gen-featviz-button')\n",
    "            ], className= \"five columns\"),\n",
    "        \n",
    "        \n",
    "        \n",
    "            html.Div([\n",
    "            html.Label('Model Ablations', style={'fontSize': 18,'font-weight':'bold'}),\n",
    "            dcc.Textarea(\n",
    "                id='ablations-textarea',\n",
    "                value='',\n",
    "                style={'width': '70%', 'height': 300}),\n",
    "            html.Button('Ablate', id='ablate-model-button')\n",
    "            ], className= \"four columns\"),\n",
    "        \n",
    "        ], className=\"row\"\n",
    "        ),\n",
    "                \n",
    "#         html.Div([\n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Hover Data**\n",
    "\n",
    "#                     Mouse over values in the graph.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='hover-data', style=styles['pre'])\n",
    "#             ], className='two columns'),\n",
    "\n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Click Data**\n",
    "\n",
    "#                     Click on points in the graph.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='click-data', style=styles['pre']),\n",
    "#             ], className='two columns'),\n",
    "\n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Selection Data**\n",
    "\n",
    "#                     Choose the lasso or rectangle tool in the graph's menu\n",
    "#                     bar and then select points in the graph.\n",
    "\n",
    "#                     Note that if `layout.clickmode = 'event+select'`, selection data also \n",
    "#                     accumulates (or un-accumulates) selected data if you hold down the shift\n",
    "#                     button while clicking.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='selected-data', style=styles['pre']),\n",
    "#             ], className='two columns'),\n",
    "\n",
    "# #                 html.Div([\n",
    "# #                     dcc.Markdown(\"\"\"\n",
    "# #                         **Zoom and Relayout Data**\n",
    "\n",
    "# #                         Click and drag on the graph to zoom or click on the zoom\n",
    "# #                         buttons in the graph's menu bar.\n",
    "# #                         Clicking on legend items will also fire\n",
    "# #                         this event.\n",
    "# #                     \"\"\"),\n",
    "# #                     html.Pre(id='relayout-data', style=styles['pre']),\n",
    "# #                 ], className='two columns')\n",
    "                \n",
    "#             html.Div([\n",
    "#                 dcc.Markdown(\"\"\"\n",
    "#                     **Figure Data**\n",
    "\n",
    "#                     Figure json info.\n",
    "#                 \"\"\"),\n",
    "#                 html.Pre(id='figure-data', style=styles['pre']),\n",
    "#             ], className='four columns')\n",
    "\n",
    "#         ], className= 'row'\n",
    "#         ),\n",
    "\n",
    "    #hidden divs for storing intermediate values     \n",
    "    # The memory store reverts to the default on every page refresh\n",
    "    dcc.Store(id='memory',data=state),\n",
    "    # The local store will take the initial data\n",
    "    # only the first time the page is loaded\n",
    "    # and keep it until it is cleared.\n",
    "    #dcc.Store(id='local', storage_type='local'),\n",
    "    # Same as the local store but will lose the data\n",
    "    # when the browser/tab closes.\n",
    "    #dcc.Store(id='session', storage_type='session',data=state),\n",
    "    \n",
    "\n",
    "    # hidden signal value\n",
    "    html.Div(id='input-image-signal',  style={'display': 'none'}),\n",
    "    html.Div(id='target-signal', style={'display': 'none'},children = [state['target_category'],state['target_node']]),\n",
    "    html.Div(id='ablations-signal',  style={'display': 'none'}, children = [])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# perform expensive computations in this \"global store\"\n",
    "# these computations are cached in a globally available\n",
    "# 'cached' folder in the prepped_models/[model] folder\n",
    "@cache.memoize()\n",
    "def activations_store(image_name,ablation_list):\n",
    "\n",
    "    print('Updating cached activations with {}'.format(image_name))\n",
    "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
    "    \n",
    "    return activations\n",
    "\n",
    "@app.callback(Output('input-image-signal', 'children'), \n",
    "              [Input('dynamic-input-image-dropdown', 'value'),\n",
    "               Input('ablations-signal', 'children')])\n",
    "def update_activations_store(image_name,ablation_list):\n",
    "    # compute value and send a signal when done\n",
    "    activations_store(image_name,ablation_list)\n",
    "    return image_name\n",
    "\n",
    "\n",
    "@cache.memoize()\n",
    "def ranksdf_store(target_category, target_node,ablation_list,model_dis=model_dis):\n",
    "    print('Updating cached rank dfs with {}'.format(target_category))\n",
    "    model_dis = clear_ranks_across_model(model_dis)\n",
    "    target_type = image_category_or_contrast(target_category,params)\n",
    "    target_category_nodes_df = None\n",
    "    target_category_edges_df = None\n",
    "    if target_type == 'category' and target_node == 'loss' and ablation_list == []:\n",
    "        #edges\n",
    "        if categories_edges_df is not None:\n",
    "            if len(categories_edges_df.loc[categories_edges_df['category']==target_category]) > 0:\n",
    "                target_category_edges_df = categories_edges_df.loc[categories_edges_df['category']==target_category]\n",
    "        if target_category_edges_df is None:\n",
    "            target_category_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','%s_edges_rank.pt'%target_category))   \n",
    "        #node\n",
    "        if categories_nodes_df is not None:\n",
    "            if len(categories_nodes_df.loc[categories_nodes_df['category']==target_category]) > 0:\n",
    "                target_category_nodes_df = categories_nodes_df.loc[categories_nodes_df['category']==target_category]\n",
    "        if target_category_nodes_df is None:\n",
    "            target_category_nodes_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_nodes','%s_nodes_rank.pt'%target_category))\n",
    "    elif target_type == 'category':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
    "    elif target_type == 'input_image':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_from_image(get_image_path(target_category,params)[1],target_node, model_dis, params))\n",
    "\n",
    "    else:  #contrast\n",
    "        target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
    "    print('FROM RANKS DF STORE')\n",
    "    print(target_category_edges_df)\n",
    "    return target_category_nodes_df,target_category_edges_df\n",
    "\n",
    "@app.callback(Output('target-signal', 'children'), \n",
    "              [Input('input-category', 'value'),\n",
    "               Input('target-node','value'),\n",
    "               Input('ablations-signal', 'children')])\n",
    "def update_ranksdf_store(target_category,target_node,ablation_list):\n",
    "    # compute value and send a signal when done\n",
    "    print('update ranksdf_store triggered')\n",
    "    ranksdf_store(target_category,target_node,ablation_list)\n",
    "    return [target_category,target_node]\n",
    "\n",
    "\n",
    "\n",
    "####Call Back Functions\n",
    "\n",
    "#Ablations\n",
    "@app.callback(Output('ablations-signal', 'children'), \n",
    "              [Input('ablate-model-button', 'n_clicks')],\n",
    "              [State('ablations-textarea','value')])\n",
    "def update_ablations(n_clicks,text,model_dis=model_dis):\n",
    "    # compute value and send a signal when done\n",
    "    ablation_list = ablation_text_2_list(text, params)\n",
    "    ablate_model_with_list(ablation_list,model_dis,params)\n",
    "    return ablation_list\n",
    "\n",
    "\n",
    "#Hidden State\n",
    "@app.callback(\n",
    "    Output('memory', 'data'),\n",
    "    [Input('target-signal', 'children'),\n",
    "     Input('node-actmap-dropdown', 'value'),\n",
    "     Input('edge-actmaps-input', 'value'),\n",
    "     Input('edge-thresh-slider','value'),\n",
    "     Input('node-thresh-slider','value'),\n",
    "     Input('layer-projection','value'),\n",
    "     Input('subgraph-criterion','value')],\n",
    "    [State('memory', 'data'),\n",
    "     State('ablations-signal', 'children')])\n",
    "def update_store(target,node_value,edge_value,edge_threshold,node_threshold,projection,rank_type,state,ablation_list):\n",
    "    print('CALLED: update_store\\n')\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        raise Exception('no figure updates yet')\n",
    "    else:\n",
    "        trigger = ctx.triggered[0]['prop_id']\n",
    "    state['last_trigger'] = trigger  #store the last trigger of state change in state\n",
    "    print('TRIGGER %s'%trigger)\n",
    "    \n",
    "    hierarchical = False\n",
    "    if rank_type == 'hierarchical':\n",
    "        hierarchical = True\n",
    "        rank_type = 'actxgrad'\n",
    "        \n",
    "    target_category,target_node = target[0],target[1]\n",
    "    #fetch select edges DF\n",
    "    if trigger in ['target-signal.children','edge-thresh-slider.value','node-thresh-slider.value','layer-projection.value','subgraph-criterion.value']:\n",
    "        if rank_type == 'weight':\n",
    "            target_edges_df = weight_edges_df\n",
    "            target_nodes_df = weight_nodes_df\n",
    "            weight=True\n",
    "        else:   \n",
    "            target_nodes_df,target_edges_df = ranksdf_store(target_category,target_node,ablation_list)\n",
    "            weight=False   \n",
    "        target_edges_df = minmax_normalize_ranks_df(target_edges_df,params,weight=weight)\n",
    "        target_nodes_df = minmax_normalize_ranks_df(target_nodes_df,params,weight=weight)\n",
    "\n",
    "        if hierarchical:\n",
    "            #nodes_thresholded_df = get_thresholded_ranksdf(node_threshold,rank_type, target_nodes_df)\n",
    "            #filter_edges_df = filter_edges_by_nodes(target_edges_df,nodes_thresholded_df)\n",
    "            #edges_thresholded_df = get_thresholded_ranksdf(edge_threshold,rank_type,filter_edges_df)\n",
    "            #edges_thresholded_df = hierarchically_threshold_edges(edge_threshold,rank_type,target_edges_df,nodes_thresholded_df)\n",
    "            print('finding hierarchical subgraph')\n",
    "            start = time.time()\n",
    "            nodes_thresholded_df,edges_thresholded_df = hierarchical_accum_threshold(node_threshold[0],edge_threshold[0],rank_type,target_edges_df,target_nodes_df,ascending=False)\n",
    "            print('time: %s'%str(time.time() - start))\n",
    "            print('found %s nodes and %s edges'%(str(len(nodes_thresholded_df)),str(len(edges_thresholded_df))))\n",
    "            #node_minmax = node_threshold\n",
    "            node_min = {}\n",
    "            for layer in target_nodes_df['layer'].unique():\n",
    "                if len(nodes_thresholded_df.loc[nodes_thresholded_df['layer']==layer]) > 1:\n",
    "                    node_min[layer] = nodes_thresholded_df.loc[nodes_thresholded_df['layer']==layer][rank_type+'_rank'].min()\n",
    "                else:\n",
    "                    node_min[layer] = None\n",
    "\n",
    "        else: \n",
    "            nodes_thresholded_df = None\n",
    "            edges_thresholded_df = get_thresholded_ranksdf(edge_threshold,rank_type,target_edges_df)\n",
    "            node_min = None\n",
    "\n",
    "    if trigger == 'target-signal.children':\n",
    "        print('changing target category to %s'%target_category)\n",
    "        #print(target_nodes_df)\n",
    "        state['node_colors'], state['node_weights'] = gen_node_colors(target_nodes_df,rank_type,params,node_min=node_min)\n",
    "        #state['max_edge_weight'] = get_max_edge_weight(target_category)\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'],state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "\n",
    "    elif trigger == 'node-actmap-dropdown.value' or trigger == 'edge-actmaps-input.value':\n",
    "        state['last_trigger'] = 'selection_change'\n",
    "        print(edge_value)\n",
    "        #update node if button value different than store value\n",
    "        if state['node_select_history'][-1] != node_value:\n",
    "            print('changing selected node to %s'%node_value)\n",
    "            state['node_select_history'].append(node_value)\n",
    "            if len(state['node_select_history']) > 10:\n",
    "                del state['node_select_history'][0] \n",
    "        #update edge if button value different than store value\n",
    "        if state['edge_select_history'][-1] != edge_value and check_edge_validity(edge_value.strip(),params)[0]:\n",
    "            print('changing selected edge to %s'%edge_value)\n",
    "            state['edge_select_history'].append(edge_value)\n",
    "            print(state['edge_select_history'])\n",
    "            if len(state['edge_select_history']) > 10:\n",
    "                del state['edge_select_history'][0]              \n",
    "\n",
    "    elif trigger == 'edge-thresh-slider.value':\n",
    "        print('changing edge thresholds to %s - %s'%(edge_threshold[0],edge_threshold[1]))\n",
    "        state['edge_threshold'] == edge_threshold\n",
    "        print('found %s edges'%len(edges_thresholded_df))\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'], state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "    \n",
    "    elif trigger == 'node-thresh-slider.value':\n",
    "        print('changing node thresholds to %s - %s'%(node_threshold[0],node_threshold[1]))\n",
    "        state['node_threshold'] == node_threshold\n",
    "        print('found %s nodes'%len(nodes_thresholded_df))\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'], state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "        state['node_colors'], state['node_weights'] = gen_node_colors(target_nodes_df,rank_type,params,node_min=node_min)\n",
    "        \n",
    "        \n",
    "    elif trigger == 'layer-projection.value':\n",
    "        print('changing layer projection to %s\\n'%projection)\n",
    "        state['projection']=projection\n",
    "        if projection == 'Grid':\n",
    "            node_positions = all_node_positions[projection]\n",
    "        else:\n",
    "            node_positions = all_node_positions[projection][rank_type]\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'],state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "\n",
    "    elif trigger == 'subgraph-criterion.value':\n",
    "        print('changing weighting criterion to %s\\n'%rank_type)\n",
    "        state['rank_type']=rank_type\n",
    "        state['node_colors'], state['node_weights'] = gen_node_colors(target_nodes_df,rank_type,params,node_min=node_min)\n",
    "        #state['node_positions']=format_node_positions(projection=projection,rank_type=rank_type)\n",
    "        state['edge_positions'], state['edge_colors'], state['edge_widths'],state['edge_weights'], state['edge_names'], state['max_edge_width_indices'] = gen_edge_graphdata(edges_thresholded_df, state['node_positions'], rank_type, target_category,params)\n",
    "\n",
    "    else:\n",
    "        raise Exception('unknown trigger: %s'%trigger)    \n",
    "    return state\n",
    "\n",
    "\n",
    "#Network Graph Figure\n",
    "@app.callback(\n",
    "    Output('network-graph', 'figure'),\n",
    "    [Input('memory', 'data')],\n",
    "    [State('network-graph','figure')])\n",
    "def update_figure(state, fig):\n",
    "    #network_graph_layout['uirevision'] = True\n",
    "    print('CALLED: update_figure\\n')\n",
    "    print(state['edge_threshold'])\n",
    "    print(state['edge_select_history'])\n",
    "    print(state['node_select_history'])\n",
    "    if state['last_trigger'] == 'selection_change':   #minimal updates\n",
    "        #hightlight edge\n",
    "        print('updating edge highlight to %s'%state['edge_select_history'][-1])\n",
    "        #if len(state['edge_select_history']) >1:\n",
    "        #if state['edge_select_history'][-1] != state['edge_select_history'][-2]:  #didnt click same point\n",
    "        flat_edge_names = [item for sublist in state['edge_names'] for item in sublist]\n",
    "        flat_edge_colors = [item for sublist in state['edge_colors'] for item in sublist]\n",
    "        try:  #update current edge if it exists to black\n",
    "            #print(flat_edge_names)\n",
    "            fig['data'][flat_edge_names.index(state['edge_select_history'][-1])+params['num_layers']+1]['line']['color'] = 'rgba(0,0,0,1)'\n",
    "        except:\n",
    "            print('select edge, %s,  not recolored as no longer shown'%state['edge_select_history'][-1])\n",
    "        if len(state['edge_select_history']) > 1: #there is a previous edge to unselect\n",
    "            try: #recolor previous edge if it exists from black\n",
    "                fig['data'][flat_edge_names.index(state['edge_select_history'][-2])+params['num_layers']+1]['line']['color'] = flat_edge_colors[flat_edge_names.index(state['edge_select_history'][-2])]\n",
    "            except:\n",
    "                print('previous edge, %s,  not recolored as no longer shown'%state['edge_select_history'][-2])\n",
    "        #highlight node\n",
    "        print('updating node highlight to %s'%state['node_select_history'][-1])\n",
    "        #if len(state['node_select_history']) >1:\n",
    "        #    if state['node_select_history'][-1] != state['node_select_history'][-2]: \n",
    "                #update current node color to black\n",
    "        if str(state['node_select_history'][-1]).isnumeric():  #if normal node\n",
    "            select_layer,select_position,select_layer_name = nodeid_2_perlayerid(state['node_select_history'][-1],params)\n",
    "            fig['data'][select_layer+1]['marker']['color'][select_position] = 'rgba(0,0,0,1)'\n",
    "        else:   #imgnode\n",
    "            fig['data'][0]['marker']['color'][fig['data'][0]['text'].index(state['node_select_history'][-1])] = 'rgba(0,0,0,1)'\n",
    "        #update previous node color to its usual color\n",
    "        if len(state['node_select_history']) > 1: #there is a previous node to unselect\n",
    "            if str(state['node_select_history'][-2]).isnumeric():  #if normal node\n",
    "                prev_select_layer,prev_select_position,prev_select_layer_name = nodeid_2_perlayerid(state['node_select_history'][-2],params)\n",
    "                print(prev_select_layer,prev_select_position,prev_select_layer_name)\n",
    "                fig['data'][prev_select_layer+1]['marker']['color'][prev_select_position] = state['node_colors'][prev_select_layer][prev_select_position]\n",
    "            else:   #imgnode\n",
    "                fig['data'][0]['marker']['color'][fig['data'][0]['text'].index(state['node_select_history'][-2])] = state['imgnode_colors'][fig['data'][0]['text'].index(state['node_select_history'][-2])]\n",
    "        #fig['layout']['uirevision']=True   \n",
    "        return fig    \n",
    "    else:   #regenerate full traces\n",
    "        combined_traces = gen_networkgraph_traces(state,params)\n",
    "        fig['data'] = combined_traces\n",
    "        #layout = network_graph_layout\n",
    "        #layout['uirevision'] = True\n",
    "        return fig\n",
    "\n",
    "#Node Actmap Dropdown\n",
    "@app.callback(\n",
    "    Output('node-actmap-dropdown', 'value'),\n",
    "    [Input('network-graph', 'clickData')],\n",
    "    [State('node-actmap-dropdown', 'value')])\n",
    "def switch_node_actmap_click(clickData,current_value):\n",
    "    print('CALLED: switch_node_actmap_click')\n",
    "    if clickData is None:\n",
    "        return current_value \n",
    "        #raise Exception('no click data')\n",
    "    if int(clickData['points'][0]['curveNumber']) > params['num_layers']:\n",
    "        return current_value\n",
    "        #raise Exception('edge was clicked')\n",
    "    return clickData['points'][0]['text']\n",
    "\n",
    "#Edge Actmaps Input\n",
    "@app.callback(\n",
    "    Output('edge-actmaps-input', 'value'),\n",
    "    [Input('network-graph', 'clickData')],\n",
    "    [State('edge-actmaps-input', 'value'),\n",
    "     State('memory', 'data')])\n",
    "def switch_edge_actmaps_click(clickData,current_value,state):\n",
    "    print('CALLED: switch_edge_actmaps_click')\n",
    "    if clickData is None:\n",
    "        return current_value\n",
    "        #raise Exception('no click data')\n",
    "    if int(clickData['points'][0]['curveNumber']) <= params['num_layers']:\n",
    "        return current_value\n",
    "        #raise Exception('node was clicked')\n",
    "    return get_nth_element_from_nested_list(state['edge_names'],int(clickData['points'][0]['curveNumber'])-(params['num_layers']+1))\n",
    "\n",
    "\n",
    "#Node actmap graph\n",
    "@app.callback(\n",
    "    Output('node-actmap-graph', 'figure'),\n",
    "    [Input('node-actmap-dropdown', 'value'),\n",
    "     Input('relu-checkbox','value'),\n",
    "     Input('input-image-signal', 'children')],\n",
    "    [State('ablations-signal', 'children')])\n",
    "def update_node_actmap(nodeid,relu_checked,image_name,ablation_list):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_node_actmap')\n",
    "    layer, within_id,layer_name = nodeid_2_perlayerid(nodeid,params)\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations  = activations_store(image_name,ablation_list)\n",
    "        \n",
    "    if layer == 'img': #code for returning color channel as activation map\n",
    "        #np_chan_im = get_channelwise_image(image_name,state['imgnode_names'].index(nodeid),params['input_image_directory']=params['input_image_directory'])\n",
    "        np_chan_im = activations['edges_in'][image_name][0][within_id]\n",
    "        return go.Figure(data=go.Heatmap( z = np.flip(np_chan_im,0), name = nodeid),\n",
    "                        layout=node_actmap_layout) \n",
    "    act_map = activations['nodes'][image_name][layer][within_id]\n",
    "    if relu_checked != []:\n",
    "        act_map = relu(act_map)\n",
    "    return go.Figure(data=go.Heatmap( z = np.flip(act_map,0),\n",
    "                                      #zmin=-11,\n",
    "                                      #zmax=14,\n",
    "                                      colorbar = dict(thicknessmode = \"fraction\",thickness=.1)\n",
    "                                    ),\n",
    "                     layout=node_actmap_layout) \n",
    "\n",
    "@app.callback(\n",
    "    Output('node-sum', 'children'),\n",
    "    [Input('node-actmap-graph', 'figure')])\n",
    "def update_node_sum(fig):\n",
    "    mean = np.mean(fig['data'][0]['z'])\n",
    "    return 'mean: %s'%str(mean)\n",
    "\n",
    "\n",
    "#Node deepviz graph\n",
    "@app.callback(\n",
    "    Output('node-deepviz-image', 'figure'),\n",
    "    [Input('node-actmap-dropdown', 'value')])\n",
    "def update_node_deepviz(nodeid):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_node_deepviz')\n",
    "    layer,within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)    \n",
    "    if layer == 'img': \n",
    "        return figure_init\n",
    "    image_name = fetch_deepviz_img(model,str(nodeid),params)\n",
    "    image_path = params['prepped_model_path']+'/visualizations/images/'+image_name\n",
    "    return image2plot(image_path,input_image_layout)\n",
    "    \n",
    "\n",
    "#Edge deepviz graph\n",
    "@app.callback(\n",
    "    Output('edge-deepviz-image', 'figure'),\n",
    "    [Input('edge-actmaps-input', 'value')])\n",
    "def update_edge_deepviz(edgename):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_edge_deepviz')\n",
    "    #layer,within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)    \n",
    "    #if layer == 'img': \n",
    "    #    return figure_init\n",
    "    image_name = fetch_deepviz_img(model_dis,edgename,params)\n",
    "    image_path = params['prepped_model_path']+'/visualizations/images/'+image_name\n",
    "    return image2plot(image_path,input_image_layout)\n",
    "     \n",
    "\n",
    "#Node inputs actmap graph\n",
    "@app.callback(\n",
    "    Output('node-inputs-graph', 'figure'),\n",
    "    [Input('node-actmap-dropdown', 'value'),\n",
    "     Input('input-image-signal', 'children'),\n",
    "     Input('target-signal', 'children'),\n",
    "     Input('subgraph-criterion','value')],\n",
    "     [State('ablations-signal', 'children')])\n",
    "def update_node_inputs(nodeid,image_name,target,rank_type,ablation_list,model=model_dis,max_num = params['max_node_inputs']):       \n",
    "    print('CALLED: update_node_inputs')\n",
    "    \n",
    "    hierarchical = False\n",
    "    if rank_type == 'hierarchical':\n",
    "        hierarchical = True\n",
    "        rank_type = 'actxgrad'\n",
    "    \n",
    "    \n",
    "    target_category,target_node = target[0],target[1]\n",
    "    node_layer,node_within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations = activations_store(image_name,ablation_list)\n",
    "    #fetch edges df\n",
    "    if rank_type == 'weight':\n",
    "        target_edges_df = weight_edges_df\n",
    "    else:\n",
    "        target_edges_df = ranksdf_store(target_category,target_node,ablation_list)[1]\n",
    "    #return no input if on input image node \n",
    "    if node_layer == 'img':\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[]))\n",
    "        fig.update_layout(xaxis=dict(visible=False),\n",
    "                          yaxis=dict(visible=False),\n",
    "                          annotations = [dict(text=\"No Inputs\",\n",
    "                                              xref=\"paper\",\n",
    "                                              yref=\"paper\",\n",
    "                                              showarrow=False,\n",
    "                                              font=dict(size=28))]\n",
    "                         )\n",
    "        return fig\n",
    "\n",
    "    all_node_edges_df = target_edges_df.loc[(target_edges_df['layer']==node_layer) & (target_edges_df['out_channel'] == node_within_layer_id)]\n",
    "    #if sort_images:                      \n",
    "    all_node_edges_df = all_node_edges_df.sort_values(by=[rank_type+'_rank'],ascending=False)\n",
    "    top_node_edges_df = all_node_edges_df.head(max_num)\n",
    "    fig = make_subplots(rows=len(top_node_edges_df)+1, cols=3)\n",
    "    #print(top_node_edges_df)\n",
    "    i=1\n",
    "    for row in top_node_edges_df.itertuples():\n",
    "        if node_layer == 0:\n",
    "            edge_name = str(params['imgnode_names'][row.in_channel])+'-'+str(nodeid)\n",
    "        else:\n",
    "            edge_name = str(params['layer_nodes'][node_layer-1][1][row.in_channel])+'-'+str(nodeid)\n",
    "        #add activation map\n",
    "        fig.add_trace(\n",
    "               go.Heatmap(z = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)[2],\n",
    "                          #zmin = -1,\n",
    "                          #zmax = 1,\n",
    "                          name = edge_name,\n",
    "                          coloraxis=\"coloraxis\"\n",
    "                          #showscale = False,\n",
    "                          #colorbar = dict(lenmode='fraction',len=1/len(top_node_edges_df), \n",
    "                          #                y=(i)/len(top_node_edges_df)-.01,\n",
    "                          #                thicknessmode = \"fraction\",thickness=.1,\n",
    "                          #                ypad=1\n",
    "                          #               )\n",
    "                          ),\n",
    "               row=i, col=2),\n",
    "        #add kernel\n",
    "        fig.add_trace(\n",
    "               go.Heatmap(z = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)[0],\n",
    "                          #zmin = -1,\n",
    "                          #zmax = 1,\n",
    "                          name = edge_name+'_kernel',\n",
    "                          coloraxis=\"coloraxis2\"\n",
    "                          #showscale = False,\n",
    "                          #colorbar = dict(lenmode='fraction',len=1/len(top_node_edges_df), \n",
    "                          #                y=(i)/len(top_node_edges_df)-.01,\n",
    "                          #                thicknessmode = \"fraction\",thickness=.1,\n",
    "                          #                ypad=1\n",
    "                          #               )\n",
    "                          ),\n",
    "               row=i, col=3),\n",
    "\n",
    "        #add visualization\n",
    "        viz_img_name = fetch_deepviz_img_for_node_inputs(model,edge_name,params)\n",
    "        viz_img_path = params['prepped_model_path']+'/visualizations/images/'+viz_img_name\n",
    "        viz_img = Image.open(viz_img_path)\n",
    "        #fig.add_trace(go.Image(z=viz_img,name=viz_img_name), row=i, col=1)\n",
    "        fig.add_trace(go.Scatter(x=[],y=[]),row=i,col=1)\n",
    "        fig.add_layout_image(\n",
    "                            source=viz_img,\n",
    "                            xref=\"x\",\n",
    "                            yref=\"y\",\n",
    "                            x=0,\n",
    "                            y=10,\n",
    "                            sizex=10,\n",
    "                            sizey=10,\n",
    "                            sizing=\"stretch\",\n",
    "                            opacity=1,\n",
    "                            layer=\"below\",\n",
    "                            row=i, col=1\n",
    "                            )\n",
    "        fig.update_xaxes(visible=False,range=(0,10),showline=False,showgrid=False,showticklabels=False,row=i,col=1)\n",
    "        fig.update_yaxes(visible=False,range=(0,10),showline=False,showgrid=False,showticklabels=False,row=i,col=1)\n",
    "   \n",
    "\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    fig.update_layout(height=200*len(top_node_edges_df), \n",
    "                      width=340,\n",
    "                      #yaxis=dict(scaleanchor=\"x\", scaleratio=1/len(top_node_edges_df)),\n",
    "                      #title_text=\"Inputs to Node\",\n",
    "                      #xaxis=dict(visible=False),\n",
    "                      #yaxis=dict(visible=False),\n",
    "                      coloraxis_showscale=False,\n",
    "                      coloraxis2 = dict(showscale=False,\n",
    "                                        colorscale='inferno',\n",
    "                                        colorbar = dict(\n",
    "                                                        thicknessmode = \"fraction\",thickness=.05, \n",
    "                                                        lenmode='fraction',len=.7)),\n",
    "                      margin=dict(\n",
    "                                    l=0,\n",
    "                                    r=0,\n",
    "                                    b=0,\n",
    "                                    t=0,\n",
    "                                    pad=0)\n",
    "                     )\n",
    "    fig.update_coloraxes(colorscale='inferno',colorbar = dict(\n",
    "                                                              thicknessmode = \"fraction\",thickness=.05, \n",
    "                                                              lenmode='fraction',len=.7)\n",
    "                        )\n",
    "#     fig.update_coloraxes2(colorscale='inferno',colorbar = dict(\n",
    "#                                                               thicknessmode = \"fraction\",thickness=.05, \n",
    "#                                                               lenmode='fraction',len=.7)\n",
    "#                        )\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#image graph\n",
    "@app.callback(\n",
    "    Output('img-actmap-graph', 'figure'),\n",
    "    [Input('dynamic-input-image-dropdown', 'value'),\n",
    "     Input('node-actmap-graph','clickData'),\n",
    "     Input('node-actmap-graph','figure')],\n",
    "    [State('img-actmap-graph', 'figure'),\n",
    "     State('node-actmap-dropdown', 'value')])\n",
    "def update_inputimg_actmap(image_name,click_data,node_actmap_fig,image_fig,nodeid): \n",
    "    print('CALLED: update_inputimg_actmap')\n",
    "    #if os.path.exists(params['input_image_directory']+image_name):\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        raise Exception('no figure updates yet')\n",
    "    else:\n",
    "        trigger = ctx.triggered[0]['prop_id']\n",
    "    if trigger == 'dynamic-input-image-dropdown.value':\n",
    "        return image2plot(get_image_path(image_name,params)[1],input_image_layout)\n",
    "    elif receptive_fields is None:\n",
    "        return image2plot(get_image_path(image_name,params)[1],input_image_layout)\n",
    "    elif click_data is None:\n",
    "        return image2plot(get_image_path(image_name,params)[1],input_image_layout)\n",
    "    else:\n",
    "        #nodeid = node_actmap_fig['data'][0]['name']\n",
    "        layer_name = nodeid_2_perlayerid(nodeid,params)[2]\n",
    "        if layer_name == 'img':\n",
    "            raise Exception('no receptive fields for input image actmap')\n",
    "        heatmap_dim_y = len(node_actmap_fig['data'][0]['z'])\n",
    "        heatmap_dim_x = len(node_actmap_fig['data'][0]['z'][0]) \n",
    "        x_click = click_data['points'][0]['x']\n",
    "        y_click = heatmap_dim_y - click_data['points'][0]['y']-1\n",
    "        print('x_click')\n",
    "        print(x_click)\n",
    "        print('y_click')\n",
    "        print(y_click)\n",
    "        recep_field = receptive_field_for_unit(receptive_fields, layer_name, (x_click,y_click))\n",
    "        recep_field_normed = [[recep_field[0][0]*10/input_image_size,recep_field[0][1]*10/input_image_size],\n",
    "                              [recep_field[1][0]*10/input_image_size,recep_field[1][1]*10/input_image_size]]\n",
    "        print('normalized')\n",
    "        print(recep_field_normed)\n",
    "        x_points = [recep_field_normed[0][0],recep_field_normed[0][0],recep_field_normed[0][1],recep_field_normed[0][1],recep_field_normed[0][0]]\n",
    "        y_points = [10 - recep_field_normed[1][0],10 - recep_field_normed[1][1],10 - recep_field_normed[1][1],10 - recep_field_normed[1][0],10 - recep_field_normed[1][0]]\n",
    "        print('x points')\n",
    "        print(x_points)\n",
    "        print('y points')\n",
    "        print(y_points)\n",
    "        image_fig['data'] = [{'mode': 'lines', 'x': x_points, 'y': y_points, 'type': 'scatter'}]\n",
    "        return image_fig\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #else:\n",
    "        #return image2plot(params['prepped_model_path']+'/visualizations/'+image_name,input_image_layout)\n",
    "    \n",
    "# #image dropdown\n",
    "# @app.callback(\n",
    "#     Output('input-image-dropdown', 'options'),\n",
    "#     [Input('node-deepviz-image', 'figure'),\n",
    "#      Input('edge-deepviz-image', 'figure')])\n",
    "# def update_inputimg_dropdown(node_fig,edge_fig): \n",
    "#     print('CALLED: update_inputimg_dropdown options')\n",
    "#     return [{'label': i, 'value': i} for i in params['input_image_list']+os.listdir(params['prepped_model_path']+'/visualizations/images/')]\n",
    "\n",
    "#dynamic dropdown\n",
    "@app.callback(\n",
    "    dash.dependencies.Output(\"dynamic-input-image-dropdown\", \"options\"),\n",
    "    [dash.dependencies.Input(\"dynamic-input-image-dropdown\", \"search_value\")],\n",
    ")\n",
    "def update_options(search_value):\n",
    "    if not search_value:\n",
    "        raise PreventUpdate\n",
    "    return [{'label': i, 'value': i} for i in params['input_image_list']+os.listdir(params['prepped_model_path']+'/visualizations/images/') if search_value in i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#kernel\n",
    "@app.callback(\n",
    "    Output('edge-kernel-graph', 'figure'),\n",
    "    [Input('edge-actmaps-input','value')],\n",
    "    [State('edge-kernel-graph','figure')])\n",
    "def update_edge_kernelmap(edge_name,figure):\n",
    "    print('CALLED: update_edge_kernelmap')\n",
    "    kernel,inmap,outmap = edgename_2_edge_figures(edge_name, None, kernels, None,params)\n",
    "    if kernel is not None:\n",
    "        return go.Figure(data=go.Heatmap(z = kernel,\n",
    "                                         #zmin=-.5,\n",
    "                                         #zmax=.5,\n",
    "                                         colorbar = dict(thicknessmode = \"fraction\",thickness=.1)),\n",
    "                         layout=kernel_layout)\n",
    "    else:\n",
    "        return figure\n",
    "                \n",
    "\n",
    "#edge in        \n",
    "@app.callback(\n",
    "    Output('edge-inmap-graph', 'figure'),\n",
    "    [Input('edge-actmaps-input','value'),\n",
    "     Input('input-image-signal', 'children')],\n",
    "    [State('edge-inmap-graph','figure'),\n",
    "     State('ablations-signal', 'children')])\n",
    "def update_edge_inmap(edge_name,image_name,figure,ablation_list):\n",
    "    print('CALLED: update_edge_inmap')\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations = activations_store(image_name, ablation_list)\n",
    "        \n",
    "    kernel,inmap,outmap = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)\n",
    "    if inmap is not None:\n",
    "        return go.Figure(data=go.Heatmap(z = inmap,\n",
    "                                         #zmin=-2,zmax=2,\n",
    "                                         colorbar = dict(thicknessmode = \"fraction\",thickness=.1)\n",
    "                                        ),\n",
    "                         layout=edge_inmap_layout)\n",
    "    else:\n",
    "        print('edge inmap error')\n",
    "        return figure\n",
    "\n",
    "@app.callback(\n",
    "    Output('edgein-sum', 'children'),\n",
    "    [Input('edge-inmap-graph', 'figure')])\n",
    "def update_node_sum(fig):\n",
    "    mean = np.mean(fig['data'][0]['z'])\n",
    "    return 'mean: %s'%str(mean)    \n",
    "\n",
    "#edge out\n",
    "@app.callback(\n",
    "    Output('edge-outmap-graph', 'figure'),\n",
    "    [Input('edge-actmaps-input','value'),\n",
    "     Input('input-image-signal', 'children')],\n",
    "    [State('edge-outmap-graph','figure'),\n",
    "     State('ablations-signal', 'children')])\n",
    "def update_edge_outmap(edge_name,image_name,figure, ablation_list):\n",
    "    print('CALLED: update_edge_outmap')\n",
    "    #fetch activations\n",
    "    if image_name in all_activations['nodes'] and ablation_list == []:\n",
    "        activations = all_activations\n",
    "    else:\n",
    "        activations = activations_store(image_name,ablation_list)\n",
    "        \n",
    "    kernel,inmap,outmap = edgename_2_edge_figures(edge_name, image_name, kernels, activations,params)\n",
    "    if outmap is not None:\n",
    "        return go.Figure(data=go.Heatmap(z = outmap,\n",
    "                                         #zmin=-11,\n",
    "                                         #zmax=14,\n",
    "                                         colorbar = dict(thicknessmode = \"fraction\",thickness=.1)\n",
    "                                        ),\n",
    "                         layout=edge_outmap_layout)\n",
    "    else:\n",
    "        print('edge outmap error')\n",
    "        return figure\n",
    "        \n",
    "@app.callback(\n",
    "    Output('edgeout-sum', 'children'),\n",
    "    [Input('edge-outmap-graph', 'figure')])\n",
    "def update_node_sum(fig):\n",
    "    mean = np.mean(fig['data'][0]['z'])\n",
    "    return 'mean: %s'%str(mean)\n",
    "\n",
    "\n",
    " \n",
    "#feature viz graph\n",
    "@app.callback(\n",
    "    Output('featviz-image', 'figure'),\n",
    "    [Input('featviz-button','n_clicks')],\n",
    "    [State('featviz-nodeedge-toggle', 'value'),\n",
    "     State('featviz-channelneuron-toggle', 'value'),\n",
    "     State('node-actmap-dropdown','value'),\n",
    "     State('edge-actmaps-input','value')],\n",
    "    prevent_initial_call=True)\n",
    "def update_featviz_image(n_clicks,edge,neuron,nodeid,edgeid):       #EDIT: needs support for black and white images\n",
    "    print('CALLED: update_featviz')\n",
    "    if edge:\n",
    "        image_name = regen_visualization(model_dis,edgeid,neuron,params)\n",
    "    else:\n",
    "        layer,within_layer_id,layer_name = nodeid_2_perlayerid(nodeid,params)    \n",
    "        if layer == 'img': \n",
    "            return figure_init\n",
    "        image_name = regen_visualization(model_dis,nodeid,neuron,params)\n",
    "        \n",
    "    image_path = params['prepped_model_path']+'/visualizations/images/'+image_name\n",
    "    return image2plot(image_path,input_image_layout)\n",
    "\n",
    "\n",
    "# #JSON INFO\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('hover-data', 'children'),\n",
    "#     [Input('node-actmap-graph', 'hoverData')])\n",
    "# def display_hover_data(hoverData):\n",
    "#     return json.dumps(hoverData, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('click-data', 'children'),\n",
    "#     [Input('network-graph', 'clickData')])\n",
    "# def display_click_data(clickData):\n",
    "#     return json.dumps(clickData, indent=2)\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('selected-data', 'children'),\n",
    "#     [Input('network-graph', 'selectedData')])\n",
    "# def display_selected_data(selectedData):\n",
    "#     return json.dumps(selectedData, indent=2)\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('figure-data', 'children'),\n",
    "#     [Input('input-category', 'value'),\n",
    "#      Input('network-graph', 'clickData'),\n",
    "#      Input('edge-thresh-slider','value'),\n",
    "#      Input('memory','data')])\n",
    "# def display_trigger(target_category,clickData,edge_thresh,state):\n",
    "#     ctx = dash.callback_context\n",
    "#     if not ctx.triggered:\n",
    "#         raise Exception('no figure updates yet')\n",
    "#     else:\n",
    "#         trigger = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "#     ctx_msg = json.dumps({\n",
    "#         'states': ctx.states,\n",
    "#         'triggered': ctx.triggered,\n",
    "#         'inputs': ctx.inputs,\n",
    "#         'full_state':state\n",
    "#     }, indent=2)\n",
    "#     return ctx_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8051/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:13] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:13] \"\u001b[37mGET /_dash-component-suites/dash_renderer/polyfill@7.v1_6_0m1596203731.8.7.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_renderer/react@16.v1_6_0m1596203731.13.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_html_components/dash_html_components.v1_0_3m1585840840.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_daq/dash_daq.v0_5_0m1614143217.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_renderer/react-dom@16.v1_6_0m1596203731.13.0.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components.v1_10_2m1596203744.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_renderer/prop-types@15.v1_6_0m1596203731.7.2.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_core_components/dash_core_components-shared.v1_10_2m1596203744.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-component-suites/dash_renderer/dash_renderer.v1_6_0m1596203731.min.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:14] \"\u001b[37mGET /_favicon.ico?v=1.14.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:16] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:17] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:17] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\" in ablation list is not a node/edge\n",
      "Updating cached activations with Afghan_hound_10.JPEG\n",
      "running model to fetch activations\n",
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with overall\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 580, in update_activations_store\n",
      "    activations_store(image_name,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 911, in get_model_activations_from_image\n",
      "    output = model_dis(image)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torchvision/models/alexnet.py\", line 45, in forward\n",
      "    x = self.features(x)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prep_model_scripts/dissected_Conv2d.py\", line 269, in forward\n",
      "    preadd_out = self.preadd_conv(x)  #get output of convolutions\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 423, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 420, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: Assertion `THCTensor_(checkGPU)(state, 3, input, output, weight)' failed. Some of weight/gradient/input tensors are located on different GPUs. Please move them to a single one. at /pytorch/aten/src/THCUNN/generic/SpatialDepthwiseConvolution.cu:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:30] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: switch_edge_actmaps_click\n",
      "CALLED: switch_node_actmap_click\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:32] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM RANKS DF STORE\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.217977   \n",
      "1              1   features_0      0            0           1  1.793965   \n",
      "2              2   features_0      0            0           2  0.604349   \n",
      "3              3   features_0      0            1           0  0.479389   \n",
      "4              4   features_0      0            1           1  1.453592   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.089054   \n",
      "250044    250044  features_10      4          255         252  0.062168   \n",
      "250045    250045  features_10      4          255         253  0.000005   \n",
      "250046    250046  features_10      4          255         254  0.053664   \n",
      "250047    250047  features_10      4          255         255  0.000042   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000014   2.927448e-05  \n",
      "1        0.000014   4.915277e-05  \n",
      "2        0.000014   1.576725e-05  \n",
      "3        0.000016   7.772094e-06  \n",
      "4        0.000016   3.509826e-05  \n",
      "...           ...            ...  \n",
      "250043   0.000021   1.617071e-06  \n",
      "250044   0.000021   1.465305e-06  \n",
      "250045   0.000021   1.104610e-10  \n",
      "250046   0.000021   1.507973e-06  \n",
      "250047   0.000021   1.115119e-09  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "CALLED: update_edge_inmap\n",
      "Updating cached activations with None\n",
      "running model to fetch activations\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 1175, in update_edge_inmap\n",
      "    activations = activations_store(image_name, ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 908, in get_model_activations_from_image\n",
      "    image = preprocess_image(image_path,params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 310, in preprocess_image\n",
      "    image_name = image_path.split('/')[-1]\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:37] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: update_edge_outmap\n",
      "CALLED: update_edge_deepviz\n",
      "generating feature_viz objective string for g-21\n",
      "Updating cached activations with None\n",
      "CALLED: update_node_actmap\n",
      "CALLED: update_node_deepviz\n",
      "generating feature_viz objective string for 0\n",
      "found pre-generated image\n",
      "CALLED: update_edge_kernelmap\n",
      "found pre-generated image\n",
      "Updating cached activations with None\n",
      "running model to fetch activations\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 863, in update_node_actmap\n",
      "    activations  = activations_store(image_name,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 908, in get_model_activations_from_image\n",
      "    image = preprocess_image(image_path,params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 310, in preprocess_image\n",
      "    image_name = image_path.split('/')[-1]\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:37] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model to fetch activations\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 1208, in update_edge_outmap\n",
      "    activations = activations_store(image_name,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 908, in get_model_activations_from_image\n",
      "    image = preprocess_image(image_path,params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 310, in preprocess_image\n",
      "    image_name = image_path.split('/')[-1]\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:37] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: update_store\n",
      "\n",
      "TRIGGER target-signal.children\n",
      "CALLED: update_node_inputs\n",
      "Updating cached activations with None\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 1192, in update_node_sum\n",
      "    mean = np.mean(fig['data'][0]['z'])\n",
      "KeyError: 'z'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:37] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model to fetch activations\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 939, in update_node_inputs\n",
      "    activations = activations_store(image_name,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 908, in get_model_activations_from_image\n",
      "    image = preprocess_image(image_path,params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 310, in preprocess_image\n",
      "    image_name = image_path.split('/')[-1]\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:37] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing target category to overall\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 1226, in update_node_sum\n",
      "    mean = np.mean(fig['data'][0]['z'])\n",
      "KeyError: 'z'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:38] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 884, in update_node_sum\n",
      "    mean = np.mean(fig['data'][0]['z'])\n",
      "KeyError: 'z'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:38] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:20:40] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: update_figure\n",
      "\n",
      "[0.7, 1]\n",
      "['g-21']\n",
      "['0']\n",
      "building graph from browser \"state\"\n",
      "CALLED: update_inputimg_actmap\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 1079, in update_inputimg_actmap\n",
      "    raise Exception('no figure updates yet')\n",
      "Exception: no figure updates yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:20:50] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:03] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:03] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:03] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:03] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:03] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:05] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 204 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cached activations with tiger_10.JPEG\n",
      "running model to fetch activations\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 580, in update_activations_store\n",
      "    activations_store(image_name,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 911, in get_model_activations_from_image\n",
      "    output = model_dis(image)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torchvision/models/alexnet.py\", line 45, in forward\n",
      "    x = self.features(x)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prep_model_scripts/dissected_Conv2d.py\", line 269, in forward\n",
      "    preadd_out = self.preadd_conv(x)  #get output of convolutions\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 423, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 420, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: Assertion `THCTensor_(checkGPU)(state, 3, input, output, weight)' failed. Some of weight/gradient/input tensors are located on different GPUs. Please move them to a single one. at /pytorch/aten/src/THCUNN/generic/SpatialDepthwiseConvolution.cu:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:21:07] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [26/Apr/2021 17:21:17] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: update_inputimg_actmap\n",
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with t\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 610, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 167, in contrast_str_2_dfs\n",
      "    var_dict, sym_contrast_string = parse_contrast(contrast_string,all_input_images,params['categories'])\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 72, in parse_contrast\n",
      "    raise ValueError(message)\n",
      "ValueError: \"t\" is not a valid weight category, all weight categories must be from image names in the \"input_image\" folder, or folder names under the \"rank_image\" folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:02] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with ti\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 610, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 167, in contrast_str_2_dfs\n",
      "    var_dict, sym_contrast_string = parse_contrast(contrast_string,all_input_images,params['categories'])\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 72, in parse_contrast\n",
      "    raise ValueError(message)\n",
      "ValueError: \"ti\" is not a valid weight category, all weight categories must be from image names in the \"input_image\" folder, or folder names under the \"rank_image\" folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:02] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with tig\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 610, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 167, in contrast_str_2_dfs\n",
      "    var_dict, sym_contrast_string = parse_contrast(contrast_string,all_input_images,params['categories'])\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 72, in parse_contrast\n",
      "    raise ValueError(message)\n",
      "ValueError: \"tig\" is not a valid weight category, all weight categories must be from image names in the \"input_image\" folder, or folder names under the \"rank_image\" folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:02] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with tige\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 610, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 167, in contrast_str_2_dfs\n",
      "    var_dict, sym_contrast_string = parse_contrast(contrast_string,all_input_images,params['categories'])\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/contrast_helper_functions.py\", line 72, in parse_contrast\n",
      "    raise ValueError(message)\n",
      "ValueError: \"tige\" is not a valid weight category, all weight categories must be from image names in the \"input_image\" folder, or folder names under the \"rank_image\" folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:02] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with tiger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:04] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM RANKS DF STORE\n",
      "        edge_num   layer_name  layer  out_channel  in_channel  act_rank  \\\n",
      "0              0   features_0      0            0           0  1.434301   \n",
      "1              1   features_0      0            0           1  2.071391   \n",
      "2              2   features_0      0            0           2  0.610750   \n",
      "3              3   features_0      0            1           0  0.420140   \n",
      "4              4   features_0      0            1           1  1.245248   \n",
      "...          ...          ...    ...          ...         ...       ...   \n",
      "250043    250043  features_10      4          255         251  0.032214   \n",
      "250044    250044  features_10      4          255         252  0.041738   \n",
      "250045    250045  features_10      4          255         253  0.000002   \n",
      "250046    250046  features_10      4          255         254  0.057158   \n",
      "250047    250047  features_10      4          255         255  0.000040   \n",
      "\n",
      "        grad_rank  actxgrad_rank  \n",
      "0        0.000011   2.498242e-05  \n",
      "1        0.000011   4.007856e-05  \n",
      "2        0.000011   1.413675e-05  \n",
      "3        0.000010   3.815513e-06  \n",
      "4        0.000010   2.082237e-05  \n",
      "...           ...            ...  \n",
      "250043   0.000022   5.388548e-07  \n",
      "250044   0.000022   1.512417e-06  \n",
      "250045   0.000022   3.889378e-11  \n",
      "250046   0.000022   1.230155e-06  \n",
      "250047   0.000022   8.918222e-10  \n",
      "\n",
      "[250048 rows x 8 columns]\n",
      "CALLED: update_node_inputs\n",
      "Updating cached activations with None\n",
      "running model to fetch activations\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 939, in update_node_inputs\n",
      "    activations = activations_store(image_name,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 571, in activations_store\n",
      "    activations = get_model_activations_from_image(get_image_path(image_name,params)[1], model_dis, params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 908, in get_model_activations_from_image\n",
      "    image = preprocess_image(image_path,params)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 310, in preprocess_image\n",
      "    image_name = image_path.split('/')[-1]\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:04] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: update_store\n",
      "\n",
      "TRIGGER target-signal.children\n",
      "changing target category to tiger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:04] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLED: update_figure\n",
      "\n",
      "[0.7, 1]\n",
      "['g-21']\n",
      "['0']\n",
      "building graph from browser \"state\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:06] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with tiger\n",
      "running model to get ranks for \"tiger\" on target \"664\"\n",
      "using device cuda:1\n",
      "batch 0\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 605, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 1018, in get_model_ranks_for_category\n",
      "    output = model_dis(batch)    #running forward pass sets up hooks and stores activations in each dissected_Conv2d module\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torchvision/models/alexnet.py\", line 45, in forward\n",
      "    x = self.features(x)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prep_model_scripts/dissected_Conv2d.py\", line 273, in forward\n",
      "    preadd_out.index_fill_(1,self.edge_ablations,0)\n",
      "TypeError: index_fill_() received an invalid combination of arguments - got (int, list, int), but expected one of:\n",
      " * (name dim, Tensor index, Tensor value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (int dim, Tensor index, Tensor value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (name dim, Tensor index, Number value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (int dim, Tensor index, Number value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:16] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with tiger\n",
      "running model to get ranks for \"tiger\" on target \"663\"\n",
      "using device cuda:1\n",
      "batch 0\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 605, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 1018, in get_model_ranks_for_category\n",
      "    output = model_dis(batch)    #running forward pass sets up hooks and stores activations in each dissected_Conv2d module\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torchvision/models/alexnet.py\", line 45, in forward\n",
      "    x = self.features(x)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prep_model_scripts/dissected_Conv2d.py\", line 273, in forward\n",
      "    preadd_out.index_fill_(1,self.edge_ablations,0)\n",
      "TypeError: index_fill_() received an invalid combination of arguments - got (int, list, int), but expected one of:\n",
      " * (name dim, Tensor index, Tensor value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (int dim, Tensor index, Tensor value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (name dim, Tensor index, Number value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (int dim, Tensor index, Number value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:18] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update ranksdf_store triggered\n",
      "Updating cached rank dfs with tiger\n",
      "running model to get ranks for \"tiger\" on target \"766\"\n",
      "using device cuda:1\n",
      "batch 0\n",
      "Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/dash/dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-14-44178776240b>\", line 622, in update_ranksdf_store\n",
      "    ranksdf_store(target_category,target_node,ablation_list)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/flask_caching/__init__.py\", line 779, in decorated_function\n",
      "    rv = f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-44178776240b>\", line 605, in ranksdf_store\n",
      "    target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/visualizer_scripts/visualizer_helper_functions.py\", line 1018, in get_model_ranks_for_category\n",
      "    output = model_dis(batch)    #running forward pass sets up hooks and stores activations in each dissected_Conv2d module\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torchvision/models/alexnet.py\", line 45, in forward\n",
      "    x = self.features(x)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/chris/miniconda3/envs/pruning_viz/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/mnt/data/chris/dropbox/Research-Hamblin/Projects/cnn_subgraph_visualizer/prep_model_scripts/dissected_Conv2d.py\", line 273, in forward\n",
      "    preadd_out.index_fill_(1,self.edge_ablations,0)\n",
      "TypeError: index_fill_() received an invalid combination of arguments - got (int, list, int), but expected one of:\n",
      " * (name dim, Tensor index, Tensor value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (int dim, Tensor index, Tensor value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (name dim, Tensor index, Number value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      " * (int dim, Tensor index, Number value)\n",
      "      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2021 17:22:48] \"\u001b[35m\u001b[1mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "app.run_server(port=8051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df,e_df=ranksdf_store('tiger', '644', [],model_dis=model_dis)\n",
    "n_df = minmax_normalize_ranks_df(n_df,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lucent_edited.optvis import render\n",
    "from lucent_edited.modelzoo import inceptionv1\n",
    "from lucent_edited.modelzoo.util import get_model_layers\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeid_2_perlayerid(644,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['layer_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dis = set_across_model(model_dis,'target_node',None)\n",
    "model.to('cuda')\n",
    "start =time.time()\n",
    "\n",
    "param_f = lambda: param.image(224,batch=1)\n",
    "obj = objectives.neuron(\"features_0\", 0, batch=0)\n",
    "        #objectives.neuron(\"features_0\", 2, batch=2) - objectives.neuron(\"features_0\", 3, batch=3)\n",
    "        #objectives.channel(\"features_0\", 4, batch=4) + objectives.neuron(\"features_0\", 5, batch=5) \n",
    "        #objectives.neuron(\"features_0\", 6, batch=6) - objectives.neuron(\"features_0\", 7, batch=7) \n",
    "    \n",
    "\n",
    "_ = render.render_vis(model_dis, obj, param_f, verbose=True, show_inline=True, save_image=True,image_name = 'prepped_models/alexnet_sparse/visualizations/testing/test1.jpg')\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('prepped_models/alexnet_sparse/visualizations/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['device'] = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dis.to('cuda:1')\n",
    "subgraph_sizes={}\n",
    "start = time.time()\n",
    "for node in range(256,1151):\n",
    "    n_df,e_df=ranksdf_store('small_SPAN', str(node), [],model_dis=model_dis)\n",
    "    n_df = minmax_normalize_ranks_df(n_df,params)\n",
    "    threshed_n_df,threshed_e_df = hierarchical_accum_threshold(.9,.9,rank_type,e_df,n_df)\n",
    "    subgraph_sizes[node] = (len(threshed_n_df),len(threshed_e_df))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('prepped_models/alexnet_sparse/subgraphs')\n",
    "os.mkdir('prepped_models/alexnet_sparse/subgraphs/info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dis.features[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subgraph_sizes = pickle.load(open('prepped_models/alexnet_sparse/subgraphs/info/subgraph_sizes_.9.9.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sizes = []\n",
    "edge_sizes = []\n",
    "for node in subgraph_sizes:\n",
    "    node_sizes.append(subgraph_sizes[node][0])\n",
    "    edge_sizes.append(subgraph_sizes[node][1])\n",
    "    \n",
    "print(max(edge_sizes))\n",
    "print(max(node_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(threshed_n_df.loc[threshed_n_df['layer']==3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_ hierarchical_accum_threshold(target_category,target_node,model_dis):\n",
    "    ablation_list = []\n",
    "    model_dis = clear_ranks_across_model(model_dis)\n",
    "    target_type = image_category_or_contrast(target_category,params)\n",
    "    target_category_nodes_df = None\n",
    "    target_category_edges_df = None\n",
    "    if target_type == 'category' and target_node == 'loss' and ablation_list == []:\n",
    "        #edges\n",
    "        if categories_edges_df is not None:\n",
    "            if len(categories_edges_df.loc[categories_edges_df['category']==target_category]) > 0:\n",
    "                target_category_edges_df = categories_edges_df.loc[categories_edges_df['category']==target_category]\n",
    "        if target_category_edges_df is None:\n",
    "            target_category_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','%s_edges_rank.pt'%target_category))   \n",
    "        #node\n",
    "        if categories_nodes_df is not None:\n",
    "            if len(categories_nodes_df.loc[categories_nodes_df['category']==target_category]) > 0:\n",
    "                target_category_nodes_df = categories_nodes_df.loc[categories_nodes_df['category']==target_category]\n",
    "        if target_category_nodes_df is None:\n",
    "            target_category_nodes_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_nodes','%s_nodes_rank.pt'%target_category))\n",
    "    elif target_type == 'category':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
    "    elif target_type == 'input_image':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_from_image(get_image_path(target_category,params)[1],target_node, model_dis, params))\n",
    "\n",
    "    else:  #contrast\n",
    "        target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
    "    print('FROM RANKS DF STORE')\n",
    "    print(target_category_edges_df)\n",
    "    return target_category_nodes_df,target_category_edges_df    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ranksdf_store(target_category, target_node,ablation_list,model_dis=model_dis):\n",
    "    print('Updating cached rank dfs with {}'.format(target_category))\n",
    "    model_dis = clear_ranks_across_model(model_dis)\n",
    "    target_type = image_category_or_contrast(target_category,params)\n",
    "    target_category_nodes_df = None\n",
    "    target_category_edges_df = None\n",
    "    if target_type == 'category' and target_node == 'loss' and ablation_list == []:\n",
    "        #edges\n",
    "        if categories_edges_df is not None:\n",
    "            if len(categories_edges_df.loc[categories_edges_df['category']==target_category]) > 0:\n",
    "                target_category_edges_df = categories_edges_df.loc[categories_edges_df['category']==target_category]\n",
    "        if target_category_edges_df is None:\n",
    "            target_category_edges_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_edges','%s_edges_rank.pt'%target_category))   \n",
    "        #node\n",
    "        if categories_nodes_df is not None:\n",
    "            if len(categories_nodes_df.loc[categories_nodes_df['category']==target_category]) > 0:\n",
    "                target_category_nodes_df = categories_nodes_df.loc[categories_nodes_df['category']==target_category]\n",
    "        if target_category_nodes_df is None:\n",
    "            target_category_nodes_df = rank_file_2_df(os.path.join(params['ranks_data_path'],'categories_nodes','%s_nodes_rank.pt'%target_category))\n",
    "    elif target_type == 'category':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_for_category(target_category, target_node, model_dis,params))\n",
    "    elif target_type == 'input_image':\n",
    "        target_category_nodes_df,target_category_edges_df = rank_dict_2_df(get_model_ranks_from_image(get_image_path(target_category,params)[1],target_node, model_dis, params))\n",
    "\n",
    "    else:  #contrast\n",
    "        target_category_nodes_df,target_category_edges_df = contrast_str_2_dfs(target_category,target_node,model_dis,params,ablation_list)\n",
    "    print('FROM RANKS DF STORE')\n",
    "    print(target_category_edges_df)\n",
    "    return target_category_nodes_df,target_category_edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "x = torch.rand([2,3,4,4])\n",
    "print(x.shape)\n",
    "#index = torch.tensor([]).type(torch.LongTensor)\n",
    "#x.index_fill_(1, index, -1)\n",
    "#x[:,:,:,:]\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subgraph(name,model,thresholded_nodes_df,thresholded_egdes_df,params, save=True):\n",
    "    #this is currently hacky only works on models with all nn.sequential or .features module\n",
    "    model.to('cpu')\n",
    "    l = 0\n",
    "    subgraph_model = nn.Sequential()\n",
    "    \n",
    "    #hack\n",
    "    for layer in model.children():\n",
    "        if not isinstance(layer, nn.Conv2d):\n",
    "            model = model.features\n",
    "            break\n",
    "        break\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        for layer in model.children():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                name = 'conv_{}'.format(l)\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                name = 'relu_{}'.format(l)\n",
    "                layer = nn.ReLU(inplace=False)\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                name = 'pool_{}'.format(l)\n",
    "            elif isinstance(layer, nn.BatchNorm2d):\n",
    "                name = 'bn_{}'.format(l)\n",
    "            else:\n",
    "                raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "            if not isinstance(layer, nn.Conv2d):\n",
    "                subgraph_model.add_module(name, layer)\n",
    "            else:\n",
    "                print('layer: %s'%str(l))\n",
    "                old_conv = layer\n",
    "                out_channels = list(thresholded_nodes_df.loc[thresholded_nodes_df['layer'] == l]['node_num_by_layer'].sort_values().unique())\n",
    "                num_out_channels = len(out_channels)\n",
    "                if l == 0:\n",
    "                    num_in_channels = old_conv.in_channels\n",
    "                    in_channels = list(range(num_in_channels))\n",
    "                else:\n",
    "                    in_channels = list(thresholded_nodes_df.loc[thresholded_nodes_df['layer'] == l-1]['node_num_by_layer'].sort_values().unique())\n",
    "                    num_in_channels = len(in_channels)\n",
    "                new_conv = \\\n",
    "                        torch.nn.Conv2d(in_channels = num_in_channels, \\\n",
    "                        out_channels = num_out_channels ,\n",
    "                        kernel_size = old_conv.kernel_size, \\\n",
    "                        stride = old_conv.stride,\n",
    "                        padding = old_conv.padding,\n",
    "                        dilation = old_conv.dilation,\n",
    "                        groups = old_conv.groups,\n",
    "                        bias = (old_conv.bias is not None))                \n",
    "            \n",
    "                #full_weights = []\n",
    "                #GENERATE WEIGHT MATRIX\n",
    "                weights = new_conv.weight\n",
    "                weights.fill_(0.)\n",
    "                print(out_channels)\n",
    "                print(len(out_channels))\n",
    "                for o_i,o in enumerate(out_channels):\n",
    "                    for i_i,row in enumerate(thresholded_egdes_df.loc[(thresholded_egdes_df['layer'] == l) & (thresholded_egdes_df['out_channel'] == o)].sort_values('in_channel').itertuples()):\n",
    "                        weights[o_i,in_channels.index(row.in_channel),:,:] = old_conv.weight[o,row.in_channel,:,:]\n",
    "                #for node in thresholded_nodes_df.loc[thresholded_nodes_df['layer'] == l].sort_values('node_num_by_layer')['node_num_by_layer']:\n",
    "                    #print(node)\n",
    "                    #ws.append(weights[node,:,:,:].unsqueeze(0))\n",
    "                \n",
    "                #GENERATE BIAS \n",
    "                if new_conv.bias is not None:\n",
    "                    for o_i,o in enumerate(out_channels):\n",
    "                        new_conv.bias[o_i] = old_conv.bias[o]\n",
    "                \n",
    "                \n",
    "                subgraph_model.add_module(name, new_conv)\n",
    "                #next layer\n",
    "                l += 1\n",
    "\n",
    "            if l not in thresholded_nodes_df['layer'].unique():\n",
    "                break\n",
    "\n",
    "        \n",
    "            \n",
    "    return subgraph_model\n",
    "\n",
    "sub_model = extract_subgraph('',model,threshed_n_df,threshed_e_df,params)\n",
    "\n",
    "\n",
    "# def extract_subgraph_recurse(module,thresholded_nodes_df,thresholded_egdes_df):\n",
    "#     conv_count = 0\n",
    "# \tfor layer, (name, submodule) in enumerate(module._modules.items()):\n",
    "# \t\t#print(submodule)\n",
    "# \t\tif isinstance(submodule, torch.nn.modules.conv.Conv2d):\n",
    "\n",
    "\n",
    "# \t\t\tfor rank_type in rank_types:\n",
    "# \t\t\t\t#submodule.gen_normalizations(rank_type)\n",
    "# \t\t\t\tlayer_ranks['nodes'][rank_type].append([submodule.name,submodule.postbias_ranks[rank_type].cpu().detach().numpy()])\n",
    "# \t\t\t\tlayer_ranks['edges'][rank_type].append([submodule.name,submodule.format_edges(data= 'ranks',rank_type=rank_type,weight_rank=weight_rank)])\n",
    "# \t\t\t\t#print(layer_ranks['edges'][-1].shape)\n",
    "# \t\telif len(list(submodule.children())) > 0:\n",
    "# \t\t\tlayer_ranks = get_ranks_from_dissected_Conv2d_modules(submodule,layer_ranks=layer_ranks,weight_rank=weight_rank)   #module has modules inside it, so recurse on this module\n",
    "# \treturn layer_ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model.to('cuda')\n",
    "\n",
    "param_f = lambda: param.image(224,batch=4)\n",
    "obj =  objectives.channel(\"conv_3\", 0, batch=0) + objectives.channel(\"conv_3\", 0, batch=1) + \\\n",
    "      objectives.neuron(\"conv_3\", 0, batch=3) + objectives.neuron(\"conv_3\", 0, batch=4)\n",
    "\n",
    "_ = render.render_vis(sub_model, obj, param_f, verbose=True, show_inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dis = set_across_model(model_dis,'target_node',None)\n",
    "\n",
    "param_f = lambda: param.image(224,batch=4)\n",
    "obj = objectives.neuron(\"features_6\", 0, batch=0) + objectives.neuron(\"features_6\", 0, batch=1) + \\\n",
    "      objectives.neuron(\"features_6\", 0, batch=2) + objectives.neuron(\"features_6\", 0, batch=3)\n",
    "\n",
    "_ = render.render_vis(model_dis, obj, param_f, verbose=True, show_inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(sub_model[6].weight[0,2,:,:])\n",
    "print(model.features[6].weight[4,7,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [2,4,6,8]\n",
    "l.index(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sub_model[0].bias[3])\n",
    "print(model.features[0].bias[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outchannels = threshed_e_df.loc[(threshed_e_df['layer'] == 1)]['out_channel'].sort_values().unique()\n",
    "outchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshed_n_df.loc[threshed_n_df['layer'] == 0].sort_values('node_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for row in threshed_e_df.loc[threshed_e_df['layer'] == i].itertuples():\n",
    "    print(row)\n",
    "    print(model.features[0].weight[row.out_channel,row.in_channel,:,:])\n",
    "    sub_model[i].weight[row.out_channel,row.in_channel,:,:] = model.features[0].weight[row.out_channel,row.in_channel,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [sub_model[i].weight[5,:,:,:].unsqueeze(0),sub_model[i].weight[5,:,:,:].unsqueeze(0)]\n",
    "w = torch.cat(weights)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features[0].bias[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in model.children():\n",
    "    print(layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     if isinstance(layer, nn.Conv2d):\n",
    "#         i += 1\n",
    "#         name = 'conv_{}'.format(i)\n",
    "#     elif isinstance(layer, nn.ReLU):\n",
    "#         name = 'relu_{}'.format(i)\n",
    "#         # The in-place version doesn't play very nicely with the ContentLoss\n",
    "#         # and StyleLoss we insert below. So we replace with out-of-place\n",
    "#         # ones here.\n",
    "#         layer = nn.ReLU(inplace=False)\n",
    "#     elif isinstance(layer, nn.MaxPool2d):\n",
    "#         name = 'pool_{}'.format(i)\n",
    "#     elif isinstance(layer, nn.BatchNorm2d):\n",
    "#         name = 'bn_{}'.format(i)\n",
    "#     else:\n",
    "#         raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "\n",
    "#     model.add_module(name, layer)\n",
    "\n",
    "#     if name in content_layers:\n",
    "#         # add content loss:\n",
    "#         target = model(content_img).detach()\n",
    "#         content_loss = ContentLoss(target)\n",
    "#         model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "#         content_losses.append(content_loss)\n",
    "\n",
    "#     if name in style_layers:\n",
    "#         # add style loss:\n",
    "#         target_feature = model(style_img).detach()\n",
    "#         style_loss = StyleLoss(target_feature)\n",
    "#         model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "#         style_losses.append(style_loss)\n",
    "\n",
    "# # now we trim off the layers after the last content and style losses\n",
    "# for i in range(len(model) - 1, -1, -1):\n",
    "#     if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "#         break\n",
    "\n",
    "# model = model[:(i + 1)]\n",
    "\n",
    "# return model, style_losses, content_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_min = {}\n",
    "for layer in n_df['layer'].unique():\n",
    "    if len(nodes_thresholded_df.loc[nodes_thresholded_df['layer']==layer]) > 1:\n",
    "        node_min[layer] = nodes_thresholded_df.loc[nodes_thresholded_df['layer']==layer][rank_type+'_rank'].min()\n",
    "    else:\n",
    "        node_min[layer] = None\n",
    "\n",
    "node_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df.loc[n_df['layer'] == 4]['actxgrad_rank'].sum()\n",
    "n_df['layer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_thresholded_ranksdf(threshold,rank_type,df):          #just get those edges that pass the threshold criteria for the target category\n",
    "\tif len(threshold) != 2:\n",
    "\t\traise Exception('length of threshold needs to be two ([lower, higher])')\n",
    "\treturn df.loc[(df[rank_type+'_rank'] >= threshold[0]) & (df[rank_type+'_rank'] <= threshold[1])]\n",
    "\n",
    "\n",
    "def filter_edges_by_nodes(edges_df,thresholded_nodes_df):\n",
    "    valid_nodes = {}\n",
    "    node_time= time.time()\n",
    "    for row in thresholded_nodes_df.itertuples():\n",
    "        if row.layer not in valid_nodes.keys():\n",
    "            valid_nodes[row.layer] = [row.node_num_by_layer]\n",
    "        else:\n",
    "            valid_nodes[row.layer].append(row.node_num_by_layer)\n",
    "\n",
    "    print(time.time()-node_time)\n",
    "    def filter_edges_fn(row):\n",
    "        try: \n",
    "            if (row['out_channel'] in valid_nodes[row['layer']]): #try block because maybe no valid nodes in row['layer']\n",
    "                if row['layer'] == 0:\n",
    "                    return True\n",
    "                elif row['in_channel'] in valid_nodes[row['layer']-1]:\n",
    "                    return True\n",
    "        except:\n",
    "            return False\n",
    "        return False\n",
    "    edge_time = time.time()\n",
    "    #mask = edges_df.apply(filter_edges_fn, axis=1)\n",
    "    df_out = pd.DataFrame(columns = edges_df.columns)\n",
    "    entries = []\n",
    "for i in search_keys:\n",
    "    entry = df.loc[edges_df['out_channel'] in ]\n",
    "    entries.append(entry)\n",
    "\n",
    "found_df = pd.concat(entries)\n",
    "result_df = pd.concat([old_df, found_df])\n",
    "    print(time.time()-edge_time)\n",
    "    return edges_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_n_df = get_thresholded_ranksdf((.3,1),'actxgrad',n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thresholded_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_e_df = filter_edges_by_nodes(e_df,thresholded_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filter_e_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_e_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = filter_e_df.loc[filter_e_df['act_rank'] > .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e_df)/(len(thresholded_n_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_nodes = {}\n",
    "node_time= time.time()\n",
    "for row in thresholded_n_df.itertuples():\n",
    "    if row.layer not in valid_nodes.keys():\n",
    "        valid_nodes[row.layer] = [row.node_num_by_layer]\n",
    "    else:\n",
    "        valid_nodes[row.layer].append(row.node_num_by_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = e_df.loc[e_df['out_channel'] in valid_nodes[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "filtered_df = pd.DataFrame(columns = e_df.columns)\n",
    "entries = []\n",
    "for i in valid_nodes:\n",
    "    entry = e_df.loc[(e_df['out_channel'].isin(valid_nodes[i])) & (e_df['layer'] == i)]\n",
    "    if i != 0:\n",
    "         entry =  entry.loc[entry['in_channel'].isin(valid_nodes[i-1])]\n",
    "    entries.append(entry)\n",
    "\n",
    "found_df = pd.concat(entries)\n",
    "filtered_df = pd.concat([filtered_df, found_df])\n",
    "print(time.time()-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchically_threshold_edges(threshold,rank_type,edges_df,thresholded_nodes_df):          #just get those edges that pass the threshold criteria for the target category\n",
    "    if len(threshold) != 2:\n",
    "        raise Exception('length of threshold needs to be two ([lower, higher])')\n",
    "        \n",
    "    valid_nodes = {}\n",
    "    for row in thresholded_nodes_df.itertuples():\n",
    "        if row.layer not in valid_nodes.keys():\n",
    "            valid_nodes[row.layer] = [row.node_num_by_layer]\n",
    "        else:\n",
    "            valid_nodes[row.layer].append(row.node_num_by_layer)\n",
    "\n",
    "    \n",
    "    filtered_df = pd.DataFrame(columns = edges_df.columns)\n",
    "    \n",
    "    layers_edges = []\n",
    "    for layer in valid_nodes:\n",
    "        layer_edges = edges_df.loc[(edges_df['out_channel'].isin(valid_nodes[layer])) & (edges_df['layer'] == layer)]\n",
    "        if layer != 0:\n",
    "            layer_edges =  layer_edges.loc[layer_edges['in_channel'].isin(valid_nodes[layer-1])]\n",
    "            \n",
    "        nodes_edges = []\n",
    "        for node in valid_nodes[layer]:\n",
    "            node_edges = layer_edges.loc[layer_edges['out_channel']== node]\n",
    "            minmax = [node_edges[rank_type+'_rank'].min(),node_edges[rank_type+'_rank'].max()]\n",
    "            minmax_t = [threshold[0]*(minmax[1]-minmax[0])+minmax[0],threshold[1]*(minmax[1]-minmax[0])+minmax[0]]\n",
    "            node_edges = node_edges.loc[(node_edges[rank_type+'_rank'] >= minmax_t[0]) & (node_edges[rank_type+'_rank'] <= minmax_t[1])]\n",
    "            nodes_edges.append(node_edges)\n",
    "                                         \n",
    "        layer_edges= pd.concat(nodes_edges)                               \n",
    "        layers_edges.append(layer_edges)\n",
    "\n",
    "    found_df = pd.concat(layers_edges)\n",
    "    filtered_df = pd.concat([filtered_df, found_df])     \n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold  = [.4,1.0]\n",
    "threshed_e_df = hierarchically_threshold_edges(threshold,'actxgrad',e_df,thresholded_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = n_df.loc[n_df['layer'] == 2][rank_type+'_rank']\n",
    "thresh=.99\n",
    "\n",
    "start = time.time()\n",
    "total_imp = series.sum()\n",
    "total_imp\n",
    "print(time.time()-start)\n",
    "start = time.time()\n",
    "s= series.sort_values(ascending=False)\n",
    "print(time.time()-start)\n",
    "print(len(s))\n",
    "\n",
    "start = time.time()\n",
    "x = n_df.loc[(n_df['layer'] == 2) & n_df[rank_type+'_rank'] > .8]\n",
    "print(time.time()-start)\n",
    "\n",
    "start = time.time()\n",
    "running_tot = 0\n",
    "for i in s.index:\n",
    "    running_tot+=s[i]\n",
    "    if running_tot/total_imp >= thresh:\n",
    "        break\n",
    "print(time.time()-start)\n",
    "    \n",
    "start = time.time()\n",
    "tot = 0\n",
    "\n",
    "layer_df = n_df.loc[n_df['layer'] == 2]\n",
    "layer_df = layer_df.sort_values(rank_type+'_rank',ascending=False)\n",
    "layer_df.iloc[0:4][rank_type+'_rank']\n",
    "\n",
    "len(layer_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_df.iloc[0][rank_type+'_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_thresholded_ranksdf(threshold,rank_type,df):          #just get those edges that pass the threshold criteria for the target category\n",
    "\tif len(threshold) != 2:\n",
    "\t\traise Exception('length of threshold needs to be two ([lower, higher])')\n",
    "\treturn df.loc[(df[rank_type+'_rank'] >= threshold[0]) & (df[rank_type+'_rank'] <= threshold[1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hierarchically_threshold_edges(threshold,rank_type,edges_df,nodes_thresholded_df):          #just get those edges that pass the threshold criteria for the target category\n",
    "\tif len(threshold) != 2:\n",
    "\t\traise Exception('length of threshold needs to be two ([lower, higher])')\n",
    "\t\t\n",
    "\tvalid_nodes = {}\n",
    "\tfor row in nodes_thresholded_df.itertuples():\n",
    "\t\tif row.layer not in valid_nodes.keys():\n",
    "\t\t\tvalid_nodes[row.layer] = [row.node_num_by_layer]\n",
    "\t\telse:\n",
    "\t\t\tvalid_nodes[row.layer].append(row.node_num_by_layer)\n",
    "\n",
    "\t\n",
    "\tfiltered_df = pd.DataFrame(columns = edges_df.columns)\n",
    "\t\n",
    "\tlayers_edges = []\n",
    "\tfor layer in valid_nodes:\n",
    "\t\tlayer_edges = edges_df.loc[(edges_df['out_channel'].isin(valid_nodes[layer])) & (edges_df['layer'] == layer)]\n",
    "\t\tif layer != 0:\n",
    "\t\t\tlayer_edges =  layer_edges.loc[layer_edges['in_channel'].isin(valid_nodes[layer-1])]\n",
    "\t\t\t\n",
    "\t\tnodes_edges = []\n",
    "\t\tfor node in valid_nodes[layer]:\n",
    "\t\t\tnode_edges = layer_edges.loc[layer_edges['out_channel']== node]\n",
    "\t\t\tminmax = [node_edges[rank_type+'_rank'].min(),node_edges[rank_type+'_rank'].max()]\n",
    "\t\t\tminmax_t = [threshold[0]*(minmax[1]-minmax[0])+minmax[0],threshold[1]*(minmax[1]-minmax[0])+minmax[0]]\n",
    "\t\t\tnode_edges = node_edges.loc[(node_edges[rank_type+'_rank'] >= minmax_t[0]) & (node_edges[rank_type+'_rank'] <= minmax_t[1])]\n",
    "\t\t\tnodes_edges.append(node_edges)\n",
    "\t\t\t\t\t\t\t\t\t\t \n",
    "\t\tlayer_edges= pd.concat(nodes_edges)                               \n",
    "\t\tlayers_edges.append(layer_edges)\n",
    "\n",
    "\tfound_df = pd.concat(layers_edges)\n",
    "\tfiltered_df = pd.concat([filtered_df, found_df])     \n",
    "\t\n",
    "\treturn filtered_df\n",
    "\n",
    "\n",
    "def hierarchical_accum_threshold(threshold_node,threshold_edge,rank_type,edges_df,nodes_df,ascending=False):\n",
    "    threshed_nodes_df = get_accum_thresholded_ranksdf(threshold_node,rank_type,nodes_df, ascending=ascending)\n",
    "    \n",
    "    valid_nodes = {}\n",
    "    for row in threshed_nodes_df.itertuples():\n",
    "        if row.layer not in valid_nodes.keys():\n",
    "            valid_nodes[row.layer] = [row.node_num_by_layer]\n",
    "        else:\n",
    "            valid_nodes[row.layer].append(row.node_num_by_layer)\n",
    "\n",
    "\n",
    "    threshed_edges_df = pd.DataFrame(columns = edges_df.columns)\n",
    "    \n",
    "    layers_edges = []\n",
    "    for layer in valid_nodes:\n",
    "        layer_edges = edges_df.loc[(edges_df['out_channel'].isin(valid_nodes[layer])) & (edges_df['layer'] == layer)]\n",
    "        if layer != 0:\n",
    "            layer_edges =  layer_edges.loc[layer_edges['in_channel'].isin(valid_nodes[layer-1])]\n",
    "\n",
    "        nodes_edges = []\n",
    "        for node_out in layer_edges['out_channel'].unique():\n",
    "            node_out_edges = layer_edges.loc[layer_edges['out_channel']== node_out]\n",
    "            node_out_edges = node_out_edges.sort_values(rank_type+'_rank',ascending=ascending)\n",
    "            total_imp = node_out_edges[rank_type+'_rank'].sum()\n",
    "            running_total = 0\n",
    "            for i in range(len(node_out_edges)):\n",
    "                running_total+=node_out_edges.iloc[i][rank_type+'_rank']\n",
    "                if running_total/total_imp >= threshold_edge:\n",
    "                    break\n",
    "            node_out_edges = node_out_edges.iloc[0:i+1]\n",
    "            nodes_edges.append(node_out_edges)\n",
    "        for node_in in layer_edges['in_channel'].unique():\n",
    "            node_in_edges = layer_edges.loc[layer_edges['in_channel']== node_in]\n",
    "            node_in_edges = node_in_edges.sort_values(rank_type+'_rank',ascending=ascending)\n",
    "            total_imp = node_in_edges[rank_type+'_rank'].sum()\n",
    "            running_total = 0\n",
    "            for i in range(len(node_in_edges)):\n",
    "                running_total+=node_in_edges.iloc[i][rank_type+'_rank']\n",
    "                if running_total/total_imp >= threshold_edge:\n",
    "                    break\n",
    "            node_in_edges = node_in_edges.iloc[0:i+1]\n",
    "            nodes_edges.append(node_in_edges)\n",
    "            \n",
    "        layer_edges= pd.concat(nodes_edges).drop_duplicates()                               \n",
    "        layers_edges.append(layer_edges)\n",
    "\n",
    "    found_df = pd.concat(layers_edges).drop_duplicates()\n",
    "    threshed_edges_df = pd.concat([threshed_edges_df, found_df])     \n",
    "    \n",
    "    return threshed_nodes_df,threshed_edges_df\n",
    "\n",
    "\n",
    "def get_accum_thresholded_ranksdf(threshold,rank_type,df, ascending=False):          #just get those edges that pass the threshold criteria for the target category\n",
    "    layers = df['layer'].unique()\n",
    "    layers.sort()\n",
    "    threshold_df = pd.DataFrame(columns = df.columns)\n",
    "    \n",
    "    layers_dfs = []   \n",
    "    for layer in layers:\n",
    "        layer_df = df.loc[n_df['layer'] == layer]\n",
    "        layer_df = layer_df.sort_values(rank_type+'_rank',ascending=ascending)\n",
    "        \n",
    "        total_imp = layer_df[rank_type+'_rank'].sum()\n",
    "\n",
    "        running_total = 0\n",
    "        for i in range(len(layer_df)):\n",
    "            running_total+=layer_df.iloc[i][rank_type+'_rank']\n",
    "            if running_total/total_imp >= threshold:\n",
    "                break\n",
    "        layer_df = layer_df.iloc[0:i+1]\n",
    "\n",
    "        layers_dfs.append(layer_df)\n",
    "    \n",
    "    found_df = pd.concat(layers_dfs)\n",
    "    threshold_df = pd.concat([threshold_df, found_df])\n",
    "    return threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_n_df = get_accum_thresholded_ranksdf(.5,rank_type,n_df, ascending=False)\n",
    "len(thresh_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshed_n_df,threshed_e_df = hierarchical_accum_threshold(.5,.2,rank_type,e_df,n_df,ascending=False)\n",
    "len(threshed_e_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(threshed_e_df)\n",
    "threshed_e_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = e_df\n",
    "nodes_df = n_df\n",
    "rank_type='actxgrad'\n",
    "threshold_node = .5\n",
    "threshold_edge = .9\n",
    "ascending=False\n",
    "\n",
    "threshed_nodes_df = get_accum_thresholded_ranksdf(threshold_node,rank_type,nodes_df, ascending=ascending)\n",
    "\n",
    "\n",
    "valid_nodes = {}\n",
    "for row in threshed_nodes_df.itertuples():\n",
    "    if row.layer not in valid_nodes.keys():\n",
    "        valid_nodes[row.layer] = [row.node_num_by_layer]\n",
    "    else:\n",
    "        valid_nodes[row.layer].append(row.node_num_by_layer)\n",
    "\n",
    "\n",
    "threshed_edges_df = pd.DataFrame(columns = edges_df.columns)\n",
    "\n",
    "layers_edges = []\n",
    "for layer in valid_nodes:\n",
    "    layer_edges = edges_df.loc[(edges_df['out_channel'].isin(valid_nodes[layer])) & (edges_df['layer'] == layer)]\n",
    "    if layer != 0:\n",
    "        layer_edges =  layer_edges.loc[layer_edges['in_channel'].isin(valid_nodes[layer-1])]\n",
    "    print(valid_nodes[layer])\n",
    "    print(len(layer_edges))\n",
    "    print(layer_edges)\n",
    "\n",
    "layer = 2\n",
    "layer_edges = edges_df.loc[(edges_df['out_channel'].isin(valid_nodes[layer])) & (edges_df['layer'] == layer)]\n",
    "if layer != 0:\n",
    "    layer_edges =  layer_edges.loc[layer_edges['in_channel'].isin(valid_nodes[layer-1])]\n",
    "\n",
    "layer_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  = layer_edges.out_channel.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in out:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruning_viz",
   "language": "python",
   "name": "pruning_viz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
